{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Introduction:**\n",
    "\n",
    "Using simple random search. In our case, the cost function is just the reach error -- calculated by the reach error between the previous lamdba values and the current one. \n",
    "\n",
    "Error is defined as reach error: $ error = ||t-y||^2 $ and the perturbation term $ p_{2k+1} $ can be thought of a normal distribution.\n",
    "\n",
    "$$ FR+ = FR - \\frac{\\nu}{N\\delta} \\sum_{n = 1}^N ( error(FR + \\delta p) - error(FR) ) \\cdot  p, p \\sim \\mathcal{N}(0,\\sigma^2) $$\n",
    "\n",
    "Note: p is a perturbation taken from a distribution with mean = 0\n",
    "\n",
    "References:\n",
    "\n",
    "[1] G. Cauwenberghs, “A Fast Stochastic Error-Descent Algorithm for Supervised Learning and Optimization,” in Advances in Neural Information Processing Systems 5, S. J. Hanson, J. D. Cowan, and C. L. Giles, Eds. Morgan-Kaufmann, 1993, pp. 244–251.\n",
    "\n",
    "[2] R. Héliot, K. Ganguly, J. Jimenez, and J. M. Carmena, “Learning in Closed-Loop Brain–Machine Interfaces: Modeling and Experimental Validation,” IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics), vol. 40, no. 5, pp. 1387–1397, Oct. 2010, doi: 10.1109/TSMCB.2009.2036931.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import linalg\n",
    "import numpy.matlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "\n",
    "seaborn.set()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Brain Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Brain Model \n",
    "###################\n",
    "# Function that calculates firing rate from b, W, t\n",
    "# B(t) = b + [Wx Wy][tx ty]' = firing rate\n",
    "# This is Equation (2.a, 2.b) in Heliot et al, 2010\n",
    "\n",
    "## INPUT\n",
    "# N = number of neurons\n",
    "# lambda_vect = [b, W_x, W_y] for each neuron; N x 3\n",
    "# targ_vect = 2 x 1\n",
    "## OUTPUT\n",
    "# newFR = N x 1\n",
    "def brainFiringRate(lambda_vect, targ_vect):\n",
    "    targ_vect_mult = np.insert(targ_vect.copy(), 0, 1)\n",
    "    newFR = np.zeros( (np.size(lambda_vect, 0), 1) )\n",
    "    newFR[:, 0] = np.matmul(lambda_vect, targ_vect_mult)\n",
    "    return newFR\n",
    "\n",
    "###################\n",
    "# Function that alters the lambda paramters (b, W) for the brain\n",
    "# B(t) = b + [Wx Wy][tx ty]' = firing rate\n",
    "# This is Equation (6) in Heliot et al, 2010\n",
    "\n",
    "## INPUT\n",
    "# N = number of neurons\n",
    "# lambda_vect = [b, W_x, W_y] for each neuron; N x 3\n",
    "# delta_perturb = N x 1\n",
    "# targ_vect = 2 x 1\n",
    "## MIDDLE\n",
    "# targ_vect_mult = 3 x 1 [1 t_x t_y]'\n",
    "# targ_matx = N x 3\n",
    "# delta_matx = N x 3\n",
    "# next_term = delta_matx*delta_matx (element-wise mult) = N x 3\n",
    "## OUTPUT\n",
    "# lambda_vect_new = N x 3\n",
    "\n",
    "def calcNextLambda(lambda_vect, gamma, delta_perturb, targ_vect):\n",
    "    # This is the vector to multiply the lambda update term with = [1 t_x t_y]'\n",
    "    num_neurons = np.size(lambda_vect.copy(), 0)\n",
    "    targ_vect_mult = np.insert(targ_vect.copy(), 0, 1) # 3 x 1  \n",
    "    targ_matx = (np.matlib.repmat(targ_vect_mult, num_neurons, 1)) # N x 3\n",
    "\n",
    "    # next gradient term: \\gamma*delta_perturb\n",
    "    delta_matx = np.matlib.repmat(delta_perturb, 1, 3) # N x 3\n",
    "    next_term = (delta_matx*targ_matx) # 3 x N\n",
    "\n",
    "    lambda_vect_new = lambda_vect.copy() - (gamma*next_term)\n",
    "    return lambda_vect_new\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################\n",
    "# Decoder Model \n",
    "# Affine Function that calculates target postion from firing rate\n",
    "# Y = D(f) = a + Kf --> Weiner Filter\n",
    "# This is Equation (1) in Heliot et al, 2010\n",
    "\n",
    "## INPUT\n",
    "# N = number of neurons, d = dimension of target\n",
    "# decoder params = current a vector and K matrix (a = d x 1, K = d x N)\n",
    "# fr_curr = current firing rate as a vector\n",
    "# targ_vect = target position (T_x, Y_y)\n",
    "## OUTPUT\n",
    "# Cursor position = Y_x, Y_y\n",
    "def decoder_findY(decoder_params, brain_params):\n",
    "    # check firing rate \n",
    "    # Start with affine decoder\n",
    "    (a_vect_in, k_matx_in) = decoder_params\n",
    "    (fr_curr, targ) = brain_params\n",
    "    a_vect = a_vect_in.copy()\n",
    "    k_matx = k_matx_in.copy()\n",
    "    cursor_pos = np.zeros( (NUM_DIM, 1))\n",
    "    cursor_pos = a_vect.reshape(NUM_DIM, 1) +  (np.matmul(k_matx, fr_curr))\n",
    "#     print(\"in decoder_findY\")\n",
    "#     print(cursor_pos)\n",
    "#     print(np.shape(cursor_pos))\n",
    "    return (cursor_pos)\n",
    "\n",
    "# Function uses stochastic gradient descent to adjust decoder parameters\n",
    "## INPUT\n",
    "# decoder params = current a vector and K matrix (a = d x 1, K = d x N)\n",
    "# fr_curr = current firing rate as a vector\n",
    "## OUTPUT\n",
    "# next decoder parameters = a_next, k_next\n",
    "def calcNextDecoder(decoder_params, brain_vars):\n",
    "    (a_vect, a_rate, a_dist, k_matx, k_rate, k_dist) = decoder_params\n",
    "    cost_func_args = ( (a_vect, k_matx), brain_vars)\n",
    "    # a vector\n",
    "    if (ADAPT_DEC == True):\n",
    "        a_grad = findErrorGrad(a_vect.copy(), A_VAR, a_dist,error_costFunc, cost_func_args)\n",
    "        k_grad = findErrorGrad(k_matx.copy(), K_VAR, k_dist, error_costFunc, cost_func_args)\n",
    "        a_next = a_vect.copy().reshape(np.shape(a_grad)) - a_rate*a_grad\n",
    "        k_next = k_matx.copy() - k_rate*k_grad\n",
    "    else:\n",
    "        a_next = a_vect\n",
    "        k_next = k_matx\n",
    "\n",
    "    return (a_next, k_next)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reach Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################\n",
    "# Reach error\n",
    "# This is Equation (3) in Heliot et al, 2010\n",
    "\n",
    "## INPUT\n",
    "# y_x, y_y = predicted cursor position\n",
    "# t_x, t_y = target position\n",
    "## OUTPUT\n",
    "# norm squared of (target position - cursor position)\n",
    "# where reach error is the target position - cursor position\n",
    "def calcReachError(y_vect, t_vect):\n",
    "    norm_vect = np.array(y_vect) - np.array(t_vect)\n",
    "    return (np.linalg.norm(norm_vect, 2)**2)\n",
    "\n",
    "## INPUT\n",
    "# cost_func_params = decoder params (a vect, k matx) and current firing rate\n",
    "## OUTPUT\n",
    "# reach error = scalar; norm squared of (target position - cursor position)\n",
    "# where reach error is the target position - cursor position\n",
    "def error_costFunc(cost_func_params):\n",
    "    (decoder_params, brain_vars) = cost_func_params\n",
    "    (fr_curr, targ_vect) = brain_vars\n",
    "    y_vect = decoder_findY(decoder_params, brain_vars)\n",
    "    t_vect = targ_vect\n",
    "    return calcReachError(y_vect, t_vect)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stochastic Error Descent: Update Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "\n",
    "\n",
    "## Stochastic Error Descent\n",
    "# This is Equation (4) and Equation (5) in Heliot, 2010\n",
    "# Derivation is found in Cauwenberghs, 1993 \n",
    "\n",
    "# This function is one iteration of the error descent calcuation\n",
    "## INPUT\n",
    "# input_vect = vector to stochastically perturb\n",
    "# input_var = FR_VAR, A_VAR OR K_VAR \n",
    "# param_dist = distribution from which perturbations to the input are selected\n",
    "# cost_func = cost function (always reach error)\n",
    "# cost_func_args = arguments to the cost function (depends on error cost function)\n",
    "## OUTPUT\n",
    "# errorGrad = gradient for updating parameter (input vect)\n",
    "def findErrorGrad(input_vect, input_var, param_dist, cost_func, cost_func_args):\n",
    "    # Un-nest everything\n",
    "    (sigma, delta, num_dist) = param_dist\n",
    "    (decoder_params, (curr_fr, targ_vect) ) = cost_func_args\n",
    "    (a_vect, k_matx) = decoder_params\n",
    "    \n",
    "    # Get size of input vector\n",
    "    num_neurons = np.size(k_matx, 1)\n",
    "    num_input_row = np.size(input_vect, 0) \n",
    "    num_input_column = 1\n",
    "    if (input_vect.ndim > 1): \n",
    "        num_input_column = np.size(input_vect, 1)\n",
    "    \n",
    "    # What to perturb and input firing rate for error cost function\n",
    "    input_vect = input_vect.copy().reshape(num_input_row, num_input_column)\n",
    "    input_fr = curr_fr.copy().reshape(num_neurons, 1)\n",
    "       \n",
    "    error_sum = np.zeros((num_input_row, 1)) \n",
    "    error_grad = np.zeros((num_input_row, 1))\n",
    "    perturb_rand = np.zeros((num_input_row, num_input_column, num_dist))\n",
    "    \n",
    "    \n",
    "    for iC in range(num_input_column):\n",
    "        for iN in range(num_input_row):\n",
    "            random.seed(time.time())\n",
    "            perturb_rand[iN, iC, :] = np.random.uniform(0, sigma, num_dist) \n",
    "            # perturb_rand = N_input x N_dist\n",
    "            # for each iteration, np.random.normal returns a N_dist x 1 array\n",
    "    \n",
    "    for iD in range(num_dist):\n",
    "        # perturb_vect = stochastic pertrbation (amount of stochastic descent perturbation)\n",
    "        perturb_vect = np.squeeze(perturb_rand[:, :, [iD]])\n",
    "        perturb_vect = perturb_vect.copy().reshape(num_input_row, num_input_column)\n",
    "        \n",
    "        # find the delta error caused by the perturbation (direction to descend gradient in) \n",
    "        input_perturb = np.add(input_vect, delta*perturb_vect) \n",
    "        \n",
    "        # Case 1: firing rate\n",
    "        # error = reachError(a + K*fr')\n",
    "        if (input_var == FR_VAR):        \n",
    "            # Calculate error \n",
    "            perturb_cost_args = (decoder_params, (input_perturb, targ_vect) ) \n",
    "            \n",
    "        # case 2: a\n",
    "        # error = reachError(a' + K*fr)\n",
    "        elif (input_var == A_VAR):\n",
    "            decoder_params_perturb = (input_perturb, k_matx)\n",
    "            perturb_cost_args = (decoder_params_perturb, (input_fr, targ_vect))\n",
    "\n",
    "        # case 3: k\n",
    "        # error = reachError(a + K'*fr)\n",
    "        elif (input_var == K_VAR):\n",
    "            decoder_params_perturb = (a_vect, input_perturb)\n",
    "            perturb_cost_args = (decoder_params_perturb, (input_fr, targ_vect))   \n",
    "        \n",
    "        # default: do nothing\n",
    "        else:\n",
    "            perturb_cost_args = cost_func_args\n",
    "        \n",
    "        error_perturb = cost_func(perturb_cost_args)   \n",
    "        error_input = cost_func(cost_func_args)\n",
    "        error_sum = np.add(error_sum, (error_perturb - error_input)*perturb_vect)\n",
    "\n",
    "    error_grad = np.array(error_sum/(num_dist*delta))\n",
    "    return error_grad\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stochastic Gradient Descent: Update Step and Recalculate Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function goes through and updates brain paramters over the num_iter times\n",
    "def brain_adapt_sgd(brain_params, decoder_params, targ_vect, num_iter):\n",
    "    (fr_init, fr_dist, lambda_init, lambda_rate) = brain_params\n",
    "    (fr_init, targ_vect)= brain_vars\n",
    "    (fr_sigma, fr_delta, fr_dist_size) = fr_dist\n",
    "    (a_init, a_rate, a_dist, k_init, k_rate, k_dist) = decoder_params\n",
    "    decoder_init = (a_init, k_init)\n",
    "    grad_args_init = (decoder_init, brain_vars)\n",
    "    \n",
    "\n",
    "    num_neurons = np.size(fr_init, 0)\n",
    "    runs_num = 1\n",
    "\n",
    "    # for sigma in sigma_list:\n",
    "    for iR in range(runs_num):\n",
    "        # Set the u vectors\n",
    "        fr_vect = np.zeros( (num_neurons, 1, num_iter) )\n",
    "        fr_vect[:, :, 0] = fr_init #fr init = num_neurons x 1\n",
    "#         fr_vect[:, 0] = fr_init\n",
    "        fr_final = np.zeros((num_neurons, 1, runs_num))\n",
    "        re_final = np.zeros(runs_num)\n",
    "        lambda_final = np.zeros((num_neurons, np.size(lambda_init, 1), runs_num))\n",
    "\n",
    "        print(\"starting fr vect = \" + str( fr_vect[:, :, 0] ))\n",
    "        # lambda init = N x 3\n",
    "        # lambda_vect = N x 3 X ITER\n",
    "        lambda_vect = np.zeros( (num_neurons, np.size(lambda_init, 1), num_iter))\n",
    "        lambda_vect[:,:,0] = lambda_init \n",
    "\n",
    "        # set the cost vector\n",
    "        err_vect = np.zeros(num_iter)\n",
    "        err_vect[0] = error_costFunc(grad_args_init)\n",
    "        print('initial error = ' + str(err_vect[0]))\n",
    "\n",
    "        # calculate the initial delta e\n",
    "        grad_new = np.zeros(num_iter)\n",
    "        grad_new = findErrorGrad(fr_init, FR_VAR, fr_dist, error_costFunc, grad_args_init)\n",
    "\n",
    "        for iT in range(num_iter-1):\n",
    "            ## calculate the new u \n",
    "            # (1) lambda+ = lambda - learn_rate*grad_error; B(lambda) = f\n",
    "            lambda_next = calcNextLambda(lambda_vect[:, :, iT], lambda_rate, grad_new, targ_vect)\n",
    "            lambda_vect[:,:, iT + 1] = lambda_next\n",
    "            \n",
    "            # (2) fr+ = B(lambda+)\n",
    "            fr_next = brainFiringRate(lambda_next, targ_vect)\n",
    "            fr_vect[:, :, iT+1] = fr_next\n",
    "\n",
    "            # Update parameters for calculating error and calculate the new cost\n",
    "            # (3) Calculate the new reach error \n",
    "            brain_vars_next = fr_next, targ_vect\n",
    "            grad_args_next = (decoder_init, brain_vars_next)\n",
    "            err_next = np.array(error_costFunc(grad_args_next))\n",
    "            err_vect[iT+1] = err_next\n",
    "\n",
    "            # (4) calculate the next error descent term to update FR again\n",
    "            grad_new = findErrorGrad(fr_next, FR_VAR, fr_dist, error_costFunc, grad_args_next)\n",
    "        \n",
    "        fr_final[:, :, iR] = fr_next\n",
    "        re_final[iR] = err_next\n",
    "        lambda_final[:, :, iR] = lambda_next        \n",
    "\n",
    "    return (re_final, fr_final, lambda_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function goes through and updates brain paramters over the num_iter times\n",
    "def calcNextBrain(brain_params, decoder_params, targ_vect, num_iter):\n",
    "    # Unpack arguments that are being passed in\n",
    "    (fr_init, fr_dist, lambda_init, lambda_rate) = brain_params\n",
    "#     (fr_sigma, fr_delta, fr_dist_size) = fr_dist\n",
    "    (a_vect, a_rate, a_dist, k_matx, k_rate, k_dist) = decoder_params\n",
    "    decoder_vals = (a_vect, k_matx)\n",
    "#     grad_args_init = (decoder_vals, fr_init)\n",
    "    \n",
    "    num_neurons = np.size(fr_init, 0)\n",
    "    fr_vect = np.zeros( (num_neurons, 1, num_iter) )\n",
    "    fr_final = np.zeros( np.size(fr_init) )\n",
    "    fr_vect[:, :, 0] = fr_init #fr init = num_neurons x 1\n",
    "    \n",
    "    # lambda init = N x 3\n",
    "    # lambda_vect = N x 3 X ITER\n",
    "    lambda_vect = np.zeros( (num_neurons, np.size(lambda_init, 1), num_iter))\n",
    "    lambda_vect[:, :, 0] = lambda_init \n",
    "    lambda_final = np.zeros(np.size(lambda_init))\n",
    "    \n",
    "    for iT in range(num_iter-1):\n",
    "        # (1) calculate the perturbation\n",
    "        brain_vars = (fr_vect[:, :, iT], targ_vect)\n",
    "        grad_args = (decoder_vals, brain_vars)\n",
    "        grad_new = findErrorGrad(fr_vect[:, :, iT], FR_VAR, fr_dist, error_costFunc, grad_args)\n",
    "       \n",
    "        # (2) lambda+ = lambda - learn_rate*grad_error; B(lambda) = f\n",
    "        lambda_next = calcNextLambda(lambda_vect[:, :, iT], lambda_rate, grad_new, targ_vect)\n",
    "        lambda_vect[:,:, iT + 1] = lambda_next\n",
    "       \n",
    "        # (2) fr+ = B(lambda+)\n",
    "        fr_next = brainFiringRate(lambda_next, targ_vect)\n",
    "        fr_vect[:, :, iT + 1] = fr_next\n",
    "       \n",
    "    lambda_final = lambda_next\n",
    "    fr_final = fr_next\n",
    "\n",
    "    return  (fr_final, lambda_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate New Trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findNextTarget(curr_cursor, prev_targ):\n",
    "    ## random\n",
    "    x_pos = int(np.random.random_sample()*10)\n",
    "    y_pos = int(np.random.random_sample()*10)\n",
    "\n",
    "#     x_pos = prev_targ[0][0]\n",
    "#     y_pos = prev_targ[1][0]\n",
    "\n",
    "    return np.array( [x_pos, y_pos] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set initial conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INITIAL CONDITIONS\n",
      "NUM NEURONS = 10\n",
      "(2, 1)\n",
      "initial target = [[1]\n",
      " [1]]\n",
      "baseline shape = (10,)\n",
      "b =[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "K MATX = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "A = [-0. -0.]\n",
      "lambda init = \n",
      "[[ 0.          0.53020654 -0.2322202 ]\n",
      " [ 0.          0.36705474 -0.15737009]\n",
      " [ 0.         -0.14629582  0.24261404]\n",
      " [ 0.         -0.08877213  0.18799136]\n",
      " [ 0.          0.20486852  0.02360278]\n",
      " [ 0.         -0.07854344  0.25002723]\n",
      " [ 0.         -0.03748972  0.14111247]\n",
      " [ 0.         -0.0597867   0.25435404]\n",
      " [ 0.         -0.07409235  0.18348285]\n",
      " [ 0.          0.23653843  0.10488391]]\n"
     ]
    }
   ],
   "source": [
    "########\n",
    "## Set some initial conditions here\n",
    "\n",
    "# Helper info:\n",
    "# fr_init = N x 1\n",
    "# lambda init = N x 3\n",
    "# baseline = 1 x N\n",
    "# target_vector = 2 x 1\n",
    "# K_matx = 2 x N\n",
    "# A = 2 x 1\n",
    "\n",
    "NUM_NEURONS = 10\n",
    "NUM_DIM = 2\n",
    "NUM_LAMBDA = NUM_DIM + 1\n",
    "\n",
    "print(\"INITIAL CONDITIONS\")\n",
    "print(\"NUM NEURONS = \" + str(NUM_NEURONS))\n",
    "# target position\n",
    "TARGET_VECTOR = np.array([[1] , [1]])\n",
    "print(np.shape(TARGET_VECTOR))\n",
    "print(\"initial target = \" + str(TARGET_VECTOR))\n",
    "\n",
    "# firing rate \n",
    "fr_init = np.zeros( (NUM_NEURONS, 1) ) \n",
    "\n",
    "# BASELINE (b)\n",
    "BASELINE = (0*np.random.random_sample(NUM_NEURONS))  # random float [0, 10)\n",
    "print(\"baseline shape = \" + str(np.shape(BASELINE)))\n",
    "print(\"b =\" + str(BASELINE))\n",
    "\n",
    "# decoder initial paramters\n",
    "# IDEAL: y = a + Kf = a + K(b + Wt) = a + Kb + KWt\n",
    "# in order for y = t, want: a + Kb --> 0 and KW --> Identity matx\n",
    "K_MATX = np.random.random_sample( (NUM_DIM, NUM_NEURONS) ) # random float [0, 1)\n",
    "A_VECT = (-np.matmul(K_MATX, BASELINE))*0\n",
    "print(\"K MATX = \" + str(K_MATX))\n",
    "print(\"A = \" + str(A_VECT))\n",
    "\n",
    "# lambda\n",
    "lambda_init = np.zeros((NUM_NEURONS, NUM_LAMBDA))\n",
    "W_init = np.linalg.pinv(K_MATX) \n",
    "W_rand = 0*np.random.random_sample( (NUM_NEURONS, NUM_DIM) )\n",
    "W_init = W_init + W_rand\n",
    "lambda_init[:, 0] = np.array([BASELINE])        # lambda[0] = baseline\n",
    "lambda_init[:, 1:3] = W_init\n",
    "print(\"lambda init = \")\n",
    "print(lambda_init)\n",
    "\n",
    "# lambda_init[:, 1] = np.random.random_sample(np.shape(lambda_init[:, 0]))    # lambda[2] = w_y\n",
    "# lambda_init[:, 2] = np.random.random_sample(np.shape(lambda_init[:, 0]))*10 \n",
    "# # lambda_init[:, 1] = np.array([0.4, 0.6, 1, 2])  # lambda[1] = w_x\n",
    "# # lambda_init[:, 2] = np.array([3, 5, 4, 2])      # lambda[2] = w_\n",
    "\n",
    "# SGD initial parameters\n",
    "# Mapping for variables\n",
    "FR_VAR = 1\n",
    "A_VAR = 2\n",
    "K_VAR = 3\n",
    "\n",
    "# Brain\n",
    "FR_SIGMA = 1\n",
    "FR_DELTA = 1\n",
    "FR_DIST_SIZE = 100\n",
    "\n",
    "# Decoder\n",
    "# A_RATE = 1e-4\n",
    "A_SIGMA = 1\n",
    "A_DELTA = 1\n",
    "A_DIST_SIZE = 100\n",
    "# --\n",
    "# K_RATE = 5e-4\n",
    "K_SIGMA = 1\n",
    "K_DELTA = 1\n",
    "K_DIST_SIZE = 100\n",
    "\n",
    "# display parameters\n",
    "fig_x = 10\n",
    "fig_y = 5\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adaptive Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "+++++++++++++++++++++++++++++++++++\n",
      "Session #0\n",
      "target at trial 0 = [[1.]\n",
      " [1.]]\n",
      "K MATX INIT= [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "A VECT INIT = [-0. -0.]\n",
      "lambda\n",
      "[[ 0.          0.53020654 -0.2322202 ]\n",
      " [ 0.          0.36705474 -0.15737009]\n",
      " [ 0.         -0.14629582  0.24261404]\n",
      " [ 0.         -0.08877213  0.18799136]\n",
      " [ 0.          0.20486852  0.02360278]\n",
      " [ 0.         -0.07854344  0.25002723]\n",
      " [ 0.         -0.03748972  0.14111247]\n",
      " [ 0.         -0.0597867   0.25435404]\n",
      " [ 0.         -0.07409235  0.18348285]\n",
      " [ 0.          0.23653843  0.10488391]]\n",
      "a\n",
      "[-0. -0.]\n",
      "K\n",
      "[[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #0 | lambda learn rate = 0.0001\n",
      "Target = [[1.]\n",
      " [1.]]\n",
      "lambda end of trial = [[ 0.          0.52953639 -0.23289034]\n",
      " [ 0.          0.36633877 -0.15808606]\n",
      " [ 0.         -0.1469537   0.24195616]\n",
      " [ 0.         -0.08938073  0.18738276]\n",
      " [ 0.          0.20414462  0.02287887]\n",
      " [ 0.         -0.07920297  0.2493677 ]\n",
      " [ 0.         -0.03818921  0.14041299]\n",
      " [ 0.         -0.06048517  0.25365556]\n",
      " [ 0.         -0.07469184  0.18288336]\n",
      " [ 0.          0.23584322  0.1041887 ]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #1 | lambda learn rate = 0.0001\n",
      "Target = [[4.]\n",
      " [8.]]\n",
      "lambda end of trial = [[ 0.          0.52722619 -0.23751074]\n",
      " [ 0.          0.36409528 -0.16257304]\n",
      " [ 0.         -0.14936834  0.23712688]\n",
      " [ 0.         -0.09171222  0.18271977]\n",
      " [ 0.          0.2019793   0.01854824]\n",
      " [ 0.         -0.08184941  0.24407483]\n",
      " [ 0.         -0.04061125  0.1355689 ]\n",
      " [ 0.         -0.06277015  0.24908562]\n",
      " [ 0.         -0.07697149  0.17832407]\n",
      " [ 0.          0.23325225  0.09900676]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #2 | lambda learn rate = 0.0001\n",
      "Target = [[5.]\n",
      " [1.]]\n",
      "lambda end of trial = [[ 0.          0.5240728  -0.23814142]\n",
      " [ 0.          0.36093829 -0.16320444]\n",
      " [ 0.         -0.15253925  0.2364927 ]\n",
      " [ 0.         -0.09503984  0.18205424]\n",
      " [ 0.          0.19875341  0.01790306]\n",
      " [ 0.         -0.08497555  0.2434496 ]\n",
      " [ 0.         -0.04374507  0.13494214]\n",
      " [ 0.         -0.06614591  0.24841046]\n",
      " [ 0.         -0.08010439  0.17769749]\n",
      " [ 0.          0.22974254  0.09830481]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #3 | lambda learn rate = 0.0001\n",
      "Target = [[9.]\n",
      " [7.]]\n",
      "lambda end of trial = [[ 0.          0.51979481 -0.24146875]\n",
      " [ 0.          0.356406   -0.16672955]\n",
      " [ 0.         -0.15624023  0.23361416]\n",
      " [ 0.         -0.09946548  0.17861208]\n",
      " [ 0.          0.19467178  0.01472846]\n",
      " [ 0.         -0.08954965  0.23989197]\n",
      " [ 0.         -0.04764613  0.13190799]\n",
      " [ 0.         -0.07066626  0.24489463]\n",
      " [ 0.         -0.08434856  0.17439647]\n",
      " [ 0.          0.2251614   0.09474171]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #4 | lambda learn rate = 0.0001\n",
      "Target = [[3.]\n",
      " [6.]]\n",
      "lambda end of trial = [[ 0.          0.51853193 -0.2439945 ]\n",
      " [ 0.          0.35516437 -0.16921281]\n",
      " [ 0.         -0.15743786  0.2312189 ]\n",
      " [ 0.         -0.10077108  0.17600089]\n",
      " [ 0.          0.19334282  0.01207055]\n",
      " [ 0.         -0.09080175  0.23738778]\n",
      " [ 0.         -0.04885089  0.12949847]\n",
      " [ 0.         -0.07191864  0.24238988]\n",
      " [ 0.         -0.08564419  0.17180522]\n",
      " [ 0.          0.22394791  0.09231473]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #5 | lambda learn rate = 0.0001\n",
      "Target = [[6.]\n",
      " [6.]]\n",
      "lambda end of trial = [[ 0.          0.51685784 -0.24566859]\n",
      " [ 0.          0.35338564 -0.17099154]\n",
      " [ 0.         -0.15912862  0.22952814]\n",
      " [ 0.         -0.10269154  0.17408043]\n",
      " [ 0.          0.19141875  0.01014648]\n",
      " [ 0.         -0.09267034  0.23551919]\n",
      " [ 0.         -0.0506901   0.12765925]\n",
      " [ 0.         -0.07374312  0.2405654 ]\n",
      " [ 0.         -0.08720634  0.17024306]\n",
      " [ 0.          0.22190418  0.090271  ]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #6 | lambda learn rate = 0.0001\n",
      "Target = [[7.]\n",
      " [3.]]\n",
      "lambda end of trial = [[ 0.          0.51426602 -0.24677937]\n",
      " [ 0.          0.35097563 -0.1720244 ]\n",
      " [ 0.         -0.16130951  0.22859347]\n",
      " [ 0.         -0.10503268  0.17307708]\n",
      " [ 0.          0.18884141  0.0090419 ]\n",
      " [ 0.         -0.09551841  0.23429858]\n",
      " [ 0.         -0.05314692  0.12660633]\n",
      " [ 0.         -0.07644018  0.23940951]\n",
      " [ 0.         -0.08963486  0.16920227]\n",
      " [ 0.          0.21926962  0.0891419 ]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #7 | lambda learn rate = 0.0001\n",
      "Target = [[2.]\n",
      " [0.]]\n",
      "lambda end of trial = [[ 0.          0.51311081 -0.24677937]\n",
      " [ 0.          0.3497092  -0.1720244 ]\n",
      " [ 0.         -0.16255593  0.22859347]\n",
      " [ 0.         -0.10639235  0.17307708]\n",
      " [ 0.          0.18759001  0.0090419 ]\n",
      " [ 0.         -0.09680032  0.23429858]\n",
      " [ 0.         -0.05433859  0.12660633]\n",
      " [ 0.         -0.07768783  0.23940951]\n",
      " [ 0.         -0.09088308  0.16920227]\n",
      " [ 0.          0.21805218  0.0891419 ]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #8 | lambda learn rate = 0.0001\n",
      "Target = [[9.]\n",
      " [0.]]\n",
      "lambda end of trial = [[ 0.          0.51052319 -0.24677937]\n",
      " [ 0.          0.34679347 -0.1720244 ]\n",
      " [ 0.         -0.16525903  0.22859347]\n",
      " [ 0.         -0.108868    0.17307708]\n",
      " [ 0.          0.18496584  0.0090419 ]\n",
      " [ 0.         -0.09948701  0.23429858]\n",
      " [ 0.         -0.05690045  0.12660633]\n",
      " [ 0.         -0.08036954  0.23940951]\n",
      " [ 0.         -0.09332109  0.16920227]\n",
      " [ 0.          0.2152488   0.0891419 ]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #9 | lambda learn rate = 0.0001\n",
      "Target = [[2.]\n",
      " [6.]]\n",
      "lambda end of trial = [[ 0.          0.50976308 -0.2490597 ]\n",
      " [ 0.          0.34610944 -0.17407649]\n",
      " [ 0.         -0.16588679  0.22671019]\n",
      " [ 0.         -0.10949126  0.17120729]\n",
      " [ 0.          0.18424195  0.00687023]\n",
      " [ 0.         -0.10015835  0.23228459]\n",
      " [ 0.         -0.05756747  0.12460527]\n",
      " [ 0.         -0.08105095  0.2373653 ]\n",
      " [ 0.         -0.09394983  0.16731605]\n",
      " [ 0.          0.21452923  0.08698318]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #10 | lambda learn rate = 0.0001\n",
      "Target = [[4.]\n",
      " [5.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda end of trial = [[ 0.          0.50871263 -0.25037277]\n",
      " [ 0.          0.34501817 -0.17544057]\n",
      " [ 0.         -0.16695541  0.22537441]\n",
      " [ 0.         -0.11048639  0.16996339]\n",
      " [ 0.          0.18327925  0.00566685]\n",
      " [ 0.         -0.10133614  0.23081234]\n",
      " [ 0.         -0.05860249  0.1233115 ]\n",
      " [ 0.         -0.08218094  0.23595281]\n",
      " [ 0.         -0.0949612   0.16605183]\n",
      " [ 0.          0.21335648  0.08551725]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #11 | lambda learn rate = 0.0001\n",
      "Target = [[8.]\n",
      " [0.]]\n",
      "lambda end of trial = [[ 0.          0.50663859 -0.25037277]\n",
      " [ 0.          0.34323834 -0.17544057]\n",
      " [ 0.         -0.1689343   0.22537441]\n",
      " [ 0.         -0.11250649  0.16996339]\n",
      " [ 0.          0.18130622  0.00566685]\n",
      " [ 0.         -0.103306    0.23081234]\n",
      " [ 0.         -0.06047771  0.1233115 ]\n",
      " [ 0.         -0.08407309  0.23595281]\n",
      " [ 0.         -0.0969746   0.16605183]\n",
      " [ 0.          0.21131027  0.08551725]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #12 | lambda learn rate = 0.0001\n",
      "Target = [[4.]\n",
      " [2.]]\n",
      "lambda end of trial = [[ 0.          0.50530411 -0.25104001]\n",
      " [ 0.          0.34178898 -0.17616525]\n",
      " [ 0.         -0.17024467  0.22471923]\n",
      " [ 0.         -0.11367392  0.16937967]\n",
      " [ 0.          0.17991066  0.00496907]\n",
      " [ 0.         -0.10456636  0.23018216]\n",
      " [ 0.         -0.06181137  0.12264467]\n",
      " [ 0.         -0.08545976  0.23525947]\n",
      " [ 0.         -0.09831428  0.16538199]\n",
      " [ 0.          0.20992949  0.08482685]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #13 | lambda learn rate = 0.0001\n",
      "Target = [[9.]\n",
      " [0.]]\n",
      "lambda end of trial = [[ 0.          0.50447264 -0.25104001]\n",
      " [ 0.          0.34102867 -0.17616525]\n",
      " [ 0.         -0.17109272  0.22471923]\n",
      " [ 0.         -0.11441502  0.16937967]\n",
      " [ 0.          0.17911041  0.00496907]\n",
      " [ 0.         -0.10542272  0.23018216]\n",
      " [ 0.         -0.06256304  0.12264467]\n",
      " [ 0.         -0.08638031  0.23525947]\n",
      " [ 0.         -0.09917244  0.16538199]\n",
      " [ 0.          0.20894723  0.08482685]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #14 | lambda learn rate = 0.0001\n",
      "Target = [[0.]\n",
      " [7.]]\n",
      "lambda end of trial = [[ 0.          0.50447264 -0.25326072]\n",
      " [ 0.          0.34102867 -0.17824932]\n",
      " [ 0.         -0.17109272  0.22242138]\n",
      " [ 0.         -0.11441502  0.16732076]\n",
      " [ 0.          0.17911041  0.00281179]\n",
      " [ 0.         -0.10542272  0.22820035]\n",
      " [ 0.         -0.06256304  0.12065062]\n",
      " [ 0.         -0.08638031  0.23309995]\n",
      " [ 0.         -0.09917244  0.16325455]\n",
      " [ 0.          0.20894723  0.0822713 ]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #15 | lambda learn rate = 0.0001\n",
      "Target = [[4.]\n",
      " [2.]]\n",
      "lambda end of trial = [[ 0.          0.50309754 -0.25394828]\n",
      " [ 0.          0.33960059 -0.17896336]\n",
      " [ 0.         -0.17264081  0.22164734]\n",
      " [ 0.         -0.11586151  0.16659752]\n",
      " [ 0.          0.17773006  0.00212161]\n",
      " [ 0.         -0.10692516  0.22744913]\n",
      " [ 0.         -0.06389167  0.1199863 ]\n",
      " [ 0.         -0.08786319  0.23235851]\n",
      " [ 0.         -0.10056657  0.16255748]\n",
      " [ 0.          0.20742887  0.08151212]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #16 | lambda learn rate = 0.0001\n",
      "Target = [[3.]\n",
      " [2.]]\n",
      "lambda end of trial = [[ 0.          0.50210711 -0.25460856]\n",
      " [ 0.          0.33857159 -0.17964935]\n",
      " [ 0.         -0.17368437  0.22095163]\n",
      " [ 0.         -0.11694154  0.1658775 ]\n",
      " [ 0.          0.17681306  0.00151028]\n",
      " [ 0.         -0.10803591  0.22670863]\n",
      " [ 0.         -0.06495777  0.11927557]\n",
      " [ 0.         -0.08896949  0.23162097]\n",
      " [ 0.         -0.10163809  0.16184314]\n",
      " [ 0.          0.20632352  0.08077522]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #17 | lambda learn rate = 0.0001\n",
      "Target = [[2.]\n",
      " [4.]]\n",
      "lambda end of trial = [[ 0.00000000e+00  5.01484100e-01 -2.55854581e-01]\n",
      " [ 0.00000000e+00  3.37965815e-01 -1.80860910e-01]\n",
      " [ 0.00000000e+00 -1.74320535e-01  2.19679303e-01]\n",
      " [ 0.00000000e+00 -1.17542894e-01  1.64674786e-01]\n",
      " [ 0.00000000e+00  1.76182627e-01  2.49412786e-04]\n",
      " [ 0.00000000e+00 -1.08692099e-01  2.25396246e-01]\n",
      " [ 0.00000000e+00 -6.54916180e-02  1.18207880e-01]\n",
      " [ 0.00000000e+00 -8.95877781e-02  2.30384400e-01]\n",
      " [ 0.00000000e+00 -1.02241781e-01  1.60635752e-01]\n",
      " [ 0.00000000e+00  2.05662117e-01  7.94524132e-02]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #18 | lambda learn rate = 0.0001\n",
      "Target = [[5.]\n",
      " [6.]]\n",
      "lambda end of trial = [[ 0.          0.50187004 -0.25539145]\n",
      " [ 0.          0.33831196 -0.18044553]\n",
      " [ 0.         -0.17397442  0.22009464]\n",
      " [ 0.         -0.11714626  0.16515075]\n",
      " [ 0.          0.17654026  0.00067857]\n",
      " [ 0.         -0.10833883  0.22582016]\n",
      " [ 0.         -0.06516029  0.11860547]\n",
      " [ 0.         -0.08925239  0.23078687]\n",
      " [ 0.         -0.10186947  0.16108252]\n",
      " [ 0.          0.20597812  0.07983162]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #19 | lambda learn rate = 0.0001\n",
      "Target = [[9.]\n",
      " [8.]]\n",
      "lambda end of trial = [[ 0.          0.5056739  -0.25201024]\n",
      " [ 0.          0.34259245 -0.17664065]\n",
      " [ 0.         -0.1700309   0.22359999]\n",
      " [ 0.         -0.11284322  0.16897567]\n",
      " [ 0.          0.18064709  0.00432909]\n",
      " [ 0.         -0.10415673  0.22953759]\n",
      " [ 0.         -0.06069832  0.12257167]\n",
      " [ 0.         -0.08567991  0.23396241]\n",
      " [ 0.         -0.09794962  0.16456683]\n",
      " [ 0.          0.20973595  0.08317192]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #20 | lambda learn rate = 0.0001\n",
      "Target = [[1.]\n",
      " [2.]]\n",
      "lambda end of trial = [[ 0.          0.5051931  -0.25297185]\n",
      " [ 0.          0.34215491 -0.17751574]\n",
      " [ 0.         -0.17049796  0.22266587]\n",
      " [ 0.         -0.11334658  0.16796895]\n",
      " [ 0.          0.18011703  0.00326897]\n",
      " [ 0.         -0.10465479  0.22854146]\n",
      " [ 0.         -0.06116475  0.1216388 ]\n",
      " [ 0.         -0.08620503  0.23291217]\n",
      " [ 0.         -0.0984274   0.16361128]\n",
      " [ 0.          0.2092303   0.0821606 ]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #21 | lambda learn rate = 0.0001\n",
      "Target = [[7.]\n",
      " [5.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda end of trial = [[ 0.          0.5055167  -0.25274071]\n",
      " [ 0.          0.34247567 -0.17728663]\n",
      " [ 0.         -0.17032187  0.22279165]\n",
      " [ 0.         -0.11303425  0.16819205]\n",
      " [ 0.          0.18038385  0.00345955]\n",
      " [ 0.         -0.1043691   0.22874553]\n",
      " [ 0.         -0.06086847  0.12185043]\n",
      " [ 0.         -0.08606834  0.2330098 ]\n",
      " [ 0.         -0.0980745   0.16386335]\n",
      " [ 0.          0.20945688  0.08232244]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #22 | lambda learn rate = 0.0001\n",
      "Target = [[5.]\n",
      " [1.]]\n",
      "lambda end of trial = [[ 0.          0.50368607 -0.25310683]\n",
      " [ 0.          0.34109027 -0.17756371]\n",
      " [ 0.         -0.17203144  0.22244973]\n",
      " [ 0.         -0.11465834  0.16786723]\n",
      " [ 0.          0.17860951  0.00310468]\n",
      " [ 0.         -0.1061306   0.22839323]\n",
      " [ 0.         -0.06240931  0.12154226]\n",
      " [ 0.         -0.08778351  0.23266677]\n",
      " [ 0.         -0.09982379  0.16351349]\n",
      " [ 0.          0.20764133  0.08195933]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #23 | lambda learn rate = 0.0001\n",
      "Target = [[0.]\n",
      " [6.]]\n",
      "lambda end of trial = [[ 0.          0.50368607 -0.25483761]\n",
      " [ 0.          0.34109027 -0.17945269]\n",
      " [ 0.         -0.17203144  0.22030638]\n",
      " [ 0.         -0.11465834  0.16576577]\n",
      " [ 0.          0.17860951  0.00102941]\n",
      " [ 0.         -0.1061306   0.22632808]\n",
      " [ 0.         -0.06240931  0.11951355]\n",
      " [ 0.         -0.08778351  0.23051345]\n",
      " [ 0.         -0.09982379  0.16139525]\n",
      " [ 0.          0.20764133  0.07988623]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #24 | lambda learn rate = 0.0001\n",
      "Target = [[2.]\n",
      " [0.]]\n",
      "lambda end of trial = [[ 0.          0.50268916 -0.25483761]\n",
      " [ 0.          0.34002062 -0.17945269]\n",
      " [ 0.         -0.1730373   0.22030638]\n",
      " [ 0.         -0.11569797  0.16576577]\n",
      " [ 0.          0.17758594  0.00102941]\n",
      " [ 0.         -0.10708237  0.22632808]\n",
      " [ 0.         -0.0634454   0.11951355]\n",
      " [ 0.         -0.0888858   0.23051345]\n",
      " [ 0.         -0.10089949  0.16139525]\n",
      " [ 0.          0.20658912  0.07988623]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #25 | lambda learn rate = 0.0001\n",
      "Target = [[5.]\n",
      " [9.]]\n",
      "lambda end of trial = [[ 0.          0.50369099 -0.25303432]\n",
      " [ 0.          0.34095642 -0.17776825]\n",
      " [ 0.         -0.17207051  0.2220466 ]\n",
      " [ 0.         -0.11468489  0.16758931]\n",
      " [ 0.          0.17858441  0.00282665]\n",
      " [ 0.         -0.10619575  0.22792399]\n",
      " [ 0.         -0.06243085  0.12133973]\n",
      " [ 0.         -0.08779119  0.23248375]\n",
      " [ 0.         -0.0999687   0.16307067]\n",
      " [ 0.          0.20753648  0.08159149]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #26 | lambda learn rate = 0.0001\n",
      "Target = [[6.]\n",
      " [6.]]\n",
      "lambda end of trial = [[ 0.          0.50397305 -0.25275225]\n",
      " [ 0.          0.34113498 -0.17758969]\n",
      " [ 0.         -0.17179452  0.22232259]\n",
      " [ 0.         -0.11451     0.16776421]\n",
      " [ 0.          0.17876051  0.00300275]\n",
      " [ 0.         -0.10603202  0.22808773]\n",
      " [ 0.         -0.06218171  0.12158887]\n",
      " [ 0.         -0.08757248  0.23270245]\n",
      " [ 0.         -0.0997532   0.16328617]\n",
      " [ 0.          0.20767302  0.08172803]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #27 | lambda learn rate = 0.0001\n",
      "Target = [[2.]\n",
      " [1.]]\n",
      "lambda end of trial = [[ 0.          0.50309037 -0.25319359]\n",
      " [ 0.          0.34026615 -0.17802411]\n",
      " [ 0.         -0.17264708  0.22189631]\n",
      " [ 0.         -0.11543842  0.16729999]\n",
      " [ 0.          0.17778478  0.00251489]\n",
      " [ 0.         -0.10708392  0.22756178]\n",
      " [ 0.         -0.06303537  0.12116204]\n",
      " [ 0.         -0.08852264  0.23222737]\n",
      " [ 0.         -0.10073056  0.16279749]\n",
      " [ 0.          0.20663163  0.08120733]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #28 | lambda learn rate = 0.0001\n",
      "Target = [[3.]\n",
      " [3.]]\n",
      "lambda end of trial = [[ 0.          0.50221466 -0.25406931]\n",
      " [ 0.          0.33954956 -0.1787407 ]\n",
      " [ 0.         -0.17360924  0.22093414]\n",
      " [ 0.         -0.11633929  0.16639913]\n",
      " [ 0.          0.1767339   0.00146401]\n",
      " [ 0.         -0.10799143  0.22665427]\n",
      " [ 0.         -0.0639349   0.1202625 ]\n",
      " [ 0.         -0.08948286  0.23126715]\n",
      " [ 0.         -0.10168985  0.1618382 ]\n",
      " [ 0.          0.20565098  0.08022668]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #29 | lambda learn rate = 0.0001\n",
      "Target = [[3.]\n",
      " [8.]]\n",
      "lambda end of trial = [[ 0.          0.50214265 -0.25426133]\n",
      " [ 0.          0.33952844 -0.17879702]\n",
      " [ 0.         -0.17366938  0.22077379]\n",
      " [ 0.         -0.11639394  0.16625339]\n",
      " [ 0.          0.17664412  0.0012246 ]\n",
      " [ 0.         -0.10807728  0.22642535]\n",
      " [ 0.         -0.06401704  0.12004346]\n",
      " [ 0.         -0.08959432  0.23096991]\n",
      " [ 0.         -0.10177273  0.16161719]\n",
      " [ 0.          0.20553526  0.0799181 ]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #30 | lambda learn rate = 0.0001\n",
      "Target = [[1.]\n",
      " [3.]]\n",
      "lambda end of trial = [[ 0.00000000e+00  5.01755768e-01 -2.55421969e-01]\n",
      " [ 0.00000000e+00  3.39111798e-01 -1.80046941e-01]\n",
      " [ 0.00000000e+00 -1.74098498e-01  2.19486424e-01]\n",
      " [ 0.00000000e+00 -1.16845973e-01  1.64897296e-01]\n",
      " [ 0.00000000e+00  1.76213919e-01 -6.60109273e-05]\n",
      " [ 0.00000000e+00 -1.08493409e-01  2.25176951e-01]\n",
      " [ 0.00000000e+00 -6.44420967e-02  1.18768306e-01]\n",
      " [ 0.00000000e+00 -9.00366097e-02  2.29643051e-01]\n",
      " [ 0.00000000e+00 -1.02204247e-01  1.60322645e-01]\n",
      " [ 0.00000000e+00  2.05107967e-01  7.86362208e-02]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #31 | lambda learn rate = 0.0001\n",
      "Target = [[1.]\n",
      " [7.]]\n",
      "lambda end of trial = [[ 0.          0.50152075 -0.25706708]\n",
      " [ 0.          0.33890888 -0.18146737]\n",
      " [ 0.         -0.17432541  0.21789802]\n",
      " [ 0.         -0.11704663  0.16349267]\n",
      " [ 0.          0.17600383 -0.00153662]\n",
      " [ 0.         -0.1087013   0.2237217 ]\n",
      " [ 0.         -0.06465916  0.11724886]\n",
      " [ 0.         -0.09025282  0.22812955]\n",
      " [ 0.         -0.10239735  0.1589709 ]\n",
      " [ 0.          0.20485588  0.07687159]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #32 | lambda learn rate = 0.0001\n",
      "Target = [[6.]\n",
      " [5.]]\n",
      "lambda end of trial = [[ 0.          0.50215485 -0.25653866]\n",
      " [ 0.          0.33955347 -0.18093021]\n",
      " [ 0.         -0.1736268   0.2184802 ]\n",
      " [ 0.         -0.11641202  0.16402152]\n",
      " [ 0.          0.17664645 -0.0010011 ]\n",
      " [ 0.         -0.10812208  0.22420439]\n",
      " [ 0.         -0.06398894  0.11780738]\n",
      " [ 0.         -0.08964425  0.2286367 ]\n",
      " [ 0.         -0.10172386  0.15953215]\n",
      " [ 0.          0.20540264  0.07732722]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #33 | lambda learn rate = 0.0001\n",
      "Target = [[5.]\n",
      " [2.]]\n",
      "lambda end of trial = [[ 0.          0.5013293  -0.25686888]\n",
      " [ 0.          0.33880775 -0.1812285 ]\n",
      " [ 0.         -0.1744722   0.21814204]\n",
      " [ 0.         -0.11723733  0.1636914 ]\n",
      " [ 0.          0.17581754 -0.00133266]\n",
      " [ 0.         -0.10894103  0.22387681]\n",
      " [ 0.         -0.064757    0.11750016]\n",
      " [ 0.         -0.0904054   0.22833223]\n",
      " [ 0.         -0.1025441   0.15920405]\n",
      " [ 0.          0.20437357  0.07691559]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #34 | lambda learn rate = 0.0001\n",
      "Target = [[4.]\n",
      " [7.]]\n",
      "lambda end of trial = [[ 0.          0.50160029 -0.25639465]\n",
      " [ 0.          0.33908545 -0.18074252]\n",
      " [ 0.         -0.17421094  0.21859924]\n",
      " [ 0.         -0.11701715  0.16407672]\n",
      " [ 0.          0.17605201 -0.00092235]\n",
      " [ 0.         -0.10871237  0.22427697]\n",
      " [ 0.         -0.06448328  0.11797915]\n",
      " [ 0.         -0.09016815  0.22874743]\n",
      " [ 0.         -0.10229825  0.15963428]\n",
      " [ 0.          0.20458981  0.07729402]]\n",
      "a = [0. 0.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #35 | lambda learn rate = 0.0001\n",
      "Target = [[4.]\n",
      " [7.]]\n",
      "lambda end of trial = [[ 0.          0.50185001 -0.25595764]\n",
      " [ 0.          0.33930504 -0.18035823]\n",
      " [ 0.         -0.17400776  0.21895481]\n",
      " [ 0.         -0.11683391  0.16439738]\n",
      " [ 0.          0.17621609 -0.00063522]\n",
      " [ 0.         -0.10852283  0.22460866]\n",
      " [ 0.         -0.06422416  0.11843262]\n",
      " [ 0.         -0.0899561   0.22911852]\n",
      " [ 0.         -0.1020986   0.15998368]\n",
      " [ 0.          0.20471589  0.07751466]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #36 | lambda learn rate = 0.0001\n",
      "Target = [[6.]\n",
      " [7.]]\n",
      "lambda end of trial = [[ 0.          0.50306161 -0.25454411]\n",
      " [ 0.          0.34054102 -0.17891626]\n",
      " [ 0.         -0.17275006  0.22042213]\n",
      " [ 0.         -0.1154678   0.16599117]\n",
      " [ 0.          0.17756834  0.00094241]\n",
      " [ 0.         -0.10722069  0.22612782]\n",
      " [ 0.         -0.06291581  0.11995903]\n",
      " [ 0.         -0.08880787  0.23045811]\n",
      " [ 0.         -0.10084029  0.1614517 ]\n",
      " [ 0.          0.20588415  0.07887763]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #37 | lambda learn rate = 0.0001\n",
      "Target = [[3.]\n",
      " [1.]]\n",
      "lambda end of trial = [[ 0.          0.50197052 -0.2549078 ]\n",
      " [ 0.          0.33943881 -0.17928366]\n",
      " [ 0.         -0.17392797  0.22002949]\n",
      " [ 0.         -0.11659014  0.16561706]\n",
      " [ 0.          0.17635313  0.00053734]\n",
      " [ 0.         -0.1082859   0.22577275]\n",
      " [ 0.         -0.06416609  0.11954227]\n",
      " [ 0.         -0.0900895   0.2300309 ]\n",
      " [ 0.         -0.10192514  0.16109009]\n",
      " [ 0.          0.20464363  0.07846412]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #38 | lambda learn rate = 0.0001\n",
      "Target = [[4.]\n",
      " [2.]]\n",
      "lambda end of trial = [[ 0.00000000e+00  5.00907005e-01 -2.55439561e-01]\n",
      " [ 0.00000000e+00  3.38410230e-01 -1.79797952e-01]\n",
      " [ 0.00000000e+00 -1.74865944e-01  2.19560505e-01]\n",
      " [ 0.00000000e+00 -1.17703965e-01  1.65060147e-01]\n",
      " [ 0.00000000e+00  1.75317411e-01  1.94837419e-05]\n",
      " [ 0.00000000e+00 -1.09306345e-01  2.25262530e-01]\n",
      " [ 0.00000000e+00 -6.52290287e-02  1.19010795e-01]\n",
      " [ 0.00000000e+00 -9.12231783e-02  2.29464065e-01]\n",
      " [ 0.00000000e+00 -1.02953394e-01  1.60575961e-01]\n",
      " [ 0.00000000e+00  2.03498942e-01  7.78917794e-02]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #39 | lambda learn rate = 0.0001\n",
      "Target = [[8.]\n",
      " [0.]]\n",
      "lambda end of trial = [[ 0.00000000e+00  5.00317478e-01 -2.55439561e-01]\n",
      " [ 0.00000000e+00  3.38042392e-01 -1.79797952e-01]\n",
      " [ 0.00000000e+00 -1.75302267e-01  2.19560505e-01]\n",
      " [ 0.00000000e+00 -1.18295506e-01  1.65060147e-01]\n",
      " [ 0.00000000e+00  1.74802010e-01  1.94837419e-05]\n",
      " [ 0.00000000e+00 -1.09959113e-01  2.25262530e-01]\n",
      " [ 0.00000000e+00 -6.57270048e-02  1.19010795e-01]\n",
      " [ 0.00000000e+00 -9.19322179e-02  2.29464065e-01]\n",
      " [ 0.00000000e+00 -1.03553410e-01  1.60575961e-01]\n",
      " [ 0.00000000e+00  2.02809674e-01  7.78917794e-02]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #40 | lambda learn rate = 0.0001\n",
      "Target = [[0.]\n",
      " [0.]]\n",
      "lambda end of trial = [[ 0.00000000e+00  5.00317478e-01 -2.55439561e-01]\n",
      " [ 0.00000000e+00  3.38042392e-01 -1.79797952e-01]\n",
      " [ 0.00000000e+00 -1.75302267e-01  2.19560505e-01]\n",
      " [ 0.00000000e+00 -1.18295506e-01  1.65060147e-01]\n",
      " [ 0.00000000e+00  1.74802010e-01  1.94837419e-05]\n",
      " [ 0.00000000e+00 -1.09959113e-01  2.25262530e-01]\n",
      " [ 0.00000000e+00 -6.57270048e-02  1.19010795e-01]\n",
      " [ 0.00000000e+00 -9.19322179e-02  2.29464065e-01]\n",
      " [ 0.00000000e+00 -1.03553410e-01  1.60575961e-01]\n",
      " [ 0.00000000e+00  2.02809674e-01  7.78917794e-02]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #41 | lambda learn rate = 0.0001\n",
      "Target = [[6.]\n",
      " [8.]]\n",
      "lambda end of trial = [[ 0.          0.5018684  -0.25337167]\n",
      " [ 0.          0.33969815 -0.17759028]\n",
      " [ 0.         -0.1735507   0.22189593]\n",
      " [ 0.         -0.11659394  0.1673289 ]\n",
      " [ 0.          0.17657527  0.00238383]\n",
      " [ 0.         -0.10806861  0.2277832 ]\n",
      " [ 0.         -0.06416392  0.12109491]\n",
      " [ 0.         -0.09032001  0.23161368]\n",
      " [ 0.         -0.10194168  0.16272493]\n",
      " [ 0.          0.20443573  0.08005986]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #42 | lambda learn rate = 0.0001\n",
      "Target = [[0.]\n",
      " [8.]]\n",
      "lambda end of trial = [[ 0.00000000e+00  5.01868400e-01 -2.55290487e-01]\n",
      " [ 0.00000000e+00  3.39698148e-01 -1.79447333e-01]\n",
      " [ 0.00000000e+00 -1.73550696e-01  2.19735861e-01]\n",
      " [ 0.00000000e+00 -1.16593944e-01  1.65391285e-01]\n",
      " [ 0.00000000e+00  1.76575269e-01  4.30541251e-04]\n",
      " [ 0.00000000e+00 -1.08068614e-01  2.25741621e-01]\n",
      " [ 0.00000000e+00 -6.41639167e-02  1.19178294e-01]\n",
      " [ 0.00000000e+00 -9.03200056e-02  2.29747838e-01]\n",
      " [ 0.00000000e+00 -1.01941680e-01  1.60745609e-01]\n",
      " [ 0.00000000e+00  2.04435733e-01  7.78337135e-02]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #43 | lambda learn rate = 0.0001\n",
      "Target = [[2.]\n",
      " [4.]]\n",
      "lambda end of trial = [[ 0.          0.50119993 -0.25662742]\n",
      " [ 0.          0.33914152 -0.1805606 ]\n",
      " [ 0.         -0.17409888  0.21863949]\n",
      " [ 0.         -0.1171208   0.16433757]\n",
      " [ 0.          0.17604234 -0.00063533]\n",
      " [ 0.         -0.1086023   0.22467426]\n",
      " [ 0.         -0.06472376  0.11805861]\n",
      " [ 0.         -0.09094408  0.22849969]\n",
      " [ 0.         -0.10253757  0.15955383]\n",
      " [ 0.          0.2038459   0.07665406]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #44 | lambda learn rate = 0.0001\n",
      "Target = [[6.]\n",
      " [5.]]\n",
      "lambda end of trial = [[ 0.00000000e+00  5.01769307e-01 -2.56152945e-01]\n",
      " [ 0.00000000e+00  3.39697713e-01 -1.80097098e-01]\n",
      " [ 0.00000000e+00 -1.73635434e-01  2.19025699e-01]\n",
      " [ 0.00000000e+00 -1.16577016e-01  1.64790724e-01]\n",
      " [ 0.00000000e+00  1.76594136e-01 -1.75492079e-04]\n",
      " [ 0.00000000e+00 -1.08128890e-01  2.25068762e-01]\n",
      " [ 0.00000000e+00 -6.41442161e-02  1.18541565e-01]\n",
      " [ 0.00000000e+00 -9.04896906e-02  2.28878345e-01]\n",
      " [ 0.00000000e+00 -1.02084949e-01  1.59931014e-01]\n",
      " [ 0.00000000e+00  2.04228037e-01  7.69724994e-02]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #45 | lambda learn rate = 0.0001\n",
      "Target = [[7.]\n",
      " [4.]]\n",
      "lambda end of trial = [[ 0.00000000e+00  5.02418133e-01 -2.55782187e-01]\n",
      " [ 0.00000000e+00  3.40271724e-01 -1.79769093e-01]\n",
      " [ 0.00000000e+00 -1.73002344e-01  2.19387465e-01]\n",
      " [ 0.00000000e+00 -1.15924872e-01  1.65163378e-01]\n",
      " [ 0.00000000e+00  1.77209272e-01  1.76013970e-04]\n",
      " [ 0.00000000e+00 -1.07558792e-01  2.25394532e-01]\n",
      " [ 0.00000000e+00 -6.35390359e-02  1.18887382e-01]\n",
      " [ 0.00000000e+00 -8.99038165e-02  2.29213130e-01]\n",
      " [ 0.00000000e+00 -1.01450439e-01  1.60293591e-01]\n",
      " [ 0.00000000e+00  2.04765442e-01  7.72795879e-02]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #46 | lambda learn rate = 0.0001\n",
      "Target = [[2.]\n",
      " [8.]]\n",
      "lambda end of trial = [[ 0.00000000e+00  5.02318292e-01 -2.56181550e-01]\n",
      " [ 0.00000000e+00  3.40214146e-01 -1.79999404e-01]\n",
      " [ 0.00000000e+00 -1.73086290e-01  2.19051681e-01]\n",
      " [ 0.00000000e+00 -1.16008247e-01  1.64829879e-01]\n",
      " [ 0.00000000e+00  1.77114265e-01 -2.04012757e-04]\n",
      " [ 0.00000000e+00 -1.07645961e-01  2.25045857e-01]\n",
      " [ 0.00000000e+00 -6.36011814e-02  1.18638800e-01]\n",
      " [ 0.00000000e+00 -9.00236954e-02  2.28733614e-01]\n",
      " [ 0.00000000e+00 -1.01545893e-01  1.59911776e-01]\n",
      " [ 0.00000000e+00  2.04648225e-01  7.68107230e-02]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #47 | lambda learn rate = 0.0001\n",
      "Target = [[6.]\n",
      " [4.]]\n",
      "lambda end of trial = [[ 0.00000000e+00  5.02336555e-01 -2.56169375e-01]\n",
      " [ 0.00000000e+00  3.40308078e-01 -1.79936782e-01]\n",
      " [ 0.00000000e+00 -1.73082738e-01  2.19054049e-01]\n",
      " [ 0.00000000e+00 -1.15982454e-01  1.64847075e-01]\n",
      " [ 0.00000000e+00  1.77112329e-01 -2.05303308e-04]\n",
      " [ 0.00000000e+00 -1.07692253e-01  2.25014996e-01]\n",
      " [ 0.00000000e+00 -6.35634723e-02  1.18663939e-01]\n",
      " [ 0.00000000e+00 -9.00416973e-02  2.28721613e-01]\n",
      " [ 0.00000000e+00 -1.01597501e-01  1.59877371e-01]\n",
      " [ 0.00000000e+00  2.04553933e-01  7.67478613e-02]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #48 | lambda learn rate = 0.0001\n",
      "Target = [[5.]\n",
      " [2.]]\n",
      "lambda end of trial = [[ 0.          0.50136082 -0.25655967]\n",
      " [ 0.          0.33951141 -0.18025545]\n",
      " [ 0.         -0.17412334  0.21863781]\n",
      " [ 0.         -0.1168338   0.16450654]\n",
      " [ 0.          0.17621691 -0.00056347]\n",
      " [ 0.         -0.10865105  0.22463148]\n",
      " [ 0.         -0.06451224  0.11828443]\n",
      " [ 0.         -0.09105257  0.22831726]\n",
      " [ 0.         -0.10240809  0.15955313]\n",
      " [ 0.          0.20348237  0.07631924]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #49 | lambda learn rate = 0.0001\n",
      "Target = [[0.]\n",
      " [4.]]\n",
      "lambda end of trial = [[ 0.          0.50136082 -0.25817468]\n",
      " [ 0.          0.33951141 -0.18169529]\n",
      " [ 0.         -0.17412334  0.21703095]\n",
      " [ 0.         -0.1168338   0.16296871]\n",
      " [ 0.          0.17621691 -0.00212207]\n",
      " [ 0.         -0.10865105  0.22299468]\n",
      " [ 0.         -0.06451224  0.11660719]\n",
      " [ 0.         -0.09105257  0.22669925]\n",
      " [ 0.         -0.10240809  0.15788794]\n",
      " [ 0.          0.20348237  0.07457526]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #50 | lambda learn rate = 0.0001\n",
      "Target = [[3.]\n",
      " [7.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda end of trial = [[ 0.          0.50142767 -0.2580187 ]\n",
      " [ 0.          0.33957701 -0.18154222]\n",
      " [ 0.         -0.17405913  0.21718078]\n",
      " [ 0.         -0.11676997  0.16311765]\n",
      " [ 0.          0.17626414 -0.00201187]\n",
      " [ 0.         -0.10864028  0.22301982]\n",
      " [ 0.         -0.06446142  0.11672578]\n",
      " [ 0.         -0.09103802  0.22673321]\n",
      " [ 0.         -0.10236385  0.15799118]\n",
      " [ 0.          0.20348449  0.0745802 ]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #51 | lambda learn rate = 0.0001\n",
      "Target = [[9.]\n",
      " [9.]]\n",
      "lambda end of trial = [[ 0.          0.50701219 -0.25243418]\n",
      " [ 0.          0.34512595 -0.17599328]\n",
      " [ 0.         -0.16831896  0.22292095]\n",
      " [ 0.         -0.11055162  0.169336  ]\n",
      " [ 0.          0.18139884  0.00312283]\n",
      " [ 0.         -0.10337274  0.22828736]\n",
      " [ 0.         -0.05949373  0.12169347]\n",
      " [ 0.         -0.08568887  0.23208236]\n",
      " [ 0.         -0.09680532  0.1635497 ]\n",
      " [ 0.          0.20865938  0.07975509]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #52 | lambda learn rate = 0.0001\n",
      "Target = [[6.]\n",
      " [8.]]\n",
      "lambda end of trial = [[ 0.          0.5076751  -0.2515503 ]\n",
      " [ 0.          0.34570186 -0.1752254 ]\n",
      " [ 0.         -0.16765193  0.22381032]\n",
      " [ 0.         -0.10992616  0.17016994]\n",
      " [ 0.          0.18207655  0.00402645]\n",
      " [ 0.         -0.1027798   0.22907795]\n",
      " [ 0.         -0.05882226  0.12258876]\n",
      " [ 0.         -0.08505929  0.23292179]\n",
      " [ 0.         -0.09613268  0.16444655]\n",
      " [ 0.          0.20925133  0.08054435]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #53 | lambda learn rate = 0.0001\n",
      "Target = [[1.]\n",
      " [3.]]\n",
      "lambda end of trial = [[ 0.          0.50718606 -0.25301742]\n",
      " [ 0.          0.3452042  -0.17671837]\n",
      " [ 0.         -0.16811765  0.22241316]\n",
      " [ 0.         -0.11040067  0.16874641]\n",
      " [ 0.          0.1815854   0.00255299]\n",
      " [ 0.         -0.10330495  0.2275025 ]\n",
      " [ 0.         -0.05927458  0.1212318 ]\n",
      " [ 0.         -0.08556514  0.23140425]\n",
      " [ 0.         -0.09663233  0.16294761]\n",
      " [ 0.          0.20874811  0.07903469]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #54 | lambda learn rate = 0.0001\n",
      "Target = [[6.]\n",
      " [1.]]\n",
      "lambda end of trial = [[ 0.          0.50551125 -0.25329656]\n",
      " [ 0.          0.34379593 -0.17695308]\n",
      " [ 0.         -0.16962169  0.22216249]\n",
      " [ 0.         -0.11196159  0.16848626]\n",
      " [ 0.          0.17987393  0.00226774]\n",
      " [ 0.         -0.10488079  0.22723986]\n",
      " [ 0.         -0.06085144  0.12096899]\n",
      " [ 0.         -0.08721463  0.23112933]\n",
      " [ 0.         -0.09798118  0.1627228 ]\n",
      " [ 0.          0.20712771  0.07876463]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #55 | lambda learn rate = 0.0001\n",
      "Target = [[3.]\n",
      " [1.]]\n",
      "lambda end of trial = [[ 0.          0.50427527 -0.25370855]\n",
      " [ 0.          0.34251033 -0.17738161]\n",
      " [ 0.         -0.17088066  0.22174283]\n",
      " [ 0.         -0.11336191  0.16801949]\n",
      " [ 0.          0.17856275  0.00183068]\n",
      " [ 0.         -0.10611115  0.22682974]\n",
      " [ 0.         -0.06205674  0.12056722]\n",
      " [ 0.         -0.08850778  0.23069828]\n",
      " [ 0.         -0.09929378  0.16228527]\n",
      " [ 0.          0.20567582  0.07828067]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #56 | lambda learn rate = 0.0001\n",
      "Target = [[7.]\n",
      " [5.]]\n",
      "lambda end of trial = [[ 0.          0.50488149 -0.25327553]\n",
      " [ 0.          0.34301096 -0.17702402]\n",
      " [ 0.         -0.17025187  0.22219196]\n",
      " [ 0.         -0.11277273  0.16844033]\n",
      " [ 0.          0.17909283  0.00220932]\n",
      " [ 0.         -0.10561251  0.22718591]\n",
      " [ 0.         -0.06147552  0.12098238]\n",
      " [ 0.         -0.08799434  0.23106502]\n",
      " [ 0.         -0.09869963  0.16270966]\n",
      " [ 0.          0.20616083  0.0786271 ]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #57 | lambda learn rate = 0.0001\n",
      "Target = [[3.]\n",
      " [5.]]\n",
      "lambda end of trial = [[ 0.          0.50428354 -0.25427213]\n",
      " [ 0.          0.34249528 -0.17788348]\n",
      " [ 0.         -0.17078448  0.22130428]\n",
      " [ 0.         -0.11327755  0.16759896]\n",
      " [ 0.          0.17857473  0.00134581]\n",
      " [ 0.         -0.10625277  0.22611881]\n",
      " [ 0.         -0.0620042   0.12010124]\n",
      " [ 0.         -0.08854185  0.23015251]\n",
      " [ 0.         -0.09920434  0.16186849]\n",
      " [ 0.          0.20552436  0.07756631]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #58 | lambda learn rate = 0.0001\n",
      "Target = [[8.]\n",
      " [9.]]\n",
      "lambda end of trial = [[ 0.          0.5073349  -0.25083934]\n",
      " [ 0.          0.34571711 -0.17425893]\n",
      " [ 0.         -0.16766936  0.2248088 ]\n",
      " [ 0.         -0.10985118  0.17145362]\n",
      " [ 0.          0.18148032  0.0046146 ]\n",
      " [ 0.         -0.10329666  0.22944444]\n",
      " [ 0.         -0.05919392  0.12326281]\n",
      " [ 0.         -0.08540626  0.23368005]\n",
      " [ 0.         -0.09590362  0.16558179]\n",
      " [ 0.          0.20849655  0.08091002]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #59 | lambda learn rate = 0.0001\n",
      "Target = [[9.]\n",
      " [2.]]\n",
      "lambda end of trial = [[ 0.          0.50708123 -0.25089572]\n",
      " [ 0.          0.34553834 -0.17429865]\n",
      " [ 0.         -0.16788253  0.22476142]\n",
      " [ 0.         -0.10991843  0.17143868]\n",
      " [ 0.          0.18123293  0.00455962]\n",
      " [ 0.         -0.10343552  0.22941358]\n",
      " [ 0.         -0.05932051  0.12323468]\n",
      " [ 0.         -0.08574796  0.23360411]\n",
      " [ 0.         -0.09616845  0.16552294]\n",
      " [ 0.          0.2080775   0.0808169 ]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #60 | lambda learn rate = 0.0001\n",
      "Target = [[6.]\n",
      " [3.]]\n",
      "lambda end of trial = [[ 0.          0.50621238 -0.25133014]\n",
      " [ 0.          0.34469096 -0.17472234]\n",
      " [ 0.         -0.16875339  0.22432599]\n",
      " [ 0.         -0.11073326  0.17103126]\n",
      " [ 0.          0.1802934   0.00408986]\n",
      " [ 0.         -0.1043158   0.22897344]\n",
      " [ 0.         -0.06020976  0.12279005]\n",
      " [ 0.         -0.08661173  0.23317223]\n",
      " [ 0.         -0.09697939  0.16511747]\n",
      " [ 0.          0.20718391  0.0803701 ]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #61 | lambda learn rate = 0.0001\n",
      "Target = [[3.]\n",
      " [2.]]\n",
      "lambda end of trial = [[ 0.          0.50513697 -0.25204708]\n",
      " [ 0.          0.34366553 -0.17540596]\n",
      " [ 0.         -0.16980942  0.22362198]\n",
      " [ 0.         -0.1117477   0.17035497]\n",
      " [ 0.          0.17903113  0.00324835]\n",
      " [ 0.         -0.1056129   0.22810871]\n",
      " [ 0.         -0.06134468  0.12203344]\n",
      " [ 0.         -0.0877824   0.23239178]\n",
      " [ 0.         -0.09803854  0.16441137]\n",
      " [ 0.          0.20602934  0.07960039]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #62 | lambda learn rate = 0.0001\n",
      "Target = [[8.]\n",
      " [5.]]\n",
      "lambda end of trial = [[ 0.          0.50606361 -0.25146793]\n",
      " [ 0.          0.34463939 -0.1747973 ]\n",
      " [ 0.         -0.16907014  0.22408402]\n",
      " [ 0.         -0.11075318  0.17097655]\n",
      " [ 0.          0.17986075  0.00376686]\n",
      " [ 0.         -0.10470222  0.22867788]\n",
      " [ 0.         -0.06050351  0.12255917]\n",
      " [ 0.         -0.0870988   0.23281904]\n",
      " [ 0.         -0.09713878  0.16497372]\n",
      " [ 0.          0.20670955  0.08002552]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #63 | lambda learn rate = 0.0001\n",
      "Target = [[3.]\n",
      " [8.]]\n",
      "lambda end of trial = [[ 0.          0.50583541 -0.25207647]\n",
      " [ 0.          0.34443659 -0.1753381 ]\n",
      " [ 0.         -0.16928429  0.22351298]\n",
      " [ 0.         -0.11095953  0.1704263 ]\n",
      " [ 0.          0.17961001  0.00309821]\n",
      " [ 0.         -0.10496718  0.22797133]\n",
      " [ 0.         -0.06067831  0.12209302]\n",
      " [ 0.         -0.08731562  0.23224084]\n",
      " [ 0.         -0.09737154  0.16435303]\n",
      " [ 0.          0.20643528  0.07929413]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #64 | lambda learn rate = 0.0001\n",
      "Target = [[8.]\n",
      " [0.]]\n",
      "lambda end of trial = [[ 0.          0.50425743 -0.25207647]\n",
      " [ 0.          0.34307344 -0.1753381 ]\n",
      " [ 0.         -0.17067885  0.22351298]\n",
      " [ 0.         -0.11242633  0.1704263 ]\n",
      " [ 0.          0.17821064  0.00309821]\n",
      " [ 0.         -0.10645248  0.22797133]\n",
      " [ 0.         -0.06231447  0.12209302]\n",
      " [ 0.         -0.08897138  0.23224084]\n",
      " [ 0.         -0.09872725  0.16435303]\n",
      " [ 0.          0.20486525  0.07929413]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #65 | lambda learn rate = 0.0001\n",
      "Target = [[4.]\n",
      " [3.]]\n",
      "lambda end of trial = [[ 0.          0.5033212  -0.25277865]\n",
      " [ 0.          0.34219798 -0.1759947 ]\n",
      " [ 0.         -0.17161088  0.22281395]\n",
      " [ 0.         -0.1133514   0.1697325 ]\n",
      " [ 0.          0.1773048   0.00241882]\n",
      " [ 0.         -0.10737268  0.22728118]\n",
      " [ 0.         -0.06315034  0.12146612]\n",
      " [ 0.         -0.08984821  0.23158321]\n",
      " [ 0.         -0.09957081  0.16372036]\n",
      " [ 0.          0.20398446  0.07863354]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #66 | lambda learn rate = 0.0001\n",
      "Target = [[5.]\n",
      " [6.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda end of trial = [[ 0.          0.50330516 -0.2527979 ]\n",
      " [ 0.          0.3422916  -0.17588235]\n",
      " [ 0.         -0.17157102  0.22286179]\n",
      " [ 0.         -0.11328583  0.16981118]\n",
      " [ 0.          0.17732307  0.00244075]\n",
      " [ 0.         -0.10740712  0.22723985]\n",
      " [ 0.         -0.06311678  0.12150639]\n",
      " [ 0.         -0.08988471  0.23153941]\n",
      " [ 0.         -0.0995912   0.1636959 ]\n",
      " [ 0.          0.20396622  0.07861165]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #67 | lambda learn rate = 0.0001\n",
      "Target = [[2.]\n",
      " [5.]]\n",
      "lambda end of trial = [[ 0.          0.50275917 -0.25416286]\n",
      " [ 0.          0.34173302 -0.1772788 ]\n",
      " [ 0.         -0.17211175  0.22150995]\n",
      " [ 0.         -0.11379688  0.16853355]\n",
      " [ 0.          0.17678157  0.001087  ]\n",
      " [ 0.         -0.1079252   0.22594465]\n",
      " [ 0.         -0.06365317  0.12016541]\n",
      " [ 0.         -0.09048994  0.23002635]\n",
      " [ 0.         -0.10006599  0.16250892]\n",
      " [ 0.          0.2034441   0.07730634]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #68 | lambda learn rate = 0.0001\n",
      "Target = [[2.]\n",
      " [0.]]\n",
      "lambda end of trial = [[ 0.          0.50169242 -0.25416286]\n",
      " [ 0.          0.34079714 -0.1772788 ]\n",
      " [ 0.         -0.17312549  0.22150995]\n",
      " [ 0.         -0.11489409  0.16853355]\n",
      " [ 0.          0.17573412  0.001087  ]\n",
      " [ 0.         -0.10897759  0.22594465]\n",
      " [ 0.         -0.06462083  0.12016541]\n",
      " [ 0.         -0.09161915  0.23002635]\n",
      " [ 0.         -0.10109038  0.16250892]\n",
      " [ 0.          0.2023603   0.07730634]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #69 | lambda learn rate = 0.0001\n",
      "Target = [[3.]\n",
      " [6.]]\n",
      "lambda end of trial = [[ 0.          0.50135394 -0.25483982]\n",
      " [ 0.          0.34044395 -0.17798518]\n",
      " [ 0.         -0.17346899  0.22082297]\n",
      " [ 0.         -0.11517882  0.1679641 ]\n",
      " [ 0.          0.17545137  0.00052151]\n",
      " [ 0.         -0.10931143  0.22527697]\n",
      " [ 0.         -0.06494228  0.1195225 ]\n",
      " [ 0.         -0.09196291  0.22933883]\n",
      " [ 0.         -0.10143602  0.16181764]\n",
      " [ 0.          0.20198895  0.07656363]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #70 | lambda learn rate = 0.0001\n",
      "Target = [[1.]\n",
      " [3.]]\n",
      "lambda end of trial = [[ 0.          0.50098028 -0.2559608 ]\n",
      " [ 0.          0.34004571 -0.1791799 ]\n",
      " [ 0.         -0.17382839  0.21974476]\n",
      " [ 0.         -0.11560623  0.16668188]\n",
      " [ 0.          0.17501473 -0.00078842]\n",
      " [ 0.         -0.10974817  0.22396673]\n",
      " [ 0.         -0.0653486   0.11830356]\n",
      " [ 0.         -0.09241484  0.22798305]\n",
      " [ 0.         -0.10185521  0.16056004]\n",
      " [ 0.          0.20156918  0.07530434]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #71 | lambda learn rate = 0.0001\n",
      "Target = [[0.]\n",
      " [4.]]\n",
      "lambda end of trial = [[ 0.          0.50098028 -0.2577825 ]\n",
      " [ 0.          0.34004571 -0.1807588 ]\n",
      " [ 0.         -0.17382839  0.21802327]\n",
      " [ 0.         -0.11560623  0.16483466]\n",
      " [ 0.          0.17501473 -0.00222592]\n",
      " [ 0.         -0.10974817  0.22222352]\n",
      " [ 0.         -0.0653486   0.11667492]\n",
      " [ 0.         -0.09241484  0.22627953]\n",
      " [ 0.         -0.10185521  0.1589784 ]\n",
      " [ 0.          0.20156918  0.0735301 ]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #72 | lambda learn rate = 0.0001\n",
      "Target = [[6.]\n",
      " [8.]]\n",
      "lambda end of trial = [[ 0.00000000e+00  5.02846627e-01 -2.55294040e-01]\n",
      " [ 0.00000000e+00  3.41958315e-01 -1.78208667e-01]\n",
      " [ 0.00000000e+00 -1.71975645e-01  2.20493590e-01]\n",
      " [ 0.00000000e+00 -1.13705758e-01  1.67368616e-01]\n",
      " [ 0.00000000e+00  1.76948936e-01  3.53021175e-04]\n",
      " [ 0.00000000e+00 -1.07832510e-01  2.24777742e-01]\n",
      " [ 0.00000000e+00 -6.34058703e-02  1.19265221e-01]\n",
      " [ 0.00000000e+00 -9.05302729e-02  2.28792279e-01]\n",
      " [ 0.00000000e+00 -9.99413159e-02  1.61530266e-01]\n",
      " [ 0.00000000e+00  2.03244050e-01  7.57632611e-02]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #73 | lambda learn rate = 0.0001\n",
      "Target = [[2.]\n",
      " [8.]]\n",
      "lambda end of trial = [[ 0.00000000e+00  5.02736089e-01 -2.55736193e-01]\n",
      " [ 0.00000000e+00  3.41875773e-01 -1.78538836e-01]\n",
      " [ 0.00000000e+00 -1.72059412e-01  2.20158523e-01]\n",
      " [ 0.00000000e+00 -1.13811743e-01  1.66944673e-01]\n",
      " [ 0.00000000e+00  1.76836708e-01 -9.58932239e-05]\n",
      " [ 0.00000000e+00 -1.07927858e-01  2.24396354e-01]\n",
      " [ 0.00000000e+00 -6.35058748e-02  1.18865203e-01]\n",
      " [ 0.00000000e+00 -9.06589676e-02  2.28277501e-01]\n",
      " [ 0.00000000e+00 -1.00036168e-01  1.61150856e-01]\n",
      " [ 0.00000000e+00  2.03093399e-01  7.51606594e-02]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #74 | lambda learn rate = 0.0001\n",
      "Target = [[0.]\n",
      " [5.]]\n",
      "lambda end of trial = [[ 0.          0.50273609 -0.25755305]\n",
      " [ 0.          0.34187577 -0.18018686]\n",
      " [ 0.         -0.17205941  0.21837287]\n",
      " [ 0.         -0.11381174  0.16512212]\n",
      " [ 0.          0.17683671 -0.00184255]\n",
      " [ 0.         -0.10792786  0.22244925]\n",
      " [ 0.         -0.06350587  0.11715761]\n",
      " [ 0.         -0.09065897  0.22645446]\n",
      " [ 0.         -0.10003617  0.15929667]\n",
      " [ 0.          0.2030934   0.0732787 ]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #75 | lambda learn rate = 0.0001\n",
      "Target = [[5.]\n",
      " [4.]]\n",
      "lambda end of trial = [[ 0.          0.50261199 -0.25765232]\n",
      " [ 0.          0.34174172 -0.18029409]\n",
      " [ 0.         -0.17216819  0.21828584]\n",
      " [ 0.         -0.11393439  0.165024  ]\n",
      " [ 0.          0.17668612 -0.00196302]\n",
      " [ 0.         -0.10810139  0.22231043]\n",
      " [ 0.         -0.06360953  0.11707469]\n",
      " [ 0.         -0.09084876  0.22630263]\n",
      " [ 0.         -0.10013078  0.15922098]\n",
      " [ 0.          0.20293236  0.07314987]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #76 | lambda learn rate = 0.0001\n",
      "Target = [[0.]\n",
      " [3.]]\n",
      "lambda end of trial = [[ 0.          0.50261199 -0.25899494]\n",
      " [ 0.          0.34174172 -0.18169771]\n",
      " [ 0.         -0.17216819  0.2170159 ]\n",
      " [ 0.         -0.11393439  0.16384997]\n",
      " [ 0.          0.17668612 -0.00326209]\n",
      " [ 0.         -0.10810139  0.22107127]\n",
      " [ 0.         -0.06360953  0.1157346 ]\n",
      " [ 0.         -0.09084876  0.22503974]\n",
      " [ 0.         -0.10013078  0.15795708]\n",
      " [ 0.          0.20293236  0.07174211]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #77 | lambda learn rate = 0.0001\n",
      "Target = [[4.]\n",
      " [2.]]\n",
      "lambda end of trial = [[ 0.          0.50177672 -0.25941257]\n",
      " [ 0.          0.34101469 -0.18206122]\n",
      " [ 0.         -0.17295924  0.21662038]\n",
      " [ 0.         -0.11478747  0.16342343]\n",
      " [ 0.          0.17591805 -0.00364612]\n",
      " [ 0.         -0.10892832  0.2206578 ]\n",
      " [ 0.         -0.06437671  0.11535101]\n",
      " [ 0.         -0.09165201  0.22463812]\n",
      " [ 0.         -0.10100379  0.15752057]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [ 0.          0.20208246  0.07131715]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #78 | lambda learn rate = 0.0001\n",
      "Target = [[4.]\n",
      " [3.]]\n",
      "lambda end of trial = [[ 0.          0.50118977 -0.25985279]\n",
      " [ 0.          0.34044197 -0.18249077]\n",
      " [ 0.         -0.17360796  0.21613384]\n",
      " [ 0.         -0.11543444  0.1629382 ]\n",
      " [ 0.          0.17537663 -0.00405219]\n",
      " [ 0.         -0.1095383   0.22020032]\n",
      " [ 0.         -0.06498785  0.11489266]\n",
      " [ 0.         -0.09225974  0.22418232]\n",
      " [ 0.         -0.10164041  0.1570431 ]\n",
      " [ 0.          0.20140506  0.0708091 ]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #79 | lambda learn rate = 0.0001\n",
      "Target = [[5.]\n",
      " [8.]]\n",
      "lambda end of trial = [[ 0.          0.50248642 -0.25777814]\n",
      " [ 0.          0.34197201 -0.18004271]\n",
      " [ 0.         -0.17224372  0.21831662]\n",
      " [ 0.         -0.11401231  0.16521361]\n",
      " [ 0.          0.17690229 -0.00161113]\n",
      " [ 0.         -0.10815167  0.22241893]\n",
      " [ 0.         -0.06350932  0.11725831]\n",
      " [ 0.         -0.0908758   0.22639662]\n",
      " [ 0.         -0.10021346  0.15932623]\n",
      " [ 0.          0.20270327  0.07288624]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #80 | lambda learn rate = 0.0001\n",
      "Target = [[8.]\n",
      " [8.]]\n",
      "lambda end of trial = [[ 0.          0.50571599 -0.25454857]\n",
      " [ 0.          0.34555533 -0.17645939]\n",
      " [ 0.         -0.16872793  0.22183241]\n",
      " [ 0.         -0.11019282  0.1690331 ]\n",
      " [ 0.          0.18039239  0.00187897]\n",
      " [ 0.         -0.10477368  0.22579692]\n",
      " [ 0.         -0.05976864  0.12099899]\n",
      " [ 0.         -0.08756404  0.22970838]\n",
      " [ 0.         -0.09663325  0.16290644]\n",
      " [ 0.          0.20617619  0.07635916]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #81 | lambda learn rate = 0.0001\n",
      "Target = [[1.]\n",
      " [2.]]\n",
      "lambda end of trial = [[ 0.          0.50533598 -0.2553086 ]\n",
      " [ 0.          0.34516116 -0.17724773]\n",
      " [ 0.         -0.16913593  0.22101641]\n",
      " [ 0.         -0.1105971   0.16822454]\n",
      " [ 0.          0.1799492   0.0009926 ]\n",
      " [ 0.         -0.10516844  0.2250074 ]\n",
      " [ 0.         -0.06017741  0.12018144]\n",
      " [ 0.         -0.08799914  0.22883818]\n",
      " [ 0.         -0.09701144  0.16215006]\n",
      " [ 0.          0.20576361  0.075534  ]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #82 | lambda learn rate = 0.0001\n",
      "Target = [[5.]\n",
      " [2.]]\n",
      "lambda end of trial = [[ 0.00000000e+00  5.04278909e-01 -2.55731431e-01]\n",
      " [ 0.00000000e+00  3.44135704e-01 -1.77657908e-01]\n",
      " [ 0.00000000e+00 -1.70278993e-01  2.20559181e-01]\n",
      " [ 0.00000000e+00 -1.11700282e-01  1.67783269e-01]\n",
      " [ 0.00000000e+00  1.78694466e-01  4.90700279e-04]\n",
      " [ 0.00000000e+00 -1.06374854e-01  2.24524831e-01]\n",
      " [ 0.00000000e+00 -6.12005178e-02  1.19772202e-01]\n",
      " [ 0.00000000e+00 -8.90936279e-02  2.28400381e-01]\n",
      " [ 0.00000000e+00 -9.81249396e-02  1.61704661e-01]\n",
      " [ 0.00000000e+00  2.04549347e-01  7.50482939e-02]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #83 | lambda learn rate = 0.0001\n",
      "Target = [[8.]\n",
      " [8.]]\n",
      "lambda end of trial = [[ 0.          0.50696095 -0.25304939]\n",
      " [ 0.          0.34668062 -0.17511299]\n",
      " [ 0.         -0.16703008  0.22380809]\n",
      " [ 0.         -0.10876872  0.17071483]\n",
      " [ 0.          0.18149022  0.00328645]\n",
      " [ 0.         -0.10394421  0.22695548]\n",
      " [ 0.         -0.05818541  0.12278731]\n",
      " [ 0.         -0.08621674  0.23127727]\n",
      " [ 0.         -0.09543558  0.16439403]\n",
      " [ 0.          0.20720396  0.07770291]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #84 | lambda learn rate = 0.0001\n",
      "Target = [[8.]\n",
      " [1.]]\n",
      "lambda end of trial = [[ 0.          0.5057839  -0.25319652]\n",
      " [ 0.          0.34566335 -0.17524015]\n",
      " [ 0.         -0.16825638  0.2236548 ]\n",
      " [ 0.         -0.10991982  0.17057094]\n",
      " [ 0.          0.180205    0.0031258 ]\n",
      " [ 0.         -0.10517083  0.22680215]\n",
      " [ 0.         -0.05945796  0.12262824]\n",
      " [ 0.         -0.08749235  0.23111782]\n",
      " [ 0.         -0.09676102  0.16422834]\n",
      " [ 0.          0.20583088  0.07753127]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #85 | lambda learn rate = 0.0001\n",
      "Target = [[4.]\n",
      " [8.]]\n",
      "lambda end of trial = [[ 0.          0.50591756 -0.25292921]\n",
      " [ 0.          0.34583063 -0.1749056 ]\n",
      " [ 0.         -0.16814038  0.22388681]\n",
      " [ 0.         -0.10980852  0.17079355]\n",
      " [ 0.          0.18030814  0.00333208]\n",
      " [ 0.         -0.105085    0.22697381]\n",
      " [ 0.         -0.05929173  0.1229607 ]\n",
      " [ 0.         -0.08737817  0.23134619]\n",
      " [ 0.         -0.09665385  0.16444269]\n",
      " [ 0.          0.20592238  0.07771426]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #86 | lambda learn rate = 0.0001\n",
      "Target = [[5.]\n",
      " [4.]]\n",
      "lambda end of trial = [[ 0.          0.5053197  -0.2534075 ]\n",
      " [ 0.          0.34537883 -0.17526703]\n",
      " [ 0.         -0.16870884  0.22343203]\n",
      " [ 0.         -0.11034096  0.17036759]\n",
      " [ 0.          0.17965651  0.00281078]\n",
      " [ 0.         -0.10574296  0.22644743]\n",
      " [ 0.         -0.05987034  0.12249781]\n",
      " [ 0.         -0.08803119  0.23082378]\n",
      " [ 0.         -0.09728433  0.1639383 ]\n",
      " [ 0.          0.20527829  0.07719899]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #87 | lambda learn rate = 0.0001\n",
      "Target = [[9.]\n",
      " [5.]]\n",
      "lambda end of trial = [[ 0.          0.50700533 -0.25247104]\n",
      " [ 0.          0.34689887 -0.17442257]\n",
      " [ 0.         -0.1671012   0.22432517]\n",
      " [ 0.         -0.10868507  0.17128753]\n",
      " [ 0.          0.18118412  0.00365944]\n",
      " [ 0.         -0.10416165  0.22732594]\n",
      " [ 0.         -0.05847067  0.12327541]\n",
      " [ 0.         -0.08648675  0.2316818 ]\n",
      " [ 0.         -0.09568168  0.16482866]\n",
      " [ 0.          0.2068549   0.07807489]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #88 | lambda learn rate = 0.0001\n",
      "Target = [[3.]\n",
      " [1.]]\n",
      "lambda end of trial = [[ 0.          0.50582859 -0.25286329]\n",
      " [ 0.          0.34572202 -0.17481485]\n",
      " [ 0.         -0.16831928  0.22391914]\n",
      " [ 0.         -0.10996554  0.17086071]\n",
      " [ 0.          0.18002792  0.00327405]\n",
      " [ 0.         -0.10535117  0.22692944]\n",
      " [ 0.         -0.05965613  0.12288025]\n",
      " [ 0.         -0.08774344  0.2312629 ]\n",
      " [ 0.         -0.09692637  0.16441377]\n",
      " [ 0.          0.20568049  0.07768342]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #89 | lambda learn rate = 0.0001\n",
      "Target = [[9.]\n",
      " [8.]]\n",
      "lambda end of trial = [[ 0.          0.50885426 -0.2501738 ]\n",
      " [ 0.          0.34845248 -0.17238778]\n",
      " [ 0.         -0.16539123  0.22652186]\n",
      " [ 0.         -0.10651943  0.17392392]\n",
      " [ 0.          0.18282645  0.00576163]\n",
      " [ 0.         -0.10253915  0.229429  ]\n",
      " [ 0.         -0.05700177  0.12523969]\n",
      " [ 0.         -0.08481289  0.23386783]\n",
      " [ 0.         -0.09365916  0.16731796]\n",
      " [ 0.          0.20853739  0.08022288]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #90 | lambda learn rate = 0.0001\n",
      "Target = [[7.]\n",
      " [9.]]\n",
      "lambda end of trial = [[ 0.          0.50981566 -0.24893771]\n",
      " [ 0.          0.34938772 -0.17118533]\n",
      " [ 0.         -0.16454722  0.227607  ]\n",
      " [ 0.         -0.10567996  0.17500324]\n",
      " [ 0.          0.18380471  0.00701939]\n",
      " [ 0.         -0.10160811  0.23062606]\n",
      " [ 0.         -0.0559457   0.12659749]\n",
      " [ 0.         -0.08395186  0.23497487]\n",
      " [ 0.         -0.09259008  0.16869248]\n",
      " [ 0.          0.20949413  0.08145298]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #91 | lambda learn rate = 0.0001\n",
      "Target = [[3.]\n",
      " [0.]]\n",
      "lambda end of trial = [[ 0.          0.50813111 -0.24893771]\n",
      " [ 0.          0.34768639 -0.17118533]\n",
      " [ 0.         -0.16633028  0.227607  ]\n",
      " [ 0.         -0.10730903  0.17500324]\n",
      " [ 0.          0.18201492  0.00701939]\n",
      " [ 0.         -0.10328803  0.23062606]\n",
      " [ 0.         -0.05746293  0.12659749]\n",
      " [ 0.         -0.08564545  0.23497487]\n",
      " [ 0.         -0.09431039  0.16869248]\n",
      " [ 0.          0.20759204  0.08145298]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #92 | lambda learn rate = 0.0001\n",
      "Target = [[6.]\n",
      " [9.]]\n",
      "lambda end of trial = [[ 0.          0.50866965 -0.24812991]\n",
      " [ 0.          0.34821518 -0.17039215]\n",
      " [ 0.         -0.16592266  0.22821844]\n",
      " [ 0.         -0.10681167  0.17574928]\n",
      " [ 0.          0.18240865  0.00760999]\n",
      " [ 0.         -0.10281385  0.23133733]\n",
      " [ 0.         -0.0570092   0.12727808]\n",
      " [ 0.         -0.08521845  0.23561538]\n",
      " [ 0.         -0.09382343  0.16942292]\n",
      " [ 0.          0.20796724  0.08201578]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #93 | lambda learn rate = 0.0001\n",
      "Target = [[2.]\n",
      " [8.]]\n",
      "lambda end of trial = [[ 0.          0.50824574 -0.24982556]\n",
      " [ 0.          0.34788534 -0.17171149]\n",
      " [ 0.         -0.16630935  0.22667167]\n",
      " [ 0.         -0.1072457   0.17401316]\n",
      " [ 0.          0.18192351  0.00566944]\n",
      " [ 0.         -0.10329887  0.22939724]\n",
      " [ 0.         -0.05747806  0.12540264]\n",
      " [ 0.         -0.08569786  0.23369772]\n",
      " [ 0.         -0.09431504  0.1674565 ]\n",
      " [ 0.          0.20753912  0.0803033 ]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #94 | lambda learn rate = 0.0001\n",
      "Target = [[2.]\n",
      " [2.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda end of trial = [[ 0.          0.50736266 -0.25070863]\n",
      " [ 0.          0.34697043 -0.1726264 ]\n",
      " [ 0.         -0.16722842  0.22575261]\n",
      " [ 0.         -0.10812428  0.17313457]\n",
      " [ 0.          0.18096522  0.00471115]\n",
      " [ 0.         -0.10421029  0.22848582]\n",
      " [ 0.         -0.05826975  0.12461095]\n",
      " [ 0.         -0.08658083  0.23281475]\n",
      " [ 0.         -0.09520175  0.16656979]\n",
      " [ 0.          0.20662173  0.07938591]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #95 | lambda learn rate = 0.0001\n",
      "Target = [[5.]\n",
      " [2.]]\n",
      "lambda end of trial = [[ 0.          0.50580399 -0.2513321 ]\n",
      " [ 0.          0.34539735 -0.17325564]\n",
      " [ 0.         -0.16876898  0.22513638]\n",
      " [ 0.         -0.10968109  0.17251185]\n",
      " [ 0.          0.17950209  0.0041259 ]\n",
      " [ 0.         -0.10575643  0.22786737]\n",
      " [ 0.         -0.05963843  0.12406348]\n",
      " [ 0.         -0.08810946  0.2322033 ]\n",
      " [ 0.         -0.09644312  0.16607324]\n",
      " [ 0.          0.20500513  0.07873927]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #96 | lambda learn rate = 0.0001\n",
      "Target = [[0.]\n",
      " [0.]]\n",
      "lambda end of trial = [[ 0.          0.50580399 -0.2513321 ]\n",
      " [ 0.          0.34539735 -0.17325564]\n",
      " [ 0.         -0.16876898  0.22513638]\n",
      " [ 0.         -0.10968109  0.17251185]\n",
      " [ 0.          0.17950209  0.0041259 ]\n",
      " [ 0.         -0.10575643  0.22786737]\n",
      " [ 0.         -0.05963843  0.12406348]\n",
      " [ 0.         -0.08810946  0.2322033 ]\n",
      " [ 0.         -0.09644312  0.16607324]\n",
      " [ 0.          0.20500513  0.07873927]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #97 | lambda learn rate = 0.0001\n",
      "Target = [[9.]\n",
      " [9.]]\n",
      "lambda end of trial = [[ 0.          0.50901251 -0.24812358]\n",
      " [ 0.          0.34844508 -0.17020791]\n",
      " [ 0.         -0.16546212  0.22844324]\n",
      " [ 0.         -0.10619309  0.17599985]\n",
      " [ 0.          0.18279161  0.00741542]\n",
      " [ 0.         -0.10258674  0.23103705]\n",
      " [ 0.         -0.05659304  0.12710887]\n",
      " [ 0.         -0.08464979  0.23566297]\n",
      " [ 0.         -0.0933634   0.16915296]\n",
      " [ 0.          0.20815463  0.08188877]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #98 | lambda learn rate = 0.0001\n",
      "Target = [[6.]\n",
      " [3.]]\n",
      "lambda end of trial = [[ 0.          0.50762127 -0.2488192 ]\n",
      " [ 0.          0.34718535 -0.17083778]\n",
      " [ 0.         -0.16659081  0.22787889]\n",
      " [ 0.         -0.10744054  0.17537613]\n",
      " [ 0.          0.18147327  0.00675625]\n",
      " [ 0.         -0.10390345  0.2303787 ]\n",
      " [ 0.         -0.0578075   0.12650164]\n",
      " [ 0.         -0.08598457  0.23499558]\n",
      " [ 0.         -0.09456203  0.16855364]\n",
      " [ 0.          0.20680415  0.08121353]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "+++++++++++++++++++++++++++++++++++\n",
      "Session #1\n",
      "target at trial 0 = [[1.]\n",
      " [1.]]\n",
      "K MATX INIT= [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "A VECT INIT = [-0. -0.]\n",
      "lambda\n",
      "[[ 0.          0.53020654 -0.2322202 ]\n",
      " [ 0.          0.36705474 -0.15737009]\n",
      " [ 0.         -0.14629582  0.24261404]\n",
      " [ 0.         -0.08877213  0.18799136]\n",
      " [ 0.          0.20486852  0.02360278]\n",
      " [ 0.         -0.07854344  0.25002723]\n",
      " [ 0.         -0.03748972  0.14111247]\n",
      " [ 0.         -0.0597867   0.25435404]\n",
      " [ 0.         -0.07409235  0.18348285]\n",
      " [ 0.          0.23653843  0.10488391]]\n",
      "a\n",
      "[-0. -0.]\n",
      "K\n",
      "[[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #0 | lambda learn rate = 0.0001\n",
      "Target = [[1.]\n",
      " [1.]]\n",
      "lambda end of trial = [[ 0.          0.52959716 -0.23282958]\n",
      " [ 0.          0.36639566 -0.15802917]\n",
      " [ 0.         -0.14695418  0.24195568]\n",
      " [ 0.         -0.08946477  0.18729871]\n",
      " [ 0.          0.20418186  0.02291611]\n",
      " [ 0.         -0.07929075  0.24927992]\n",
      " [ 0.         -0.03817642  0.14042578]\n",
      " [ 0.         -0.06056001  0.25358072]\n",
      " [ 0.         -0.07477144  0.18280376]\n",
      " [ 0.          0.23588276  0.10422824]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #1 | lambda learn rate = 0.0001\n",
      "Target = [[5.]\n",
      " [2.]]\n",
      "lambda end of trial = [[ 0.          0.52645697 -0.23408566]\n",
      " [ 0.          0.36306834 -0.1593601 ]\n",
      " [ 0.         -0.14999271  0.24074027]\n",
      " [ 0.         -0.0929464   0.18590606]\n",
      " [ 0.          0.20057375  0.02147287]\n",
      " [ 0.         -0.08273896  0.24790064]\n",
      " [ 0.         -0.04149203  0.13909953]\n",
      " [ 0.         -0.06399942  0.25220496]\n",
      " [ 0.         -0.07823137  0.18141979]\n",
      " [ 0.          0.23214522  0.10273323]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #2 | lambda learn rate = 0.0001\n",
      "Target = [[2.]\n",
      " [1.]]\n",
      "lambda end of trial = [[ 0.          0.52544127 -0.23459351]\n",
      " [ 0.          0.36193373 -0.1599274 ]\n",
      " [ 0.         -0.1512116   0.24013083]\n",
      " [ 0.         -0.09405541  0.18535156]\n",
      " [ 0.          0.19937485  0.02087342]\n",
      " [ 0.         -0.08397033  0.24728495]\n",
      " [ 0.         -0.04268654  0.13850228]\n",
      " [ 0.         -0.06515038  0.25162948]\n",
      " [ 0.         -0.07928983  0.18089056]\n",
      " [ 0.          0.23096926  0.10214525]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #3 | lambda learn rate = 0.0001\n",
      "Target = [[3.]\n",
      " [4.]]\n",
      "lambda end of trial = [[ 0.          0.52345159 -0.23724641]\n",
      " [ 0.          0.36015443 -0.1622998 ]\n",
      " [ 0.         -0.15326438  0.23739379]\n",
      " [ 0.         -0.09605591  0.18268422]\n",
      " [ 0.          0.19721774  0.01799728]\n",
      " [ 0.         -0.08588586  0.24473091]\n",
      " [ 0.         -0.04470497  0.13581104]\n",
      " [ 0.         -0.06719803  0.24889928]\n",
      " [ 0.         -0.08141253  0.17806029]\n",
      " [ 0.          0.22882894  0.09929148]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #4 | lambda learn rate = 0.0001\n",
      "Target = [[7.]\n",
      " [1.]]\n",
      "lambda end of trial = [[ 0.          0.51960523 -0.23779589]\n",
      " [ 0.          0.35602263 -0.16289006]\n",
      " [ 0.         -0.15723847  0.23682606]\n",
      " [ 0.         -0.09978671  0.18215125]\n",
      " [ 0.          0.19334368  0.01744384]\n",
      " [ 0.         -0.09002514  0.24413958]\n",
      " [ 0.         -0.04844416  0.13527687]\n",
      " [ 0.         -0.07128143  0.24831594]\n",
      " [ 0.         -0.08520095  0.17751909]\n",
      " [ 0.          0.22467488  0.09869805]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #5 | lambda learn rate = 0.0001\n",
      "Target = [[5.]\n",
      " [2.]]\n",
      "lambda end of trial = [[ 0.          0.51714365 -0.23878052]\n",
      " [ 0.          0.35363032 -0.16384699]\n",
      " [ 0.         -0.15988267  0.23576839]\n",
      " [ 0.         -0.10231576  0.18113963]\n",
      " [ 0.          0.19092121  0.01647485]\n",
      " [ 0.         -0.09254282  0.24313251]\n",
      " [ 0.         -0.0509798   0.13426261]\n",
      " [ 0.         -0.07367526  0.24735841]\n",
      " [ 0.         -0.08775071  0.17649918]\n",
      " [ 0.          0.22211764  0.09767515]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #6 | lambda learn rate = 0.0001\n",
      "Target = [[7.]\n",
      " [2.]]\n",
      "lambda end of trial = [[ 0.          0.5146962  -0.23947979]\n",
      " [ 0.          0.3507952  -0.16465702]\n",
      " [ 0.         -0.16255549  0.23500472]\n",
      " [ 0.         -0.10485079  0.18041534]\n",
      " [ 0.          0.18797351  0.01563266]\n",
      " [ 0.         -0.09522439  0.24236635]\n",
      " [ 0.         -0.0537474   0.13347187]\n",
      " [ 0.         -0.07650421  0.24655013]\n",
      " [ 0.         -0.09052463  0.17570664]\n",
      " [ 0.          0.21954504  0.09694012]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #7 | lambda learn rate = 0.0001\n",
      "Target = [[5.]\n",
      " [5.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda end of trial = [[ 0.          0.5127225  -0.24145349]\n",
      " [ 0.          0.34903703 -0.16641519]\n",
      " [ 0.         -0.16463673  0.23292348]\n",
      " [ 0.         -0.10675884  0.17850728]\n",
      " [ 0.          0.18612331  0.01378245]\n",
      " [ 0.         -0.09719725  0.24039349]\n",
      " [ 0.         -0.05570421  0.13151506]\n",
      " [ 0.         -0.07830378  0.24475057]\n",
      " [ 0.         -0.0922319   0.17399936]\n",
      " [ 0.          0.21762566  0.09502075]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #8 | lambda learn rate = 0.0001\n",
      "Target = [[8.]\n",
      " [9.]]\n",
      "lambda end of trial = [[ 0.          0.51214596 -0.2421021 ]\n",
      " [ 0.          0.34845925 -0.16706519]\n",
      " [ 0.         -0.1651999   0.23228992]\n",
      " [ 0.         -0.10732026  0.17787569]\n",
      " [ 0.          0.18550666  0.01308873]\n",
      " [ 0.         -0.0978819   0.23962326]\n",
      " [ 0.         -0.05627189  0.13087642]\n",
      " [ 0.         -0.07897392  0.24399666]\n",
      " [ 0.         -0.09275646  0.17340923]\n",
      " [ 0.          0.21694449  0.09425443]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #9 | lambda learn rate = 0.0001\n",
      "Target = [[4.]\n",
      " [5.]]\n",
      "lambda end of trial = [[ 0.          0.51050588 -0.24415221]\n",
      " [ 0.          0.34709003 -0.16877671]\n",
      " [ 0.         -0.16661636  0.23051934]\n",
      " [ 0.         -0.10879251  0.17603537]\n",
      " [ 0.          0.18390293  0.01108405]\n",
      " [ 0.         -0.09946034  0.23765021]\n",
      " [ 0.         -0.05778348  0.12898694]\n",
      " [ 0.         -0.08039961  0.24221454]\n",
      " [ 0.         -0.09407919  0.17175582]\n",
      " [ 0.          0.21529166  0.09218839]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #10 | lambda learn rate = 0.0001\n",
      "Target = [[5.]\n",
      " [9.]]\n",
      "lambda end of trial = [[ 0.          0.50990717 -0.24522988]\n",
      " [ 0.          0.34644418 -0.16993925]\n",
      " [ 0.         -0.16725235  0.22937456]\n",
      " [ 0.         -0.1093715   0.1749932 ]\n",
      " [ 0.          0.18324741  0.00990412]\n",
      " [ 0.         -0.10009554  0.23650685]\n",
      " [ 0.         -0.05839021  0.12789481]\n",
      " [ 0.         -0.08104463  0.24105351]\n",
      " [ 0.         -0.09473546  0.17057453]\n",
      " [ 0.          0.21452641  0.09081095]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #11 | lambda learn rate = 0.0001\n",
      "Target = [[7.]\n",
      " [4.]]\n",
      "lambda end of trial = [[ 0.          0.50869716 -0.24592131]\n",
      " [ 0.          0.34522557 -0.1706356 ]\n",
      " [ 0.         -0.16834855  0.22874816]\n",
      " [ 0.         -0.11051118  0.17434195]\n",
      " [ 0.          0.18204751  0.00921847]\n",
      " [ 0.         -0.10135454  0.23578742]\n",
      " [ 0.         -0.05950321  0.12725881]\n",
      " [ 0.         -0.08222643  0.24037819]\n",
      " [ 0.         -0.09587189  0.16992515]\n",
      " [ 0.          0.21320366  0.09005509]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #12 | lambda learn rate = 0.0001\n",
      "Target = [[3.]\n",
      " [7.]]\n",
      "lambda end of trial = [[ 0.          0.50799024 -0.24757081]\n",
      " [ 0.          0.34466126 -0.17195231]\n",
      " [ 0.         -0.16907491  0.22705331]\n",
      " [ 0.         -0.11126746  0.1725773 ]\n",
      " [ 0.          0.18135274  0.00759734]\n",
      " [ 0.         -0.10212532  0.23398894]\n",
      " [ 0.         -0.06024247  0.12553388]\n",
      " [ 0.         -0.08291571  0.23876987]\n",
      " [ 0.         -0.09658186  0.16826855]\n",
      " [ 0.          0.21239495  0.08816809]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #13 | lambda learn rate = 0.0001\n",
      "Target = [[4.]\n",
      " [7.]]\n",
      "lambda end of trial = [[ 0.          0.50749344 -0.24844021]\n",
      " [ 0.          0.34403318 -0.17305147]\n",
      " [ 0.         -0.16971598  0.22593145]\n",
      " [ 0.         -0.11179609  0.17165219]\n",
      " [ 0.          0.18064183  0.00635325]\n",
      " [ 0.         -0.10282157  0.2327705 ]\n",
      " [ 0.         -0.06084385  0.12448147]\n",
      " [ 0.         -0.08353043  0.23769412]\n",
      " [ 0.         -0.09710624  0.16735088]\n",
      " [ 0.          0.21168686  0.08692894]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #14 | lambda learn rate = 0.0001\n",
      "Target = [[0.]\n",
      " [5.]]\n",
      "lambda end of trial = [[ 0.          0.50749344 -0.25104688]\n",
      " [ 0.          0.34403318 -0.17527099]\n",
      " [ 0.         -0.16971598  0.22341574]\n",
      " [ 0.         -0.11179609  0.16931929]\n",
      " [ 0.          0.18064183  0.00413727]\n",
      " [ 0.         -0.10282157  0.23021082]\n",
      " [ 0.         -0.06084385  0.12224389]\n",
      " [ 0.         -0.08353043  0.23515931]\n",
      " [ 0.         -0.09710624  0.16507915]\n",
      " [ 0.          0.21168686  0.08463545]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #15 | lambda learn rate = 0.0001\n",
      "Target = [[4.]\n",
      " [1.]]\n",
      "lambda end of trial = [[ 0.          0.5059255  -0.25143887]\n",
      " [ 0.          0.34251068 -0.17565161]\n",
      " [ 0.         -0.17133539  0.22301089]\n",
      " [ 0.         -0.11322875  0.16896112]\n",
      " [ 0.          0.1790772   0.00374611]\n",
      " [ 0.         -0.10451018  0.22978866]\n",
      " [ 0.         -0.06253849  0.12182023]\n",
      " [ 0.         -0.08511344  0.23476356]\n",
      " [ 0.         -0.09867814  0.16468618]\n",
      " [ 0.          0.21025615  0.08427777]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #16 | lambda learn rate = 0.0001\n",
      "Target = [[3.]\n",
      " [6.]]\n",
      "lambda end of trial = [[ 0.          0.50531421 -0.25266144]\n",
      " [ 0.          0.34198134 -0.17671028]\n",
      " [ 0.         -0.17185567  0.22197032]\n",
      " [ 0.         -0.11375981  0.167899  ]\n",
      " [ 0.          0.17853103  0.00265377]\n",
      " [ 0.         -0.10515292  0.22850319]\n",
      " [ 0.         -0.06307691  0.12074339]\n",
      " [ 0.         -0.08570847  0.2335735 ]\n",
      " [ 0.         -0.0991753   0.16369186]\n",
      " [ 0.          0.20967205  0.08310956]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #17 | lambda learn rate = 0.0001\n",
      "Target = [[8.]\n",
      " [1.]]\n",
      "lambda end of trial = [[ 0.          0.50427425 -0.25279143]\n",
      " [ 0.          0.34106042 -0.1768254 ]\n",
      " [ 0.         -0.17288341  0.22184185]\n",
      " [ 0.         -0.11460792  0.16779299]\n",
      " [ 0.          0.17741923  0.00251479]\n",
      " [ 0.         -0.10623004  0.22836855]\n",
      " [ 0.         -0.06385743  0.12064582]\n",
      " [ 0.         -0.08682465  0.23343398]\n",
      " [ 0.         -0.10009006  0.16357751]\n",
      " [ 0.          0.20861309  0.08297719]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #18 | lambda learn rate = 0.0001\n",
      "Target = [[8.]\n",
      " [0.]]\n",
      "lambda end of trial = [[ 0.          0.50336533 -0.25279143]\n",
      " [ 0.          0.33999047 -0.1768254 ]\n",
      " [ 0.         -0.17395594  0.22184185]\n",
      " [ 0.         -0.11558236  0.16779299]\n",
      " [ 0.          0.1762818   0.00251479]\n",
      " [ 0.         -0.10731968  0.22836855]\n",
      " [ 0.         -0.0648769   0.12064582]\n",
      " [ 0.         -0.0880415   0.23343398]\n",
      " [ 0.         -0.10120494  0.16357751]\n",
      " [ 0.          0.20747182  0.08297719]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #19 | lambda learn rate = 0.0001\n",
      "Target = [[9.]\n",
      " [9.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda end of trial = [[ 0.          0.506817   -0.24933975]\n",
      " [ 0.          0.34372599 -0.17308989]\n",
      " [ 0.         -0.16979261  0.22600518]\n",
      " [ 0.         -0.11167522  0.17170013]\n",
      " [ 0.          0.1802145   0.00644749]\n",
      " [ 0.         -0.10355005  0.23213818]\n",
      " [ 0.         -0.06118422  0.12433851]\n",
      " [ 0.         -0.08413815  0.23733733]\n",
      " [ 0.         -0.09712499  0.16765746]\n",
      " [ 0.          0.2116201   0.08712548]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #20 | lambda learn rate = 0.0001\n",
      "Target = [[4.]\n",
      " [3.]]\n",
      "lambda end of trial = [[ 0.          0.50555044 -0.25028968]\n",
      " [ 0.          0.34264676 -0.17389931]\n",
      " [ 0.         -0.17090279  0.22517255]\n",
      " [ 0.         -0.11283268  0.17083202]\n",
      " [ 0.          0.17918616  0.00567624]\n",
      " [ 0.         -0.10482658  0.23118078]\n",
      " [ 0.         -0.06213628  0.12362446]\n",
      " [ 0.         -0.08541669  0.23637842]\n",
      " [ 0.         -0.0984001   0.16670113]\n",
      " [ 0.          0.21044571  0.08624469]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #21 | lambda learn rate = 0.0001\n",
      "Target = [[9.]\n",
      " [6.]]\n",
      "lambda end of trial = [[ 0.          0.50715042 -0.24922303]\n",
      " [ 0.          0.34430092 -0.17279653]\n",
      " [ 0.         -0.16949668  0.22610996]\n",
      " [ 0.         -0.11124701  0.17188914]\n",
      " [ 0.          0.18072621  0.00670294]\n",
      " [ 0.         -0.10320908  0.23225912]\n",
      " [ 0.         -0.06035052  0.12481497]\n",
      " [ 0.         -0.08404035  0.23729599]\n",
      " [ 0.         -0.09694686  0.16766996]\n",
      " [ 0.          0.21214162  0.08737529]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #22 | lambda learn rate = 0.0001\n",
      "Target = [[7.]\n",
      " [8.]]\n",
      "lambda end of trial = [[ 0.          0.50767209 -0.24862683]\n",
      " [ 0.          0.34482165 -0.17220142]\n",
      " [ 0.         -0.16892979  0.22675783]\n",
      " [ 0.         -0.11067258  0.17254563]\n",
      " [ 0.          0.18127168  0.00732633]\n",
      " [ 0.         -0.10277546  0.23275468]\n",
      " [ 0.         -0.05976333  0.12548603]\n",
      " [ 0.         -0.0836013   0.23779775]\n",
      " [ 0.         -0.09633224  0.16837238]\n",
      " [ 0.          0.21258539  0.08788246]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #23 | lambda learn rate = 0.0001\n",
      "Target = [[9.]\n",
      " [9.]]\n",
      "lambda end of trial = [[ 0.          0.509357   -0.24694192]\n",
      " [ 0.          0.34681492 -0.17020815]\n",
      " [ 0.         -0.16720981  0.22847781]\n",
      " [ 0.         -0.10912893  0.17408928]\n",
      " [ 0.          0.18301663  0.00907128]\n",
      " [ 0.         -0.10101889  0.23451125]\n",
      " [ 0.         -0.05792905  0.12732032]\n",
      " [ 0.         -0.08176456  0.23963449]\n",
      " [ 0.         -0.09446297  0.17024165]\n",
      " [ 0.          0.21465507  0.08995214]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #24 | lambda learn rate = 0.0001\n",
      "Target = [[7.]\n",
      " [1.]]\n",
      "lambda end of trial = [[ 0.          0.50769726 -0.24717903]\n",
      " [ 0.          0.34498296 -0.17046986]\n",
      " [ 0.         -0.16916825  0.22819803]\n",
      " [ 0.         -0.11100052  0.17382191]\n",
      " [ 0.          0.18110545  0.00879826]\n",
      " [ 0.         -0.10283624  0.23425163]\n",
      " [ 0.         -0.05972371  0.12706394]\n",
      " [ 0.         -0.08367607  0.23936142]\n",
      " [ 0.         -0.09620926  0.16999218]\n",
      " [ 0.          0.21259411  0.08965772]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #25 | lambda learn rate = 0.0001\n",
      "Target = [[3.]\n",
      " [1.]]\n",
      "lambda end of trial = [[ 0.          0.50643026 -0.24760136]\n",
      " [ 0.          0.34371517 -0.17089246]\n",
      " [ 0.         -0.17056766  0.22773156]\n",
      " [ 0.         -0.11224233  0.17340797]\n",
      " [ 0.          0.17969558  0.0083283 ]\n",
      " [ 0.         -0.10419517  0.23379865]\n",
      " [ 0.         -0.06098901  0.12664218]\n",
      " [ 0.         -0.08505272  0.23890253]\n",
      " [ 0.         -0.09752784  0.16955266]\n",
      " [ 0.          0.2111909   0.08918998]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #26 | lambda learn rate = 0.0001\n",
      "Target = [[9.]\n",
      " [9.]]\n",
      "lambda end of trial = [[ 0.          0.50841025 -0.24562137]\n",
      " [ 0.          0.34563977 -0.16896785]\n",
      " [ 0.         -0.16865543  0.22964379]\n",
      " [ 0.         -0.11002665  0.17562365]\n",
      " [ 0.          0.18187341  0.01050612]\n",
      " [ 0.         -0.10229502  0.23569881]\n",
      " [ 0.         -0.05914481  0.12848638]\n",
      " [ 0.         -0.083267    0.24068825]\n",
      " [ 0.         -0.09569632  0.17138417]\n",
      " [ 0.          0.21321543  0.09121451]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #27 | lambda learn rate = 0.0001\n",
      "Target = [[8.]\n",
      " [7.]]\n",
      "lambda end of trial = [[ 0.          0.50864069 -0.24541974]\n",
      " [ 0.          0.34599838 -0.16865407]\n",
      " [ 0.         -0.16839077  0.22987536]\n",
      " [ 0.         -0.10971786  0.17589384]\n",
      " [ 0.          0.18214409  0.01074298]\n",
      " [ 0.         -0.10210179  0.23586789]\n",
      " [ 0.         -0.0588672   0.12872929]\n",
      " [ 0.         -0.08307981  0.24085204]\n",
      " [ 0.         -0.09533854  0.17169723]\n",
      " [ 0.          0.2134552   0.09142431]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #28 | lambda learn rate = 0.0001\n",
      "Target = [[4.]\n",
      " [2.]]\n",
      "lambda end of trial = [[ 0.          0.50706126 -0.24620946]\n",
      " [ 0.          0.34450294 -0.16940179]\n",
      " [ 0.         -0.16994937  0.22909606]\n",
      " [ 0.         -0.11119964  0.17515295]\n",
      " [ 0.          0.18059904  0.00997045]\n",
      " [ 0.         -0.10364686  0.23509535]\n",
      " [ 0.         -0.06049542  0.12791518]\n",
      " [ 0.         -0.08466864  0.24005763]\n",
      " [ 0.         -0.09696648  0.17088326]\n",
      " [ 0.          0.21169837  0.09054589]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #29 | lambda learn rate = 0.0001\n",
      "Target = [[8.]\n",
      " [6.]]\n",
      "lambda end of trial = [[ 0.          0.50731038 -0.24602261]\n",
      " [ 0.          0.34471079 -0.1692459 ]\n",
      " [ 0.         -0.16970123  0.22928217]\n",
      " [ 0.         -0.11094104  0.1753469 ]\n",
      " [ 0.          0.18089451  0.01019205]\n",
      " [ 0.         -0.10345698  0.23523776]\n",
      " [ 0.         -0.06019771  0.12813846]\n",
      " [ 0.         -0.08447579  0.24020226]\n",
      " [ 0.         -0.09671685  0.17107048]\n",
      " [ 0.          0.21182396  0.09064009]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #30 | lambda learn rate = 0.0001\n",
      "Target = [[4.]\n",
      " [8.]]\n",
      "lambda end of trial = [[ 0.          0.5067935  -0.24705638]\n",
      " [ 0.          0.34418055 -0.17030639]\n",
      " [ 0.         -0.17030484  0.22807495]\n",
      " [ 0.         -0.11150726  0.17421447]\n",
      " [ 0.          0.18036787  0.00913877]\n",
      " [ 0.         -0.10401733  0.23411706]\n",
      " [ 0.         -0.06069186  0.12715016]\n",
      " [ 0.         -0.08505122  0.23905141]\n",
      " [ 0.         -0.09727171  0.16996076]\n",
      " [ 0.          0.21118437  0.08936091]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #31 | lambda learn rate = 0.0001\n",
      "Target = [[4.]\n",
      " [4.]]\n",
      "lambda end of trial = [[ 0.          0.50592289 -0.24792698]\n",
      " [ 0.          0.34322288 -0.17126406]\n",
      " [ 0.         -0.1712809   0.22709889]\n",
      " [ 0.         -0.11245439  0.17326734]\n",
      " [ 0.          0.1794716   0.0082425 ]\n",
      " [ 0.         -0.1050739   0.23306048]\n",
      " [ 0.         -0.06173683  0.12610519]\n",
      " [ 0.         -0.08607722  0.23802541]\n",
      " [ 0.         -0.0982004   0.16903207]\n",
      " [ 0.          0.21018867  0.08836521]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #32 | lambda learn rate = 0.0001\n",
      "Target = [[9.]\n",
      " [4.]]\n",
      "lambda end of trial = [[ 0.          0.50658165 -0.2476342 ]\n",
      " [ 0.          0.34380093 -0.17100715]\n",
      " [ 0.         -0.17058103  0.22740994]\n",
      " [ 0.         -0.11177601  0.17356884]\n",
      " [ 0.          0.18009128  0.00851791]\n",
      " [ 0.         -0.1044658   0.23333075]\n",
      " [ 0.         -0.06098413  0.12643972]\n",
      " [ 0.         -0.08546748  0.2382964 ]\n",
      " [ 0.         -0.09749811  0.1693442 ]\n",
      " [ 0.          0.21069968  0.08859233]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #33 | lambda learn rate = 0.0001\n",
      "Target = [[1.]\n",
      " [5.]]\n",
      "lambda end of trial = [[ 0.          0.50617088 -0.24968804]\n",
      " [ 0.          0.34337391 -0.17314225]\n",
      " [ 0.         -0.1709568   0.22553113]\n",
      " [ 0.         -0.11213162  0.17179079]\n",
      " [ 0.          0.17962882  0.00620558]\n",
      " [ 0.         -0.10486176  0.23135097]\n",
      " [ 0.         -0.06135099  0.12460542]\n",
      " [ 0.         -0.08586684  0.23629962]\n",
      " [ 0.         -0.09789054  0.16738203]\n",
      " [ 0.          0.21028646  0.08652622]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #34 | lambda learn rate = 0.0001\n",
      "Target = [[5.]\n",
      " [2.]]\n",
      "lambda end of trial = [[ 0.          0.5046052  -0.25031431]\n",
      " [ 0.          0.34191414 -0.17372616]\n",
      " [ 0.         -0.17259889  0.22487429]\n",
      " [ 0.         -0.11362658  0.17119281]\n",
      " [ 0.          0.17804393  0.00557163]\n",
      " [ 0.         -0.1066554   0.23063351]\n",
      " [ 0.         -0.06280565  0.12402356]\n",
      " [ 0.         -0.08758442  0.23561259]\n",
      " [ 0.         -0.09937796  0.16678706]\n",
      " [ 0.          0.20843286  0.08578478]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #35 | lambda learn rate = 0.0001\n",
      "Target = [[4.]\n",
      " [1.]]\n",
      "lambda end of trial = [[ 0.          0.50315623 -0.25067655]\n",
      " [ 0.          0.34039449 -0.17410607]\n",
      " [ 0.         -0.17382973  0.22456658]\n",
      " [ 0.         -0.11512018  0.17081941]\n",
      " [ 0.          0.1764065   0.00516227]\n",
      " [ 0.         -0.10810694  0.23027062]\n",
      " [ 0.         -0.06424095  0.12366474]\n",
      " [ 0.         -0.08927156  0.2351908 ]\n",
      " [ 0.         -0.10090992  0.16640408]\n",
      " [ 0.          0.2066835   0.08534744]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #36 | lambda learn rate = 0.0001\n",
      "Target = [[0.]\n",
      " [7.]]\n",
      "lambda end of trial = [[ 0.          0.50315623 -0.25312814]\n",
      " [ 0.          0.34039449 -0.17657009]\n",
      " [ 0.         -0.17382973  0.22231226]\n",
      " [ 0.         -0.11512018  0.16847701]\n",
      " [ 0.          0.1764065   0.00296635]\n",
      " [ 0.         -0.10810694  0.22804436]\n",
      " [ 0.         -0.06424095  0.12123783]\n",
      " [ 0.         -0.08927156  0.23278438]\n",
      " [ 0.         -0.10090992  0.16435709]\n",
      " [ 0.          0.2066835   0.0828351 ]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #37 | lambda learn rate = 0.0001\n",
      "Target = [[5.]\n",
      " [3.]]\n",
      "lambda end of trial = [[ 0.          0.50225906 -0.25366643]\n",
      " [ 0.          0.33953375 -0.17708653]\n",
      " [ 0.         -0.17469641  0.22179225]\n",
      " [ 0.         -0.11597019  0.16796701]\n",
      " [ 0.          0.17558146  0.00247132]\n",
      " [ 0.         -0.10903718  0.22748621]\n",
      " [ 0.         -0.06504488  0.12075547]\n",
      " [ 0.         -0.09020446  0.23222464]\n",
      " [ 0.         -0.10170756  0.1638785 ]\n",
      " [ 0.          0.20567746  0.08223148]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #38 | lambda learn rate = 0.0001\n",
      "Target = [[1.]\n",
      " [7.]]\n",
      "lambda end of trial = [[ 0.          0.50206961 -0.25499259]\n",
      " [ 0.          0.3393347  -0.17847982]\n",
      " [ 0.         -0.1749163   0.22025305]\n",
      " [ 0.         -0.11616736  0.16658681]\n",
      " [ 0.          0.17537042  0.00099405]\n",
      " [ 0.         -0.10924652  0.22602083]\n",
      " [ 0.         -0.06525199  0.11930574]\n",
      " [ 0.         -0.09041227  0.23076994]\n",
      " [ 0.         -0.10189997  0.16253164]\n",
      " [ 0.          0.20544634  0.08061364]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #39 | lambda learn rate = 0.0001\n",
      "Target = [[6.]\n",
      " [7.]]\n",
      "lambda end of trial = [[ 0.          0.5031377  -0.25374649]\n",
      " [ 0.          0.34047366 -0.17715104]\n",
      " [ 0.         -0.17391725  0.2214186 ]\n",
      " [ 0.         -0.11507649  0.16785949]\n",
      " [ 0.          0.1762613   0.00203341]\n",
      " [ 0.         -0.10819225  0.22725082]\n",
      " [ 0.         -0.06404974  0.12070836]\n",
      " [ 0.         -0.08943442  0.23191076]\n",
      " [ 0.         -0.10088472  0.1637161 ]\n",
      " [ 0.          0.20639907  0.08172515]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #40 | lambda learn rate = 0.0001\n",
      "Target = [[5.]\n",
      " [6.]]\n",
      "lambda end of trial = [[ 0.          0.50304949 -0.25385234]\n",
      " [ 0.          0.34045876 -0.17716892]\n",
      " [ 0.         -0.17394405  0.22138644]\n",
      " [ 0.         -0.11517421  0.16774223]\n",
      " [ 0.          0.17624115  0.00200923]\n",
      " [ 0.         -0.10823604  0.22719827]\n",
      " [ 0.         -0.0640509   0.12070697]\n",
      " [ 0.         -0.08952303  0.23180443]\n",
      " [ 0.         -0.1009123   0.163683  ]\n",
      " [ 0.          0.20628369  0.0815867 ]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #41 | lambda learn rate = 0.0001\n",
      "Target = [[2.]\n",
      " [0.]]\n",
      "lambda end of trial = [[ 0.          0.50205414 -0.25385234]\n",
      " [ 0.          0.33940096 -0.17716892]\n",
      " [ 0.         -0.17512772  0.22138644]\n",
      " [ 0.         -0.1161915   0.16774223]\n",
      " [ 0.          0.17523964  0.00200923]\n",
      " [ 0.         -0.10931003  0.22719827]\n",
      " [ 0.         -0.06507592  0.12070697]\n",
      " [ 0.         -0.0906023   0.23180443]\n",
      " [ 0.         -0.10199806  0.163683  ]\n",
      " [ 0.          0.20517824  0.0815867 ]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #42 | lambda learn rate = 0.0001\n",
      "Target = [[7.]\n",
      " [5.]]\n",
      "lambda end of trial = [[ 0.          0.50293831 -0.25322079]\n",
      " [ 0.          0.34025882 -0.17655616]\n",
      " [ 0.         -0.17419502  0.22205265]\n",
      " [ 0.         -0.11542037  0.16829303]\n",
      " [ 0.          0.17616333  0.00266901]\n",
      " [ 0.         -0.10841696  0.22783618]\n",
      " [ 0.         -0.06421603  0.12132118]\n",
      " [ 0.         -0.0898025   0.23237571]\n",
      " [ 0.         -0.10113597  0.16429878]\n",
      " [ 0.          0.20586839  0.08207966]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #43 | lambda learn rate = 0.0001\n",
      "Target = [[2.]\n",
      " [5.]]\n",
      "lambda end of trial = [[ 0.          0.50234484 -0.25470447]\n",
      " [ 0.          0.33961488 -0.17816603]\n",
      " [ 0.         -0.17487996  0.2203403 ]\n",
      " [ 0.         -0.11605167  0.1667148 ]\n",
      " [ 0.          0.17553141  0.00108923]\n",
      " [ 0.         -0.10902191  0.2263238 ]\n",
      " [ 0.         -0.06484917  0.11973834]\n",
      " [ 0.         -0.09044973  0.23075766]\n",
      " [ 0.         -0.10181019  0.16261321]\n",
      " [ 0.          0.20521442  0.08044472]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #44 | lambda learn rate = 0.0001\n",
      "Target = [[8.]\n",
      " [0.]]\n",
      "lambda end of trial = [[ 0.          0.50189092 -0.25470447]\n",
      " [ 0.          0.33921904 -0.17816603]\n",
      " [ 0.         -0.17533962  0.2203403 ]\n",
      " [ 0.         -0.11646506  0.1667148 ]\n",
      " [ 0.          0.17514311  0.00108923]\n",
      " [ 0.         -0.10947257  0.2263238 ]\n",
      " [ 0.         -0.06525154  0.11973834]\n",
      " [ 0.         -0.09109247  0.23075766]\n",
      " [ 0.         -0.10238815  0.16261321]\n",
      " [ 0.          0.20464862  0.08044472]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #45 | lambda learn rate = 0.0001\n",
      "Target = [[8.]\n",
      " [3.]]\n",
      "lambda end of trial = [[ 0.          0.50262017 -0.254431  ]\n",
      " [ 0.          0.33997169 -0.17788378]\n",
      " [ 0.         -0.17466038  0.22059502]\n",
      " [ 0.         -0.11574029  0.16698659]\n",
      " [ 0.          0.1758862   0.00136789]\n",
      " [ 0.         -0.10880668  0.22657351]\n",
      " [ 0.         -0.06443994  0.12004269]\n",
      " [ 0.         -0.09040159  0.23101673]\n",
      " [ 0.         -0.1015774   0.16291725]\n",
      " [ 0.          0.20541037  0.08073038]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #46 | lambda learn rate = 0.0001\n",
      "Target = [[0.]\n",
      " [3.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda end of trial = [[ 0.00000000e+00  5.02620174e-01 -2.55970510e-01]\n",
      " [ 0.00000000e+00  3.39971689e-01 -1.79336692e-01]\n",
      " [ 0.00000000e+00 -1.74660376e-01  2.19160353e-01]\n",
      " [ 0.00000000e+00 -1.15740288e-01  1.65574086e-01]\n",
      " [ 0.00000000e+00  1.75886199e-01 -1.52871151e-04]\n",
      " [ 0.00000000e+00 -1.08806682e-01  2.25048598e-01]\n",
      " [ 0.00000000e+00 -6.44399433e-02  1.18509355e-01]\n",
      " [ 0.00000000e+00 -9.04015924e-02  2.29484297e-01]\n",
      " [ 0.00000000e+00 -1.01577399e-01  1.61434717e-01]\n",
      " [ 0.00000000e+00  2.05410373e-01  7.89903044e-02]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #47 | lambda learn rate = 0.0001\n",
      "Target = [[4.]\n",
      " [1.]]\n",
      "lambda end of trial = [[ 0.00000000e+00  5.01202051e-01 -2.56325041e-01]\n",
      " [ 0.00000000e+00  3.38615383e-01 -1.79675769e-01]\n",
      " [ 0.00000000e+00 -1.75843985e-01  2.18864451e-01]\n",
      " [ 0.00000000e+00 -1.16956216e-01  1.65270105e-01]\n",
      " [ 0.00000000e+00  1.74568796e-01 -4.82221950e-04]\n",
      " [ 0.00000000e+00 -1.10218948e-01  2.24695531e-01]\n",
      " [ 0.00000000e+00 -6.57446169e-02  1.18183187e-01]\n",
      " [ 0.00000000e+00 -9.17083744e-02  2.29157602e-01]\n",
      " [ 0.00000000e+00 -1.02817662e-01  1.61124651e-01]\n",
      " [ 0.00000000e+00  2.03985065e-01  7.86339775e-02]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #48 | lambda learn rate = 0.0001\n",
      "Target = [[6.]\n",
      " [8.]]\n",
      "lambda end of trial = [[ 0.          0.50278651 -0.25421244]\n",
      " [ 0.          0.34026425 -0.17747727]\n",
      " [ 0.         -0.174187    0.22107377]\n",
      " [ 0.         -0.11527062  0.16751756]\n",
      " [ 0.          0.17633744  0.00187597]\n",
      " [ 0.         -0.10847124  0.2270258 ]\n",
      " [ 0.         -0.06412087  0.12034818]\n",
      " [ 0.         -0.08992856  0.23153069]\n",
      " [ 0.         -0.10116905  0.16332279]\n",
      " [ 0.          0.20562428  0.0808196 ]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #49 | lambda learn rate = 0.0001\n",
      "Target = [[6.]\n",
      " [5.]]\n",
      "lambda end of trial = [[ 0.          0.50302405 -0.25401448]\n",
      " [ 0.          0.34058874 -0.17720687]\n",
      " [ 0.         -0.17392495  0.22129215]\n",
      " [ 0.         -0.1150449   0.16770567]\n",
      " [ 0.          0.17655402  0.00205646]\n",
      " [ 0.         -0.10830851  0.22716141]\n",
      " [ 0.         -0.063871    0.12055641]\n",
      " [ 0.         -0.08978894  0.23164704]\n",
      " [ 0.         -0.10096358  0.16349403]\n",
      " [ 0.          0.20572512  0.08090363]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #50 | lambda learn rate = 0.0001\n",
      "Target = [[4.]\n",
      " [9.]]\n",
      "lambda end of trial = [[ 0.          0.50344996 -0.25305618]\n",
      " [ 0.          0.34115697 -0.17592835]\n",
      " [ 0.         -0.17344517  0.22237163]\n",
      " [ 0.         -0.11460301  0.16869992]\n",
      " [ 0.          0.17704689  0.0031654 ]\n",
      " [ 0.         -0.10791472  0.22804745]\n",
      " [ 0.         -0.06335215  0.12172383]\n",
      " [ 0.         -0.08933627  0.23266554]\n",
      " [ 0.         -0.10049786  0.1645419 ]\n",
      " [ 0.          0.20610564  0.0817598 ]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #51 | lambda learn rate = 0.0001\n",
      "Target = [[6.]\n",
      " [5.]]\n",
      "lambda end of trial = [[ 0.          0.50350256 -0.25301235]\n",
      " [ 0.          0.34120992 -0.17588423]\n",
      " [ 0.         -0.17345521  0.22236327]\n",
      " [ 0.         -0.11465124  0.16865973]\n",
      " [ 0.          0.17704468  0.00316356]\n",
      " [ 0.         -0.10797005  0.22800133]\n",
      " [ 0.         -0.06333553  0.12173768]\n",
      " [ 0.         -0.08937654  0.23263198]\n",
      " [ 0.         -0.10046351  0.16457052]\n",
      " [ 0.          0.20604377  0.08170824]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #52 | lambda learn rate = 0.0001\n",
      "Target = [[3.]\n",
      " [7.]]\n",
      "lambda end of trial = [[ 0.          0.50323016 -0.25364795]\n",
      " [ 0.          0.34099303 -0.17639029]\n",
      " [ 0.         -0.17372226  0.22174014]\n",
      " [ 0.         -0.11488575  0.16811254]\n",
      " [ 0.          0.1767924   0.0025749 ]\n",
      " [ 0.         -0.10823001  0.22739477]\n",
      " [ 0.         -0.06359562  0.1211308 ]\n",
      " [ 0.         -0.08966351  0.2319624 ]\n",
      " [ 0.         -0.10072725  0.16395512]\n",
      " [ 0.          0.20576711  0.08106271]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #53 | lambda learn rate = 0.0001\n",
      "Target = [[0.]\n",
      " [1.]]\n",
      "lambda end of trial = [[ 0.          0.50323016 -0.25425592]\n",
      " [ 0.          0.34099303 -0.17704224]\n",
      " [ 0.         -0.17372226  0.22109704]\n",
      " [ 0.         -0.11488575  0.1674563 ]\n",
      " [ 0.          0.1767924   0.00194017]\n",
      " [ 0.         -0.10823001  0.22673325]\n",
      " [ 0.         -0.06359562  0.120559  ]\n",
      " [ 0.         -0.08966351  0.23126048]\n",
      " [ 0.         -0.10072725  0.1633139 ]\n",
      " [ 0.          0.20576711  0.08039485]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #54 | lambda learn rate = 0.0001\n",
      "Target = [[9.]\n",
      " [0.]]\n",
      "lambda end of trial = [[ 0.          0.50294997 -0.25425592]\n",
      " [ 0.          0.34068759 -0.17704224]\n",
      " [ 0.         -0.17392865  0.22109704]\n",
      " [ 0.         -0.11504717  0.1674563 ]\n",
      " [ 0.          0.17654097  0.00194017]\n",
      " [ 0.         -0.10845192  0.22673325]\n",
      " [ 0.         -0.06382231  0.120559  ]\n",
      " [ 0.         -0.08995226  0.23126048]\n",
      " [ 0.         -0.10099763  0.1633139 ]\n",
      " [ 0.          0.20534837  0.08039485]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #55 | lambda learn rate = 0.0001\n",
      "Target = [[2.]\n",
      " [5.]]\n",
      "lambda end of trial = [[ 0.00000000e+00  5.02400454e-01 -2.55629704e-01]\n",
      " [ 0.00000000e+00  3.40181877e-01 -1.78306526e-01]\n",
      " [ 0.00000000e+00 -1.74467897e-01  2.19748917e-01]\n",
      " [ 0.00000000e+00 -1.15571739e-01  1.66144880e-01]\n",
      " [ 0.00000000e+00  1.75961905e-01  4.92512363e-04]\n",
      " [ 0.00000000e+00 -1.09003287e-01  2.25354823e-01]\n",
      " [ 0.00000000e+00 -6.43557883e-02  1.19225292e-01]\n",
      " [ 0.00000000e+00 -9.04742497e-02  2.29955501e-01]\n",
      " [ 0.00000000e+00 -1.01538069e-01  1.61962795e-01]\n",
      " [ 0.00000000e+00  2.04772720e-01  7.89557300e-02]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #56 | lambda learn rate = 0.0001\n",
      "Target = [[5.]\n",
      " [5.]]\n",
      "lambda end of trial = [[ 0.00000000e+00  5.02328426e-01 -2.55701731e-01]\n",
      " [ 0.00000000e+00  3.40195098e-01 -1.78293305e-01]\n",
      " [ 0.00000000e+00 -1.74496041e-01  2.19720772e-01]\n",
      " [ 0.00000000e+00 -1.15625621e-01  1.66090999e-01]\n",
      " [ 0.00000000e+00  1.75950187e-01  4.80793845e-04]\n",
      " [ 0.00000000e+00 -1.09112307e-01  2.25245803e-01]\n",
      " [ 0.00000000e+00 -6.43883530e-02  1.19192727e-01]\n",
      " [ 0.00000000e+00 -9.05895038e-02  2.29840247e-01]\n",
      " [ 0.00000000e+00 -1.01626148e-01  1.61874716e-01]\n",
      " [ 0.00000000e+00  2.04595687e-01  7.87786976e-02]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #57 | lambda learn rate = 0.0001\n",
      "Target = [[9.]\n",
      " [3.]]\n",
      "lambda end of trial = [[ 0.          0.50373199 -0.25523388]\n",
      " [ 0.          0.34176911 -0.17776863]\n",
      " [ 0.         -0.17289135  0.22025567]\n",
      " [ 0.         -0.1141449   0.16658457]\n",
      " [ 0.          0.17752999  0.0010074 ]\n",
      " [ 0.         -0.1075831   0.22575554]\n",
      " [ 0.         -0.06275105  0.1197385 ]\n",
      " [ 0.         -0.08903825  0.23035733]\n",
      " [ 0.         -0.10011481  0.16237849]\n",
      " [ 0.          0.20604     0.07926014]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #58 | lambda learn rate = 0.0001\n",
      "Target = [[9.]\n",
      " [5.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda end of trial = [[ 0.          0.50585896 -0.25405223]\n",
      " [ 0.          0.34391859 -0.17657448]\n",
      " [ 0.         -0.17089433  0.22136512]\n",
      " [ 0.         -0.11211999  0.16770952]\n",
      " [ 0.          0.17952917  0.00211805]\n",
      " [ 0.         -0.10560272  0.22685575]\n",
      " [ 0.         -0.06064568  0.12090814]\n",
      " [ 0.         -0.08694264  0.23152156]\n",
      " [ 0.         -0.09793241  0.16359094]\n",
      " [ 0.          0.20818743  0.08045315]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #59 | lambda learn rate = 0.0001\n",
      "Target = [[6.]\n",
      " [6.]]\n",
      "lambda end of trial = [[ 0.          0.50605043 -0.25386075]\n",
      " [ 0.          0.34412317 -0.1763699 ]\n",
      " [ 0.         -0.1707857   0.22147376]\n",
      " [ 0.         -0.11193005  0.16789946]\n",
      " [ 0.          0.17971288  0.00230176]\n",
      " [ 0.         -0.10543985  0.22701862]\n",
      " [ 0.         -0.06053463  0.1210192 ]\n",
      " [ 0.         -0.08682065  0.23164355]\n",
      " [ 0.         -0.09774211  0.16378124]\n",
      " [ 0.          0.2083075   0.08057322]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #60 | lambda learn rate = 0.0001\n",
      "Target = [[1.]\n",
      " [1.]]\n",
      "lambda end of trial = [[ 0.          0.50552011 -0.25439108]\n",
      " [ 0.          0.34363042 -0.17686265]\n",
      " [ 0.         -0.17131034  0.22094911]\n",
      " [ 0.         -0.11248016  0.16734935]\n",
      " [ 0.          0.17922872  0.0018176 ]\n",
      " [ 0.         -0.10594747  0.226511  ]\n",
      " [ 0.         -0.06106771  0.12048611]\n",
      " [ 0.         -0.08734774  0.23111646]\n",
      " [ 0.         -0.09829394  0.16322941]\n",
      " [ 0.          0.20777845  0.08004417]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #61 | lambda learn rate = 0.0001\n",
      "Target = [[4.]\n",
      " [4.]]\n",
      "lambda end of trial = [[ 0.          0.5047551  -0.25515608]\n",
      " [ 0.          0.34286754 -0.17762552]\n",
      " [ 0.         -0.1720901   0.22016936]\n",
      " [ 0.         -0.11321253  0.16661698]\n",
      " [ 0.          0.17849055  0.00107943]\n",
      " [ 0.         -0.106727    0.22573147]\n",
      " [ 0.         -0.06180434  0.11974948]\n",
      " [ 0.         -0.08808379  0.23038041]\n",
      " [ 0.         -0.09905284  0.16247051]\n",
      " [ 0.          0.20690179  0.07916751]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #62 | lambda learn rate = 0.0001\n",
      "Target = [[2.]\n",
      " [3.]]\n",
      "lambda end of trial = [[ 0.00000000e+00  5.03945248e-01 -2.56370866e-01]\n",
      " [ 0.00000000e+00  3.42016335e-01 -1.78902337e-01]\n",
      " [ 0.00000000e+00 -1.72904485e-01  2.18947780e-01]\n",
      " [ 0.00000000e+00 -1.14061335e-01  1.65343773e-01]\n",
      " [ 0.00000000e+00  1.77602544e-01 -2.52578772e-04]\n",
      " [ 0.00000000e+00 -1.07488961e-01  2.24588529e-01]\n",
      " [ 0.00000000e+00 -6.26055084e-02  1.18547733e-01]\n",
      " [ 0.00000000e+00 -8.88673385e-02  2.29205086e-01]\n",
      " [ 0.00000000e+00 -9.99130988e-02  1.61180121e-01]\n",
      " [ 0.00000000e+00  2.06017105e-01  7.78404831e-02]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #63 | lambda learn rate = 0.0001\n",
      "Target = [[4.]\n",
      " [4.]]\n",
      "lambda end of trial = [[ 0.          0.5033494  -0.25696672]\n",
      " [ 0.          0.34142702 -0.17949166]\n",
      " [ 0.         -0.17343589  0.21841638]\n",
      " [ 0.         -0.11471042  0.16469468]\n",
      " [ 0.          0.1770387  -0.00081643]\n",
      " [ 0.         -0.10813086  0.22394663]\n",
      " [ 0.         -0.06321385  0.11793939]\n",
      " [ 0.         -0.08942157  0.22865086]\n",
      " [ 0.         -0.10052984  0.16056338]\n",
      " [ 0.          0.20534249  0.07716586]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #64 | lambda learn rate = 0.0001\n",
      "Target = [[7.]\n",
      " [5.]]\n",
      "lambda end of trial = [[ 0.00000000e+00  5.04223432e-01 -2.56342407e-01]\n",
      " [ 0.00000000e+00  3.42415617e-01 -1.78785512e-01]\n",
      " [ 0.00000000e+00 -1.72474986e-01  2.19102737e-01]\n",
      " [ 0.00000000e+00 -1.13753738e-01  1.65378031e-01]\n",
      " [ 0.00000000e+00  1.77932536e-01 -1.77968714e-04]\n",
      " [ 0.00000000e+00 -1.07188367e-01  2.24619837e-01]\n",
      " [ 0.00000000e+00 -6.22195386e-02  1.18649614e-01]\n",
      " [ 0.00000000e+00 -8.84987987e-02  2.29309978e-01]\n",
      " [ 0.00000000e+00 -9.95658266e-02  1.61251960e-01]\n",
      " [ 0.00000000e+00  2.06176652e-01  7.77616974e-02]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #65 | lambda learn rate = 0.0001\n",
      "Target = [[6.]\n",
      " [8.]]\n",
      "lambda end of trial = [[ 0.          0.50553501 -0.25459364]\n",
      " [ 0.          0.3436666  -0.17711754]\n",
      " [ 0.         -0.17124579  0.22074167]\n",
      " [ 0.         -0.11239599  0.16718836]\n",
      " [ 0.          0.17919465  0.00150485]\n",
      " [ 0.         -0.10582105  0.22644293]\n",
      " [ 0.         -0.06090909  0.12039688]\n",
      " [ 0.         -0.08722166  0.23101283]\n",
      " [ 0.         -0.09841142  0.16279117]\n",
      " [ 0.          0.20735086  0.07932731]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #66 | lambda learn rate = 0.0001\n",
      "Target = [[9.]\n",
      " [8.]]\n",
      "lambda end of trial = [[ 0.          0.50871806 -0.25176426]\n",
      " [ 0.          0.346934   -0.17421318]\n",
      " [ 0.         -0.1677333   0.22386388]\n",
      " [ 0.         -0.10890779  0.17028898]\n",
      " [ 0.          0.18220989  0.00418506]\n",
      " [ 0.         -0.10302264  0.22893041]\n",
      " [ 0.         -0.05738283  0.12353133]\n",
      " [ 0.         -0.08410802  0.23378051]\n",
      " [ 0.         -0.09502035  0.16580545]\n",
      " [ 0.          0.21078571  0.08238051]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #67 | lambda learn rate = 0.0001\n",
      "Target = [[7.]\n",
      " [0.]]\n",
      "lambda end of trial = [[ 0.          0.50700523 -0.25176426]\n",
      " [ 0.          0.3451018  -0.17421318]\n",
      " [ 0.         -0.16946502  0.22386388]\n",
      " [ 0.         -0.11053232  0.17028898]\n",
      " [ 0.          0.180439    0.00418506]\n",
      " [ 0.         -0.10477274  0.22893041]\n",
      " [ 0.         -0.05927939  0.12353133]\n",
      " [ 0.         -0.08602746  0.23378051]\n",
      " [ 0.         -0.09684448  0.16580545]\n",
      " [ 0.          0.20903541  0.08238051]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #68 | lambda learn rate = 0.0001\n",
      "Target = [[1.]\n",
      " [5.]]\n",
      "lambda end of trial = [[ 0.          0.50661925 -0.25369416]\n",
      " [ 0.          0.34473203 -0.176062  ]\n",
      " [ 0.         -0.16980529  0.22216249]\n",
      " [ 0.         -0.11093113  0.16829493]\n",
      " [ 0.          0.18001135  0.00204681]\n",
      " [ 0.         -0.1051666   0.22696113]\n",
      " [ 0.         -0.05965155  0.12167052]\n",
      " [ 0.         -0.08643896  0.23172302]\n",
      " [ 0.         -0.09726512  0.16370225]\n",
      " [ 0.          0.20869246  0.08066581]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #69 | lambda learn rate = 0.0001\n",
      "Target = [[5.]\n",
      " [2.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda end of trial = [[ 0.          0.50532269 -0.25421278]\n",
      " [ 0.          0.34338979 -0.1765989 ]\n",
      " [ 0.         -0.17117025  0.22161651]\n",
      " [ 0.         -0.11226269  0.16776231]\n",
      " [ 0.          0.17854165  0.00145893]\n",
      " [ 0.         -0.10647833  0.22643643]\n",
      " [ 0.         -0.06110479  0.12108922]\n",
      " [ 0.         -0.08791245  0.23113362]\n",
      " [ 0.         -0.09859477  0.16317039]\n",
      " [ 0.          0.2072904   0.08010498]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #70 | lambda learn rate = 0.0001\n",
      "Target = [[7.]\n",
      " [5.]]\n",
      "lambda end of trial = [[ 0.          0.50577188 -0.25389193]\n",
      " [ 0.          0.34389177 -0.17624035]\n",
      " [ 0.         -0.17070518  0.2219487 ]\n",
      " [ 0.         -0.11172955  0.16814313]\n",
      " [ 0.          0.17899548  0.0017831 ]\n",
      " [ 0.         -0.10616208  0.22666233]\n",
      " [ 0.         -0.0606038   0.12144707]\n",
      " [ 0.         -0.0874371   0.23147315]\n",
      " [ 0.         -0.09809154  0.16352984]\n",
      " [ 0.          0.20759981  0.08032599]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #71 | lambda learn rate = 0.0001\n",
      "Target = [[9.]\n",
      " [9.]]\n",
      "lambda end of trial = [[ 0.          0.50947214 -0.25019167]\n",
      " [ 0.          0.34769241 -0.1724397 ]\n",
      " [ 0.         -0.16725147  0.22540241]\n",
      " [ 0.         -0.10819224  0.17168043]\n",
      " [ 0.          0.18273264  0.00552026]\n",
      " [ 0.         -0.10221952  0.23060488]\n",
      " [ 0.         -0.05747187  0.12457899]\n",
      " [ 0.         -0.08389183  0.23501843]\n",
      " [ 0.         -0.09424467  0.16737671]\n",
      " [ 0.          0.21102827  0.08375445]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #72 | lambda learn rate = 0.0001\n",
      "Target = [[7.]\n",
      " [3.]]\n",
      "lambda end of trial = [[ 0.          0.50837704 -0.250661  ]\n",
      " [ 0.          0.34667703 -0.17287487]\n",
      " [ 0.         -0.16828234  0.22496061]\n",
      " [ 0.         -0.10912924  0.17127886]\n",
      " [ 0.          0.1817335   0.00509205]\n",
      " [ 0.         -0.10325957  0.23015915]\n",
      " [ 0.         -0.05852738  0.12412664]\n",
      " [ 0.         -0.08495723  0.23456183]\n",
      " [ 0.         -0.09532991  0.1669116 ]\n",
      " [ 0.          0.20986943  0.0832578 ]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #73 | lambda learn rate = 0.0001\n",
      "Target = [[7.]\n",
      " [0.]]\n",
      "lambda end of trial = [[ 0.          0.50645106 -0.250661  ]\n",
      " [ 0.          0.34480044 -0.17287487]\n",
      " [ 0.         -0.17048437  0.22496061]\n",
      " [ 0.         -0.1109918   0.17127886]\n",
      " [ 0.          0.17960748  0.00509205]\n",
      " [ 0.         -0.1054861   0.23015915]\n",
      " [ 0.         -0.06071883  0.12412664]\n",
      " [ 0.         -0.08704971  0.23456183]\n",
      " [ 0.         -0.09713774  0.1669116 ]\n",
      " [ 0.          0.20751742  0.0832578 ]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #74 | lambda learn rate = 0.0001\n",
      "Target = [[8.]\n",
      " [6.]]\n",
      "lambda end of trial = [[ 0.          0.50743536 -0.24992278]\n",
      " [ 0.          0.34592217 -0.17203357]\n",
      " [ 0.         -0.16957798  0.2256404 ]\n",
      " [ 0.         -0.1100309   0.17199953]\n",
      " [ 0.          0.18049642  0.00575875]\n",
      " [ 0.         -0.10461713  0.23081088]\n",
      " [ 0.         -0.05964978  0.12492842]\n",
      " [ 0.         -0.08623252  0.23517472]\n",
      " [ 0.         -0.09625503  0.16757364]\n",
      " [ 0.          0.2082372   0.08379764]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #75 | lambda learn rate = 0.0001\n",
      "Target = [[7.]\n",
      " [1.]]\n",
      "lambda end of trial = [[ 0.          0.50620414 -0.25009867]\n",
      " [ 0.          0.34456141 -0.17222797]\n",
      " [ 0.         -0.17096061  0.22544288]\n",
      " [ 0.         -0.11135072  0.17181099]\n",
      " [ 0.          0.1791912   0.00557229]\n",
      " [ 0.         -0.10599473  0.23061407]\n",
      " [ 0.         -0.06081719  0.12476165]\n",
      " [ 0.         -0.08761284  0.23497753]\n",
      " [ 0.         -0.09751304  0.16739392]\n",
      " [ 0.          0.20671497  0.08358018]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #76 | lambda learn rate = 0.0001\n",
      "Target = [[5.]\n",
      " [1.]]\n",
      "lambda end of trial = [[ 0.          0.50464467 -0.25041057]\n",
      " [ 0.          0.34305744 -0.17252876]\n",
      " [ 0.         -0.17245575  0.22514385]\n",
      " [ 0.         -0.11295436  0.17149026]\n",
      " [ 0.          0.17757501  0.00524906]\n",
      " [ 0.         -0.1076209   0.23028884]\n",
      " [ 0.         -0.06244076  0.12443694]\n",
      " [ 0.         -0.08925489  0.23464912]\n",
      " [ 0.         -0.09901302  0.16709392]\n",
      " [ 0.          0.2051014   0.08325746]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #77 | lambda learn rate = 0.0001\n",
      "Target = [[5.]\n",
      " [4.]]\n",
      "lambda end of trial = [[ 0.          0.50397137 -0.25094921]\n",
      " [ 0.          0.34237585 -0.17307403]\n",
      " [ 0.         -0.17311285  0.22461817]\n",
      " [ 0.         -0.11358783  0.17098349]\n",
      " [ 0.          0.17689147  0.00470222]\n",
      " [ 0.         -0.10831067  0.22973703]\n",
      " [ 0.         -0.06313514  0.12388144]\n",
      " [ 0.         -0.09005085  0.23401236]\n",
      " [ 0.         -0.09974093  0.1665116 ]\n",
      " [ 0.          0.20430072  0.08261692]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #78 | lambda learn rate = 0.0001\n",
      "Target = [[4.]\n",
      " [7.]]\n",
      "lambda end of trial = [[ 0.          0.50370092 -0.25142249]\n",
      " [ 0.          0.34213245 -0.17349999]\n",
      " [ 0.         -0.17337209  0.2241645 ]\n",
      " [ 0.         -0.11384383  0.17053548]\n",
      " [ 0.          0.17663781  0.00425833]\n",
      " [ 0.         -0.10862842  0.22918097]\n",
      " [ 0.         -0.06341241  0.12339621]\n",
      " [ 0.         -0.09029995  0.23357643]\n",
      " [ 0.         -0.09995085  0.16614423]\n",
      " [ 0.          0.20397531  0.08204745]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #79 | lambda learn rate = 0.0001\n",
      "Target = [[1.]\n",
      " [4.]]\n",
      "lambda end of trial = [[ 0.          0.50328448 -0.25308825]\n",
      " [ 0.          0.34175891 -0.17499416]\n",
      " [ 0.         -0.17379384  0.22247748]\n",
      " [ 0.         -0.11427125  0.16882582]\n",
      " [ 0.          0.17621436  0.00256451]\n",
      " [ 0.         -0.1090316   0.22756821]\n",
      " [ 0.         -0.06380504  0.12182567]\n",
      " [ 0.         -0.09076852  0.23170217]\n",
      " [ 0.         -0.10033375  0.16461263]\n",
      " [ 0.          0.20354944  0.08034397]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #80 | lambda learn rate = 0.0001\n",
      "Target = [[1.]\n",
      " [0.]]\n",
      "lambda end of trial = [[ 0.          0.5027082  -0.25308825]\n",
      " [ 0.          0.34119278 -0.17499416]\n",
      " [ 0.         -0.17431784  0.22247748]\n",
      " [ 0.         -0.11483165  0.16882582]\n",
      " [ 0.          0.17568306  0.00256451]\n",
      " [ 0.         -0.10963076  0.22756821]\n",
      " [ 0.         -0.06439434  0.12182567]\n",
      " [ 0.         -0.09139756  0.23170217]\n",
      " [ 0.         -0.10090537  0.16461263]\n",
      " [ 0.          0.20293058  0.08034397]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #81 | lambda learn rate = 0.0001\n",
      "Target = [[8.]\n",
      " [4.]]\n",
      "lambda end of trial = [[ 0.          0.50374004 -0.25257232]\n",
      " [ 0.          0.34230744 -0.17443683]\n",
      " [ 0.         -0.17326167  0.22300557]\n",
      " [ 0.         -0.11387284  0.16930523]\n",
      " [ 0.          0.17665463  0.0030503 ]\n",
      " [ 0.         -0.10876924  0.22799897]\n",
      " [ 0.         -0.06331008  0.12236781]\n",
      " [ 0.         -0.09055603  0.23212293]\n",
      " [ 0.         -0.1000422   0.16504422]\n",
      " [ 0.          0.20386833  0.08081285]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #82 | lambda learn rate = 0.0001\n",
      "Target = [[5.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [8.]]\n",
      "lambda end of trial = [[ 0.          0.50413753 -0.25193634]\n",
      " [ 0.          0.3427796  -0.17368137]\n",
      " [ 0.         -0.17287977  0.22361659]\n",
      " [ 0.         -0.11339168  0.17007507]\n",
      " [ 0.          0.17703849  0.00366448]\n",
      " [ 0.         -0.10829502  0.22875772]\n",
      " [ 0.         -0.06283711  0.12312456]\n",
      " [ 0.         -0.09017026  0.23274016]\n",
      " [ 0.         -0.09961338  0.16573034]\n",
      " [ 0.          0.2042156   0.08136848]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #83 | lambda learn rate = 0.0001\n",
      "Target = [[8.]\n",
      " [3.]]\n",
      "lambda end of trial = [[ 0.          0.50431077 -0.25187137]\n",
      " [ 0.          0.34302049 -0.17359103]\n",
      " [ 0.         -0.17261402  0.22371625]\n",
      " [ 0.         -0.11321878  0.17013991]\n",
      " [ 0.          0.17717593  0.00371602]\n",
      " [ 0.         -0.10815572  0.22880996]\n",
      " [ 0.         -0.06259146  0.12321668]\n",
      " [ 0.         -0.09009995  0.23276653]\n",
      " [ 0.         -0.09937933  0.16581811]\n",
      " [ 0.          0.20428914  0.08139606]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #84 | lambda learn rate = 0.0001\n",
      "Target = [[4.]\n",
      " [1.]]\n",
      "lambda end of trial = [[ 0.          0.50303963 -0.25218916]\n",
      " [ 0.          0.34174237 -0.17391056]\n",
      " [ 0.         -0.17382852  0.22341263]\n",
      " [ 0.         -0.11447488  0.16982589]\n",
      " [ 0.          0.17584475  0.00338322]\n",
      " [ 0.         -0.1094696   0.22848149]\n",
      " [ 0.         -0.0638187   0.12290987]\n",
      " [ 0.         -0.09145273  0.23242834]\n",
      " [ 0.         -0.10072064  0.16548278]\n",
      " [ 0.          0.20288039  0.08104387]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #85 | lambda learn rate = 0.0001\n",
      "Target = [[5.]\n",
      " [0.]]\n",
      "lambda end of trial = [[ 0.          0.50137169 -0.25218916]\n",
      " [ 0.          0.33994206 -0.17391056]\n",
      " [ 0.         -0.17548322  0.22341263]\n",
      " [ 0.         -0.11627062  0.16982589]\n",
      " [ 0.          0.17392381  0.00338322]\n",
      " [ 0.         -0.11148512  0.22848149]\n",
      " [ 0.         -0.0657667   0.12290987]\n",
      " [ 0.         -0.09330921  0.23242834]\n",
      " [ 0.         -0.10273139  0.16548278]\n",
      " [ 0.          0.20076919  0.08104387]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #86 | lambda learn rate = 0.0001\n",
      "Target = [[6.]\n",
      " [4.]]\n",
      "lambda end of trial = [[ 0.          0.50140232 -0.25216874]\n",
      " [ 0.          0.33998506 -0.17388189]\n",
      " [ 0.         -0.17546365  0.22342567]\n",
      " [ 0.         -0.11614855  0.16990727]\n",
      " [ 0.          0.17399174  0.00342851]\n",
      " [ 0.         -0.1114683   0.2284927 ]\n",
      " [ 0.         -0.06561539  0.12301074]\n",
      " [ 0.         -0.09327599  0.23245048]\n",
      " [ 0.         -0.10265643  0.16553275]\n",
      " [ 0.          0.20078368  0.08105353]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #87 | lambda learn rate = 0.0001\n",
      "Target = [[8.]\n",
      " [9.]]\n",
      "lambda end of trial = [[ 0.          0.50431623 -0.24889059]\n",
      " [ 0.          0.34343971 -0.16999542]\n",
      " [ 0.         -0.17246495  0.22679921]\n",
      " [ 0.         -0.11334781  0.1730581 ]\n",
      " [ 0.          0.17736452  0.00722288]\n",
      " [ 0.         -0.10813267  0.23224528]\n",
      " [ 0.         -0.06243304  0.12659089]\n",
      " [ 0.         -0.09004623  0.23608397]\n",
      " [ 0.         -0.09916757  0.16945772]\n",
      " [ 0.          0.2040102   0.08468336]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #88 | lambda learn rate = 0.0001\n",
      "Target = [[9.]\n",
      " [5.]]\n",
      "lambda end of trial = [[ 0.          0.50576569 -0.24808534]\n",
      " [ 0.          0.34491046 -0.16917833]\n",
      " [ 0.         -0.17113526  0.22753793]\n",
      " [ 0.         -0.11169444  0.17397664]\n",
      " [ 0.          0.17898989  0.00812587]\n",
      " [ 0.         -0.10673283  0.23302297]\n",
      " [ 0.         -0.06090035  0.12744238]\n",
      " [ 0.         -0.08862055  0.23687601]\n",
      " [ 0.         -0.09774506  0.170248  ]\n",
      " [ 0.          0.20544871  0.08548253]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #89 | lambda learn rate = 0.0001\n",
      "Target = [[6.]\n",
      " [6.]]\n",
      "lambda end of trial = [[ 0.          0.50562209 -0.24822894]\n",
      " [ 0.          0.344779   -0.16930979]\n",
      " [ 0.         -0.17130356  0.22736963]\n",
      " [ 0.         -0.11191542  0.17375566]\n",
      " [ 0.          0.17881244  0.00794842]\n",
      " [ 0.         -0.10695248  0.23280333]\n",
      " [ 0.         -0.06107632  0.12726641]\n",
      " [ 0.         -0.08882122  0.23667534]\n",
      " [ 0.         -0.09789055  0.17010252]\n",
      " [ 0.          0.20524799  0.08528181]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #90 | lambda learn rate = 0.0001\n",
      "Target = [[2.]\n",
      " [7.]]\n",
      "lambda end of trial = [[ 0.          0.50510942 -0.25002326]\n",
      " [ 0.          0.34426552 -0.17110696]\n",
      " [ 0.         -0.17179056  0.22566514]\n",
      " [ 0.         -0.11236597  0.17217874]\n",
      " [ 0.          0.17835778  0.0063571 ]\n",
      " [ 0.         -0.10745754  0.23103561]\n",
      " [ 0.         -0.06154773  0.12561647]\n",
      " [ 0.         -0.0893784   0.23472523]\n",
      " [ 0.         -0.09838     0.16838944]\n",
      " [ 0.          0.20470669  0.08338726]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #91 | lambda learn rate = 0.0001\n",
      "Target = [[1.]\n",
      " [4.]]\n",
      "lambda end of trial = [[ 0.          0.50466402 -0.25180487]\n",
      " [ 0.          0.34384139 -0.17280349]\n",
      " [ 0.         -0.17220429  0.22401023]\n",
      " [ 0.         -0.11279481  0.17046339]\n",
      " [ 0.          0.17796535  0.00478738]\n",
      " [ 0.         -0.1078537   0.22945095]\n",
      " [ 0.         -0.06199473  0.12382847]\n",
      " [ 0.         -0.08983084  0.23291546]\n",
      " [ 0.         -0.0987975   0.16671943]\n",
      " [ 0.          0.20427016  0.08164117]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #92 | lambda learn rate = 0.0001\n",
      "Target = [[1.]\n",
      " [1.]]\n",
      "lambda end of trial = [[ 0.          0.50403002 -0.25243887]\n",
      " [ 0.          0.34323267 -0.17341221]\n",
      " [ 0.         -0.17282091  0.22339361]\n",
      " [ 0.         -0.11337503  0.16988317]\n",
      " [ 0.          0.17730971  0.00413174]\n",
      " [ 0.         -0.10850854  0.22879612]\n",
      " [ 0.         -0.06258233  0.12324088]\n",
      " [ 0.         -0.09050011  0.23224619]\n",
      " [ 0.         -0.09940181  0.16611512]\n",
      " [ 0.          0.20362351  0.08099452]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #93 | lambda learn rate = 0.0001\n",
      "Target = [[4.]\n",
      " [2.]]\n",
      "lambda end of trial = [[ 0.          0.50284593 -0.25303091]\n",
      " [ 0.          0.34221405 -0.17392152]\n",
      " [ 0.         -0.1739149   0.22284661]\n",
      " [ 0.         -0.11450955  0.16931591]\n",
      " [ 0.          0.17614833  0.00355105]\n",
      " [ 0.         -0.10973646  0.22818216]\n",
      " [ 0.         -0.06390286  0.12258062]\n",
      " [ 0.         -0.09160013  0.23169617]\n",
      " [ 0.         -0.10063729  0.16549738]\n",
      " [ 0.          0.20239317  0.08037935]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #94 | lambda learn rate = 0.0001\n",
      "Target = [[4.]\n",
      " [7.]]\n",
      "lambda end of trial = [[ 0.          0.50277191 -0.25316045]\n",
      " [ 0.          0.34215639 -0.17402241]\n",
      " [ 0.         -0.17396383  0.222761  ]\n",
      " [ 0.         -0.11459861  0.16916005]\n",
      " [ 0.          0.17607685  0.00342597]\n",
      " [ 0.         -0.10990778  0.22788234]\n",
      " [ 0.         -0.06394461  0.12250755]\n",
      " [ 0.         -0.09169701  0.23152665]\n",
      " [ 0.         -0.10073382  0.16532845]\n",
      " [ 0.          0.20221752  0.08007196]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #95 | lambda learn rate = 0.0001\n",
      "Target = [[4.]\n",
      " [7.]]\n",
      "lambda end of trial = [[ 0.          0.50268797 -0.25330735]\n",
      " [ 0.          0.34206038 -0.17419044]\n",
      " [ 0.         -0.17410058  0.22252169]\n",
      " [ 0.         -0.11471828  0.16895062]\n",
      " [ 0.          0.17596891  0.00323707]\n",
      " [ 0.         -0.11005192  0.22763009]\n",
      " [ 0.         -0.06407538  0.12227869]\n",
      " [ 0.         -0.09182747  0.23129834]\n",
      " [ 0.         -0.10083482  0.1651517 ]\n",
      " [ 0.          0.20201428  0.07971629]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #96 | lambda learn rate = 0.0001\n",
      "Target = [[0.]\n",
      " [4.]]\n",
      "lambda end of trial = [[ 0.          0.50268797 -0.2551445 ]\n",
      " [ 0.          0.34206038 -0.17591559]\n",
      " [ 0.         -0.17410058  0.22072762]\n",
      " [ 0.         -0.11471828  0.16711953]\n",
      " [ 0.          0.17596891  0.00119849]\n",
      " [ 0.         -0.11005192  0.22586423]\n",
      " [ 0.         -0.06407538  0.12061815]\n",
      " [ 0.         -0.09182747  0.22942827]\n",
      " [ 0.         -0.10083482  0.16337903]\n",
      " [ 0.          0.20201428  0.07764476]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #97 | lambda learn rate = 0.0001\n",
      "Target = [[1.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [7.]]\n",
      "lambda end of trial = [[ 0.00000000e+00  5.02499766e-01 -2.56461913e-01]\n",
      " [ 0.00000000e+00  3.41892055e-01 -1.77093847e-01]\n",
      " [ 0.00000000e+00 -1.74278274e-01  2.19483729e-01]\n",
      " [ 0.00000000e+00 -1.14910081e-01  1.65776963e-01]\n",
      " [ 0.00000000e+00  1.75805489e-01  5.45279431e-05]\n",
      " [ 0.00000000e+00 -1.10265043e-01  2.24372391e-01]\n",
      " [ 0.00000000e+00 -6.42706129e-02  1.19251548e-01]\n",
      " [ 0.00000000e+00 -9.20320322e-02  2.27996338e-01]\n",
      " [ 0.00000000e+00 -1.01000566e-01  1.62218796e-01]\n",
      " [ 0.00000000e+00  2.01812030e-01  7.62290180e-02]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #98 | lambda learn rate = 0.0001\n",
      "Target = [[1.]\n",
      " [2.]]\n",
      "lambda end of trial = [[ 0.          0.50202354 -0.25741436]\n",
      " [ 0.          0.34142695 -0.17802406]\n",
      " [ 0.         -0.17472616  0.21858795]\n",
      " [ 0.         -0.1153268   0.16494352]\n",
      " [ 0.          0.17534477 -0.00086691]\n",
      " [ 0.         -0.11075021  0.22340206]\n",
      " [ 0.         -0.06471869  0.11835539]\n",
      " [ 0.         -0.09254325  0.22697391]\n",
      " [ 0.         -0.10145978  0.16130037]\n",
      " [ 0.          0.20132943  0.07526382]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "+++++++++++++++++++++++++++++++++++\n",
      "Session #2\n",
      "target at trial 0 = [[1.]\n",
      " [1.]]\n",
      "K MATX INIT= [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "A VECT INIT = [-0. -0.]\n",
      "lambda\n",
      "[[ 0.          0.53020654 -0.2322202 ]\n",
      " [ 0.          0.36705474 -0.15737009]\n",
      " [ 0.         -0.14629582  0.24261404]\n",
      " [ 0.         -0.08877213  0.18799136]\n",
      " [ 0.          0.20486852  0.02360278]\n",
      " [ 0.         -0.07854344  0.25002723]\n",
      " [ 0.         -0.03748972  0.14111247]\n",
      " [ 0.         -0.0597867   0.25435404]\n",
      " [ 0.         -0.07409235  0.18348285]\n",
      " [ 0.          0.23653843  0.10488391]]\n",
      "a\n",
      "[-0. -0.]\n",
      "K\n",
      "[[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #0 | lambda learn rate = 0.0001\n",
      "Target = [[1.]\n",
      " [1.]]\n",
      "lambda end of trial = [[ 0.          0.52956453 -0.23286221]\n",
      " [ 0.          0.36643119 -0.15799364]\n",
      " [ 0.         -0.14702967  0.24188019]\n",
      " [ 0.         -0.08933242  0.18743106]\n",
      " [ 0.          0.20423059  0.02296485]\n",
      " [ 0.         -0.07922086  0.24934981]\n",
      " [ 0.         -0.03812106  0.14048114]\n",
      " [ 0.         -0.06043921  0.25370153]\n",
      " [ 0.         -0.07477864  0.18279656]\n",
      " [ 0.          0.23578056  0.10412605]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #1 | lambda learn rate = 0.0001\n",
      "Target = [[9.]\n",
      " [7.]]\n",
      "lambda end of trial = [[ 0.          0.52255388 -0.23831494]\n",
      " [ 0.          0.36003702 -0.16296689]\n",
      " [ 0.         -0.152757    0.23742561]\n",
      " [ 0.         -0.09568003  0.18249403]\n",
      " [ 0.          0.19696559  0.01731429]\n",
      " [ 0.         -0.086999    0.24330015]\n",
      " [ 0.         -0.04459744  0.13544396]\n",
      " [ 0.         -0.06714537  0.24848562]\n",
      " [ 0.         -0.08159862  0.17749213]\n",
      " [ 0.          0.22828613  0.09829704]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #2 | lambda learn rate = 0.0001\n",
      "Target = [[8.]\n",
      " [4.]]\n",
      "lambda end of trial = [[ 0.          0.51894684 -0.24011845]\n",
      " [ 0.          0.35639322 -0.16478879]\n",
      " [ 0.         -0.15641687  0.23559567]\n",
      " [ 0.         -0.09933983  0.18066414]\n",
      " [ 0.          0.1932352   0.0154491 ]\n",
      " [ 0.         -0.09061883  0.24149023]\n",
      " [ 0.         -0.04780977  0.13383779]\n",
      " [ 0.         -0.07105682  0.2465299 ]\n",
      " [ 0.         -0.08533527  0.17562381]\n",
      " [ 0.          0.22464275  0.09647535]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #3 | lambda learn rate = 0.0001\n",
      "Target = [[1.]\n",
      " [8.]]\n",
      "lambda end of trial = [[ 0.          0.51844432 -0.24413862]\n",
      " [ 0.          0.35597985 -0.16809571]\n",
      " [ 0.         -0.15689901  0.23173857]\n",
      " [ 0.         -0.0998131   0.17687793]\n",
      " [ 0.          0.19273773  0.01146934]\n",
      " [ 0.         -0.09112034  0.2374781 ]\n",
      " [ 0.         -0.04825748  0.1302561 ]\n",
      " [ 0.         -0.07156127  0.24249431]\n",
      " [ 0.         -0.08581026  0.17182386]\n",
      " [ 0.          0.22412481  0.09233185]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #4 | lambda learn rate = 0.0001\n",
      "Target = [[2.]\n",
      " [4.]]\n",
      "lambda end of trial = [[ 0.          0.51745371 -0.24611985]\n",
      " [ 0.          0.35498782 -0.17007978]\n",
      " [ 0.         -0.15792151  0.22969356]\n",
      " [ 0.         -0.10082376  0.17485661]\n",
      " [ 0.          0.19171873  0.00943133]\n",
      " [ 0.         -0.09206064  0.23559751]\n",
      " [ 0.         -0.04919348  0.1283841 ]\n",
      " [ 0.         -0.07262904  0.24035877]\n",
      " [ 0.         -0.08664351  0.17015736]\n",
      " [ 0.          0.2231312   0.09034465]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #5 | lambda learn rate = 0.0001\n",
      "Target = [[0.]\n",
      " [3.]]\n",
      "lambda end of trial = [[ 0.          0.51745371 -0.24782002]\n",
      " [ 0.          0.35498782 -0.17192629]\n",
      " [ 0.         -0.15792151  0.22788172]\n",
      " [ 0.         -0.10082376  0.17303791]\n",
      " [ 0.          0.19171873  0.00778886]\n",
      " [ 0.         -0.09206064  0.23364035]\n",
      " [ 0.         -0.04919348  0.12665397]\n",
      " [ 0.         -0.07262904  0.23865328]\n",
      " [ 0.         -0.08664351  0.16850574]\n",
      " [ 0.          0.2231312   0.08868457]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #6 | lambda learn rate = 0.0001\n",
      "Target = [[1.]\n",
      " [6.]]\n",
      "lambda end of trial = [[ 0.          0.51706221 -0.25016901]\n",
      " [ 0.          0.35458818 -0.17432414]\n",
      " [ 0.         -0.15834423  0.22534542]\n",
      " [ 0.         -0.10123513  0.17056968]\n",
      " [ 0.          0.19132379  0.00541925]\n",
      " [ 0.         -0.09253541  0.23079174]\n",
      " [ 0.         -0.04956413  0.12443008]\n",
      " [ 0.         -0.07307672  0.23596719]\n",
      " [ 0.         -0.08705823  0.16601744]\n",
      " [ 0.          0.22267059  0.08592087]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #7 | lambda learn rate = 0.0001\n",
      "Target = [[7.]\n",
      " [9.]]\n",
      "lambda end of trial = [[ 0.          0.51681044 -0.2504927 ]\n",
      " [ 0.          0.35439543 -0.17457196]\n",
      " [ 0.         -0.15853693  0.22509766]\n",
      " [ 0.         -0.10138836  0.17037268]\n",
      " [ 0.          0.19105166  0.00506936]\n",
      " [ 0.         -0.09277943  0.230478  ]\n",
      " [ 0.         -0.04969796  0.12425801]\n",
      " [ 0.         -0.07328954  0.23569357]\n",
      " [ 0.         -0.08723347  0.16579213]\n",
      " [ 0.          0.22241811  0.08559626]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #8 | lambda learn rate = 0.0001\n",
      "Target = [[6.]\n",
      " [6.]]\n",
      "lambda end of trial = [[ 0.          0.5154515  -0.25185164]\n",
      " [ 0.          0.35311921 -0.17584818]\n",
      " [ 0.         -0.15991364  0.22372095]\n",
      " [ 0.         -0.10268369  0.16907735]\n",
      " [ 0.          0.18963891  0.00365661]\n",
      " [ 0.         -0.09397173  0.2292857 ]\n",
      " [ 0.         -0.0509286   0.12302737]\n",
      " [ 0.         -0.0747733   0.23420981]\n",
      " [ 0.         -0.08849808  0.16452752]\n",
      " [ 0.          0.22096058  0.08413873]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #9 | lambda learn rate = 0.0001\n",
      "Target = [[3.]\n",
      " [0.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda end of trial = [[ 0.          0.51376245 -0.25185164]\n",
      " [ 0.          0.35146375 -0.17584818]\n",
      " [ 0.         -0.1614386   0.22372095]\n",
      " [ 0.         -0.10438179  0.16907735]\n",
      " [ 0.          0.18805649  0.00365661]\n",
      " [ 0.         -0.09579055  0.2292857 ]\n",
      " [ 0.         -0.05242769  0.12302737]\n",
      " [ 0.         -0.07633069  0.23420981]\n",
      " [ 0.         -0.09021136  0.16452752]\n",
      " [ 0.          0.21910323  0.08413873]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #10 | lambda learn rate = 0.0001\n",
      "Target = [[8.]\n",
      " [7.]]\n",
      "lambda end of trial = [[ 0.          0.5140589  -0.25159226]\n",
      " [ 0.          0.3516727  -0.17566535]\n",
      " [ 0.         -0.16117465  0.2239519 ]\n",
      " [ 0.         -0.10413144  0.16929641]\n",
      " [ 0.          0.18826713  0.00384092]\n",
      " [ 0.         -0.09564465  0.22941336]\n",
      " [ 0.         -0.05221885  0.1232101 ]\n",
      " [ 0.         -0.07622428  0.23430292]\n",
      " [ 0.         -0.08998475  0.16472579]\n",
      " [ 0.          0.21919617  0.08422005]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #11 | lambda learn rate = 0.0001\n",
      "Target = [[6.]\n",
      " [1.]]\n",
      "lambda end of trial = [[ 0.          0.51142564 -0.25203113]\n",
      " [ 0.          0.34927449 -0.17606505]\n",
      " [ 0.         -0.16361067  0.2235459 ]\n",
      " [ 0.         -0.10671709  0.16886547]\n",
      " [ 0.          0.18549211  0.00337842]\n",
      " [ 0.         -0.09811545  0.22900156]\n",
      " [ 0.         -0.05462776  0.12280862]\n",
      " [ 0.         -0.07846166  0.23393002]\n",
      " [ 0.         -0.09230975  0.1643383 ]\n",
      " [ 0.          0.21658586  0.083785  ]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #12 | lambda learn rate = 0.0001\n",
      "Target = [[6.]\n",
      " [1.]]\n",
      "lambda end of trial = [[ 0.          0.50951879 -0.25234894]\n",
      " [ 0.          0.34730096 -0.17639397]\n",
      " [ 0.         -0.16567759  0.22320141]\n",
      " [ 0.         -0.1087745   0.16852256]\n",
      " [ 0.          0.18350526  0.00304728]\n",
      " [ 0.         -0.09997131  0.22869225]\n",
      " [ 0.         -0.05633406  0.12252423]\n",
      " [ 0.         -0.08040694  0.23360581]\n",
      " [ 0.         -0.09433025  0.16400154]\n",
      " [ 0.          0.21420755  0.08338862]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #13 | lambda learn rate = 0.0001\n",
      "Target = [[6.]\n",
      " [4.]]\n",
      "lambda end of trial = [[ 0.          0.50869247 -0.25289982]\n",
      " [ 0.          0.34656737 -0.17688303]\n",
      " [ 0.         -0.16641371  0.22271066]\n",
      " [ 0.         -0.10961939  0.16795931]\n",
      " [ 0.          0.18261629  0.00245463]\n",
      " [ 0.         -0.10080188  0.22813854]\n",
      " [ 0.         -0.05705338  0.12204469]\n",
      " [ 0.         -0.08130121  0.23300963]\n",
      " [ 0.         -0.09524193  0.16339376]\n",
      " [ 0.          0.21330383  0.08278613]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #14 | lambda learn rate = 0.0001\n",
      "Target = [[8.]\n",
      " [3.]]\n",
      "lambda end of trial = [[ 0.          0.50814988 -0.25310329]\n",
      " [ 0.          0.34614551 -0.17704123]\n",
      " [ 0.         -0.16685875  0.22254378]\n",
      " [ 0.         -0.1101369   0.16776524]\n",
      " [ 0.          0.18207881  0.00225308]\n",
      " [ 0.         -0.10126467  0.22796499]\n",
      " [ 0.         -0.05754181  0.12186153]\n",
      " [ 0.         -0.08186988  0.23279638]\n",
      " [ 0.         -0.0958182   0.16317766]\n",
      " [ 0.          0.21276485  0.08258401]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #15 | lambda learn rate = 0.0001\n",
      "Target = [[5.]\n",
      " [9.]]\n",
      "lambda end of trial = [[ 0.          0.50856237 -0.2523608 ]\n",
      " [ 0.          0.34655868 -0.17629752]\n",
      " [ 0.         -0.16640352  0.22336319]\n",
      " [ 0.         -0.10976945  0.16842665]\n",
      " [ 0.          0.18237847  0.00279248]\n",
      " [ 0.         -0.10094705  0.2285367 ]\n",
      " [ 0.         -0.05716848  0.12253352]\n",
      " [ 0.         -0.08152932  0.2334094 ]\n",
      " [ 0.         -0.09540796  0.16391608]\n",
      " [ 0.          0.21308906  0.0831676 ]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #16 | lambda learn rate = 0.0001\n",
      "Target = [[5.]\n",
      " [2.]]\n",
      "lambda end of trial = [[ 0.          0.50722962 -0.2528939 ]\n",
      " [ 0.          0.3451441  -0.17686335]\n",
      " [ 0.         -0.16785629  0.22278208]\n",
      " [ 0.         -0.11117745  0.16786345]\n",
      " [ 0.          0.18099317  0.00223835]\n",
      " [ 0.         -0.102485    0.22792152]\n",
      " [ 0.         -0.05848501  0.12200691]\n",
      " [ 0.         -0.083027    0.23281032]\n",
      " [ 0.         -0.09673057  0.16338703]\n",
      " [ 0.          0.21160748  0.08257497]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #17 | lambda learn rate = 0.0001\n",
      "Target = [[6.]\n",
      " [3.]]\n",
      "lambda end of trial = [[ 0.          0.50649463 -0.2532614 ]\n",
      " [ 0.          0.34431909 -0.17727586]\n",
      " [ 0.         -0.16860749  0.22240648]\n",
      " [ 0.         -0.11193966  0.16748235]\n",
      " [ 0.          0.18019835  0.00184095]\n",
      " [ 0.         -0.10334249  0.22749278]\n",
      " [ 0.         -0.05918578  0.12165652]\n",
      " [ 0.         -0.08379964  0.23242401]\n",
      " [ 0.         -0.09746076  0.16302194]\n",
      " [ 0.          0.21074348  0.08214297]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #18 | lambda learn rate = 0.0001\n",
      "Target = [[8.]\n",
      " [1.]]\n",
      "lambda end of trial = [[ 0.          0.50545378 -0.2533915 ]\n",
      " [ 0.          0.34336595 -0.177395  ]\n",
      " [ 0.         -0.16973681  0.22226531]\n",
      " [ 0.         -0.11311845  0.167335  ]\n",
      " [ 0.          0.17899819  0.00169093]\n",
      " [ 0.         -0.10450474  0.2273475 ]\n",
      " [ 0.         -0.06029222  0.12151822]\n",
      " [ 0.         -0.08492076  0.23228387]\n",
      " [ 0.         -0.09863882  0.16287468]\n",
      " [ 0.          0.20949755  0.08198723]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #19 | lambda learn rate = 0.0001\n",
      "Target = [[9.]\n",
      " [3.]]\n",
      "lambda end of trial = [[ 0.          0.50596456 -0.25322124]\n",
      " [ 0.          0.34396971 -0.17719375]\n",
      " [ 0.         -0.16917431  0.22245281]\n",
      " [ 0.         -0.11251086  0.16753753]\n",
      " [ 0.          0.17955926  0.00187795]\n",
      " [ 0.         -0.10392187  0.22754178]\n",
      " [ 0.         -0.05970481  0.12171402]\n",
      " [ 0.         -0.08435972  0.23247088]\n",
      " [ 0.         -0.09798754  0.16309177]\n",
      " [ 0.          0.20995068  0.08213827]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #20 | lambda learn rate = 0.0001\n",
      "Target = [[9.]\n",
      " [3.]]\n",
      "lambda end of trial = [[ 0.          0.50629607 -0.25311074]\n",
      " [ 0.          0.34439071 -0.17705341]\n",
      " [ 0.         -0.16869043  0.22261411]\n",
      " [ 0.         -0.11206025  0.16768773]\n",
      " [ 0.          0.18003446  0.00203635]\n",
      " [ 0.         -0.10361185  0.22764512]\n",
      " [ 0.         -0.0592632   0.12186122]\n",
      " [ 0.         -0.08407457  0.23256593]\n",
      " [ 0.         -0.09744846  0.16327147]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [ 0.          0.2102049   0.08222301]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #21 | lambda learn rate = 0.0001\n",
      "Target = [[5.]\n",
      " [4.]]\n",
      "lambda end of trial = [[ 0.          0.50558263 -0.25368149]\n",
      " [ 0.          0.34361985 -0.1776701 ]\n",
      " [ 0.         -0.16940088  0.22204575]\n",
      " [ 0.         -0.11273375  0.16714893]\n",
      " [ 0.          0.17929732  0.00144664]\n",
      " [ 0.         -0.10429161  0.22710131]\n",
      " [ 0.         -0.05995856  0.12130494]\n",
      " [ 0.         -0.08490634  0.23190051]\n",
      " [ 0.         -0.09817657  0.16268898]\n",
      " [ 0.          0.20933585  0.08152777]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #22 | lambda learn rate = 0.0001\n",
      "Target = [[8.]\n",
      " [0.]]\n",
      "lambda end of trial = [[ 0.          0.50421877 -0.25368149]\n",
      " [ 0.          0.34237825 -0.1776701 ]\n",
      " [ 0.         -0.17080273  0.22204575]\n",
      " [ 0.         -0.11416771  0.16714893]\n",
      " [ 0.          0.17788245  0.00144664]\n",
      " [ 0.         -0.10572024  0.22710131]\n",
      " [ 0.         -0.06139308  0.12130494]\n",
      " [ 0.         -0.08635207  0.23190051]\n",
      " [ 0.         -0.09969882  0.16268898]\n",
      " [ 0.          0.2078493   0.08152777]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #23 | lambda learn rate = 0.0001\n",
      "Target = [[4.]\n",
      " [4.]]\n",
      "lambda end of trial = [[ 0.          0.50340307 -0.25449719]\n",
      " [ 0.          0.34154588 -0.17850247]\n",
      " [ 0.         -0.17175626  0.22109221]\n",
      " [ 0.         -0.11491034  0.1664063 ]\n",
      " [ 0.          0.17712657  0.00069075]\n",
      " [ 0.         -0.10649374  0.22632781]\n",
      " [ 0.         -0.06217424  0.12052378]\n",
      " [ 0.         -0.08718156  0.23107102]\n",
      " [ 0.         -0.1005191   0.1618687 ]\n",
      " [ 0.          0.20692973  0.0806082 ]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #24 | lambda learn rate = 0.0001\n",
      "Target = [[1.]\n",
      " [7.]]\n",
      "lambda end of trial = [[ 0.          0.50319561 -0.25594938]\n",
      " [ 0.          0.34136323 -0.17978105]\n",
      " [ 0.         -0.17197147  0.21958579]\n",
      " [ 0.         -0.11513518  0.16483243]\n",
      " [ 0.          0.17692885 -0.00069324]\n",
      " [ 0.         -0.10669546  0.22491576]\n",
      " [ 0.         -0.06238952  0.11901682]\n",
      " [ 0.         -0.08740043  0.22953892]\n",
      " [ 0.         -0.10071437  0.16050178]\n",
      " [ 0.          0.2067119   0.07908344]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #25 | lambda learn rate = 0.0001\n",
      "Target = [[2.]\n",
      " [2.]]\n",
      "lambda end of trial = [[ 0.          0.50236526 -0.25677973]\n",
      " [ 0.          0.34044751 -0.18069677]\n",
      " [ 0.         -0.17283508  0.21872217]\n",
      " [ 0.         -0.11599298  0.16397463]\n",
      " [ 0.          0.17618067 -0.00144141]\n",
      " [ 0.         -0.10762132  0.2239899 ]\n",
      " [ 0.         -0.06321023  0.11819611]\n",
      " [ 0.         -0.08833351  0.22860584]\n",
      " [ 0.         -0.10150099  0.15971517]\n",
      " [ 0.          0.20581516  0.0781867 ]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #26 | lambda learn rate = 0.0001\n",
      "Target = [[9.]\n",
      " [2.]]\n",
      "lambda end of trial = [[ 0.          0.50297441 -0.25664436]\n",
      " [ 0.          0.34121968 -0.18052518]\n",
      " [ 0.         -0.1721154   0.2188821 ]\n",
      " [ 0.         -0.1151913   0.16415278]\n",
      " [ 0.          0.17670653 -0.00132456]\n",
      " [ 0.         -0.10696867  0.22413494]\n",
      " [ 0.         -0.06249002  0.11835615]\n",
      " [ 0.         -0.08777607  0.22872972]\n",
      " [ 0.         -0.10085999  0.15985761]\n",
      " [ 0.          0.20623277  0.0782795 ]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #27 | lambda learn rate = 0.0001\n",
      "Target = [[0.]\n",
      " [9.]]\n",
      "lambda end of trial = [[ 0.          0.50297441 -0.25767017]\n",
      " [ 0.          0.34121968 -0.18153791]\n",
      " [ 0.         -0.1721154   0.21785453]\n",
      " [ 0.         -0.1151913   0.16325419]\n",
      " [ 0.          0.17670653 -0.00232745]\n",
      " [ 0.         -0.10696867  0.22302598]\n",
      " [ 0.         -0.06249002  0.1174295 ]\n",
      " [ 0.         -0.08777607  0.22762813]\n",
      " [ 0.         -0.10085999  0.158945  ]\n",
      " [ 0.          0.20623277  0.07707898]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #28 | lambda learn rate = 0.0001\n",
      "Target = [[6.]\n",
      " [0.]]\n",
      "lambda end of trial = [[ 0.          0.50130499 -0.25767017]\n",
      " [ 0.          0.33950256 -0.18153791]\n",
      " [ 0.         -0.17364683  0.21785453]\n",
      " [ 0.         -0.11644693  0.16325419]\n",
      " [ 0.          0.17520765 -0.00232745]\n",
      " [ 0.         -0.10860374  0.22302598]\n",
      " [ 0.         -0.06397563  0.1174295 ]\n",
      " [ 0.         -0.08921197  0.22762813]\n",
      " [ 0.         -0.10249372  0.158945  ]\n",
      " [ 0.          0.20445947  0.07707898]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #29 | lambda learn rate = 0.0001\n",
      "Target = [[4.]\n",
      " [4.]]\n",
      "lambda end of trial = [[ 0.          0.50070132 -0.25827385]\n",
      " [ 0.          0.33900671 -0.18203376]\n",
      " [ 0.         -0.17420533  0.21729602]\n",
      " [ 0.         -0.11701199  0.16268913]\n",
      " [ 0.          0.17461282 -0.00292228]\n",
      " [ 0.         -0.10930815  0.22232158]\n",
      " [ 0.         -0.06460875  0.11679638]\n",
      " [ 0.         -0.08984548  0.22699462]\n",
      " [ 0.         -0.10302048  0.15841825]\n",
      " [ 0.          0.20380657  0.07642607]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #30 | lambda learn rate = 0.0001\n",
      "Target = [[8.]\n",
      " [8.]]\n",
      "lambda end of trial = [[ 0.          0.50435338 -0.25462178]\n",
      " [ 0.          0.34282776 -0.17821272]\n",
      " [ 0.         -0.1705753   0.22092606]\n",
      " [ 0.         -0.11380979  0.16589133]\n",
      " [ 0.          0.17828659  0.00075148]\n",
      " [ 0.         -0.10580973  0.22582   ]\n",
      " [ 0.         -0.0610729   0.12033224]\n",
      " [ 0.         -0.08594222  0.23089788]\n",
      " [ 0.         -0.09920214  0.16223659]\n",
      " [ 0.          0.20768635  0.08030585]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #31 | lambda learn rate = 0.0001\n",
      "Target = [[5.]\n",
      " [4.]]\n",
      "lambda end of trial = [[ 0.00000000e+00  5.03728695e-01 -2.55121530e-01]\n",
      " [ 0.00000000e+00  3.42215831e-01 -1.78702255e-01]\n",
      " [ 0.00000000e+00 -1.71126422e-01  2.20485158e-01]\n",
      " [ 0.00000000e+00 -1.14458681e-01  1.65372216e-01]\n",
      " [ 0.00000000e+00  1.77743771e-01  3.17232604e-04]\n",
      " [ 0.00000000e+00 -1.06460234e-01  2.25299593e-01]\n",
      " [ 0.00000000e+00 -6.16505516e-02  1.19870111e-01]\n",
      " [ 0.00000000e+00 -8.65746236e-02  2.30391956e-01]\n",
      " [ 0.00000000e+00 -9.97569392e-02  1.61792747e-01]\n",
      " [ 0.00000000e+00  2.06977080e-01  7.97384404e-02]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #32 | lambda learn rate = 0.0001\n",
      "Target = [[0.]\n",
      " [9.]]\n",
      "lambda end of trial = [[ 0.          0.50372869 -0.25622551]\n",
      " [ 0.          0.34221583 -0.17982411]\n",
      " [ 0.         -0.17112642  0.21920308]\n",
      " [ 0.         -0.11445868  0.16415959]\n",
      " [ 0.          0.17774377 -0.00106762]\n",
      " [ 0.         -0.10646023  0.22389912]\n",
      " [ 0.         -0.06165055  0.11846895]\n",
      " [ 0.         -0.08657462  0.22899505]\n",
      " [ 0.         -0.09975694  0.16045047]\n",
      " [ 0.          0.20697708  0.07821601]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #33 | lambda learn rate = 0.0001\n",
      "Target = [[9.]\n",
      " [6.]]\n",
      "lambda end of trial = [[ 0.          0.50642192 -0.25443003]\n",
      " [ 0.          0.34498436 -0.17797843]\n",
      " [ 0.         -0.16833107  0.22106665]\n",
      " [ 0.         -0.1119488   0.16583284]\n",
      " [ 0.          0.18051447  0.00077951]\n",
      " [ 0.         -0.10384577  0.2256421 ]\n",
      " [ 0.         -0.05883694  0.12034469]\n",
      " [ 0.         -0.08438332  0.23045592]\n",
      " [ 0.         -0.09692597  0.16233778]\n",
      " [ 0.          0.20973832  0.08005684]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #34 | lambda learn rate = 0.0001\n",
      "Target = [[9.]\n",
      " [8.]]\n",
      "lambda end of trial = [[ 0.          0.50941559 -0.251769  ]\n",
      " [ 0.          0.34798314 -0.17531284]\n",
      " [ 0.         -0.16538348  0.22368673]\n",
      " [ 0.         -0.10917949  0.16829445]\n",
      " [ 0.          0.18366742  0.00358213]\n",
      " [ 0.         -0.10076647  0.22837926]\n",
      " [ 0.         -0.05612497  0.12275533]\n",
      " [ 0.         -0.08152288  0.23299853]\n",
      " [ 0.         -0.09392866  0.16500206]\n",
      " [ 0.          0.21282056  0.08279661]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #35 | lambda learn rate = 0.0001\n",
      "Target = [[3.]\n",
      " [5.]]\n",
      "lambda end of trial = [[ 0.          0.50862542 -0.25308593]\n",
      " [ 0.          0.34727929 -0.17648592]\n",
      " [ 0.         -0.16613719  0.22243055]\n",
      " [ 0.         -0.10988973  0.16711072]\n",
      " [ 0.          0.18300248  0.0024739 ]\n",
      " [ 0.         -0.10149961  0.22715736]\n",
      " [ 0.         -0.05682081  0.1215956 ]\n",
      " [ 0.         -0.08227324  0.23174792]\n",
      " [ 0.         -0.09463829  0.16381935]\n",
      " [ 0.          0.21195069  0.08134682]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #36 | lambda learn rate = 0.0001\n",
      "Target = [[6.]\n",
      " [7.]]\n",
      "lambda end of trial = [[ 0.          0.50883726 -0.25283879]\n",
      " [ 0.          0.3474798  -0.176252  ]\n",
      " [ 0.         -0.16589707  0.22271068]\n",
      " [ 0.         -0.10960648  0.16744117]\n",
      " [ 0.          0.1831492   0.00264507]\n",
      " [ 0.         -0.10132343  0.2273629 ]\n",
      " [ 0.         -0.05659985  0.12185339]\n",
      " [ 0.         -0.08208195  0.23197109]\n",
      " [ 0.         -0.09447973  0.16400434]\n",
      " [ 0.          0.21204425  0.08145598]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #37 | lambda learn rate = 0.0001\n",
      "Target = [[5.]\n",
      " [7.]]\n",
      "lambda end of trial = [[ 0.          0.50865325 -0.25309641]\n",
      " [ 0.          0.3472048  -0.176637  ]\n",
      " [ 0.         -0.16617114  0.22232698]\n",
      " [ 0.         -0.10980069  0.16716928]\n",
      " [ 0.          0.18287044  0.00225481]\n",
      " [ 0.         -0.10163378  0.2269284 ]\n",
      " [ 0.         -0.05688301  0.12145695]\n",
      " [ 0.         -0.08239995  0.2315259 ]\n",
      " [ 0.         -0.09469141  0.16370798]\n",
      " [ 0.          0.21165858  0.08091604]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #38 | lambda learn rate = 0.0001\n",
      "Target = [[6.]\n",
      " [7.]]\n",
      "lambda end of trial = [[ 0.          0.50888788 -0.25282267]\n",
      " [ 0.          0.34752071 -0.17626844]\n",
      " [ 0.         -0.16590262  0.22264025]\n",
      " [ 0.         -0.10950076  0.1675192 ]\n",
      " [ 0.          0.18310814  0.00253213]\n",
      " [ 0.         -0.1013582   0.22724992]\n",
      " [ 0.         -0.0565853   0.12180429]\n",
      " [ 0.         -0.08218329  0.23177867]\n",
      " [ 0.         -0.09438048  0.16407073]\n",
      " [ 0.          0.2118182   0.08110226]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #39 | lambda learn rate = 0.0001\n",
      "Target = [[1.]\n",
      " [8.]]\n",
      "lambda end of trial = [[ 0.          0.50867974 -0.25448773]\n",
      " [ 0.          0.34730798 -0.17797028]\n",
      " [ 0.         -0.1661131   0.22095648]\n",
      " [ 0.         -0.10970493  0.16588584]\n",
      " [ 0.          0.1828982   0.00085255]\n",
      " [ 0.         -0.10158186  0.22546062]\n",
      " [ 0.         -0.05678897  0.12017489]\n",
      " [ 0.         -0.0823663   0.23031457]\n",
      " [ 0.         -0.09459066  0.16238931]\n",
      " [ 0.          0.21157994  0.07919618]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #40 | lambda learn rate = 0.0001\n",
      "Target = [[8.]\n",
      " [9.]]\n",
      "lambda end of trial = [[ 0.          0.51098755 -0.25189144]\n",
      " [ 0.          0.34955555 -0.17544176]\n",
      " [ 0.         -0.16406056  0.22326559]\n",
      " [ 0.         -0.10740731  0.16847066]\n",
      " [ 0.          0.18524373  0.00349128]\n",
      " [ 0.         -0.09944865  0.22786048]\n",
      " [ 0.         -0.05423219  0.12305127]\n",
      " [ 0.         -0.0799134   0.23307408]\n",
      " [ 0.         -0.09214466  0.16514106]\n",
      " [ 0.          0.21399603  0.08191429]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #41 | lambda learn rate = 0.0001\n",
      "Target = [[0.]\n",
      " [7.]]\n",
      "lambda end of trial = [[ 0.          0.51098755 -0.25427444]\n",
      " [ 0.          0.34955555 -0.17780157]\n",
      " [ 0.         -0.16406056  0.22113682]\n",
      " [ 0.         -0.10740731  0.16618303]\n",
      " [ 0.          0.18524373  0.001352  ]\n",
      " [ 0.         -0.09944865  0.22552498]\n",
      " [ 0.         -0.05423219  0.12074197]\n",
      " [ 0.         -0.0799134   0.23074849]\n",
      " [ 0.         -0.09214466  0.16306962]\n",
      " [ 0.          0.21399603  0.07944602]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #42 | lambda learn rate = 0.0001\n",
      "Target = [[1.]\n",
      " [5.]]\n",
      "lambda end of trial = [[ 0.00000000e+00  5.10688925e-01 -2.55767576e-01]\n",
      " [ 0.00000000e+00  3.49242894e-01 -1.79364840e-01]\n",
      " [ 0.00000000e+00 -1.64337618e-01  2.19751513e-01]\n",
      " [ 0.00000000e+00 -1.07731167e-01  1.64563762e-01]\n",
      " [ 0.00000000e+00  1.84955837e-01 -8.74838448e-05]\n",
      " [ 0.00000000e+00 -9.97742458e-02  2.23897013e-01]\n",
      " [ 0.00000000e+00 -5.45551503e-02  1.19127161e-01]\n",
      " [ 0.00000000e+00 -8.02345979e-02  2.29142506e-01]\n",
      " [ 0.00000000e+00 -9.24217683e-02  1.61684065e-01]\n",
      " [ 0.00000000e+00  2.13652485e-01  7.77282955e-02]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #43 | lambda learn rate = 0.0001\n",
      "Target = [[5.]\n",
      " [4.]]\n",
      "lambda end of trial = [[ 0.          0.50978855 -0.25648787]\n",
      " [ 0.          0.34821084 -0.18019049]\n",
      " [ 0.         -0.16527722  0.21899983]\n",
      " [ 0.         -0.1087458   0.16375205]\n",
      " [ 0.          0.18394033 -0.00089989]\n",
      " [ 0.         -0.10089921  0.22299704]\n",
      " [ 0.         -0.05550174  0.11836989]\n",
      " [ 0.         -0.08134136  0.2282571 ]\n",
      " [ 0.         -0.09341713  0.16088778]\n",
      " [ 0.          0.21253789  0.07683662]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #44 | lambda learn rate = 0.0001\n",
      "Target = [[6.]\n",
      " [3.]]\n",
      "lambda end of trial = [[ 0.          0.50883908 -0.25696261]\n",
      " [ 0.          0.34745273 -0.18056954]\n",
      " [ 0.         -0.16622302  0.21852693]\n",
      " [ 0.         -0.1097271   0.1632614 ]\n",
      " [ 0.          0.18306431 -0.0013379 ]\n",
      " [ 0.         -0.10196454  0.22246437]\n",
      " [ 0.         -0.05653561  0.11785296]\n",
      " [ 0.         -0.08230994  0.22777281]\n",
      " [ 0.         -0.09439494  0.16039887]\n",
      " [ 0.          0.21138895  0.07626215]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #45 | lambda learn rate = 0.0001\n",
      "Target = [[5.]\n",
      " [0.]]\n",
      "lambda end of trial = [[ 0.          0.50705341 -0.25696261]\n",
      " [ 0.          0.34578387 -0.18056954]\n",
      " [ 0.         -0.16810273  0.21852693]\n",
      " [ 0.         -0.11150246  0.1632614 ]\n",
      " [ 0.          0.18124753 -0.0013379 ]\n",
      " [ 0.         -0.103918    0.22246437]\n",
      " [ 0.         -0.05823296  0.11785296]\n",
      " [ 0.         -0.08434071  0.22777281]\n",
      " [ 0.         -0.09628684  0.16039887]\n",
      " [ 0.          0.20950083  0.07626215]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #46 | lambda learn rate = 0.0001\n",
      "Target = [[2.]\n",
      " [5.]]\n",
      "lambda end of trial = [[ 0.          0.50661727 -0.25805295]\n",
      " [ 0.          0.34530343 -0.18177063]\n",
      " [ 0.         -0.16858037  0.21733283]\n",
      " [ 0.         -0.11199229  0.16203682]\n",
      " [ 0.          0.1807909  -0.00247949]\n",
      " [ 0.         -0.10438013  0.22130904]\n",
      " [ 0.         -0.05864448  0.11682415]\n",
      " [ 0.         -0.08483128  0.22654637]\n",
      " [ 0.         -0.09671038  0.15934002]\n",
      " [ 0.          0.20899887  0.07500727]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #47 | lambda learn rate = 0.0001\n",
      "Target = [[1.]\n",
      " [0.]]\n",
      "lambda end of trial = [[ 0.          0.50596851 -0.25805295]\n",
      " [ 0.          0.34474114 -0.18177063]\n",
      " [ 0.         -0.16915904  0.21733283]\n",
      " [ 0.         -0.11263557  0.16203682]\n",
      " [ 0.          0.18018078 -0.00247949]\n",
      " [ 0.         -0.10508763  0.22130904]\n",
      " [ 0.         -0.05926642  0.11682415]\n",
      " [ 0.         -0.08544509  0.22654637]\n",
      " [ 0.         -0.09731324  0.15934002]\n",
      " [ 0.          0.20836696  0.07500727]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #48 | lambda learn rate = 0.0001\n",
      "Target = [[0.]\n",
      " [4.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda end of trial = [[ 0.          0.50596851 -0.25972908]\n",
      " [ 0.          0.34474114 -0.18333971]\n",
      " [ 0.         -0.16915904  0.2155387 ]\n",
      " [ 0.         -0.11263557  0.16032404]\n",
      " [ 0.          0.18018078 -0.00419753]\n",
      " [ 0.         -0.10508763  0.2196863 ]\n",
      " [ 0.         -0.05926642  0.11511399]\n",
      " [ 0.         -0.08544509  0.22473084]\n",
      " [ 0.         -0.09731324  0.15760895]\n",
      " [ 0.          0.20836696  0.07307418]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #49 | lambda learn rate = 0.0001\n",
      "Target = [[9.]\n",
      " [1.]]\n",
      "lambda end of trial = [[ 0.          0.50543481 -0.25978838]\n",
      " [ 0.          0.3441621  -0.18340405]\n",
      " [ 0.         -0.16975562  0.21547241]\n",
      " [ 0.         -0.11335983  0.16024357]\n",
      " [ 0.          0.1794248  -0.00428153]\n",
      " [ 0.         -0.10586323  0.21960012]\n",
      " [ 0.         -0.05982241  0.11505221]\n",
      " [ 0.         -0.08628189  0.22463786]\n",
      " [ 0.         -0.09795956  0.15753714]\n",
      " [ 0.          0.207606    0.07298963]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #50 | lambda learn rate = 0.0001\n",
      "Target = [[4.]\n",
      " [4.]]\n",
      "lambda end of trial = [[ 0.          0.50485222 -0.26037097]\n",
      " [ 0.          0.34362555 -0.18394059]\n",
      " [ 0.         -0.17032744  0.21490059]\n",
      " [ 0.         -0.11393792  0.15966548]\n",
      " [ 0.          0.1788338  -0.00487252]\n",
      " [ 0.         -0.10646444  0.21899891]\n",
      " [ 0.         -0.06042844  0.11444618]\n",
      " [ 0.         -0.08687035  0.22404939]\n",
      " [ 0.         -0.09850583  0.15699086]\n",
      " [ 0.          0.20697037  0.072354  ]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #51 | lambda learn rate = 0.0001\n",
      "Target = [[3.]\n",
      " [5.]]\n",
      "lambda end of trial = [[ 0.          0.50448693 -0.26097978]\n",
      " [ 0.          0.34325262 -0.18456215]\n",
      " [ 0.         -0.17069831  0.21428247]\n",
      " [ 0.         -0.11435644  0.15896794]\n",
      " [ 0.          0.17842544 -0.00555313]\n",
      " [ 0.         -0.10685405  0.21834956]\n",
      " [ 0.         -0.06080098  0.11382529]\n",
      " [ 0.         -0.08731714  0.22330476]\n",
      " [ 0.         -0.09888758  0.15635462]\n",
      " [ 0.          0.20653457  0.07162767]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #52 | lambda learn rate = 0.0001\n",
      "Target = [[0.]\n",
      " [5.]]\n",
      "lambda end of trial = [[ 0.          0.50448693 -0.26257854]\n",
      " [ 0.          0.34325262 -0.18598644]\n",
      " [ 0.         -0.17069831  0.2126709 ]\n",
      " [ 0.         -0.11435644  0.15743191]\n",
      " [ 0.          0.17842544 -0.0071745 ]\n",
      " [ 0.         -0.10685405  0.21668482]\n",
      " [ 0.         -0.06080098  0.11233551]\n",
      " [ 0.         -0.08731714  0.22176055]\n",
      " [ 0.         -0.09888758  0.15493491]\n",
      " [ 0.          0.20653457  0.06997417]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #53 | lambda learn rate = 0.0001\n",
      "Target = [[6.]\n",
      " [5.]]\n",
      "lambda end of trial = [[ 0.          0.50524243 -0.26194895]\n",
      " [ 0.          0.34405577 -0.18531714]\n",
      " [ 0.         -0.16998322  0.21326681]\n",
      " [ 0.         -0.11360904  0.15805475]\n",
      " [ 0.          0.1790779  -0.00663078]\n",
      " [ 0.         -0.10616763  0.21725683]\n",
      " [ 0.         -0.0599598   0.1130365 ]\n",
      " [ 0.         -0.0867272   0.22225217]\n",
      " [ 0.         -0.0981814   0.15552339]\n",
      " [ 0.          0.20710126  0.07044642]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #54 | lambda learn rate = 0.0001\n",
      "Target = [[8.]\n",
      " [8.]]\n",
      "lambda end of trial = [[ 0.          0.5091999  -0.25799148]\n",
      " [ 0.          0.34777648 -0.18159644]\n",
      " [ 0.         -0.16623768  0.21701235]\n",
      " [ 0.         -0.10983472  0.16182907]\n",
      " [ 0.          0.18265721 -0.00305148]\n",
      " [ 0.         -0.1026313   0.22079317]\n",
      " [ 0.         -0.05604683  0.11694946]\n",
      " [ 0.         -0.08278108  0.22619829]\n",
      " [ 0.         -0.09450369  0.15920111]\n",
      " [ 0.          0.21053727  0.07388242]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #55 | lambda learn rate = 0.0001\n",
      "Target = [[4.]\n",
      " [0.]]\n",
      "lambda end of trial = [[ 0.          0.50749968 -0.25799148]\n",
      " [ 0.          0.34601555 -0.18159644]\n",
      " [ 0.         -0.16792917  0.21701235]\n",
      " [ 0.         -0.11168802  0.16182907]\n",
      " [ 0.          0.1810195  -0.00305148]\n",
      " [ 0.         -0.10430418  0.22079317]\n",
      " [ 0.         -0.05786114  0.11694946]\n",
      " [ 0.         -0.08455172  0.22619829]\n",
      " [ 0.         -0.09608877  0.15920111]\n",
      " [ 0.          0.20862549  0.07388242]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #56 | lambda learn rate = 0.0001\n",
      "Target = [[9.]\n",
      " [7.]]\n",
      "lambda end of trial = [[ 0.          0.51072079 -0.25548618]\n",
      " [ 0.          0.34913793 -0.17916792]\n",
      " [ 0.         -0.16493209  0.21934341]\n",
      " [ 0.         -0.10882862  0.16405305]\n",
      " [ 0.          0.18404917 -0.00069507]\n",
      " [ 0.         -0.10133496  0.22310256]\n",
      " [ 0.         -0.0549851   0.11918638]\n",
      " [ 0.         -0.08149628  0.22857474]\n",
      " [ 0.         -0.09332109  0.16135374]\n",
      " [ 0.          0.21159584  0.07619269]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #57 | lambda learn rate = 0.0001\n",
      "Target = [[8.]\n",
      " [5.]]\n",
      "lambda end of trial = [[ 0.00000000e+00  5.11174997e-01 -2.55202300e-01]\n",
      " [ 0.00000000e+00  3.49671121e-01 -1.78834675e-01]\n",
      " [ 0.00000000e+00 -1.64392400e-01  2.19680715e-01]\n",
      " [ 0.00000000e+00 -1.08352942e-01  1.64350346e-01]\n",
      " [ 0.00000000e+00  1.84536292e-01 -3.90616218e-04]\n",
      " [ 0.00000000e+00 -1.00919868e-01  2.23361992e-01]\n",
      " [ 0.00000000e+00 -5.45544551e-02  1.19455534e-01]\n",
      " [ 0.00000000e+00 -8.10893453e-02  2.28829078e-01]\n",
      " [ 0.00000000e+00 -9.27967893e-02  1.61681433e-01]\n",
      " [ 0.00000000e+00  2.11957777e-01  7.64189051e-02]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #58 | lambda learn rate = 0.0001\n",
      "Target = [[3.]\n",
      " [2.]]\n",
      "lambda end of trial = [[ 0.          0.50998789 -0.2559937 ]\n",
      " [ 0.          0.34848262 -0.17962701]\n",
      " [ 0.         -0.16550621  0.21893818]\n",
      " [ 0.         -0.10948213  0.16359755]\n",
      " [ 0.          0.18335968 -0.00117503]\n",
      " [ 0.         -0.10204739  0.22261031]\n",
      " [ 0.         -0.05567245  0.1187102 ]\n",
      " [ 0.         -0.08214723  0.22812382]\n",
      " [ 0.         -0.09383923  0.16098647]\n",
      " [ 0.          0.21070939  0.07558665]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #59 | lambda learn rate = 0.0001\n",
      "Target = [[5.]\n",
      " [7.]]\n",
      "lambda end of trial = [[ 0.          0.51013475 -0.25578811]\n",
      " [ 0.          0.34869043 -0.17933607]\n",
      " [ 0.         -0.16537642  0.21911987]\n",
      " [ 0.         -0.10932677  0.16381506]\n",
      " [ 0.          0.18349866 -0.00098045]\n",
      " [ 0.         -0.1019403   0.22276023]\n",
      " [ 0.         -0.05550013  0.11895145]\n",
      " [ 0.         -0.08199395  0.22833842]\n",
      " [ 0.         -0.09365747  0.16124094]\n",
      " [ 0.          0.21081168  0.07572986]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #60 | lambda learn rate = 0.0001\n",
      "Target = [[4.]\n",
      " [4.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda end of trial = [[ 0.          0.50921491 -0.25670794]\n",
      " [ 0.          0.34771679 -0.18030971]\n",
      " [ 0.         -0.16632176  0.21817454]\n",
      " [ 0.         -0.11021747  0.16292437]\n",
      " [ 0.          0.18259739 -0.00188172]\n",
      " [ 0.         -0.10290818  0.22179235]\n",
      " [ 0.         -0.05644764  0.11800395]\n",
      " [ 0.         -0.08295272  0.22737964]\n",
      " [ 0.         -0.09468342  0.16021499]\n",
      " [ 0.          0.20974362  0.0746618 ]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #61 | lambda learn rate = 0.0001\n",
      "Target = [[2.]\n",
      " [3.]]\n",
      "lambda end of trial = [[ 0.          0.50854777 -0.25770866]\n",
      " [ 0.          0.34702646 -0.18134521]\n",
      " [ 0.         -0.16700954  0.21714286]\n",
      " [ 0.         -0.11083504  0.16199801]\n",
      " [ 0.          0.18188131 -0.00295584]\n",
      " [ 0.         -0.10354267  0.22084061]\n",
      " [ 0.         -0.05713473  0.11697331]\n",
      " [ 0.         -0.08361075  0.2263926 ]\n",
      " [ 0.         -0.0954287   0.15909707]\n",
      " [ 0.          0.2089716   0.07350376]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #62 | lambda learn rate = 0.0001\n",
      "Target = [[4.]\n",
      " [1.]]\n",
      "lambda end of trial = [[ 0.          0.50706112 -0.25808032]\n",
      " [ 0.          0.34560508 -0.18170055]\n",
      " [ 0.         -0.16863401  0.21673674]\n",
      " [ 0.         -0.11232226  0.1616262 ]\n",
      " [ 0.          0.18032388 -0.0033452 ]\n",
      " [ 0.         -0.10496954  0.2204839 ]\n",
      " [ 0.         -0.05861518  0.1166032 ]\n",
      " [ 0.         -0.08514534  0.22600895]\n",
      " [ 0.         -0.09686064  0.15873909]\n",
      " [ 0.          0.20743936  0.0731207 ]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #63 | lambda learn rate = 0.0001\n",
      "Target = [[9.]\n",
      " [6.]]\n",
      "lambda end of trial = [[ 0.          0.51005068 -0.25608729]\n",
      " [ 0.          0.34823969 -0.17994415]\n",
      " [ 0.         -0.16572936  0.21867317]\n",
      " [ 0.         -0.10961873  0.16342856]\n",
      " [ 0.          0.18283961 -0.00166805]\n",
      " [ 0.         -0.10269513  0.22200017]\n",
      " [ 0.         -0.05578478  0.11849013]\n",
      " [ 0.         -0.08251665  0.22776141]\n",
      " [ 0.         -0.09409562  0.16058243]\n",
      " [ 0.          0.21005302  0.07486314]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #64 | lambda learn rate = 0.0001\n",
      "Target = [[7.]\n",
      " [2.]]\n",
      "lambda end of trial = [[ 0.          0.50890811 -0.25641374]\n",
      " [ 0.          0.34726067 -0.18022387]\n",
      " [ 0.         -0.16686575  0.21834849]\n",
      " [ 0.         -0.11082769  0.16308314]\n",
      " [ 0.          0.18178101 -0.00197051]\n",
      " [ 0.         -0.10391417  0.22165187]\n",
      " [ 0.         -0.05686763  0.11818074]\n",
      " [ 0.         -0.08377971  0.22740054]\n",
      " [ 0.         -0.09516323  0.1602774 ]\n",
      " [ 0.          0.20862671  0.07445562]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #65 | lambda learn rate = 0.0001\n",
      "Target = [[7.]\n",
      " [6.]]\n",
      "lambda end of trial = [[ 0.          0.5098308  -0.25562285]\n",
      " [ 0.          0.34815523 -0.1794571 ]\n",
      " [ 0.         -0.16592194  0.21915747]\n",
      " [ 0.         -0.10991548  0.16386503]\n",
      " [ 0.          0.18270876 -0.00117529]\n",
      " [ 0.         -0.10295738  0.22247198]\n",
      " [ 0.         -0.05586834  0.11903727]\n",
      " [ 0.         -0.0826966   0.22832892]\n",
      " [ 0.         -0.0942956   0.16102108]\n",
      " [ 0.          0.20934612  0.07507226]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #66 | lambda learn rate = 0.0001\n",
      "Target = [[5.]\n",
      " [6.]]\n",
      "lambda end of trial = [[ 0.          0.50982203 -0.25563339]\n",
      " [ 0.          0.34807574 -0.1795525 ]\n",
      " [ 0.         -0.16598553  0.21908116]\n",
      " [ 0.         -0.11003688  0.16371935]\n",
      " [ 0.          0.18257765 -0.00133261]\n",
      " [ 0.         -0.10304791  0.22236334]\n",
      " [ 0.         -0.0560031   0.11887557]\n",
      " [ 0.         -0.08285755  0.22813578]\n",
      " [ 0.         -0.09446076  0.16082289]\n",
      " [ 0.          0.20915236  0.07483975]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #67 | lambda learn rate = 0.0001\n",
      "Target = [[1.]\n",
      " [5.]]\n",
      "lambda end of trial = [[ 0.          0.50953143 -0.25708636]\n",
      " [ 0.          0.34779553 -0.18095354]\n",
      " [ 0.         -0.1662849   0.21758431]\n",
      " [ 0.         -0.11029265  0.16244051]\n",
      " [ 0.          0.18226866 -0.00287761]\n",
      " [ 0.         -0.10334025  0.22090166]\n",
      " [ 0.         -0.0562887   0.11744758]\n",
      " [ 0.         -0.08316028  0.22662212]\n",
      " [ 0.         -0.0947389   0.15943218]\n",
      " [ 0.          0.20882227  0.0731893 ]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #68 | lambda learn rate = 0.0001\n",
      "Target = [[1.]\n",
      " [4.]]\n",
      "lambda end of trial = [[ 0.          0.50917011 -0.25853164]\n",
      " [ 0.          0.34746588 -0.18227213]\n",
      " [ 0.         -0.16663257  0.21619365]\n",
      " [ 0.         -0.11061709  0.16114274]\n",
      " [ 0.          0.18190885 -0.00431684]\n",
      " [ 0.         -0.10370062  0.21946017]\n",
      " [ 0.         -0.0566355   0.11606038]\n",
      " [ 0.         -0.08351183  0.2252159 ]\n",
      " [ 0.         -0.09507446  0.15808993]\n",
      " [ 0.          0.20846514  0.07176076]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #69 | lambda learn rate = 0.0001\n",
      "Target = [[6.]\n",
      " [1.]]\n",
      "lambda end of trial = [[ 0.          0.50789892 -0.2587435 ]\n",
      " [ 0.          0.3460276  -0.18251185]\n",
      " [ 0.         -0.16807568  0.21595313]\n",
      " [ 0.         -0.11211211  0.16089357]\n",
      " [ 0.          0.18062171 -0.00453136]\n",
      " [ 0.         -0.10513766  0.21922066]\n",
      " [ 0.         -0.05805404  0.11582396]\n",
      " [ 0.         -0.08505688  0.22495839]\n",
      " [ 0.         -0.09642177  0.15786538]\n",
      " [ 0.          0.20704691  0.07152439]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #70 | lambda learn rate = 0.0001\n",
      "Target = [[5.]\n",
      " [4.]]\n",
      "lambda end of trial = [[ 0.          0.50756623 -0.25900966]\n",
      " [ 0.          0.34551075 -0.18292533]\n",
      " [ 0.         -0.16852936  0.21559018]\n",
      " [ 0.         -0.11255702  0.16053764]\n",
      " [ 0.          0.18016684 -0.00489526]\n",
      " [ 0.         -0.10567257  0.21879273]\n",
      " [ 0.         -0.05848252  0.11548117]\n",
      " [ 0.         -0.0855805   0.2245395 ]\n",
      " [ 0.         -0.09686055  0.15751436]\n",
      " [ 0.          0.2064532   0.07104942]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #71 | lambda learn rate = 0.0001\n",
      "Target = [[2.]\n",
      " [8.]]\n",
      "lambda end of trial = [[ 0.          0.50765617 -0.25864988]\n",
      " [ 0.          0.3455999  -0.18256871]\n",
      " [ 0.         -0.1684488   0.21591243]\n",
      " [ 0.         -0.11246971  0.16088688]\n",
      " [ 0.          0.18024749 -0.00457267]\n",
      " [ 0.         -0.10558615  0.21913843]\n",
      " [ 0.         -0.05838523  0.11587033]\n",
      " [ 0.         -0.08549988  0.22486194]\n",
      " [ 0.         -0.09674289  0.15798501]\n",
      " [ 0.          0.20651736  0.07130609]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #72 | lambda learn rate = 0.0001\n",
      "Target = [[5.]\n",
      " [1.]]\n",
      "lambda end of trial = [[ 0.          0.50634774 -0.25891157]\n",
      " [ 0.          0.34422366 -0.18284396]\n",
      " [ 0.         -0.16985058  0.21563207]\n",
      " [ 0.         -0.11370209  0.1606404 ]\n",
      " [ 0.          0.17872206 -0.00487776]\n",
      " [ 0.         -0.10693709  0.21886824]\n",
      " [ 0.         -0.05983018  0.11558134]\n",
      " [ 0.         -0.08709137  0.22454365]\n",
      " [ 0.         -0.09807578  0.15771843]\n",
      " [ 0.          0.20520735  0.07104408]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #73 | lambda learn rate = 0.0001\n",
      "Target = [[7.]\n",
      " [8.]]\n",
      "lambda end of trial = [[ 0.          0.50868018 -0.25624592]\n",
      " [ 0.          0.34689906 -0.17978636]\n",
      " [ 0.         -0.16749616  0.21832283]\n",
      " [ 0.         -0.11145312  0.16321065]\n",
      " [ 0.          0.18113389 -0.00212138]\n",
      " [ 0.         -0.10419751  0.22199919]\n",
      " [ 0.         -0.05729012  0.11848427]\n",
      " [ 0.         -0.08461409  0.22737482]\n",
      " [ 0.         -0.09550188  0.16066002]\n",
      " [ 0.          0.20796189  0.07419214]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #74 | lambda learn rate = 0.0001\n",
      "Target = [[5.]\n",
      " [3.]]\n",
      "lambda end of trial = [[ 0.          0.50787784 -0.25672733]\n",
      " [ 0.          0.34594214 -0.18036051]\n",
      " [ 0.         -0.16833488  0.2178196 ]\n",
      " [ 0.         -0.11232135  0.16268972]\n",
      " [ 0.          0.18026501 -0.00264271]\n",
      " [ 0.         -0.10501915  0.22150621]\n",
      " [ 0.         -0.05813928  0.11797477]\n",
      " [ 0.         -0.08553156  0.22682434]\n",
      " [ 0.         -0.09623197  0.16022197]\n",
      " [ 0.          0.20700118  0.07361571]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #75 | lambda learn rate = 0.0001\n",
      "Target = [[5.]\n",
      " [0.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda end of trial = [[ 0.          0.5059518  -0.25672733]\n",
      " [ 0.          0.34391961 -0.18036051]\n",
      " [ 0.         -0.17013779  0.2178196 ]\n",
      " [ 0.         -0.11430044  0.16268972]\n",
      " [ 0.          0.17836667 -0.00264271]\n",
      " [ 0.         -0.10688039  0.22150621]\n",
      " [ 0.         -0.05999883  0.11797477]\n",
      " [ 0.         -0.08738916  0.22682434]\n",
      " [ 0.         -0.09801919  0.16022197]\n",
      " [ 0.          0.20502468  0.07361571]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #76 | lambda learn rate = 0.0001\n",
      "Target = [[9.]\n",
      " [3.]]\n",
      "lambda end of trial = [[ 0.          0.50707146 -0.25635411]\n",
      " [ 0.          0.34518718 -0.17993799]\n",
      " [ 0.         -0.16896051  0.21821202]\n",
      " [ 0.         -0.11298468  0.16312831]\n",
      " [ 0.          0.1797088  -0.00219533]\n",
      " [ 0.         -0.10580115  0.22186595]\n",
      " [ 0.         -0.05866748  0.11841856]\n",
      " [ 0.         -0.08615091  0.22723709]\n",
      " [ 0.         -0.09681874  0.16062212]\n",
      " [ 0.          0.20615543  0.07399262]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #77 | lambda learn rate = 0.0001\n",
      "Target = [[3.]\n",
      " [2.]]\n",
      "lambda end of trial = [[ 0.          0.50605669 -0.25703062]\n",
      " [ 0.          0.34413552 -0.18063909]\n",
      " [ 0.         -0.17009748  0.21745404]\n",
      " [ 0.         -0.11410457  0.16238171]\n",
      " [ 0.          0.17851396 -0.00299189]\n",
      " [ 0.         -0.10693151  0.22111239]\n",
      " [ 0.         -0.05967726  0.11774537]\n",
      " [ 0.         -0.08726846  0.22649206]\n",
      " [ 0.         -0.09792535  0.15988438]\n",
      " [ 0.          0.20490036  0.07315591]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #78 | lambda learn rate = 0.0001\n",
      "Target = [[0.]\n",
      " [8.]]\n",
      "lambda end of trial = [[ 0.          0.50605669 -0.25810543]\n",
      " [ 0.          0.34413552 -0.18159888]\n",
      " [ 0.         -0.17009748  0.21623426]\n",
      " [ 0.         -0.11410457  0.16128287]\n",
      " [ 0.          0.17851396 -0.00408758]\n",
      " [ 0.         -0.10693151  0.21982454]\n",
      " [ 0.         -0.05967726  0.11673263]\n",
      " [ 0.         -0.08726846  0.22519919]\n",
      " [ 0.         -0.09792535  0.15864499]\n",
      " [ 0.          0.20490036  0.07177401]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #79 | lambda learn rate = 0.0001\n",
      "Target = [[7.]\n",
      " [7.]]\n",
      "lambda end of trial = [[ 0.          0.5080269  -0.25613523]\n",
      " [ 0.          0.34603751 -0.17969689]\n",
      " [ 0.         -0.16809595  0.2182358 ]\n",
      " [ 0.         -0.1119677   0.16341974]\n",
      " [ 0.          0.18044691 -0.00215463]\n",
      " [ 0.         -0.10504257  0.22171347]\n",
      " [ 0.         -0.05782199  0.1185879 ]\n",
      " [ 0.         -0.08535632  0.22711133]\n",
      " [ 0.         -0.09589714  0.1606732 ]\n",
      " [ 0.          0.20653588  0.07340952]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #80 | lambda learn rate = 0.0001\n",
      "Target = [[2.]\n",
      " [5.]]\n",
      "lambda end of trial = [[ 0.          0.50753958 -0.25735352]\n",
      " [ 0.          0.34557645 -0.18084955]\n",
      " [ 0.         -0.16859636  0.21698477]\n",
      " [ 0.         -0.11252507  0.1620263 ]\n",
      " [ 0.          0.17996594 -0.00335704]\n",
      " [ 0.         -0.10556028  0.2204192 ]\n",
      " [ 0.         -0.05832328  0.1173347 ]\n",
      " [ 0.         -0.08584289  0.22589489]\n",
      " [ 0.         -0.09635806  0.15952092]\n",
      " [ 0.          0.20601933  0.07211815]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #81 | lambda learn rate = 0.0001\n",
      "Target = [[7.]\n",
      " [5.]]\n",
      "lambda end of trial = [[ 0.          0.50844136 -0.25670939]\n",
      " [ 0.          0.34641256 -0.18025233]\n",
      " [ 0.         -0.16789362  0.21748673]\n",
      " [ 0.         -0.1116841   0.162627  ]\n",
      " [ 0.          0.1806682  -0.00285543]\n",
      " [ 0.         -0.10471356  0.221024  ]\n",
      " [ 0.         -0.05744871  0.11795939]\n",
      " [ 0.         -0.08503176  0.22647427]\n",
      " [ 0.         -0.09553712  0.1601073 ]\n",
      " [ 0.          0.20671535  0.0726153 ]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #82 | lambda learn rate = 0.0001\n",
      "Target = [[4.]\n",
      " [8.]]\n",
      "lambda end of trial = [[ 0.          0.50892517 -0.25574177]\n",
      " [ 0.          0.34696452 -0.1791484 ]\n",
      " [ 0.         -0.16736167  0.21855061]\n",
      " [ 0.         -0.11120905  0.16357711]\n",
      " [ 0.          0.18114155 -0.00190873]\n",
      " [ 0.         -0.10429802  0.22185508]\n",
      " [ 0.         -0.05693803  0.11898074]\n",
      " [ 0.         -0.0845461   0.22744559]\n",
      " [ 0.         -0.09499352  0.16119449]\n",
      " [ 0.          0.20712379  0.07343218]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #83 | lambda learn rate = 0.0001\n",
      "Target = [[7.]\n",
      " [3.]]\n",
      "lambda end of trial = [[ 0.          0.50847022 -0.25593675]\n",
      " [ 0.          0.34648652 -0.17935326]\n",
      " [ 0.         -0.16787893  0.21832893]\n",
      " [ 0.         -0.11167049  0.16337935]\n",
      " [ 0.          0.18055509 -0.00216007]\n",
      " [ 0.         -0.10494008  0.22157991]\n",
      " [ 0.         -0.05735927  0.11880021]\n",
      " [ 0.         -0.08515932  0.22718278]\n",
      " [ 0.         -0.09546007  0.16099454]\n",
      " [ 0.          0.20637769  0.07311242]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #84 | lambda learn rate = 0.0001\n",
      "Target = [[5.]\n",
      " [8.]]\n",
      "lambda end of trial = [[ 0.          0.50917981 -0.25480141]\n",
      " [ 0.          0.34727792 -0.17808702]\n",
      " [ 0.         -0.16709294  0.21958652]\n",
      " [ 0.         -0.11106808  0.16434321]\n",
      " [ 0.          0.18136847 -0.00085866]\n",
      " [ 0.         -0.10425035  0.22268347]\n",
      " [ 0.         -0.05663361  0.11996126]\n",
      " [ 0.         -0.08447749  0.2282737 ]\n",
      " [ 0.         -0.09468904  0.1622282 ]\n",
      " [ 0.          0.20706428  0.07421096]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #85 | lambda learn rate = 0.0001\n",
      "Target = [[5.]\n",
      " [3.]]\n",
      "lambda end of trial = [[ 0.          0.50814417 -0.25542279]\n",
      " [ 0.          0.34625308 -0.17870193]\n",
      " [ 0.         -0.16818839  0.21892924]\n",
      " [ 0.         -0.11192796  0.16382728]\n",
      " [ 0.          0.18032824 -0.0014828 ]\n",
      " [ 0.         -0.10522871  0.22209646]\n",
      " [ 0.         -0.05754942  0.11941177]\n",
      " [ 0.         -0.08547333  0.2276762 ]\n",
      " [ 0.         -0.09575655  0.16158769]\n",
      " [ 0.          0.20593281  0.07353208]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #86 | lambda learn rate = 0.0001\n",
      "Target = [[2.]\n",
      " [8.]]\n",
      "lambda end of trial = [[ 0.          0.50805931 -0.25576223]\n",
      " [ 0.          0.34616687 -0.17904677]\n",
      " [ 0.         -0.16825793  0.2186511 ]\n",
      " [ 0.         -0.11200886  0.16350368]\n",
      " [ 0.          0.18025239 -0.00178618]\n",
      " [ 0.         -0.10530783  0.22177996]\n",
      " [ 0.         -0.05763143  0.11908374]\n",
      " [ 0.         -0.08554463  0.22739099]\n",
      " [ 0.         -0.0958454   0.16123229]\n",
      " [ 0.          0.205835    0.07314085]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #87 | lambda learn rate = 0.0001\n",
      "Target = [[4.]\n",
      " [8.]]\n",
      "lambda end of trial = [[ 0.          0.50840039 -0.25508007]\n",
      " [ 0.          0.34657813 -0.17822425]\n",
      " [ 0.         -0.16790211  0.21936274]\n",
      " [ 0.         -0.11164039  0.16424061]\n",
      " [ 0.          0.18054239 -0.00120619]\n",
      " [ 0.         -0.10492672  0.22254219]\n",
      " [ 0.         -0.0572664   0.11981381]\n",
      " [ 0.         -0.08519359  0.22809308]\n",
      " [ 0.         -0.09543559  0.1620519 ]\n",
      " [ 0.          0.20617068  0.07381222]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #88 | lambda learn rate = 0.0001\n",
      "Target = [[3.]\n",
      " [5.]]\n",
      "lambda end of trial = [[ 0.          0.50787278 -0.25595942]\n",
      " [ 0.          0.3461446  -0.1789468 ]\n",
      " [ 0.         -0.16842548  0.21849046]\n",
      " [ 0.         -0.11213804  0.1634112 ]\n",
      " [ 0.          0.18007747 -0.00198105]\n",
      " [ 0.         -0.10545236  0.22166613]\n",
      " [ 0.         -0.05777854  0.11896023]\n",
      " [ 0.         -0.08571883  0.22721768]\n",
      " [ 0.         -0.09595585  0.16118481]\n",
      " [ 0.          0.20560349  0.07286689]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #89 | lambda learn rate = 0.0001\n",
      "Target = [[2.]\n",
      " [8.]]\n",
      "lambda end of trial = [[ 0.          0.50781838 -0.25617702]\n",
      " [ 0.          0.34608602 -0.17918113]\n",
      " [ 0.         -0.16846169  0.2183456 ]\n",
      " [ 0.         -0.11218641  0.1632177 ]\n",
      " [ 0.          0.18002683 -0.00218359]\n",
      " [ 0.         -0.10551026  0.22143451]\n",
      " [ 0.         -0.05780523  0.11885347]\n",
      " [ 0.         -0.08578419  0.22695624]\n",
      " [ 0.         -0.09601511  0.16094777]\n",
      " [ 0.          0.20551193  0.07250066]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #90 | lambda learn rate = 0.0001\n",
      "Target = [[8.]\n",
      " [6.]]\n",
      "lambda end of trial = [[ 0.          0.50964332 -0.25480831]\n",
      " [ 0.          0.34804108 -0.17771483]\n",
      " [ 0.         -0.16677204  0.21961283]\n",
      " [ 0.         -0.11029436  0.16463674]\n",
      " [ 0.          0.18193522 -0.00075229]\n",
      " [ 0.         -0.10363234  0.22284295]\n",
      " [ 0.         -0.05603945  0.12017781]\n",
      " [ 0.         -0.0841098   0.22821203]\n",
      " [ 0.         -0.09427849  0.16225023]\n",
      " [ 0.          0.20711696  0.07370443]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #91 | lambda learn rate = 0.0001\n",
      "Target = [[0.]\n",
      " [8.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda end of trial = [[ 0.          0.50964332 -0.25615746]\n",
      " [ 0.          0.34804108 -0.17886277]\n",
      " [ 0.         -0.16677204  0.21833017]\n",
      " [ 0.         -0.11029436  0.16332245]\n",
      " [ 0.          0.18193522 -0.00223465]\n",
      " [ 0.         -0.10363234  0.2213464 ]\n",
      " [ 0.         -0.05603945  0.11890053]\n",
      " [ 0.         -0.0841098   0.22691461]\n",
      " [ 0.         -0.09427849  0.16085988]\n",
      " [ 0.          0.20711696  0.07220078]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #92 | lambda learn rate = 0.0001\n",
      "Target = [[9.]\n",
      " [0.]]\n",
      "lambda end of trial = [[ 0.          0.50819844 -0.25615746]\n",
      " [ 0.          0.34667786 -0.17886277]\n",
      " [ 0.         -0.16805047  0.21833017]\n",
      " [ 0.         -0.11167123  0.16332245]\n",
      " [ 0.          0.18049722 -0.00223465]\n",
      " [ 0.         -0.10525591  0.2213464 ]\n",
      " [ 0.         -0.05756367  0.11890053]\n",
      " [ 0.         -0.08572403  0.22691461]\n",
      " [ 0.         -0.095802    0.16085988]\n",
      " [ 0.          0.20550636  0.07220078]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #93 | lambda learn rate = 0.0001\n",
      "Target = [[1.]\n",
      " [1.]]\n",
      "lambda end of trial = [[ 0.          0.50764321 -0.25671269]\n",
      " [ 0.          0.34620078 -0.17933985]\n",
      " [ 0.         -0.16859004  0.2177906 ]\n",
      " [ 0.         -0.11220073  0.16279295]\n",
      " [ 0.          0.17994853 -0.00278334]\n",
      " [ 0.         -0.10584325  0.22075906]\n",
      " [ 0.         -0.05810406  0.11836014]\n",
      " [ 0.         -0.08629171  0.22634693]\n",
      " [ 0.         -0.09633848  0.1603234 ]\n",
      " [ 0.          0.20494146  0.07163588]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #94 | lambda learn rate = 0.0001\n",
      "Target = [[8.]\n",
      " [2.]]\n",
      "lambda end of trial = [[ 0.          0.50744057 -0.25676335]\n",
      " [ 0.          0.3461032  -0.17936425]\n",
      " [ 0.         -0.16874256  0.21775247]\n",
      " [ 0.         -0.11234176  0.16275769]\n",
      " [ 0.          0.17986581 -0.00280402]\n",
      " [ 0.         -0.10600891  0.22071764]\n",
      " [ 0.         -0.05814955  0.11834877]\n",
      " [ 0.         -0.08650505  0.22629359]\n",
      " [ 0.         -0.09649922  0.16028321]\n",
      " [ 0.          0.20466382  0.07156647]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #95 | lambda learn rate = 0.0001\n",
      "Target = [[7.]\n",
      " [2.]]\n",
      "lambda end of trial = [[ 0.          0.50666643 -0.25698453]\n",
      " [ 0.          0.34527878 -0.1795998 ]\n",
      " [ 0.         -0.16951368  0.21753215]\n",
      " [ 0.         -0.11299839  0.16257008]\n",
      " [ 0.          0.17902489 -0.00304428]\n",
      " [ 0.         -0.10690153  0.22046261]\n",
      " [ 0.         -0.05901465  0.1181016 ]\n",
      " [ 0.         -0.08746252  0.22602003]\n",
      " [ 0.         -0.09724038  0.16007146]\n",
      " [ 0.          0.20366799  0.07128195]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #96 | lambda learn rate = 0.0001\n",
      "Target = [[8.]\n",
      " [3.]]\n",
      "lambda end of trial = [[ 0.          0.50699861 -0.25685997]\n",
      " [ 0.          0.34572853 -0.17943114]\n",
      " [ 0.         -0.16917816  0.21765797]\n",
      " [ 0.         -0.11257782  0.16272779]\n",
      " [ 0.          0.17935347 -0.00292107]\n",
      " [ 0.         -0.10669073  0.22054166]\n",
      " [ 0.         -0.05855425  0.11827424]\n",
      " [ 0.         -0.08717857  0.22612651]\n",
      " [ 0.         -0.09684662  0.16021911]\n",
      " [ 0.          0.20395503  0.07138959]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #97 | lambda learn rate = 0.0001\n",
      "Target = [[3.]\n",
      " [5.]]\n",
      "lambda end of trial = [[ 0.          0.50643315 -0.2578024 ]\n",
      " [ 0.          0.34520563 -0.18030265]\n",
      " [ 0.         -0.1696978   0.2167919 ]\n",
      " [ 0.         -0.11312981  0.16180782]\n",
      " [ 0.          0.17876329 -0.00390471]\n",
      " [ 0.         -0.10733475  0.21946828]\n",
      " [ 0.         -0.05914923  0.11728262]\n",
      " [ 0.         -0.08779102  0.22510576]\n",
      " [ 0.         -0.09739755  0.15930091]\n",
      " [ 0.          0.2033081   0.07031138]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #98 | lambda learn rate = 0.0001\n",
      "Target = [[7.]\n",
      " [4.]]\n",
      "lambda end of trial = [[ 0.          0.50690697 -0.25753165]\n",
      " [ 0.          0.34567076 -0.18003686]\n",
      " [ 0.         -0.16913298  0.21711465]\n",
      " [ 0.         -0.1125781   0.16212308]\n",
      " [ 0.          0.17925059 -0.00362625]\n",
      " [ 0.         -0.1068416   0.21975008]\n",
      " [ 0.         -0.05858376  0.11760574]\n",
      " [ 0.         -0.08739508  0.22533201]\n",
      " [ 0.         -0.09681521  0.15963367]\n",
      " [ 0.          0.20379372  0.07058887]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "+++++++++++++++++++++++++++++++++++\n",
      "Session #3\n",
      "target at trial 0 = [[1.]\n",
      " [1.]]\n",
      "K MATX INIT= [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "A VECT INIT = [-0. -0.]\n",
      "lambda\n",
      "[[ 0.          0.53020654 -0.2322202 ]\n",
      " [ 0.          0.36705474 -0.15737009]\n",
      " [ 0.         -0.14629582  0.24261404]\n",
      " [ 0.         -0.08877213  0.18799136]\n",
      " [ 0.          0.20486852  0.02360278]\n",
      " [ 0.         -0.07854344  0.25002723]\n",
      " [ 0.         -0.03748972  0.14111247]\n",
      " [ 0.         -0.0597867   0.25435404]\n",
      " [ 0.         -0.07409235  0.18348285]\n",
      " [ 0.          0.23653843  0.10488391]]\n",
      "a\n",
      "[-0. -0.]\n",
      "K\n",
      "[[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #0 | lambda learn rate = 0.0001\n",
      "Target = [[1.]\n",
      " [1.]]\n",
      "lambda end of trial = [[ 0.          0.52956335 -0.23286338]\n",
      " [ 0.          0.36638793 -0.1580369 ]\n",
      " [ 0.         -0.14698402  0.24192584]\n",
      " [ 0.         -0.08947741  0.18728608]\n",
      " [ 0.          0.20419772  0.02293198]\n",
      " [ 0.         -0.07924013  0.24933055]\n",
      " [ 0.         -0.0381751   0.1404271 ]\n",
      " [ 0.         -0.06061587  0.25352486]\n",
      " [ 0.         -0.07473899  0.18283621]\n",
      " [ 0.          0.23585886  0.10420434]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #1 | lambda learn rate = 0.0001\n",
      "Target = [[6.]\n",
      " [8.]]\n",
      "lambda end of trial = [[ 0.          0.52560528 -0.23814081]\n",
      " [ 0.          0.36248942 -0.16323491]\n",
      " [ 0.         -0.1502374   0.237588  ]\n",
      " [ 0.         -0.09314213  0.18239978]\n",
      " [ 0.          0.20029581  0.01772943]\n",
      " [ 0.         -0.0831299   0.24414419]\n",
      " [ 0.         -0.04192835  0.13542276]\n",
      " [ 0.         -0.06451113  0.24833119]\n",
      " [ 0.         -0.0785529   0.17775099]\n",
      " [ 0.          0.23216733  0.0992823 ]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #2 | lambda learn rate = 0.0001\n",
      "Target = [[0.]\n",
      " [4.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda end of trial = [[ 0.          0.52560528 -0.24045233]\n",
      " [ 0.          0.36248942 -0.16576688]\n",
      " [ 0.         -0.1502374   0.23497283]\n",
      " [ 0.         -0.09314213  0.17999247]\n",
      " [ 0.          0.20029581  0.01528968]\n",
      " [ 0.         -0.0831299   0.24170664]\n",
      " [ 0.         -0.04192835  0.13310397]\n",
      " [ 0.         -0.06451113  0.24600512]\n",
      " [ 0.         -0.0785529   0.17535259]\n",
      " [ 0.          0.23216733  0.09673134]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #3 | lambda learn rate = 0.0001\n",
      "Target = [[3.]\n",
      " [8.]]\n",
      "lambda end of trial = [[ 0.          0.52427521 -0.24399919]\n",
      " [ 0.          0.36116449 -0.16930005]\n",
      " [ 0.         -0.15161797  0.2312913 ]\n",
      " [ 0.         -0.09459235  0.17612521]\n",
      " [ 0.          0.1989704   0.01175525]\n",
      " [ 0.         -0.08457469  0.23785385]\n",
      " [ 0.         -0.04327142  0.12952245]\n",
      " [ 0.         -0.06601529  0.24199403]\n",
      " [ 0.         -0.08022801  0.17088563]\n",
      " [ 0.          0.23071059  0.09284669]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #4 | lambda learn rate = 0.0001\n",
      "Target = [[1.]\n",
      " [1.]]\n",
      "lambda end of trial = [[ 0.          0.52356989 -0.24470451]\n",
      " [ 0.          0.36053067 -0.16993386]\n",
      " [ 0.         -0.15228702  0.23062226]\n",
      " [ 0.         -0.09525053  0.17546704]\n",
      " [ 0.          0.19827117  0.01105602]\n",
      " [ 0.         -0.08529304  0.2371355 ]\n",
      " [ 0.         -0.04398028  0.12881359]\n",
      " [ 0.         -0.06672053  0.24128879]\n",
      " [ 0.         -0.08089729  0.17021636]\n",
      " [ 0.          0.22998515  0.09212126]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #5 | lambda learn rate = 0.0001\n",
      "Target = [[8.]\n",
      " [5.]]\n",
      "lambda end of trial = [[ 0.          0.52002344 -0.24692104]\n",
      " [ 0.          0.35727864 -0.17196638]\n",
      " [ 0.         -0.15566207  0.22851285]\n",
      " [ 0.         -0.09890642  0.17318211]\n",
      " [ 0.          0.19483427  0.00890796]\n",
      " [ 0.         -0.08900385  0.23481624]\n",
      " [ 0.         -0.04761561  0.12654151]\n",
      " [ 0.         -0.07030534  0.23904828]\n",
      " [ 0.         -0.08467643  0.16785439]\n",
      " [ 0.          0.22616614  0.08973438]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #6 | lambda learn rate = 0.0001\n",
      "Target = [[1.]\n",
      " [1.]]\n",
      "lambda end of trial = [[ 0.          0.51942779 -0.2475167 ]\n",
      " [ 0.          0.35665385 -0.17259117]\n",
      " [ 0.         -0.15629714  0.22787778]\n",
      " [ 0.         -0.09951553  0.17257299]\n",
      " [ 0.          0.19421408  0.00828777]\n",
      " [ 0.         -0.08959308  0.23422701]\n",
      " [ 0.         -0.04820803  0.12594909]\n",
      " [ 0.         -0.07097559  0.23837802]\n",
      " [ 0.         -0.08529257  0.16723825]\n",
      " [ 0.          0.22547369  0.08904193]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #7 | lambda learn rate = 0.0001\n",
      "Target = [[4.]\n",
      " [6.]]\n",
      "lambda end of trial = [[ 0.          0.5182668  -0.24925818]\n",
      " [ 0.          0.35517877 -0.17480379]\n",
      " [ 0.         -0.15763746  0.2258673 ]\n",
      " [ 0.         -0.10082716  0.17060555]\n",
      " [ 0.          0.19282288  0.00620096]\n",
      " [ 0.         -0.0908794   0.23229754]\n",
      " [ 0.         -0.0495895   0.12387688]\n",
      " [ 0.         -0.07232142  0.23635928]\n",
      " [ 0.         -0.08663894  0.1652187 ]\n",
      " [ 0.          0.22404323  0.08689624]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #8 | lambda learn rate = 0.0001\n",
      "Target = [[1.]\n",
      " [1.]]\n",
      "lambda end of trial = [[ 0.          0.5176272  -0.24989778]\n",
      " [ 0.          0.35462784 -0.17535472]\n",
      " [ 0.         -0.15825803  0.22524673]\n",
      " [ 0.         -0.10136307  0.17006964]\n",
      " [ 0.          0.1922087   0.00558679]\n",
      " [ 0.         -0.09143773  0.2317392 ]\n",
      " [ 0.         -0.05015167  0.12331471]\n",
      " [ 0.         -0.072952    0.23572871]\n",
      " [ 0.         -0.08722763  0.16463001]\n",
      " [ 0.          0.22340819  0.0862612 ]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #9 | lambda learn rate = 0.0001\n",
      "Target = [[1.]\n",
      " [2.]]\n",
      "lambda end of trial = [[ 0.          0.51712002 -0.25091214]\n",
      " [ 0.          0.35409232 -0.17642575]\n",
      " [ 0.         -0.1588509   0.22406099]\n",
      " [ 0.         -0.10192249  0.16895081]\n",
      " [ 0.          0.19163244  0.00443425]\n",
      " [ 0.         -0.0919634   0.23068788]\n",
      " [ 0.         -0.05071582  0.12218641]\n",
      " [ 0.         -0.07349253  0.23464763]\n",
      " [ 0.         -0.08776154  0.16356218]\n",
      " [ 0.          0.22281532  0.08507546]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #10 | lambda learn rate = 0.0001\n",
      "Target = [[9.]\n",
      " [6.]]\n",
      "lambda end of trial = [[ 0.          0.51650134 -0.2513246 ]\n",
      " [ 0.          0.35351977 -0.17680745]\n",
      " [ 0.         -0.15963338  0.22353934]\n",
      " [ 0.         -0.10251043  0.16855885]\n",
      " [ 0.          0.19084587  0.00390988]\n",
      " [ 0.         -0.0926964   0.23019921]\n",
      " [ 0.         -0.05126273  0.1218218 ]\n",
      " [ 0.         -0.074252    0.23414132]\n",
      " [ 0.         -0.08851115  0.16306244]\n",
      " [ 0.          0.2219815   0.08451958]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #11 | lambda learn rate = 0.0001\n",
      "Target = [[6.]\n",
      " [3.]]\n",
      "lambda end of trial = [[ 0.          0.51474329 -0.25220362]\n",
      " [ 0.          0.35164695 -0.17774386]\n",
      " [ 0.         -0.16141457  0.22264874]\n",
      " [ 0.         -0.10440496  0.16761158]\n",
      " [ 0.          0.18873795  0.00285592]\n",
      " [ 0.         -0.09474523  0.2291748 ]\n",
      " [ 0.         -0.05303373  0.12093631]\n",
      " [ 0.         -0.07613806  0.23319829]\n",
      " [ 0.         -0.09044431  0.16209586]\n",
      " [ 0.          0.2202394   0.08364853]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #12 | lambda learn rate = 0.0001\n",
      "Target = [[6.]\n",
      " [7.]]\n",
      "lambda end of trial = [[ 0.          0.51437414 -0.25263429]\n",
      " [ 0.          0.35131753 -0.17812819]\n",
      " [ 0.         -0.16191286  0.2220674 ]\n",
      " [ 0.         -0.10484935  0.16709313]\n",
      " [ 0.          0.1883532   0.00240704]\n",
      " [ 0.         -0.09522432  0.22861586]\n",
      " [ 0.         -0.05337308  0.1205404 ]\n",
      " [ 0.         -0.07661684  0.23263972]\n",
      " [ 0.         -0.09079015  0.16169238]\n",
      " [ 0.          0.21974009  0.08306601]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #13 | lambda learn rate = 0.0001\n",
      "Target = [[3.]\n",
      " [1.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda end of trial = [[ 0.          0.51274819 -0.25317627]\n",
      " [ 0.          0.34954471 -0.17871912]\n",
      " [ 0.         -0.16367765  0.22147914]\n",
      " [ 0.         -0.10657829  0.16651681]\n",
      " [ 0.          0.18657137  0.0018131 ]\n",
      " [ 0.         -0.0971167   0.22798506]\n",
      " [ 0.         -0.0550902   0.11996802]\n",
      " [ 0.         -0.07841857  0.23203914]\n",
      " [ 0.         -0.09250693  0.16112012]\n",
      " [ 0.          0.21784855  0.08243549]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #14 | lambda learn rate = 0.0001\n",
      "Target = [[9.]\n",
      " [8.]]\n",
      "lambda end of trial = [[ 0.          0.51384845 -0.25219827]\n",
      " [ 0.          0.35089529 -0.17751861]\n",
      " [ 0.         -0.16218053  0.22280992]\n",
      " [ 0.         -0.10510023  0.16783065]\n",
      " [ 0.          0.18801572  0.00309697]\n",
      " [ 0.         -0.09561268  0.22932197]\n",
      " [ 0.         -0.05376464  0.1211463 ]\n",
      " [ 0.         -0.07713728  0.23317806]\n",
      " [ 0.         -0.09103434  0.16242909]\n",
      " [ 0.          0.2191664   0.08360692]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #15 | lambda learn rate = 0.0001\n",
      "Target = [[6.]\n",
      " [2.]]\n",
      "lambda end of trial = [[ 0.          0.51190435 -0.2528463 ]\n",
      " [ 0.          0.34906224 -0.17812963]\n",
      " [ 0.         -0.16417883  0.22214382]\n",
      " [ 0.         -0.10711507  0.16715903]\n",
      " [ 0.          0.18608585  0.00245368]\n",
      " [ 0.         -0.09758228  0.22866543]\n",
      " [ 0.         -0.05559207  0.12053715]\n",
      " [ 0.         -0.07923392  0.23247918]\n",
      " [ 0.         -0.09303923  0.16176079]\n",
      " [ 0.          0.21706879  0.08290772]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #16 | lambda learn rate = 0.0001\n",
      "Target = [[9.]\n",
      " [5.]]\n",
      "lambda end of trial = [[ 0.          0.51208482 -0.25274604]\n",
      " [ 0.          0.34927042 -0.17801397]\n",
      " [ 0.         -0.16401393  0.22223542]\n",
      " [ 0.         -0.10688161  0.16728873]\n",
      " [ 0.          0.18621775  0.00252696]\n",
      " [ 0.         -0.09743862  0.22874525]\n",
      " [ 0.         -0.0554671   0.12060658]\n",
      " [ 0.         -0.07923825  0.23247678]\n",
      " [ 0.         -0.09292853  0.16182229]\n",
      " [ 0.          0.21715586  0.08295609]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #17 | lambda learn rate = 0.0001\n",
      "Target = [[9.]\n",
      " [2.]]\n",
      "lambda end of trial = [[ 0.          0.51106684 -0.25297226]\n",
      " [ 0.          0.34832626 -0.17822378]\n",
      " [ 0.         -0.16503915  0.2220076 ]\n",
      " [ 0.         -0.10797574  0.16704559]\n",
      " [ 0.          0.18521986  0.0023052 ]\n",
      " [ 0.         -0.09857355  0.22849304]\n",
      " [ 0.         -0.05632665  0.12041557]\n",
      " [ 0.         -0.08038084  0.23222287]\n",
      " [ 0.         -0.09387069  0.16161292]\n",
      " [ 0.          0.21593811  0.08268548]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #18 | lambda learn rate = 0.0001\n",
      "Target = [[9.]\n",
      " [0.]]\n",
      "lambda end of trial = [[ 0.          0.50892513 -0.25297226]\n",
      " [ 0.          0.34634132 -0.17822378]\n",
      " [ 0.         -0.16703834  0.2220076 ]\n",
      " [ 0.         -0.10993124  0.16704559]\n",
      " [ 0.          0.18346638  0.0023052 ]\n",
      " [ 0.         -0.10041553  0.22849304]\n",
      " [ 0.         -0.05808165  0.12041557]\n",
      " [ 0.         -0.08259423  0.23222287]\n",
      " [ 0.         -0.09570842  0.16161292]\n",
      " [ 0.          0.21392591  0.08268548]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #19 | lambda learn rate = 0.0001\n",
      "Target = [[4.]\n",
      " [3.]]\n",
      "lambda end of trial = [[ 0.          0.5077205  -0.25387573]\n",
      " [ 0.          0.34516357 -0.17910709]\n",
      " [ 0.         -0.16819394  0.2211409 ]\n",
      " [ 0.         -0.11108778  0.16617818]\n",
      " [ 0.          0.18214785  0.00131631]\n",
      " [ 0.         -0.10159562  0.22760797]\n",
      " [ 0.         -0.05927258  0.11952237]\n",
      " [ 0.         -0.08389633  0.2312463 ]\n",
      " [ 0.         -0.09696122  0.16067332]\n",
      " [ 0.          0.2126216   0.08170724]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #20 | lambda learn rate = 0.0001\n",
      "Target = [[4.]\n",
      " [9.]]\n",
      "lambda end of trial = [[ 0.          0.50795696 -0.25334369]\n",
      " [ 0.          0.34537111 -0.17864014]\n",
      " [ 0.         -0.16798349  0.22161441]\n",
      " [ 0.         -0.11090822  0.1665822 ]\n",
      " [ 0.          0.18233674  0.00174131]\n",
      " [ 0.         -0.10134234  0.22817784]\n",
      " [ 0.         -0.05908523  0.11994391]\n",
      " [ 0.         -0.08367808  0.23173736]\n",
      " [ 0.         -0.09673816  0.16117521]\n",
      " [ 0.          0.2127706   0.08204249]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #21 | lambda learn rate = 0.0001\n",
      "Target = [[4.]\n",
      " [9.]]\n",
      "lambda end of trial = [[ 0.          0.50813693 -0.25293878]\n",
      " [ 0.          0.34552714 -0.17828907]\n",
      " [ 0.         -0.16778583  0.22205915]\n",
      " [ 0.         -0.11073891  0.16696314]\n",
      " [ 0.          0.18247995  0.00206353]\n",
      " [ 0.         -0.10115564  0.22859793]\n",
      " [ 0.         -0.05888319  0.12039851]\n",
      " [ 0.         -0.08354287  0.23204157]\n",
      " [ 0.         -0.09659605  0.16149495]\n",
      " [ 0.          0.21288725  0.08230496]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #22 | lambda learn rate = 0.0001\n",
      "Target = [[4.]\n",
      " [4.]]\n",
      "lambda end of trial = [[ 0.          0.50723824 -0.25383746]\n",
      " [ 0.          0.34470486 -0.17911135]\n",
      " [ 0.         -0.16863429  0.22121069]\n",
      " [ 0.         -0.11160414  0.16609791]\n",
      " [ 0.          0.18153973  0.00112331]\n",
      " [ 0.         -0.10213251  0.22762106]\n",
      " [ 0.         -0.05970111  0.11958058]\n",
      " [ 0.         -0.0845579   0.23102655]\n",
      " [ 0.         -0.09754149  0.16054952]\n",
      " [ 0.          0.2118659   0.08128361]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #23 | lambda learn rate = 0.0001\n",
      "Target = [[2.]\n",
      " [8.]]\n",
      "lambda end of trial = [[ 0.          0.50710848 -0.25435653]\n",
      " [ 0.          0.3446112  -0.17948599]\n",
      " [ 0.         -0.16876405  0.22069167]\n",
      " [ 0.         -0.11173697  0.16556658]\n",
      " [ 0.          0.1813908   0.0005276 ]\n",
      " [ 0.         -0.10227233  0.22706177]\n",
      " [ 0.         -0.05981601  0.11912099]\n",
      " [ 0.         -0.08472423  0.23036121]\n",
      " [ 0.         -0.09765398  0.16009953]\n",
      " [ 0.          0.21169975  0.08061902]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #24 | lambda learn rate = 0.0001\n",
      "Target = [[5.]\n",
      " [2.]]\n",
      "lambda end of trial = [[ 0.00000000e+00  5.05861604e-01 -2.54855277e-01]\n",
      " [ 0.00000000e+00  3.43268623e-01 -1.80023019e-01]\n",
      " [ 0.00000000e+00 -1.70126935e-01  2.20146512e-01]\n",
      " [ 0.00000000e+00 -1.13080889e-01  1.65029018e-01]\n",
      " [ 0.00000000e+00  1.80153645e-01  3.27388136e-05]\n",
      " [ 0.00000000e+00 -1.03531211e-01  2.26558214e-01]\n",
      " [ 0.00000000e+00 -6.11824710e-02  1.18574407e-01]\n",
      " [ 0.00000000e+00 -8.60435971e-02  2.29833464e-01]\n",
      " [ 0.00000000e+00 -9.89930756e-02  1.59563891e-01]\n",
      " [ 0.00000000e+00  2.10206111e-01  8.00215661e-02]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #25 | lambda learn rate = 0.0001\n",
      "Target = [[4.]\n",
      " [6.]]\n",
      "lambda end of trial = [[ 0.00000000e+00  5.05615063e-01 -2.55225088e-01]\n",
      " [ 0.00000000e+00  3.43013205e-01 -1.80406147e-01]\n",
      " [ 0.00000000e+00 -1.70342066e-01  2.19823816e-01]\n",
      " [ 0.00000000e+00 -1.13393791e-01  1.64559664e-01]\n",
      " [ 0.00000000e+00  1.79923536e-01 -3.12424854e-04]\n",
      " [ 0.00000000e+00 -1.03812634e-01  2.26136079e-01]\n",
      " [ 0.00000000e+00 -6.14421368e-02  1.18184908e-01]\n",
      " [ 0.00000000e+00 -8.62805145e-02  2.29478088e-01]\n",
      " [ 0.00000000e+00 -9.92343975e-02  1.59201908e-01]\n",
      " [ 0.00000000e+00  2.09912049e-01  7.95804723e-02]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #26 | lambda learn rate = 0.0001\n",
      "Target = [[0.]\n",
      " [0.]]\n",
      "lambda end of trial = [[ 0.00000000e+00  5.05615063e-01 -2.55225088e-01]\n",
      " [ 0.00000000e+00  3.43013205e-01 -1.80406147e-01]\n",
      " [ 0.00000000e+00 -1.70342066e-01  2.19823816e-01]\n",
      " [ 0.00000000e+00 -1.13393791e-01  1.64559664e-01]\n",
      " [ 0.00000000e+00  1.79923536e-01 -3.12424854e-04]\n",
      " [ 0.00000000e+00 -1.03812634e-01  2.26136079e-01]\n",
      " [ 0.00000000e+00 -6.14421368e-02  1.18184908e-01]\n",
      " [ 0.00000000e+00 -8.62805145e-02  2.29478088e-01]\n",
      " [ 0.00000000e+00 -9.92343975e-02  1.59201908e-01]\n",
      " [ 0.00000000e+00  2.09912049e-01  7.95804723e-02]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #27 | lambda learn rate = 0.0001\n",
      "Target = [[9.]\n",
      " [4.]]\n",
      "lambda end of trial = [[ 0.00000000e+00  5.06763341e-01 -2.54714742e-01]\n",
      " [ 0.00000000e+00  3.44281338e-01 -1.79842532e-01]\n",
      " [ 0.00000000e+00 -1.69084807e-01  2.20382597e-01]\n",
      " [ 0.00000000e+00 -1.12217692e-01  1.65082375e-01]\n",
      " [ 0.00000000e+00  1.81099885e-01  2.10397027e-04]\n",
      " [ 0.00000000e+00 -1.02679925e-01  2.26639505e-01]\n",
      " [ 0.00000000e+00 -6.01881472e-02  1.18742237e-01]\n",
      " [ 0.00000000e+00 -8.48668143e-02  2.30106399e-01]\n",
      " [ 0.00000000e+00 -9.79661352e-02  1.59765580e-01]\n",
      " [ 0.00000000e+00  2.11120351e-01  8.01174953e-02]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #28 | lambda learn rate = 0.0001\n",
      "Target = [[7.]\n",
      " [5.]]\n",
      "lambda end of trial = [[ 0.00000000e+00  5.07005666e-01 -2.54541654e-01]\n",
      " [ 0.00000000e+00  3.44675721e-01 -1.79560831e-01]\n",
      " [ 0.00000000e+00 -1.68769191e-01  2.20608038e-01]\n",
      " [ 0.00000000e+00 -1.11873251e-01  1.65328405e-01]\n",
      " [ 0.00000000e+00  1.81450999e-01  4.61192335e-04]\n",
      " [ 0.00000000e+00 -1.02373264e-01  2.26858549e-01]\n",
      " [ 0.00000000e+00 -5.98627320e-02  1.18974676e-01]\n",
      " [ 0.00000000e+00 -8.46153739e-02  2.30286000e-01]\n",
      " [ 0.00000000e+00 -9.76674326e-02  1.59978939e-01]\n",
      " [ 0.00000000e+00  2.11338825e-01  8.02735488e-02]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #29 | lambda learn rate = 0.0001\n",
      "Target = [[4.]\n",
      " [9.]]\n",
      "lambda end of trial = [[ 0.          0.50734385 -0.25378074]\n",
      " [ 0.          0.34497802 -0.17888067]\n",
      " [ 0.         -0.16843599  0.22135775]\n",
      " [ 0.         -0.11156811  0.16601498]\n",
      " [ 0.          0.18169828  0.00101757]\n",
      " [ 0.         -0.10209295  0.22748925]\n",
      " [ 0.         -0.05956372  0.11964745]\n",
      " [ 0.         -0.08431714  0.23095703]\n",
      " [ 0.         -0.09739637  0.16058882]\n",
      " [ 0.          0.21157852  0.08081287]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #30 | lambda learn rate = 0.0001\n",
      "Target = [[6.]\n",
      " [3.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda end of trial = [[ 0.          0.50661001 -0.25414766]\n",
      " [ 0.          0.34431498 -0.17921219]\n",
      " [ 0.         -0.1691779   0.22098679]\n",
      " [ 0.         -0.11227212  0.16566297]\n",
      " [ 0.          0.18102654  0.00068171]\n",
      " [ 0.         -0.10275022  0.22716061]\n",
      " [ 0.         -0.06018941  0.1193346 ]\n",
      " [ 0.         -0.08506755  0.23058183]\n",
      " [ 0.         -0.09802194  0.16027604]\n",
      " [ 0.          0.21084883  0.08044802]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #31 | lambda learn rate = 0.0001\n",
      "Target = [[7.]\n",
      " [1.]]\n",
      "lambda end of trial = [[ 0.00000000e+00  5.04973428e-01 -2.54381458e-01]\n",
      " [ 0.00000000e+00  3.42745455e-01 -1.79436404e-01]\n",
      " [ 0.00000000e+00 -1.70833390e-01  2.20750291e-01]\n",
      " [ 0.00000000e+00 -1.13848295e-01  1.65437803e-01]\n",
      " [ 0.00000000e+00  1.79245682e-01  4.27296787e-04]\n",
      " [ 0.00000000e+00 -1.04443365e-01  2.26918736e-01]\n",
      " [ 0.00000000e+00 -6.17440207e-02  1.19112516e-01]\n",
      " [ 0.00000000e+00 -8.68387957e-02  2.30328791e-01]\n",
      " [ 0.00000000e+00 -9.97333061e-02  1.60031559e-01]\n",
      " [ 0.00000000e+00  2.09084766e-01  8.01960121e-02]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #32 | lambda learn rate = 0.0001\n",
      "Target = [[3.]\n",
      " [4.]]\n",
      "lambda end of trial = [[ 0.          0.50420461 -0.25540655]\n",
      " [ 0.          0.34201311 -0.18041286]\n",
      " [ 0.         -0.1716666   0.21963935]\n",
      " [ 0.         -0.11467037  0.16434171]\n",
      " [ 0.          0.17846197 -0.00061766]\n",
      " [ 0.         -0.10524269  0.22585297]\n",
      " [ 0.         -0.06256647  0.11801592]\n",
      " [ 0.         -0.08766215  0.22923098]\n",
      " [ 0.         -0.10047499  0.15904265]\n",
      " [ 0.          0.20820188  0.07901884]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #33 | lambda learn rate = 0.0001\n",
      "Target = [[1.]\n",
      " [2.]]\n",
      "lambda end of trial = [[ 0.          0.50373864 -0.25633848]\n",
      " [ 0.          0.34156079 -0.1813175 ]\n",
      " [ 0.         -0.17216151  0.21864952]\n",
      " [ 0.         -0.11515954  0.16336336]\n",
      " [ 0.          0.17800292 -0.00153574]\n",
      " [ 0.         -0.1057268   0.22488476]\n",
      " [ 0.         -0.06297944  0.11718997]\n",
      " [ 0.         -0.08809826  0.22835877]\n",
      " [ 0.         -0.10090704  0.15817855]\n",
      " [ 0.          0.20772418  0.07806342]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #34 | lambda learn rate = 0.0001\n",
      "Target = [[2.]\n",
      " [6.]]\n",
      "lambda end of trial = [[ 0.          0.50351958 -0.25699568]\n",
      " [ 0.          0.34134336 -0.18196978]\n",
      " [ 0.         -0.17239121  0.21796041]\n",
      " [ 0.         -0.11542118  0.16257844]\n",
      " [ 0.          0.17777009 -0.00223424]\n",
      " [ 0.         -0.10598356  0.22411445]\n",
      " [ 0.         -0.06322403  0.11645622]\n",
      " [ 0.         -0.08836093  0.22757076]\n",
      " [ 0.         -0.10117388  0.15737803]\n",
      " [ 0.          0.2074371   0.0772022 ]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #35 | lambda learn rate = 0.0001\n",
      "Target = [[4.]\n",
      " [3.]]\n",
      "lambda end of trial = [[ 0.          0.50251397 -0.25774989]\n",
      " [ 0.          0.34062891 -0.18250562]\n",
      " [ 0.         -0.17319994  0.21735386]\n",
      " [ 0.         -0.11627293  0.16193962]\n",
      " [ 0.          0.17698492 -0.00282312]\n",
      " [ 0.         -0.10682468  0.22348362]\n",
      " [ 0.         -0.06408511  0.11581041]\n",
      " [ 0.         -0.08927931  0.22688198]\n",
      " [ 0.         -0.10199384  0.15676306]\n",
      " [ 0.          0.20641755  0.07643753]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #36 | lambda learn rate = 0.0001\n",
      "Target = [[9.]\n",
      " [9.]]\n",
      "lambda end of trial = [[ 0.          0.50774177 -0.25252208]\n",
      " [ 0.          0.34557155 -0.17756299]\n",
      " [ 0.         -0.16799012  0.22256369]\n",
      " [ 0.         -0.11113893  0.16707363]\n",
      " [ 0.          0.18191614  0.00210811]\n",
      " [ 0.         -0.10156093  0.22874737]\n",
      " [ 0.         -0.05891728  0.12097824]\n",
      " [ 0.         -0.08432845  0.23183284]\n",
      " [ 0.         -0.09715327  0.16160362]\n",
      " [ 0.          0.21125742  0.0812774 ]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #37 | lambda learn rate = 0.0001\n",
      "Target = [[8.]\n",
      " [7.]]\n",
      "lambda end of trial = [[ 0.          0.50924782 -0.25120429]\n",
      " [ 0.          0.34699998 -0.17631311]\n",
      " [ 0.         -0.16659941  0.22378056]\n",
      " [ 0.         -0.10974951  0.16828937]\n",
      " [ 0.          0.18313707  0.00317642]\n",
      " [ 0.         -0.10003538  0.23008222]\n",
      " [ 0.         -0.05748561  0.12223095]\n",
      " [ 0.         -0.08295295  0.23303639]\n",
      " [ 0.         -0.0958211   0.16276928]\n",
      " [ 0.          0.21246348  0.0823327 ]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #38 | lambda learn rate = 0.0001\n",
      "Target = [[8.]\n",
      " [5.]]\n",
      "lambda end of trial = [[ 0.          0.50955293 -0.2510136 ]\n",
      " [ 0.          0.34726663 -0.17614645]\n",
      " [ 0.         -0.166354    0.22393394]\n",
      " [ 0.         -0.10940839  0.16850257]\n",
      " [ 0.          0.18348333  0.00339283]\n",
      " [ 0.         -0.09977713  0.23024363]\n",
      " [ 0.         -0.05714147  0.12244603]\n",
      " [ 0.         -0.08286346  0.23309233]\n",
      " [ 0.         -0.09545188  0.16300004]\n",
      " [ 0.          0.21259893  0.08241736]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #39 | lambda learn rate = 0.0001\n",
      "Target = [[6.]\n",
      " [0.]]\n",
      "lambda end of trial = [[ 0.          0.50745599 -0.2510136 ]\n",
      " [ 0.          0.3452896  -0.17614645]\n",
      " [ 0.         -0.16842686  0.22393394]\n",
      " [ 0.         -0.11167774  0.16850257]\n",
      " [ 0.          0.1812377   0.00339283]\n",
      " [ 0.         -0.10190789  0.23024363]\n",
      " [ 0.         -0.0593706   0.12244603]\n",
      " [ 0.         -0.08532793  0.23309233]\n",
      " [ 0.         -0.09762286  0.16300004]\n",
      " [ 0.          0.21012366  0.08241736]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #40 | lambda learn rate = 0.0001\n",
      "Target = [[4.]\n",
      " [3.]]\n",
      "lambda end of trial = [[ 0.          0.50625033 -0.25191784]\n",
      " [ 0.          0.3441856  -0.17697445]\n",
      " [ 0.         -0.16963458  0.22302815]\n",
      " [ 0.         -0.11273786  0.16770748]\n",
      " [ 0.          0.18006446  0.0025129 ]\n",
      " [ 0.         -0.10328642  0.22920974]\n",
      " [ 0.         -0.06057977  0.12153916]\n",
      " [ 0.         -0.08652294  0.23219607]\n",
      " [ 0.         -0.0987461   0.16215761]\n",
      " [ 0.          0.20881426  0.08143532]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #41 | lambda learn rate = 0.0001\n",
      "Target = [[8.]\n",
      " [5.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda end of trial = [[ 0.          0.50695984 -0.2514744 ]\n",
      " [ 0.          0.34488396 -0.17653798]\n",
      " [ 0.         -0.16901949  0.22341258]\n",
      " [ 0.         -0.11192731  0.16821408]\n",
      " [ 0.          0.18072185  0.00292377]\n",
      " [ 0.         -0.10262603  0.22962248]\n",
      " [ 0.         -0.05985691  0.12199094]\n",
      " [ 0.         -0.08584404  0.23262038]\n",
      " [ 0.         -0.09798712  0.16263198]\n",
      " [ 0.          0.20950627  0.08186782]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #42 | lambda learn rate = 0.0001\n",
      "Target = [[6.]\n",
      " [9.]]\n",
      "lambda end of trial = [[ 0.          0.50783958 -0.25015479]\n",
      " [ 0.          0.3457752  -0.17520112]\n",
      " [ 0.         -0.16808484  0.22481455]\n",
      " [ 0.         -0.1109052   0.16974725]\n",
      " [ 0.          0.1816302   0.00428629]\n",
      " [ 0.         -0.10171038  0.23099596]\n",
      " [ 0.         -0.05883727  0.12352041]\n",
      " [ 0.         -0.08492476  0.23399931]\n",
      " [ 0.         -0.09688613  0.16428345]\n",
      " [ 0.          0.21038876  0.08319156]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #43 | lambda learn rate = 0.0001\n",
      "Target = [[6.]\n",
      " [4.]]\n",
      "lambda end of trial = [[ 0.          0.50693627 -0.250757  ]\n",
      " [ 0.          0.34488044 -0.17579763]\n",
      " [ 0.         -0.16892404  0.22425509]\n",
      " [ 0.         -0.1117967   0.16915292]\n",
      " [ 0.          0.18065862  0.00363857]\n",
      " [ 0.         -0.10264004  0.23037618]\n",
      " [ 0.         -0.05956724  0.12303376]\n",
      " [ 0.         -0.08587705  0.23336445]\n",
      " [ 0.         -0.09779493  0.16367759]\n",
      " [ 0.          0.2092693   0.08244525]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #44 | lambda learn rate = 0.0001\n",
      "Target = [[3.]\n",
      " [1.]]\n",
      "lambda end of trial = [[ 0.          0.50574485 -0.25115414]\n",
      " [ 0.          0.34358029 -0.17623101]\n",
      " [ 0.         -0.17013738  0.22385064]\n",
      " [ 0.         -0.11292943  0.16877534]\n",
      " [ 0.          0.17950408  0.00325372]\n",
      " [ 0.         -0.10385014  0.22997281]\n",
      " [ 0.         -0.06078659  0.12262731]\n",
      " [ 0.         -0.08712024  0.23295005]\n",
      " [ 0.         -0.09902749  0.16326673]\n",
      " [ 0.          0.20807921  0.08204855]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #45 | lambda learn rate = 0.0001\n",
      "Target = [[6.]\n",
      " [0.]]\n",
      "lambda end of trial = [[ 0.          0.50405918 -0.25115414]\n",
      " [ 0.          0.34192884 -0.17623101]\n",
      " [ 0.         -0.17180395  0.22385064]\n",
      " [ 0.         -0.11457056  0.16877534]\n",
      " [ 0.          0.1774788   0.00325372]\n",
      " [ 0.         -0.10582641  0.22997281]\n",
      " [ 0.         -0.06267472  0.12262731]\n",
      " [ 0.         -0.08884682  0.23295005]\n",
      " [ 0.         -0.10089169  0.16326673]\n",
      " [ 0.          0.20632894  0.08204855]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #46 | lambda learn rate = 0.0001\n",
      "Target = [[3.]\n",
      " [8.]]\n",
      "lambda end of trial = [[ 0.          0.50387027 -0.2516579 ]\n",
      " [ 0.          0.34174171 -0.17673003]\n",
      " [ 0.         -0.17200403  0.22331709]\n",
      " [ 0.         -0.11475171  0.16829227]\n",
      " [ 0.          0.17726948  0.00269552]\n",
      " [ 0.         -0.10609753  0.22924983]\n",
      " [ 0.         -0.0628591   0.12213563]\n",
      " [ 0.         -0.08906934  0.23235668]\n",
      " [ 0.         -0.10109395  0.16272738]\n",
      " [ 0.          0.20604898  0.08130201]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #47 | lambda learn rate = 0.0001\n",
      "Target = [[4.]\n",
      " [0.]]\n",
      "lambda end of trial = [[ 0.          0.50219032 -0.2516579 ]\n",
      " [ 0.          0.34016571 -0.17673003]\n",
      " [ 0.         -0.17370869  0.22331709]\n",
      " [ 0.         -0.11642816  0.16829227]\n",
      " [ 0.          0.17553479  0.00269552]\n",
      " [ 0.         -0.10774718  0.22924983]\n",
      " [ 0.         -0.06448404  0.12213563]\n",
      " [ 0.         -0.09089764  0.23235668]\n",
      " [ 0.         -0.1028664   0.16272738]\n",
      " [ 0.          0.20411168  0.08130201]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #48 | lambda learn rate = 0.0001\n",
      "Target = [[7.]\n",
      " [2.]]\n",
      "lambda end of trial = [[ 0.          0.50180146 -0.251769  ]\n",
      " [ 0.          0.33972142 -0.17685697]\n",
      " [ 0.         -0.17410255  0.22320456]\n",
      " [ 0.         -0.11681869  0.16818069]\n",
      " [ 0.          0.17517464  0.00259262]\n",
      " [ 0.         -0.10812165  0.22914284]\n",
      " [ 0.         -0.06490607  0.12201505]\n",
      " [ 0.         -0.09131953  0.23223614]\n",
      " [ 0.         -0.10320783  0.16262983]\n",
      " [ 0.          0.20357125  0.0811476 ]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #49 | lambda learn rate = 0.0001\n",
      "Target = [[6.]\n",
      " [9.]]\n",
      "lambda end of trial = [[ 0.          0.50345373 -0.24929059]\n",
      " [ 0.          0.34137757 -0.17437275]\n",
      " [ 0.         -0.17262474  0.22542128]\n",
      " [ 0.         -0.11515138  0.17068164]\n",
      " [ 0.          0.1767957   0.00502421]\n",
      " [ 0.         -0.10667089  0.23131897]\n",
      " [ 0.         -0.06335112  0.12434748]\n",
      " [ 0.         -0.08981685  0.23449016]\n",
      " [ 0.         -0.10164649  0.16497183]\n",
      " [ 0.          0.20480176  0.08299336]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #50 | lambda learn rate = 0.0001\n",
      "Target = [[2.]\n",
      " [7.]]\n",
      "lambda end of trial = [[ 0.          0.50301922 -0.25081136]\n",
      " [ 0.          0.34100508 -0.17567647]\n",
      " [ 0.         -0.17298426  0.22416293]\n",
      " [ 0.         -0.11552239  0.16938313]\n",
      " [ 0.          0.17641901  0.0037058 ]\n",
      " [ 0.         -0.10707913  0.22989013]\n",
      " [ 0.         -0.06371474  0.1230748 ]\n",
      " [ 0.         -0.09023244  0.23303559]\n",
      " [ 0.         -0.10207123  0.16348525]\n",
      " [ 0.          0.20436345  0.08145927]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #51 | lambda learn rate = 0.0001\n",
      "Target = [[5.]\n",
      " [4.]]\n",
      "lambda end of trial = [[ 0.          0.50242256 -0.25128869]\n",
      " [ 0.          0.34041546 -0.17614816]\n",
      " [ 0.         -0.17367218  0.22361259]\n",
      " [ 0.         -0.1161446   0.16888535]\n",
      " [ 0.          0.17581777  0.00322481]\n",
      " [ 0.         -0.10775471  0.22934967]\n",
      " [ 0.         -0.06425472  0.12264281]\n",
      " [ 0.         -0.09092785  0.23247927]\n",
      " [ 0.         -0.10264828  0.16302361]\n",
      " [ 0.          0.20368567  0.08091705]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #52 | lambda learn rate = 0.0001\n",
      "Target = [[6.]\n",
      " [5.]]\n",
      "lambda end of trial = [[ 0.          0.50247673 -0.25124355]\n",
      " [ 0.          0.34047249 -0.17610064]\n",
      " [ 0.         -0.17364366  0.22363636]\n",
      " [ 0.         -0.11607352  0.16894459]\n",
      " [ 0.          0.1758439   0.00324658]\n",
      " [ 0.         -0.10773272  0.22936799]\n",
      " [ 0.         -0.06418049  0.12270468]\n",
      " [ 0.         -0.09096214  0.23245069]\n",
      " [ 0.         -0.10262134  0.16304606]\n",
      " [ 0.          0.20356545  0.08081687]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #53 | lambda learn rate = 0.0001\n",
      "Target = [[9.]\n",
      " [6.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda end of trial = [[ 0.          0.5051887  -0.24943558]\n",
      " [ 0.          0.3430627  -0.17437383]\n",
      " [ 0.         -0.17114425  0.22530264]\n",
      " [ 0.         -0.11331399  0.17078428]\n",
      " [ 0.          0.17837762  0.00493573]\n",
      " [ 0.         -0.10518806  0.23106443]\n",
      " [ 0.         -0.06148375  0.1245025 ]\n",
      " [ 0.         -0.08832884  0.23420622]\n",
      " [ 0.         -0.10023373  0.1646378 ]\n",
      " [ 0.          0.206339    0.0826659 ]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #54 | lambda learn rate = 0.0001\n",
      "Target = [[7.]\n",
      " [8.]]\n",
      "lambda end of trial = [[ 0.          0.5063286  -0.24813283]\n",
      " [ 0.          0.34422797 -0.1730421 ]\n",
      " [ 0.         -0.16993748  0.22668181]\n",
      " [ 0.         -0.11206438  0.1722124 ]\n",
      " [ 0.          0.17964377  0.00638276]\n",
      " [ 0.         -0.10420056  0.232193  ]\n",
      " [ 0.         -0.0603259   0.12582575]\n",
      " [ 0.         -0.08710441  0.23560557]\n",
      " [ 0.         -0.0991087   0.16592354]\n",
      " [ 0.          0.20740307  0.08388198]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #55 | lambda learn rate = 0.0001\n",
      "Target = [[1.]\n",
      " [9.]]\n",
      "lambda end of trial = [[ 0.          0.50610131 -0.2501784 ]\n",
      " [ 0.          0.34403938 -0.17473933]\n",
      " [ 0.         -0.17014883  0.22477961]\n",
      " [ 0.         -0.11226344  0.17042091]\n",
      " [ 0.          0.17943954  0.00454462]\n",
      " [ 0.         -0.10443698  0.23006527]\n",
      " [ 0.         -0.06054531  0.12385112]\n",
      " [ 0.         -0.08730694  0.2337828 ]\n",
      " [ 0.         -0.09931537  0.16406356]\n",
      " [ 0.          0.20716457  0.08173552]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #56 | lambda learn rate = 0.0001\n",
      "Target = [[8.]\n",
      " [2.]]\n",
      "lambda end of trial = [[ 0.          0.50561079 -0.25030103]\n",
      " [ 0.          0.34364393 -0.1748382 ]\n",
      " [ 0.         -0.1706342   0.22465827]\n",
      " [ 0.         -0.11277397  0.17029327]\n",
      " [ 0.          0.17891122  0.00441254]\n",
      " [ 0.         -0.10502043  0.22991941]\n",
      " [ 0.         -0.06101023  0.12373489]\n",
      " [ 0.         -0.08793514  0.23362575]\n",
      " [ 0.         -0.09980089  0.16394218]\n",
      " [ 0.          0.20655884  0.08158409]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #57 | lambda learn rate = 0.0001\n",
      "Target = [[1.]\n",
      " [9.]]\n",
      "lambda end of trial = [[ 0.          0.50544578 -0.25178609]\n",
      " [ 0.          0.34349102 -0.17621435]\n",
      " [ 0.         -0.1707722   0.22341625]\n",
      " [ 0.         -0.11292944  0.16889409]\n",
      " [ 0.          0.17876296  0.00307824]\n",
      " [ 0.         -0.10516648  0.22860491]\n",
      " [ 0.         -0.06118341  0.12217628]\n",
      " [ 0.         -0.0881171   0.23198809]\n",
      " [ 0.         -0.09996949  0.16242479]\n",
      " [ 0.          0.20638117  0.07998507]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #58 | lambda learn rate = 0.0001\n",
      "Target = [[5.]\n",
      " [1.]]\n",
      "lambda end of trial = [[ 0.          0.50389167 -0.25209691]\n",
      " [ 0.          0.34187647 -0.17653726]\n",
      " [ 0.         -0.17243752  0.22308319]\n",
      " [ 0.         -0.11472992  0.16853399]\n",
      " [ 0.          0.17709982  0.00274562]\n",
      " [ 0.         -0.10677743  0.22828272]\n",
      " [ 0.         -0.06287329  0.1218383 ]\n",
      " [ 0.         -0.08993719  0.23162408]\n",
      " [ 0.         -0.1017275   0.16207319]\n",
      " [ 0.          0.20466747  0.07964233]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #59 | lambda learn rate = 0.0001\n",
      "Target = [[6.]\n",
      " [4.]]\n",
      "lambda end of trial = [[ 0.          0.50369191 -0.25223008]\n",
      " [ 0.          0.3417619  -0.17661364]\n",
      " [ 0.         -0.17258779  0.22298301]\n",
      " [ 0.         -0.11491625  0.16840977]\n",
      " [ 0.          0.17687421  0.00259521]\n",
      " [ 0.         -0.10696213  0.22815959]\n",
      " [ 0.         -0.06292062  0.12180675]\n",
      " [ 0.         -0.0901439   0.23148627]\n",
      " [ 0.         -0.10187043  0.1619779 ]\n",
      " [ 0.          0.20438268  0.07945248]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #60 | lambda learn rate = 0.0001\n",
      "Target = [[8.]\n",
      " [5.]]\n",
      "lambda end of trial = [[ 0.          0.50509675 -0.25135206]\n",
      " [ 0.          0.34327176 -0.17566998]\n",
      " [ 0.         -0.17108721  0.22392087]\n",
      " [ 0.         -0.11338196  0.1693687 ]\n",
      " [ 0.          0.17827588  0.00347125]\n",
      " [ 0.         -0.1056836   0.22895867]\n",
      " [ 0.         -0.06164662  0.12260299]\n",
      " [ 0.         -0.08862157  0.23243772]\n",
      " [ 0.         -0.10049655  0.16283658]\n",
      " [ 0.          0.20574824  0.08030595]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #61 | lambda learn rate = 0.0001\n",
      "Target = [[4.]\n",
      " [3.]]\n",
      "lambda end of trial = [[ 0.          0.50407904 -0.25211534]\n",
      " [ 0.          0.34230545 -0.17639471]\n",
      " [ 0.         -0.17218422  0.22309811]\n",
      " [ 0.         -0.11438607  0.16861562]\n",
      " [ 0.          0.17718899  0.00265608]\n",
      " [ 0.         -0.10685012  0.22808378]\n",
      " [ 0.         -0.06270778  0.12180713]\n",
      " [ 0.         -0.08969709  0.23163109]\n",
      " [ 0.         -0.10146726  0.16210855]\n",
      " [ 0.          0.20463682  0.07947239]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #62 | lambda learn rate = 0.0001\n",
      "Target = [[1.]\n",
      " [1.]]\n",
      "lambda end of trial = [[ 0.          0.50352276 -0.25267162]\n",
      " [ 0.          0.34177153 -0.17692863]\n",
      " [ 0.         -0.17271864  0.22256369]\n",
      " [ 0.         -0.11495883  0.16804286]\n",
      " [ 0.          0.17660278  0.00206988]\n",
      " [ 0.         -0.10743649  0.22749741]\n",
      " [ 0.         -0.06332281  0.1211921 ]\n",
      " [ 0.         -0.09030215  0.23102603]\n",
      " [ 0.         -0.1020523   0.16152351]\n",
      " [ 0.          0.20407152  0.07890709]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #63 | lambda learn rate = 0.0001\n",
      "Target = [[4.]\n",
      " [6.]]\n",
      "lambda end of trial = [[ 0.          0.5033338  -0.25295507]\n",
      " [ 0.          0.34155931 -0.17724696]\n",
      " [ 0.         -0.17288753  0.22231036]\n",
      " [ 0.         -0.11512183  0.16779835]\n",
      " [ 0.          0.17640402  0.00177174]\n",
      " [ 0.         -0.10767076  0.22714601]\n",
      " [ 0.         -0.06345164  0.12099885]\n",
      " [ 0.         -0.09055935  0.23064023]\n",
      " [ 0.         -0.10223145  0.16125479]\n",
      " [ 0.          0.20380386  0.0785056 ]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #64 | lambda learn rate = 0.0001\n",
      "Target = [[4.]\n",
      " [7.]]\n",
      "lambda end of trial = [[ 0.          0.50324164 -0.25311635]\n",
      " [ 0.          0.34149066 -0.1773671 ]\n",
      " [ 0.         -0.17298922  0.2221324 ]\n",
      " [ 0.         -0.11522436  0.16761893]\n",
      " [ 0.          0.17628897  0.0015704 ]\n",
      " [ 0.         -0.10778856  0.22693986]\n",
      " [ 0.         -0.06349107  0.12092984]\n",
      " [ 0.         -0.09068631  0.23041804]\n",
      " [ 0.         -0.10231822  0.16110294]\n",
      " [ 0.          0.20365794  0.07825024]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #65 | lambda learn rate = 0.0001\n",
      "Target = [[5.]\n",
      " [3.]]\n",
      "lambda end of trial = [[ 0.          0.50258801 -0.25350853]\n",
      " [ 0.          0.34088474 -0.17773065]\n",
      " [ 0.         -0.17373754  0.22168341]\n",
      " [ 0.         -0.11587595  0.16722797]\n",
      " [ 0.          0.17561225  0.00116437]\n",
      " [ 0.         -0.10852303  0.22649918]\n",
      " [ 0.         -0.0641542   0.12053197]\n",
      " [ 0.         -0.09140869  0.22998461]\n",
      " [ 0.         -0.10302209  0.16068061]\n",
      " [ 0.          0.20284261  0.07776104]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #66 | lambda learn rate = 0.0001\n",
      "Target = [[3.]\n",
      " [7.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda end of trial = [[ 0.          0.50235915 -0.25404253]\n",
      " [ 0.          0.3407223  -0.1781097 ]\n",
      " [ 0.         -0.17395435  0.22117751]\n",
      " [ 0.         -0.11606151  0.166795  ]\n",
      " [ 0.          0.17539856  0.00066577]\n",
      " [ 0.         -0.10870965  0.22606374]\n",
      " [ 0.         -0.06434354  0.12009015]\n",
      " [ 0.         -0.09162786  0.22947322]\n",
      " [ 0.         -0.10320519  0.16025339]\n",
      " [ 0.          0.20261326  0.07722589]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #67 | lambda learn rate = 0.0001\n",
      "Target = [[3.]\n",
      " [1.]]\n",
      "lambda end of trial = [[ 0.00000000e+00  5.01334987e-01 -2.54383920e-01]\n",
      " [ 0.00000000e+00  3.39630464e-01 -1.78473641e-01]\n",
      " [ 0.00000000e+00 -1.75112825e-01  2.20791352e-01]\n",
      " [ 0.00000000e+00 -1.17260144e-01  1.66395460e-01]\n",
      " [ 0.00000000e+00  1.74144383e-01  2.47705424e-04]\n",
      " [ 0.00000000e+00 -1.09853686e-01  2.25682392e-01]\n",
      " [ 0.00000000e+00 -6.54164701e-02  1.19732511e-01]\n",
      " [ 0.00000000e+00 -9.28249934e-02  2.29074171e-01]\n",
      " [ 0.00000000e+00 -1.04355578e-01  1.59869931e-01]\n",
      " [ 0.00000000e+00  2.01474579e-01  7.68463330e-02]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #68 | lambda learn rate = 0.0001\n",
      "Target = [[2.]\n",
      " [4.]]\n",
      "lambda end of trial = [[ 0.          0.50074333 -0.25556723]\n",
      " [ 0.          0.33906214 -0.17961028]\n",
      " [ 0.         -0.17566299  0.21969102]\n",
      " [ 0.         -0.11780503  0.16530568]\n",
      " [ 0.          0.17359381 -0.00085345]\n",
      " [ 0.         -0.1103824   0.22462496]\n",
      " [ 0.         -0.06591763  0.1187302 ]\n",
      " [ 0.         -0.09337572  0.22797271]\n",
      " [ 0.         -0.10489652  0.15878805]\n",
      " [ 0.          0.20096978  0.07583673]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #69 | lambda learn rate = 0.0001\n",
      "Target = [[3.]\n",
      " [9.]]\n",
      "lambda end of trial = [[ 0.00000000e+00  5.01122659e-01 -2.54429250e-01]\n",
      " [ 0.00000000e+00  3.39449982e-01 -1.78446768e-01]\n",
      " [ 0.00000000e+00 -1.75327321e-01  2.20698031e-01]\n",
      " [ 0.00000000e+00 -1.17437353e-01  1.66408722e-01]\n",
      " [ 0.00000000e+00  1.73991858e-01  3.40709084e-04]\n",
      " [ 0.00000000e+00 -1.10033264e-01  2.25672376e-01]\n",
      " [ 0.00000000e+00 -6.55597797e-02  1.19803740e-01]\n",
      " [ 0.00000000e+00 -9.30060328e-02  2.29081782e-01]\n",
      " [ 0.00000000e+00 -1.04537943e-01  1.59863776e-01]\n",
      " [ 0.00000000e+00  2.01314597e-01  7.68711925e-02]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #70 | lambda learn rate = 0.0001\n",
      "Target = [[3.]\n",
      " [2.]]\n",
      "lambda end of trial = [[ 0.00000000e+00  5.00092989e-01 -2.55115696e-01]\n",
      " [ 0.00000000e+00  3.38278700e-01 -1.79227623e-01]\n",
      " [ 0.00000000e+00 -1.76345326e-01  2.20019361e-01]\n",
      " [ 0.00000000e+00 -1.18579557e-01  1.65647253e-01]\n",
      " [ 0.00000000e+00  1.72928154e-01 -3.68427073e-04]\n",
      " [ 0.00000000e+00 -1.11053442e-01  2.24992257e-01]\n",
      " [ 0.00000000e+00 -6.65910485e-02  1.19116227e-01]\n",
      " [ 0.00000000e+00 -9.42306806e-02  2.28265350e-01]\n",
      " [ 0.00000000e+00 -1.05506128e-01  1.59218319e-01]\n",
      " [ 0.00000000e+00  2.00149074e-01  7.60941771e-02]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #71 | lambda learn rate = 0.0001\n",
      "Target = [[6.]\n",
      " [5.]]\n",
      "lambda end of trial = [[ 0.00000000e+00  5.00798566e-01 -2.54527716e-01]\n",
      " [ 0.00000000e+00  3.38885124e-01 -1.78722270e-01]\n",
      " [ 0.00000000e+00 -1.75710265e-01  2.20548579e-01]\n",
      " [ 0.00000000e+00 -1.17901741e-01  1.66212099e-01]\n",
      " [ 0.00000000e+00  1.73565991e-01  1.63104112e-04]\n",
      " [ 0.00000000e+00 -1.10446142e-01  2.25498341e-01]\n",
      " [ 0.00000000e+00 -6.59165859e-02  1.19678279e-01]\n",
      " [ 0.00000000e+00 -9.36399806e-02  2.28757600e-01]\n",
      " [ 0.00000000e+00 -1.04922939e-01  1.59704310e-01]\n",
      " [ 0.00000000e+00  2.00790034e-01  7.66283104e-02]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #72 | lambda learn rate = 0.0001\n",
      "Target = [[8.]\n",
      " [8.]]\n",
      "lambda end of trial = [[ 0.          0.50416435 -0.25116193]\n",
      " [ 0.          0.34241176 -0.17519563]\n",
      " [ 0.         -0.17240022  0.22385862]\n",
      " [ 0.         -0.114372    0.16974184]\n",
      " [ 0.          0.17707027  0.00366739]\n",
      " [ 0.         -0.10685393  0.22909056]\n",
      " [ 0.         -0.0617816   0.12381327]\n",
      " [ 0.         -0.09012544  0.23227215]\n",
      " [ 0.         -0.1010502   0.16357705]\n",
      " [ 0.          0.20408648  0.07992476]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #73 | lambda learn rate = 0.0001\n",
      "Target = [[1.]\n",
      " [9.]]\n",
      "lambda end of trial = [[ 0.          0.50398975 -0.25273336]\n",
      " [ 0.          0.34224466 -0.17669958]\n",
      " [ 0.         -0.1725719   0.22231355]\n",
      " [ 0.         -0.11452405  0.16837341]\n",
      " [ 0.          0.17687426  0.00190323]\n",
      " [ 0.         -0.1070393   0.22742221]\n",
      " [ 0.         -0.06195111  0.12228772]\n",
      " [ 0.         -0.09031536  0.23056283]\n",
      " [ 0.         -0.10121117  0.16212834]\n",
      " [ 0.          0.20387407  0.07801299]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #74 | lambda learn rate = 0.0001\n",
      "Target = [[8.]\n",
      " [4.]]\n",
      "lambda end of trial = [[ 0.          0.50490468 -0.2522759 ]\n",
      " [ 0.          0.34337885 -0.17613248]\n",
      " [ 0.         -0.17163849  0.22278026]\n",
      " [ 0.         -0.11357     0.16885043]\n",
      " [ 0.          0.17774175  0.00233698]\n",
      " [ 0.         -0.10622942  0.22782715]\n",
      " [ 0.         -0.0610504   0.12273807]\n",
      " [ 0.         -0.08942953  0.23100574]\n",
      " [ 0.         -0.10007208  0.16269788]\n",
      " [ 0.          0.20476994  0.07846093]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #75 | lambda learn rate = 0.0001\n",
      "Target = [[7.]\n",
      " [1.]]\n",
      "lambda end of trial = [[ 0.          0.50406573 -0.25239575]\n",
      " [ 0.          0.34249101 -0.17625932]\n",
      " [ 0.         -0.1724948   0.22265793]\n",
      " [ 0.         -0.11439576  0.16873247]\n",
      " [ 0.          0.17697789  0.00222786]\n",
      " [ 0.         -0.10721967  0.22768568]\n",
      " [ 0.         -0.06200532  0.12260165]\n",
      " [ 0.         -0.09043162  0.23086259]\n",
      " [ 0.         -0.10112676  0.16254722]\n",
      " [ 0.          0.20373087  0.07831249]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #76 | lambda learn rate = 0.0001\n",
      "Target = [[9.]\n",
      " [6.]]\n",
      "lambda end of trial = [[ 0.          0.50712887 -0.25035365]\n",
      " [ 0.          0.34510453 -0.17451697]\n",
      " [ 0.         -0.16985222  0.22441965]\n",
      " [ 0.         -0.11215172  0.17022849]\n",
      " [ 0.          0.17949504  0.00390596]\n",
      " [ 0.         -0.10494639  0.2292012 ]\n",
      " [ 0.         -0.05945907  0.12429916]\n",
      " [ 0.         -0.08786419  0.23257421]\n",
      " [ 0.         -0.09873995  0.16413842]\n",
      " [ 0.          0.20643819  0.08011737]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #77 | lambda learn rate = 0.0001\n",
      "Target = [[7.]\n",
      " [8.]]\n",
      "lambda end of trial = [[ 0.          0.50826558 -0.24905456]\n",
      " [ 0.          0.34633595 -0.17310963]\n",
      " [ 0.         -0.16851847  0.22594393]\n",
      " [ 0.         -0.11085391  0.17171171]\n",
      " [ 0.          0.1807995   0.00539677]\n",
      " [ 0.         -0.10367733  0.23065156]\n",
      " [ 0.         -0.05815532  0.12578915]\n",
      " [ 0.         -0.08666324  0.23394671]\n",
      " [ 0.         -0.09755081  0.16549743]\n",
      " [ 0.          0.20755915  0.08139847]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #78 | lambda learn rate = 0.0001\n",
      "Target = [[7.]\n",
      " [7.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda end of trial = [[ 0.          0.50877677 -0.24854337]\n",
      " [ 0.          0.34700278 -0.1724428 ]\n",
      " [ 0.         -0.16799697  0.22646543]\n",
      " [ 0.         -0.11026     0.17230562]\n",
      " [ 0.          0.18136481  0.00596208]\n",
      " [ 0.         -0.10320334  0.23112555]\n",
      " [ 0.         -0.05762768  0.1263168 ]\n",
      " [ 0.         -0.08613159  0.23447836]\n",
      " [ 0.         -0.09705716  0.16599109]\n",
      " [ 0.          0.20803433  0.08187365]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #79 | lambda learn rate = 0.0001\n",
      "Target = [[3.]\n",
      " [0.]]\n",
      "lambda end of trial = [[ 0.          0.50730554 -0.24854337]\n",
      " [ 0.          0.34544937 -0.1724428 ]\n",
      " [ 0.         -0.16945953  0.22646543]\n",
      " [ 0.         -0.11195984  0.17230562]\n",
      " [ 0.          0.17982294  0.00596208]\n",
      " [ 0.         -0.10480665  0.23112555]\n",
      " [ 0.         -0.05915629  0.1263168 ]\n",
      " [ 0.         -0.08782782  0.23447836]\n",
      " [ 0.         -0.09861695  0.16599109]\n",
      " [ 0.          0.20632212  0.08187365]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #80 | lambda learn rate = 0.0001\n",
      "Target = [[5.]\n",
      " [8.]]\n",
      "lambda end of trial = [[ 0.          0.50732403 -0.24851379]\n",
      " [ 0.          0.34548186 -0.17239081]\n",
      " [ 0.         -0.16942111  0.2265269 ]\n",
      " [ 0.         -0.11187916  0.1724347 ]\n",
      " [ 0.          0.17977323  0.00588254]\n",
      " [ 0.         -0.10480608  0.23112646]\n",
      " [ 0.         -0.05905566  0.1264778 ]\n",
      " [ 0.         -0.08789563  0.23436985]\n",
      " [ 0.         -0.09855816  0.16608516]\n",
      " [ 0.          0.20627273  0.08179463]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #81 | lambda learn rate = 0.0001\n",
      "Target = [[9.]\n",
      " [9.]]\n",
      "lambda end of trial = [[ 0.          0.50976887 -0.24606895]\n",
      " [ 0.          0.34829039 -0.16958229]\n",
      " [ 0.         -0.16663112  0.22931689]\n",
      " [ 0.         -0.10914749  0.17516636]\n",
      " [ 0.          0.18245298  0.00856229]\n",
      " [ 0.         -0.10210017  0.23383237]\n",
      " [ 0.         -0.05614352  0.12938994]\n",
      " [ 0.         -0.08514704  0.23711844]\n",
      " [ 0.         -0.09572109  0.16892223]\n",
      " [ 0.          0.20909656  0.08461845]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #82 | lambda learn rate = 0.0001\n",
      "Target = [[2.]\n",
      " [9.]]\n",
      "lambda end of trial = [[ 0.          0.50933514 -0.24802075]\n",
      " [ 0.          0.34787693 -0.17144284]\n",
      " [ 0.         -0.16707754  0.22730801]\n",
      " [ 0.         -0.10957288  0.17325211]\n",
      " [ 0.          0.18208171  0.00689156]\n",
      " [ 0.         -0.1025082   0.23199621]\n",
      " [ 0.         -0.05657938  0.12742855]\n",
      " [ 0.         -0.08555094  0.23530089]\n",
      " [ 0.         -0.09614321  0.16702269]\n",
      " [ 0.          0.20866965  0.08269739]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #83 | lambda learn rate = 0.0001\n",
      "Target = [[0.]\n",
      " [0.]]\n",
      "lambda end of trial = [[ 0.          0.50933514 -0.24802075]\n",
      " [ 0.          0.34787693 -0.17144284]\n",
      " [ 0.         -0.16707754  0.22730801]\n",
      " [ 0.         -0.10957288  0.17325211]\n",
      " [ 0.          0.18208171  0.00689156]\n",
      " [ 0.         -0.1025082   0.23199621]\n",
      " [ 0.         -0.05657938  0.12742855]\n",
      " [ 0.         -0.08555094  0.23530089]\n",
      " [ 0.         -0.09614321  0.16702269]\n",
      " [ 0.          0.20866965  0.08269739]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #84 | lambda learn rate = 0.0001\n",
      "Target = [[4.]\n",
      " [3.]]\n",
      "lambda end of trial = [[ 0.          0.50814486 -0.24891346]\n",
      " [ 0.          0.34679825 -0.17225185]\n",
      " [ 0.         -0.16815011  0.22650359]\n",
      " [ 0.         -0.11063013  0.17245918]\n",
      " [ 0.          0.18107799  0.00613877]\n",
      " [ 0.         -0.10361079  0.23116927]\n",
      " [ 0.         -0.05769577  0.12659125]\n",
      " [ 0.         -0.08666459  0.23446565]\n",
      " [ 0.         -0.09725776  0.16618678]\n",
      " [ 0.          0.20758404  0.08188319]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #85 | lambda learn rate = 0.0001\n",
      "Target = [[5.]\n",
      " [9.]]\n",
      "lambda end of trial = [[ 0.          0.5084322  -0.24839625]\n",
      " [ 0.          0.34704514 -0.17180745]\n",
      " [ 0.         -0.16790468  0.22694536]\n",
      " [ 0.         -0.11038981  0.17289174]\n",
      " [ 0.          0.18127376  0.00649115]\n",
      " [ 0.         -0.1034216   0.23150983]\n",
      " [ 0.         -0.0574564   0.12702213]\n",
      " [ 0.         -0.08643917  0.2348714 ]\n",
      " [ 0.         -0.09702807  0.16660021]\n",
      " [ 0.          0.20774682  0.08217619]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #86 | lambda learn rate = 0.0001\n",
      "Target = [[1.]\n",
      " [3.]]\n",
      "lambda end of trial = [[ 0.          0.50788561 -0.25003602]\n",
      " [ 0.          0.34654326 -0.17331311]\n",
      " [ 0.         -0.1684045   0.22544589]\n",
      " [ 0.         -0.11092966  0.17127221]\n",
      " [ 0.          0.18077922  0.00500753]\n",
      " [ 0.         -0.10395332  0.22991466]\n",
      " [ 0.         -0.05792677  0.12561101]\n",
      " [ 0.         -0.08697741  0.2332567 ]\n",
      " [ 0.         -0.09749909  0.16518717]\n",
      " [ 0.          0.20725385  0.08069726]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #87 | lambda learn rate = 0.0001\n",
      "Target = [[9.]\n",
      " [4.]]\n",
      "lambda end of trial = [[ 0.          0.50864613 -0.24969801]\n",
      " [ 0.          0.34744679 -0.17291154]\n",
      " [ 0.         -0.16769635  0.22576062]\n",
      " [ 0.         -0.11015431  0.1716168 ]\n",
      " [ 0.          0.18153006  0.00534124]\n",
      " [ 0.         -0.10327924  0.23021426]\n",
      " [ 0.         -0.05706079  0.12599589]\n",
      " [ 0.         -0.08616656  0.23361707]\n",
      " [ 0.         -0.09673387  0.16552727]\n",
      " [ 0.          0.20793932  0.08100192]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #88 | lambda learn rate = 0.0001\n",
      "Target = [[3.]\n",
      " [0.]]\n",
      "lambda end of trial = [[ 0.          0.50723566 -0.24969801]\n",
      " [ 0.          0.34609474 -0.17291154]\n",
      " [ 0.         -0.16893027  0.22576062]\n",
      " [ 0.         -0.11162747  0.1716168 ]\n",
      " [ 0.          0.18017099  0.00534124]\n",
      " [ 0.         -0.10463414  0.23021426]\n",
      " [ 0.         -0.05845395  0.12599589]\n",
      " [ 0.         -0.08760573  0.23361707]\n",
      " [ 0.         -0.0981747   0.16552727]\n",
      " [ 0.          0.20652884  0.08100192]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #89 | lambda learn rate = 0.0001\n",
      "Target = [[1.]\n",
      " [0.]]\n",
      "lambda end of trial = [[ 0.          0.50663873 -0.24969801]\n",
      " [ 0.          0.34538162 -0.17291154]\n",
      " [ 0.         -0.16957543  0.22576062]\n",
      " [ 0.         -0.11225568  0.1716168 ]\n",
      " [ 0.          0.17952436  0.00534124]\n",
      " [ 0.         -0.1053261   0.23021426]\n",
      " [ 0.         -0.05908777  0.12599589]\n",
      " [ 0.         -0.08827056  0.23361707]\n",
      " [ 0.         -0.09879358  0.16552727]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [ 0.          0.20585367  0.08100192]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #90 | lambda learn rate = 0.0001\n",
      "Target = [[0.]\n",
      " [6.]]\n",
      "lambda end of trial = [[ 0.          0.50663873 -0.2521581 ]\n",
      " [ 0.          0.34538162 -0.17522919]\n",
      " [ 0.         -0.16957543  0.2231205 ]\n",
      " [ 0.         -0.11225568  0.16965581]\n",
      " [ 0.          0.17952436  0.00321582]\n",
      " [ 0.         -0.1053261   0.22772152]\n",
      " [ 0.         -0.05908777  0.12367839]\n",
      " [ 0.         -0.08827056  0.23091196]\n",
      " [ 0.         -0.09879358  0.16332765]\n",
      " [ 0.          0.20585367  0.07845183]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #91 | lambda learn rate = 0.0001\n",
      "Target = [[1.]\n",
      " [8.]]\n",
      "lambda end of trial = [[ 0.          0.5064595  -0.25359191]\n",
      " [ 0.          0.34522417 -0.17648887]\n",
      " [ 0.         -0.16977442  0.22152861]\n",
      " [ 0.         -0.11243348  0.16823347]\n",
      " [ 0.          0.17934294  0.00176446]\n",
      " [ 0.         -0.10552622  0.22612058]\n",
      " [ 0.         -0.05926573  0.12225477]\n",
      " [ 0.         -0.0884722   0.22929891]\n",
      " [ 0.         -0.09896272  0.16197446]\n",
      " [ 0.          0.20563756  0.07672292]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #92 | lambda learn rate = 0.0001\n",
      "Target = [[1.]\n",
      " [8.]]\n",
      "lambda end of trial = [[ 0.00000000e+00  5.06310698e-01 -2.54782322e-01]\n",
      " [ 0.00000000e+00  3.45085525e-01 -1.77597996e-01]\n",
      " [ 0.00000000e+00 -1.69934691e-01  2.20246413e-01]\n",
      " [ 0.00000000e+00 -1.12580435e-01  1.67057805e-01]\n",
      " [ 0.00000000e+00  1.79180259e-01  4.63034711e-04]\n",
      " [ 0.00000000e+00 -1.05670725e-01  2.24964542e-01]\n",
      " [ 0.00000000e+00 -5.94096156e-02  1.21103660e-01]\n",
      " [ 0.00000000e+00 -8.86229147e-02  2.28093162e-01]\n",
      " [ 0.00000000e+00 -9.91091751e-02  1.60802854e-01]\n",
      " [ 0.00000000e+00  2.05481543e-01  7.54747822e-02]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #93 | lambda learn rate = 0.0001\n",
      "Target = [[7.]\n",
      " [4.]]\n",
      "lambda end of trial = [[ 0.          0.50652486 -0.25465994]\n",
      " [ 0.          0.34526837 -0.17749351]\n",
      " [ 0.         -0.16965148  0.22040825]\n",
      " [ 0.         -0.11234088  0.16719469]\n",
      " [ 0.          0.17934735  0.00055851]\n",
      " [ 0.         -0.10554852  0.22503438]\n",
      " [ 0.         -0.05915002  0.121252  ]\n",
      " [ 0.         -0.08849793  0.22816458]\n",
      " [ 0.         -0.09882011  0.16096803]\n",
      " [ 0.          0.20557224  0.07552661]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #94 | lambda learn rate = 0.0001\n",
      "Target = [[7.]\n",
      " [8.]]\n",
      "lambda end of trial = [[ 0.          0.50850327 -0.2523989 ]\n",
      " [ 0.          0.34733653 -0.1751299 ]\n",
      " [ 0.         -0.16765566  0.22268919]\n",
      " [ 0.         -0.11038608  0.16942875]\n",
      " [ 0.          0.18104489  0.00249856]\n",
      " [ 0.         -0.10361021  0.22724958]\n",
      " [ 0.         -0.05725546  0.12341721]\n",
      " [ 0.         -0.08670573  0.23021281]\n",
      " [ 0.         -0.09710078  0.16293298]\n",
      " [ 0.          0.20736931  0.0775804 ]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #95 | lambda learn rate = 0.0001\n",
      "Target = [[5.]\n",
      " [7.]]\n",
      "lambda end of trial = [[ 0.          0.50857527 -0.25229811]\n",
      " [ 0.          0.34748126 -0.17492728]\n",
      " [ 0.         -0.16754486  0.22284431]\n",
      " [ 0.         -0.11028764  0.16956656]\n",
      " [ 0.          0.18104893  0.00250421]\n",
      " [ 0.         -0.10357136  0.22730397]\n",
      " [ 0.         -0.05718139  0.12352091]\n",
      " [ 0.         -0.08667812  0.23025146]\n",
      " [ 0.         -0.09706746  0.16297963]\n",
      " [ 0.          0.20740626  0.07763213]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #96 | lambda learn rate = 0.0001\n",
      "Target = [[0.]\n",
      " [1.]]\n",
      "lambda end of trial = [[ 0.          0.50857527 -0.2529057 ]\n",
      " [ 0.          0.34748126 -0.17555289]\n",
      " [ 0.         -0.16754486  0.22221948]\n",
      " [ 0.         -0.11028764  0.16893281]\n",
      " [ 0.          0.18104893  0.00187526]\n",
      " [ 0.         -0.10357136  0.22667801]\n",
      " [ 0.         -0.05718139  0.12283392]\n",
      " [ 0.         -0.08667812  0.22962218]\n",
      " [ 0.         -0.09706746  0.16237813]\n",
      " [ 0.          0.20740626  0.07699325]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #97 | lambda learn rate = 0.0001\n",
      "Target = [[8.]\n",
      " [1.]]\n",
      "lambda end of trial = [[ 0.          0.50746722 -0.2530442 ]\n",
      " [ 0.          0.34652463 -0.17567247]\n",
      " [ 0.         -0.1687111   0.2220737 ]\n",
      " [ 0.         -0.11140254  0.16879344]\n",
      " [ 0.          0.18011465  0.00175847]\n",
      " [ 0.         -0.10485561  0.22651747]\n",
      " [ 0.         -0.05828766  0.12269564]\n",
      " [ 0.         -0.08790467  0.22946887]\n",
      " [ 0.         -0.09804801  0.16225556]\n",
      " [ 0.          0.20613484  0.07683432]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #98 | lambda learn rate = 0.0001\n",
      "Target = [[0.]\n",
      " [0.]]\n",
      "lambda end of trial = [[ 0.          0.50746722 -0.2530442 ]\n",
      " [ 0.          0.34652463 -0.17567247]\n",
      " [ 0.         -0.1687111   0.2220737 ]\n",
      " [ 0.         -0.11140254  0.16879344]\n",
      " [ 0.          0.18011465  0.00175847]\n",
      " [ 0.         -0.10485561  0.22651747]\n",
      " [ 0.         -0.05828766  0.12269564]\n",
      " [ 0.         -0.08790467  0.22946887]\n",
      " [ 0.         -0.09804801  0.16225556]\n",
      " [ 0.          0.20613484  0.07683432]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "+++++++++++++++++++++++++++++++++++\n",
      "Session #4\n",
      "target at trial 0 = [[1.]\n",
      " [1.]]\n",
      "K MATX INIT= [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "A VECT INIT = [-0. -0.]\n",
      "lambda\n",
      "[[ 0.          0.53020654 -0.2322202 ]\n",
      " [ 0.          0.36705474 -0.15737009]\n",
      " [ 0.         -0.14629582  0.24261404]\n",
      " [ 0.         -0.08877213  0.18799136]\n",
      " [ 0.          0.20486852  0.02360278]\n",
      " [ 0.         -0.07854344  0.25002723]\n",
      " [ 0.         -0.03748972  0.14111247]\n",
      " [ 0.         -0.0597867   0.25435404]\n",
      " [ 0.         -0.07409235  0.18348285]\n",
      " [ 0.          0.23653843  0.10488391]]\n",
      "a\n",
      "[-0. -0.]\n",
      "K\n",
      "[[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #0 | lambda learn rate = 0.0001\n",
      "Target = [[1.]\n",
      " [1.]]\n",
      "lambda end of trial = [[ 0.          0.52953312 -0.23289361]\n",
      " [ 0.          0.36642133 -0.1580035 ]\n",
      " [ 0.         -0.14695139  0.24195847]\n",
      " [ 0.         -0.08942237  0.18734111]\n",
      " [ 0.          0.20420661  0.02294086]\n",
      " [ 0.         -0.07925991  0.24931076]\n",
      " [ 0.         -0.03814896  0.14045323]\n",
      " [ 0.         -0.06044995  0.25369078]\n",
      " [ 0.         -0.07481987  0.18275533]\n",
      " [ 0.          0.23583215  0.10417763]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #1 | lambda learn rate = 0.0001\n",
      "Target = [[1.]\n",
      " [2.]]\n",
      "lambda end of trial = [[ 0.          0.52885951 -0.23424084]\n",
      " [ 0.          0.36573606 -0.15937404]\n",
      " [ 0.         -0.1476594   0.24054245]\n",
      " [ 0.         -0.0901053   0.18597526]\n",
      " [ 0.          0.2034686   0.02146485]\n",
      " [ 0.         -0.08001086  0.24780886]\n",
      " [ 0.         -0.03880698  0.1391372 ]\n",
      " [ 0.         -0.06118025  0.25223018]\n",
      " [ 0.         -0.07549037  0.18141433]\n",
      " [ 0.          0.23504103  0.10259539]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #2 | lambda learn rate = 0.0001\n",
      "Target = [[5.]\n",
      " [1.]]\n",
      "lambda end of trial = [[ 0.          0.52596911 -0.23481892]\n",
      " [ 0.          0.36294181 -0.15993289]\n",
      " [ 0.         -0.15053071  0.23996819]\n",
      " [ 0.         -0.09303879  0.18538856]\n",
      " [ 0.          0.20024013  0.02081915]\n",
      " [ 0.         -0.08333159  0.24714471]\n",
      " [ 0.         -0.04213407  0.13847178]\n",
      " [ 0.         -0.06445487  0.25157526]\n",
      " [ 0.         -0.07853777  0.18080485]\n",
      " [ 0.          0.23190715  0.10196861]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #3 | lambda learn rate = 0.0001\n",
      "Target = [[9.]\n",
      " [5.]]\n",
      "lambda end of trial = [[ 0.          0.521099   -0.23752454]\n",
      " [ 0.          0.35809212 -0.16262716]\n",
      " [ 0.         -0.15523726  0.23735344]\n",
      " [ 0.         -0.09777646  0.18275652]\n",
      " [ 0.          0.19532636  0.01808928]\n",
      " [ 0.         -0.08820264  0.24443858]\n",
      " [ 0.         -0.0469368   0.1358036 ]\n",
      " [ 0.         -0.0698448   0.24858085]\n",
      " [ 0.         -0.08337281  0.17811872]\n",
      " [ 0.          0.22677091  0.09911514]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #4 | lambda learn rate = 0.0001\n",
      "Target = [[4.]\n",
      " [7.]]\n",
      "lambda end of trial = [[ 0.          0.51901816 -0.24116601]\n",
      " [ 0.          0.35582377 -0.16659678]\n",
      " [ 0.         -0.15734385  0.23366691]\n",
      " [ 0.         -0.09985566  0.17911793]\n",
      " [ 0.          0.19324792  0.01445201]\n",
      " [ 0.         -0.09021319  0.24092012]\n",
      " [ 0.         -0.04905771  0.13209201]\n",
      " [ 0.         -0.07184179  0.24508612]\n",
      " [ 0.         -0.08545843  0.17446889]\n",
      " [ 0.          0.22449198  0.09512701]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #5 | lambda learn rate = 0.0001\n",
      "Target = [[9.]\n",
      " [0.]]\n",
      "lambda end of trial = [[ 0.          0.51546204 -0.24116601]\n",
      " [ 0.          0.35147876 -0.16659678]\n",
      " [ 0.         -0.16129712  0.23366691]\n",
      " [ 0.         -0.10405194  0.17911793]\n",
      " [ 0.          0.18957298  0.01445201]\n",
      " [ 0.         -0.09386625  0.24092012]\n",
      " [ 0.         -0.05268965  0.13209201]\n",
      " [ 0.         -0.0759985   0.24508612]\n",
      " [ 0.         -0.08939739  0.17446889]\n",
      " [ 0.          0.22019691  0.09512701]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #6 | lambda learn rate = 0.0001\n",
      "Target = [[5.]\n",
      " [0.]]\n",
      "lambda end of trial = [[ 0.          0.51329858 -0.24116601]\n",
      " [ 0.          0.34928799 -0.16659678]\n",
      " [ 0.         -0.16351005  0.23366691]\n",
      " [ 0.         -0.10631955  0.17911793]\n",
      " [ 0.          0.18725892  0.01445201]\n",
      " [ 0.         -0.09615061  0.24092012]\n",
      " [ 0.         -0.05484842  0.13209201]\n",
      " [ 0.         -0.07821358  0.24508612]\n",
      " [ 0.         -0.09143634  0.17446889]\n",
      " [ 0.          0.21795772  0.09512701]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #7 | lambda learn rate = 0.0001\n",
      "Target = [[7.]\n",
      " [3.]]\n",
      "lambda end of trial = [[ 0.          0.51124782 -0.24204491]\n",
      " [ 0.          0.34718099 -0.16749978]\n",
      " [ 0.         -0.16542039  0.23284819]\n",
      " [ 0.         -0.10860708  0.17813756]\n",
      " [ 0.          0.18501302  0.01348949]\n",
      " [ 0.         -0.09824767  0.24002138]\n",
      " [ 0.         -0.05721157  0.13107923]\n",
      " [ 0.         -0.08037033  0.24416179]\n",
      " [ 0.         -0.09357524  0.17355221]\n",
      " [ 0.          0.21573621  0.09417493]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #8 | lambda learn rate = 0.0001\n",
      "Target = [[5.]\n",
      " [0.]]\n",
      "lambda end of trial = [[ 0.          0.50923858 -0.24204491]\n",
      " [ 0.          0.34508629 -0.16749978]\n",
      " [ 0.         -0.16743332  0.23284819]\n",
      " [ 0.         -0.11042796  0.17813756]\n",
      " [ 0.          0.18277538  0.01348949]\n",
      " [ 0.         -0.10018507  0.24002138]\n",
      " [ 0.         -0.05923367  0.13107923]\n",
      " [ 0.         -0.08270967  0.24416179]\n",
      " [ 0.         -0.09552804  0.17355221]\n",
      " [ 0.          0.21358406  0.09417493]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #9 | lambda learn rate = 0.0001\n",
      "Target = [[6.]\n",
      " [3.]]\n",
      "lambda end of trial = [[ 0.          0.50784649 -0.24274095]\n",
      " [ 0.          0.34365207 -0.16821689]\n",
      " [ 0.         -0.16889411  0.2321178 ]\n",
      " [ 0.         -0.11189363  0.17740472]\n",
      " [ 0.          0.18131676  0.01276018]\n",
      " [ 0.         -0.1017562   0.23923581]\n",
      " [ 0.         -0.06063457  0.13037878]\n",
      " [ 0.         -0.08410847  0.2434624 ]\n",
      " [ 0.         -0.0969387   0.17284688]\n",
      " [ 0.          0.2120735   0.09341966]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #10 | lambda learn rate = 0.0001\n",
      "Target = [[2.]\n",
      " [6.]]\n",
      "lambda end of trial = [[ 0.          0.50707727 -0.24504861]\n",
      " [ 0.          0.34286555 -0.17057646]\n",
      " [ 0.         -0.16965617  0.22983162]\n",
      " [ 0.         -0.1125734   0.17536543]\n",
      " [ 0.          0.18063017  0.01070041]\n",
      " [ 0.         -0.10249425  0.23702166]\n",
      " [ 0.         -0.06132324  0.12831279]\n",
      " [ 0.         -0.08485845  0.24121243]\n",
      " [ 0.         -0.09765381  0.17070156]\n",
      " [ 0.          0.21129196  0.09107503]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #11 | lambda learn rate = 0.0001\n",
      "Target = [[2.]\n",
      " [1.]]\n",
      "lambda end of trial = [[ 0.          0.50598013 -0.24559718]\n",
      " [ 0.          0.34167945 -0.17116951]\n",
      " [ 0.         -0.17072106  0.22929918]\n",
      " [ 0.         -0.11360675  0.17484875]\n",
      " [ 0.          0.17952784  0.01014924]\n",
      " [ 0.         -0.10353709  0.23650024]\n",
      " [ 0.         -0.06229144  0.12782869]\n",
      " [ 0.         -0.0858708   0.24070626]\n",
      " [ 0.         -0.09880139  0.17012777]\n",
      " [ 0.          0.21019111  0.09052461]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #12 | lambda learn rate = 0.0001\n",
      "Target = [[8.]\n",
      " [8.]]\n",
      "lambda end of trial = [[ 0.          0.5068746  -0.24470271]\n",
      " [ 0.          0.34261954 -0.17022942]\n",
      " [ 0.         -0.16971277  0.23030747]\n",
      " [ 0.         -0.11267629  0.17577921]\n",
      " [ 0.          0.18040332  0.01102472]\n",
      " [ 0.         -0.10262277  0.23741456]\n",
      " [ 0.         -0.06138947  0.12873065]\n",
      " [ 0.         -0.08507539  0.24150167]\n",
      " [ 0.         -0.09786473  0.17106443]\n",
      " [ 0.          0.21103866  0.09137216]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #13 | lambda learn rate = 0.0001\n",
      "Target = [[7.]\n",
      " [1.]]\n",
      "lambda end of trial = [[ 0.          0.50536407 -0.2449185 ]\n",
      " [ 0.          0.341222   -0.17042907]\n",
      " [ 0.         -0.17121249  0.23009322]\n",
      " [ 0.         -0.11442436  0.17552949]\n",
      " [ 0.          0.17870758  0.01078247]\n",
      " [ 0.         -0.10409542  0.23720418]\n",
      " [ 0.         -0.06288662  0.12851678]\n",
      " [ 0.         -0.08644731  0.24130568]\n",
      " [ 0.         -0.09928566  0.17086144]\n",
      " [ 0.          0.20936092  0.09113248]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #14 | lambda learn rate = 0.0001\n",
      "Target = [[8.]\n",
      " [8.]]\n",
      "lambda end of trial = [[ 0.          0.5061854  -0.24409717]\n",
      " [ 0.          0.3420183  -0.16963277]\n",
      " [ 0.         -0.17043879  0.23086692]\n",
      " [ 0.         -0.11378674  0.17616711]\n",
      " [ 0.          0.17933176  0.01140665]\n",
      " [ 0.         -0.10345719  0.23784241]\n",
      " [ 0.         -0.06211548  0.12928792]\n",
      " [ 0.         -0.08576628  0.24198672]\n",
      " [ 0.         -0.0985461   0.171601  ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [ 0.          0.21006016  0.09183172]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #15 | lambda learn rate = 0.0001\n",
      "Target = [[0.]\n",
      " [6.]]\n",
      "lambda end of trial = [[ 0.          0.5061854  -0.24679107]\n",
      " [ 0.          0.3420183  -0.17234449]\n",
      " [ 0.         -0.17043879  0.22799913]\n",
      " [ 0.         -0.11378674  0.17348251]\n",
      " [ 0.          0.17933176  0.00823941]\n",
      " [ 0.         -0.10345719  0.23504635]\n",
      " [ 0.         -0.06211548  0.12662445]\n",
      " [ 0.         -0.08576628  0.23909134]\n",
      " [ 0.         -0.0985461   0.1685803 ]\n",
      " [ 0.          0.21006016  0.08901342]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #16 | lambda learn rate = 0.0001\n",
      "Target = [[4.]\n",
      " [8.]]\n",
      "lambda end of trial = [[ 0.          0.50571467 -0.24773252]\n",
      " [ 0.          0.34160111 -0.17317888]\n",
      " [ 0.         -0.17092615  0.22702441]\n",
      " [ 0.         -0.11430303  0.17244993]\n",
      " [ 0.          0.17878044  0.00713677]\n",
      " [ 0.         -0.10407877  0.23380318]\n",
      " [ 0.         -0.06256418  0.12572704]\n",
      " [ 0.         -0.08628886  0.23804616]\n",
      " [ 0.         -0.09908438  0.16750376]\n",
      " [ 0.          0.20949624  0.08788557]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #17 | lambda learn rate = 0.0001\n",
      "Target = [[3.]\n",
      " [7.]]\n",
      "lambda end of trial = [[ 0.          0.50521557 -0.2488971 ]\n",
      " [ 0.          0.34105911 -0.17444354]\n",
      " [ 0.         -0.17145602  0.22578802]\n",
      " [ 0.         -0.11473002  0.17145361]\n",
      " [ 0.          0.17828295  0.00597596]\n",
      " [ 0.         -0.10462459  0.23252962]\n",
      " [ 0.         -0.06309619  0.12448569]\n",
      " [ 0.         -0.08679051  0.23687564]\n",
      " [ 0.         -0.09954054  0.16643937]\n",
      " [ 0.          0.20895306  0.08661816]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #18 | lambda learn rate = 0.0001\n",
      "Target = [[1.]\n",
      " [5.]]\n",
      "lambda end of trial = [[ 0.          0.5048338  -0.25080595]\n",
      " [ 0.          0.34067113 -0.17638345]\n",
      " [ 0.         -0.17181864  0.22397494]\n",
      " [ 0.         -0.11509245  0.16964144]\n",
      " [ 0.          0.17788525  0.00398744]\n",
      " [ 0.         -0.10497397  0.23078269]\n",
      " [ 0.         -0.06344747  0.12272927]\n",
      " [ 0.         -0.08713694  0.2351435 ]\n",
      " [ 0.         -0.09989227  0.16468072]\n",
      " [ 0.          0.20854317  0.0845687 ]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #19 | lambda learn rate = 0.0001\n",
      "Target = [[8.]\n",
      " [9.]]\n",
      "lambda end of trial = [[ 0.          0.50727545 -0.24805909]\n",
      " [ 0.          0.34330319 -0.17342238]\n",
      " [ 0.         -0.1694921   0.2265923 ]\n",
      " [ 0.         -0.11295603  0.17204492]\n",
      " [ 0.          0.18022393  0.00661846]\n",
      " [ 0.         -0.10272758  0.23330988]\n",
      " [ 0.         -0.06140077  0.1250318 ]\n",
      " [ 0.         -0.08493029  0.23762599]\n",
      " [ 0.         -0.09740573  0.16747809]\n",
      " [ 0.          0.21086237  0.0871778 ]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #20 | lambda learn rate = 0.0001\n",
      "Target = [[3.]\n",
      " [5.]]\n",
      "lambda end of trial = [[ 0.          0.50648969 -0.2493687 ]\n",
      " [ 0.          0.34250856 -0.17474675]\n",
      " [ 0.         -0.17031089  0.22522765]\n",
      " [ 0.         -0.11353199  0.17108498]\n",
      " [ 0.          0.17938543  0.00522096]\n",
      " [ 0.         -0.1035655   0.23191336]\n",
      " [ 0.         -0.0622237   0.12366027]\n",
      " [ 0.         -0.08568863  0.23636208]\n",
      " [ 0.         -0.09820392  0.16614777]\n",
      " [ 0.          0.2099963   0.08573436]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #21 | lambda learn rate = 0.0001\n",
      "Target = [[6.]\n",
      " [1.]]\n",
      "lambda end of trial = [[ 0.          0.50491487 -0.24963117]\n",
      " [ 0.          0.34103876 -0.17499172]\n",
      " [ 0.         -0.17192166  0.22495919]\n",
      " [ 0.         -0.11510317  0.17082311]\n",
      " [ 0.          0.17802564  0.00499433]\n",
      " [ 0.         -0.10513266  0.23165216]\n",
      " [ 0.         -0.06359794  0.12343123]\n",
      " [ 0.         -0.08748169  0.23606324]\n",
      " [ 0.         -0.09980291  0.16588127]\n",
      " [ 0.          0.20816647  0.08542938]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #22 | lambda learn rate = 0.0001\n",
      "Target = [[9.]\n",
      " [5.]]\n",
      "lambda end of trial = [[ 0.          0.50631869 -0.24885127]\n",
      " [ 0.          0.34269533 -0.1740714 ]\n",
      " [ 0.         -0.17035162  0.22583143]\n",
      " [ 0.         -0.11362057  0.17164678]\n",
      " [ 0.          0.17942893  0.00577393]\n",
      " [ 0.         -0.10368462  0.23245663]\n",
      " [ 0.         -0.06224459  0.12418309]\n",
      " [ 0.         -0.08603489  0.23686702]\n",
      " [ 0.         -0.09830206  0.16671507]\n",
      " [ 0.          0.20949012  0.08616475]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #23 | lambda learn rate = 0.0001\n",
      "Target = [[7.]\n",
      " [3.]]\n",
      "lambda end of trial = [[ 0.          0.50573022 -0.24910347]\n",
      " [ 0.          0.34204988 -0.17434802]\n",
      " [ 0.         -0.17085156  0.22561717]\n",
      " [ 0.         -0.11422776  0.17138655]\n",
      " [ 0.          0.17884819  0.00552504]\n",
      " [ 0.         -0.10434071  0.23217545]\n",
      " [ 0.         -0.0627318   0.12397428]\n",
      " [ 0.         -0.08661439  0.23661866]\n",
      " [ 0.         -0.09888519  0.16646516]\n",
      " [ 0.          0.2087672   0.08585492]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #24 | lambda learn rate = 0.0001\n",
      "Target = [[6.]\n",
      " [5.]]\n",
      "lambda end of trial = [[ 0.          0.50538505 -0.24939111]\n",
      " [ 0.          0.34172304 -0.17462039]\n",
      " [ 0.         -0.17123929  0.22529406]\n",
      " [ 0.         -0.11456873  0.17110241]\n",
      " [ 0.          0.17845469  0.00519713]\n",
      " [ 0.         -0.10470202  0.23187436]\n",
      " [ 0.         -0.06311388  0.12365588]\n",
      " [ 0.         -0.08699894  0.2362982 ]\n",
      " [ 0.         -0.09919764  0.16620478]\n",
      " [ 0.          0.20832459  0.08548608]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #25 | lambda learn rate = 0.0001\n",
      "Target = [[3.]\n",
      " [5.]]\n",
      "lambda end of trial = [[ 0.          0.5045832  -0.25072753]\n",
      " [ 0.          0.34096063 -0.17589107]\n",
      " [ 0.         -0.17203706  0.22396444]\n",
      " [ 0.         -0.11531643  0.16985626]\n",
      " [ 0.          0.1776274   0.00381831]\n",
      " [ 0.         -0.10548834  0.23056382]\n",
      " [ 0.         -0.06391972  0.12231281]\n",
      " [ 0.         -0.08777842  0.23499907]\n",
      " [ 0.         -0.0999349   0.16497602]\n",
      " [ 0.          0.20747471  0.08406962]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #26 | lambda learn rate = 0.0001\n",
      "Target = [[5.]\n",
      " [8.]]\n",
      "lambda end of trial = [[ 0.          0.50492254 -0.25018459]\n",
      " [ 0.          0.34123366 -0.17545423]\n",
      " [ 0.         -0.17178873  0.22436178]\n",
      " [ 0.         -0.11502891  0.17031628]\n",
      " [ 0.          0.17787457  0.00421379]\n",
      " [ 0.         -0.10530933  0.23085023]\n",
      " [ 0.         -0.06368792  0.12268369]\n",
      " [ 0.         -0.08759587  0.23529114]\n",
      " [ 0.         -0.09964675  0.16543705]\n",
      " [ 0.          0.2075829   0.08424272]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #27 | lambda learn rate = 0.0001\n",
      "Target = [[0.]\n",
      " [6.]]\n",
      "lambda end of trial = [[ 0.          0.50492254 -0.25230654]\n",
      " [ 0.          0.34123366 -0.177806  ]\n",
      " [ 0.         -0.17178873  0.22188934]\n",
      " [ 0.         -0.11502891  0.16794248]\n",
      " [ 0.          0.17787457  0.00166953]\n",
      " [ 0.         -0.10530933  0.22857406]\n",
      " [ 0.         -0.06368792  0.12042484]\n",
      " [ 0.         -0.08759587  0.23288451]\n",
      " [ 0.         -0.09964675  0.16298393]\n",
      " [ 0.          0.2075829   0.08166413]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #28 | lambda learn rate = 0.0001\n",
      "Target = [[2.]\n",
      " [0.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda end of trial = [[ 0.          0.5038721  -0.25230654]\n",
      " [ 0.          0.34011212 -0.177806  ]\n",
      " [ 0.         -0.17288425  0.22188934]\n",
      " [ 0.         -0.11609782  0.16794248]\n",
      " [ 0.          0.17675077  0.00166953]\n",
      " [ 0.         -0.10625166  0.22857406]\n",
      " [ 0.         -0.06474787  0.12042484]\n",
      " [ 0.         -0.08874925  0.23288451]\n",
      " [ 0.         -0.10071257  0.16298393]\n",
      " [ 0.          0.206475    0.08166413]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #29 | lambda learn rate = 0.0001\n",
      "Target = [[9.]\n",
      " [4.]]\n",
      "lambda end of trial = [[ 0.          0.50535311 -0.25164831]\n",
      " [ 0.          0.34182546 -0.17704452]\n",
      " [ 0.         -0.17150408  0.22250274]\n",
      " [ 0.         -0.11465317  0.16858454]\n",
      " [ 0.          0.17837794  0.00239272]\n",
      " [ 0.         -0.10475487  0.2292393 ]\n",
      " [ 0.         -0.06314389  0.12113772]\n",
      " [ 0.         -0.08741584  0.23347714]\n",
      " [ 0.         -0.09930617  0.163609  ]\n",
      " [ 0.          0.20792686  0.0823094 ]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #30 | lambda learn rate = 0.0001\n",
      "Target = [[5.]\n",
      " [9.]]\n",
      "lambda end of trial = [[ 0.          0.50602439 -0.25044001]\n",
      " [ 0.          0.34247102 -0.17588249]\n",
      " [ 0.         -0.17084268  0.22369328]\n",
      " [ 0.         -0.11400749  0.16974678]\n",
      " [ 0.          0.17891992  0.00336828]\n",
      " [ 0.         -0.1042129   0.23021486]\n",
      " [ 0.         -0.06247308  0.12234517]\n",
      " [ 0.         -0.08679114  0.23460161]\n",
      " [ 0.         -0.09867826  0.16473923]\n",
      " [ 0.          0.20840816  0.08317574]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #31 | lambda learn rate = 0.0001\n",
      "Target = [[7.]\n",
      " [9.]]\n",
      "lambda end of trial = [[ 0.          0.50748947 -0.24855633]\n",
      " [ 0.          0.34424032 -0.17360768]\n",
      " [ 0.         -0.16927732  0.22570587]\n",
      " [ 0.         -0.11255537  0.17161378]\n",
      " [ 0.          0.18044688  0.00533152]\n",
      " [ 0.         -0.1025697   0.23232754]\n",
      " [ 0.         -0.06084671  0.12443623]\n",
      " [ 0.         -0.08511243  0.23675995]\n",
      " [ 0.         -0.09716699  0.1666823 ]\n",
      " [ 0.          0.20982555  0.0849981 ]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #32 | lambda learn rate = 0.0001\n",
      "Target = [[6.]\n",
      " [7.]]\n",
      "lambda end of trial = [[ 0.          0.50757706 -0.24845415]\n",
      " [ 0.          0.34436023 -0.17346779]\n",
      " [ 0.         -0.16921879  0.22577416]\n",
      " [ 0.         -0.11244483  0.17174275]\n",
      " [ 0.          0.18050046  0.00539403]\n",
      " [ 0.         -0.10254958  0.23235101]\n",
      " [ 0.         -0.06074574  0.12455403]\n",
      " [ 0.         -0.08505871  0.23682262]\n",
      " [ 0.         -0.09710121  0.16675904]\n",
      " [ 0.          0.20979866  0.08496674]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #33 | lambda learn rate = 0.0001\n",
      "Target = [[1.]\n",
      " [2.]]\n",
      "lambda end of trial = [[ 0.          0.50706079 -0.24948669]\n",
      " [ 0.          0.34390818 -0.17437189]\n",
      " [ 0.         -0.16971826  0.22477522]\n",
      " [ 0.         -0.11295001  0.17073239]\n",
      " [ 0.          0.17997052  0.00433414]\n",
      " [ 0.         -0.10302636  0.23139745]\n",
      " [ 0.         -0.06123707  0.12357136]\n",
      " [ 0.         -0.08558146  0.23577712]\n",
      " [ 0.         -0.09763737  0.16568672]\n",
      " [ 0.          0.20920743  0.08378427]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #34 | lambda learn rate = 0.0001\n",
      "Target = [[9.]\n",
      " [7.]]\n",
      "lambda end of trial = [[ 0.          0.5088423  -0.24810107]\n",
      " [ 0.          0.34567903 -0.17299456]\n",
      " [ 0.         -0.16788016  0.22620485]\n",
      " [ 0.         -0.11122614  0.17207317]\n",
      " [ 0.          0.18196328  0.00588407]\n",
      " [ 0.         -0.10130313  0.23273774]\n",
      " [ 0.         -0.05926094  0.12510835]\n",
      " [ 0.         -0.08370595  0.23723585]\n",
      " [ 0.         -0.09588329  0.16705101]\n",
      " [ 0.          0.21108913  0.08524781]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #35 | lambda learn rate = 0.0001\n",
      "Target = [[4.]\n",
      " [3.]]\n",
      "lambda end of trial = [[ 0.          0.50762545 -0.24901371]\n",
      " [ 0.          0.34450952 -0.1738717 ]\n",
      " [ 0.         -0.16917113  0.22523663]\n",
      " [ 0.         -0.11259238  0.1710485 ]\n",
      " [ 0.          0.18057793  0.00484505]\n",
      " [ 0.         -0.10247954  0.23185544]\n",
      " [ 0.         -0.06044088  0.12422339]\n",
      " [ 0.         -0.08494494  0.23630661]\n",
      " [ 0.         -0.09715276  0.1660989 ]\n",
      " [ 0.          0.20970173  0.08420726]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #36 | lambda learn rate = 0.0001\n",
      "Target = [[9.]\n",
      " [1.]]\n",
      "lambda end of trial = [[ 0.          0.50704335 -0.24907838]\n",
      " [ 0.          0.34394683 -0.17393422]\n",
      " [ 0.         -0.16973606  0.22517386]\n",
      " [ 0.         -0.11318203  0.17098298]\n",
      " [ 0.          0.17992891  0.00477294]\n",
      " [ 0.         -0.10304017  0.23179314]\n",
      " [ 0.         -0.06105593  0.12415505]\n",
      " [ 0.         -0.08559206  0.2362347 ]\n",
      " [ 0.         -0.09782352  0.16602437]\n",
      " [ 0.          0.20898152  0.08412724]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #37 | lambda learn rate = 0.0001\n",
      "Target = [[6.]\n",
      " [5.]]\n",
      "lambda end of trial = [[ 0.          0.50657018 -0.2494727 ]\n",
      " [ 0.          0.34352825 -0.17428304]\n",
      " [ 0.         -0.17026334  0.22473446]\n",
      " [ 0.         -0.11363217  0.17060786]\n",
      " [ 0.          0.17942102  0.0043497 ]\n",
      " [ 0.         -0.10354043  0.23137626]\n",
      " [ 0.         -0.06153866  0.12375278]\n",
      " [ 0.         -0.08607932  0.23582866]\n",
      " [ 0.         -0.09824554  0.16567268]\n",
      " [ 0.          0.20835818  0.08360779]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #38 | lambda learn rate = 0.0001\n",
      "Target = [[2.]\n",
      " [4.]]\n",
      "lambda end of trial = [[ 0.          0.50595672 -0.25069961]\n",
      " [ 0.          0.34283326 -0.17567302]\n",
      " [ 0.         -0.17103502  0.22319109]\n",
      " [ 0.         -0.11437104  0.16913012]\n",
      " [ 0.          0.17871881  0.00294528]\n",
      " [ 0.         -0.10430926  0.22983859]\n",
      " [ 0.         -0.06228873  0.12225263]\n",
      " [ 0.         -0.08689476  0.23419778]\n",
      " [ 0.         -0.09897363  0.16421651]\n",
      " [ 0.          0.2076055   0.08210242]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #39 | lambda learn rate = 0.0001\n",
      "Target = [[1.]\n",
      " [1.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda end of trial = [[ 0.          0.50544623 -0.25121011]\n",
      " [ 0.          0.3422784  -0.17622788]\n",
      " [ 0.         -0.17157721  0.2226489 ]\n",
      " [ 0.         -0.11489454  0.16860662]\n",
      " [ 0.          0.17817503  0.0024015 ]\n",
      " [ 0.         -0.10485871  0.22928914]\n",
      " [ 0.         -0.0628039   0.12173746]\n",
      " [ 0.         -0.08747213  0.2336204 ]\n",
      " [ 0.         -0.09950728  0.16368286]\n",
      " [ 0.          0.2069629   0.08145982]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #40 | lambda learn rate = 0.0001\n",
      "Target = [[2.]\n",
      " [1.]]\n",
      "lambda end of trial = [[ 0.          0.50440395 -0.25173125]\n",
      " [ 0.          0.34129554 -0.17671931]\n",
      " [ 0.         -0.17267733  0.22209885]\n",
      " [ 0.         -0.11594043  0.16808367]\n",
      " [ 0.          0.17713039  0.00187918]\n",
      " [ 0.         -0.10594321  0.22874689]\n",
      " [ 0.         -0.06377958  0.12124962]\n",
      " [ 0.         -0.08847285  0.23312005]\n",
      " [ 0.         -0.10063489  0.16311906]\n",
      " [ 0.          0.20571549  0.08083612]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #41 | lambda learn rate = 0.0001\n",
      "Target = [[8.]\n",
      " [6.]]\n",
      "lambda end of trial = [[ 0.          0.50603769 -0.25050594]\n",
      " [ 0.          0.34294901 -0.17547921]\n",
      " [ 0.         -0.17126836  0.22315557]\n",
      " [ 0.         -0.11434778  0.16927816]\n",
      " [ 0.          0.17862038  0.00299667]\n",
      " [ 0.         -0.10421184  0.23004542]\n",
      " [ 0.         -0.06226905  0.12238252]\n",
      " [ 0.         -0.08687039  0.23432189]\n",
      " [ 0.         -0.09898764  0.16435449]\n",
      " [ 0.          0.20708809  0.08186556]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #42 | lambda learn rate = 0.0001\n",
      "Target = [[6.]\n",
      " [8.]]\n",
      "lambda end of trial = [[ 0.          0.50671338 -0.24960501]\n",
      " [ 0.          0.3436579  -0.17453401]\n",
      " [ 0.         -0.1703622   0.22436379]\n",
      " [ 0.         -0.11362287  0.1702447 ]\n",
      " [ 0.          0.17942166  0.00406504]\n",
      " [ 0.         -0.10357601  0.2308932 ]\n",
      " [ 0.         -0.06147921  0.12343564]\n",
      " [ 0.         -0.08610679  0.23534003]\n",
      " [ 0.         -0.09814462  0.16547852]\n",
      " [ 0.          0.20777707  0.08278421]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #43 | lambda learn rate = 0.0001\n",
      "Target = [[8.]\n",
      " [1.]]\n",
      "lambda end of trial = [[ 0.          0.50572138 -0.24972901]\n",
      " [ 0.          0.34279069 -0.17464242]\n",
      " [ 0.         -0.17144537  0.22422839]\n",
      " [ 0.         -0.11458308  0.17012467]\n",
      " [ 0.          0.17830738  0.00392576]\n",
      " [ 0.         -0.10481057  0.23073888]\n",
      " [ 0.         -0.06263053  0.12329173]\n",
      " [ 0.         -0.08736231  0.23518309]\n",
      " [ 0.         -0.09918587  0.16534836]\n",
      " [ 0.          0.20644423  0.0826176 ]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #44 | lambda learn rate = 0.0001\n",
      "Target = [[3.]\n",
      " [7.]]\n",
      "lambda end of trial = [[ 0.          0.50538419 -0.2505158 ]\n",
      " [ 0.          0.34243382 -0.1754751 ]\n",
      " [ 0.         -0.17178608  0.2234334 ]\n",
      " [ 0.         -0.11494321  0.16928437]\n",
      " [ 0.          0.17798681  0.00317777]\n",
      " [ 0.         -0.10515081  0.22994499]\n",
      " [ 0.         -0.06299097  0.12245072]\n",
      " [ 0.         -0.08765907  0.23449064]\n",
      " [ 0.         -0.09949859  0.16461868]\n",
      " [ 0.          0.20605172  0.08170176]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #45 | lambda learn rate = 0.0001\n",
      "Target = [[7.]\n",
      " [7.]]\n",
      "lambda end of trial = [[ 0.          0.50651278 -0.24938721]\n",
      " [ 0.          0.34341088 -0.17449804]\n",
      " [ 0.         -0.17083687  0.22438261]\n",
      " [ 0.         -0.11399167  0.17023591]\n",
      " [ 0.          0.17897802  0.00416898]\n",
      " [ 0.         -0.10427664  0.23081916]\n",
      " [ 0.         -0.06193563  0.12350605]\n",
      " [ 0.         -0.08667157  0.23547814]\n",
      " [ 0.         -0.09848496  0.16563231]\n",
      " [ 0.          0.20693001  0.08258005]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #46 | lambda learn rate = 0.0001\n",
      "Target = [[8.]\n",
      " [5.]]\n",
      "lambda end of trial = [[ 0.          0.50716706 -0.24897828]\n",
      " [ 0.          0.34418228 -0.17401592]\n",
      " [ 0.         -0.17020005  0.22478063]\n",
      " [ 0.         -0.11329227  0.17067304]\n",
      " [ 0.          0.17974561  0.00464873]\n",
      " [ 0.         -0.10362904  0.23122391]\n",
      " [ 0.         -0.0612203   0.12395313]\n",
      " [ 0.         -0.08601897  0.23588601]\n",
      " [ 0.         -0.09776386  0.166083  ]\n",
      " [ 0.          0.20755207  0.08296883]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #47 | lambda learn rate = 0.0001\n",
      "Target = [[6.]\n",
      " [5.]]\n",
      "lambda end of trial = [[ 0.          0.50695159 -0.24915784]\n",
      " [ 0.          0.34397444 -0.17418912]\n",
      " [ 0.         -0.17040423  0.22461048]\n",
      " [ 0.         -0.11345615  0.17053647]\n",
      " [ 0.          0.17948353  0.00443033]\n",
      " [ 0.         -0.10391719  0.23098379]\n",
      " [ 0.         -0.06142539  0.12378222]\n",
      " [ 0.         -0.08627531  0.2356724 ]\n",
      " [ 0.         -0.09796835  0.16591259]\n",
      " [ 0.          0.20720191  0.08267704]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #48 | lambda learn rate = 0.0001\n",
      "Target = [[2.]\n",
      " [5.]]\n",
      "lambda end of trial = [[ 0.          0.50633176 -0.25070742]\n",
      " [ 0.          0.34343334 -0.17554186]\n",
      " [ 0.         -0.17095612  0.22323075]\n",
      " [ 0.         -0.11404461  0.16906531]\n",
      " [ 0.          0.17883113  0.00279931]\n",
      " [ 0.         -0.10451054  0.22950041]\n",
      " [ 0.         -0.06204621  0.12223018]\n",
      " [ 0.         -0.08693768  0.23401648]\n",
      " [ 0.         -0.09857272  0.16440166]\n",
      " [ 0.          0.20659147  0.08115092]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #49 | lambda learn rate = 0.0001\n",
      "Target = [[1.]\n",
      " [7.]]\n",
      "lambda end of trial = [[ 0.          0.50610378 -0.25230328]\n",
      " [ 0.          0.34322146 -0.17702506]\n",
      " [ 0.         -0.17118281  0.22164392]\n",
      " [ 0.         -0.11429074  0.16734246]\n",
      " [ 0.          0.17857372  0.00099743]\n",
      " [ 0.         -0.10475066  0.22781958]\n",
      " [ 0.         -0.06229638  0.12047898]\n",
      " [ 0.         -0.08720382  0.23215348]\n",
      " [ 0.         -0.09880263  0.16279226]\n",
      " [ 0.          0.20635623  0.07950423]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #50 | lambda learn rate = 0.0001\n",
      "Target = [[5.]\n",
      " [1.]]\n",
      "lambda end of trial = [[ 0.          0.50481364 -0.25256131]\n",
      " [ 0.          0.34185489 -0.17729837]\n",
      " [ 0.         -0.17268964  0.22134256]\n",
      " [ 0.         -0.1157357   0.16705347]\n",
      " [ 0.          0.17710104  0.0007029 ]\n",
      " [ 0.         -0.10628241  0.22751323]\n",
      " [ 0.         -0.06370376  0.1201975 ]\n",
      " [ 0.         -0.08888845  0.23181656]\n",
      " [ 0.         -0.10040552  0.16247168]\n",
      " [ 0.          0.20490773  0.07921453]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #51 | lambda learn rate = 0.0001\n",
      "Target = [[2.]\n",
      " [9.]]\n",
      "lambda end of trial = [[ 0.00000000e+00  5.04772427e-01 -2.52746759e-01]\n",
      " [ 0.00000000e+00  3.41845834e-01 -1.77339107e-01]\n",
      " [ 0.00000000e+00 -1.72731443e-01  2.21154425e-01]\n",
      " [ 0.00000000e+00 -1.15767673e-01  1.66909574e-01]\n",
      " [ 0.00000000e+00  1.77053826e-01  4.90418973e-04]\n",
      " [ 0.00000000e+00 -1.06329071e-01  2.27303281e-01]\n",
      " [ 0.00000000e+00 -6.37440286e-02  1.20016301e-01]\n",
      " [ 0.00000000e+00 -8.89475712e-02  2.31550492e-01]\n",
      " [ 0.00000000e+00 -1.00447047e-01  1.62284800e-01]\n",
      " [ 0.00000000e+00  2.04857913e-01  7.89903631e-02]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #52 | lambda learn rate = 0.0001\n",
      "Target = [[7.]\n",
      " [6.]]\n",
      "lambda end of trial = [[ 0.          0.50593548 -0.25174986]\n",
      " [ 0.          0.34292497 -0.17641413]\n",
      " [ 0.         -0.17154092  0.22217488]\n",
      " [ 0.         -0.11453718  0.16796428]\n",
      " [ 0.          0.17801088  0.00131075]\n",
      " [ 0.         -0.10538021  0.22811659]\n",
      " [ 0.         -0.06252918  0.1210576 ]\n",
      " [ 0.         -0.08786649  0.23247713]\n",
      " [ 0.         -0.09931467  0.16325541]\n",
      " [ 0.          0.2059564   0.07993192]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #53 | lambda learn rate = 0.0001\n",
      "Target = [[2.]\n",
      " [7.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda end of trial = [[ 0.00000000e+00  5.05655139e-01 -2.52731038e-01]\n",
      " [ 0.00000000e+00  3.42645951e-01 -1.77390703e-01]\n",
      " [ 0.00000000e+00 -1.71867305e-01  2.21032514e-01]\n",
      " [ 0.00000000e+00 -1.14810745e-01  1.67006804e-01]\n",
      " [ 0.00000000e+00  1.77697297e-01  2.13216709e-04]\n",
      " [ 0.00000000e+00 -1.05704046e-01  2.26983171e-01]\n",
      " [ 0.00000000e+00 -6.28558659e-02  1.19914187e-01]\n",
      " [ 0.00000000e+00 -8.82020423e-02  2.31302695e-01]\n",
      " [ 0.00000000e+00 -9.96536438e-02  1.62068994e-01]\n",
      " [ 0.00000000e+00  2.05616871e-01  7.87435693e-02]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #54 | lambda learn rate = 0.0001\n",
      "Target = [[9.]\n",
      " [7.]]\n",
      "lambda end of trial = [[ 0.          0.50859506 -0.25044443]\n",
      " [ 0.          0.34582849 -0.1749154 ]\n",
      " [ 0.         -0.16882879  0.2233958 ]\n",
      " [ 0.         -0.11191303  0.16926058]\n",
      " [ 0.          0.18085446  0.00266879]\n",
      " [ 0.         -0.10285915  0.22919587]\n",
      " [ 0.         -0.05984903  0.12225284]\n",
      " [ 0.         -0.08529548  0.23356336]\n",
      " [ 0.         -0.09649718  0.16452402]\n",
      " [ 0.          0.20829221  0.08082439]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #55 | lambda learn rate = 0.0001\n",
      "Target = [[4.]\n",
      " [6.]]\n",
      "lambda end of trial = [[ 0.          0.50815152 -0.25110975]\n",
      " [ 0.          0.34546962 -0.1754537 ]\n",
      " [ 0.         -0.16931127  0.22267208]\n",
      " [ 0.         -0.11236653  0.16858034]\n",
      " [ 0.          0.18043629  0.00204153]\n",
      " [ 0.         -0.10331628  0.22851017]\n",
      " [ 0.         -0.06025148  0.12164916]\n",
      " [ 0.         -0.08583992  0.23274669]\n",
      " [ 0.         -0.0969221   0.16388664]\n",
      " [ 0.          0.2078588   0.08017427]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #56 | lambda learn rate = 0.0001\n",
      "Target = [[3.]\n",
      " [1.]]\n",
      "lambda end of trial = [[ 0.          0.50703654 -0.25148141]\n",
      " [ 0.          0.34427202 -0.1758529 ]\n",
      " [ 0.         -0.17042164  0.22230196]\n",
      " [ 0.         -0.1134989   0.16820288]\n",
      " [ 0.          0.17928123  0.00165651]\n",
      " [ 0.         -0.10439579  0.22815033]\n",
      " [ 0.         -0.06136628  0.12127756]\n",
      " [ 0.         -0.08717944  0.23230019]\n",
      " [ 0.         -0.09803195  0.16351669]\n",
      " [ 0.          0.20673375  0.07979926]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #57 | lambda learn rate = 0.0001\n",
      "Target = [[8.]\n",
      " [1.]]\n",
      "lambda end of trial = [[ 0.          0.50628692 -0.25157511]\n",
      " [ 0.          0.34357783 -0.17593967]\n",
      " [ 0.         -0.17101855  0.22222734]\n",
      " [ 0.         -0.11419073  0.1681164 ]\n",
      " [ 0.          0.178591    0.00157023]\n",
      " [ 0.         -0.10514357  0.22805686]\n",
      " [ 0.         -0.06196017  0.12120332]\n",
      " [ 0.         -0.08789273  0.23221103]\n",
      " [ 0.         -0.0986836   0.16343523]\n",
      " [ 0.          0.20585936  0.07968996]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #58 | lambda learn rate = 0.0001\n",
      "Target = [[6.]\n",
      " [9.]]\n",
      "lambda end of trial = [[ 0.          0.50751621 -0.24973117]\n",
      " [ 0.          0.34481591 -0.17408255]\n",
      " [ 0.         -0.169725    0.22416768]\n",
      " [ 0.         -0.11291851  0.17002473]\n",
      " [ 0.          0.17978203  0.00335678]\n",
      " [ 0.         -0.10377194  0.23011431]\n",
      " [ 0.         -0.06057041  0.12328798]\n",
      " [ 0.         -0.08659364  0.23415965]\n",
      " [ 0.         -0.09750421  0.16520433]\n",
      " [ 0.          0.20712047  0.08158162]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #59 | lambda learn rate = 0.0001\n",
      "Target = [[8.]\n",
      " [0.]]\n",
      "lambda end of trial = [[ 0.          0.50606654 -0.24973117]\n",
      " [ 0.          0.34362523 -0.17408255]\n",
      " [ 0.         -0.17108014  0.22416768]\n",
      " [ 0.         -0.11428771  0.17002473]\n",
      " [ 0.          0.17837702  0.00335678]\n",
      " [ 0.         -0.10512763  0.23011431]\n",
      " [ 0.         -0.06198676  0.12328798]\n",
      " [ 0.         -0.08802513  0.23415965]\n",
      " [ 0.         -0.09898916  0.16520433]\n",
      " [ 0.          0.20553426  0.08158162]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #60 | lambda learn rate = 0.0001\n",
      "Target = [[7.]\n",
      " [8.]]\n",
      "lambda end of trial = [[ 0.          0.50747165 -0.24812534]\n",
      " [ 0.          0.3449267  -0.17259514]\n",
      " [ 0.         -0.16974793  0.2256902 ]\n",
      " [ 0.         -0.11297581  0.17152404]\n",
      " [ 0.          0.17987289  0.00506635]\n",
      " [ 0.         -0.10394194  0.23146939]\n",
      " [ 0.         -0.06064533  0.12482104]\n",
      " [ 0.         -0.08664907  0.23573229]\n",
      " [ 0.         -0.09757269  0.16682315]\n",
      " [ 0.          0.20676327  0.08298621]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #61 | lambda learn rate = 0.0001\n",
      "Target = [[9.]\n",
      " [8.]]\n",
      "lambda end of trial = [[ 0.          0.50990094 -0.24596597]\n",
      " [ 0.          0.34727141 -0.17051096]\n",
      " [ 0.         -0.16740972  0.22776861]\n",
      " [ 0.         -0.1104022   0.1738117 ]\n",
      " [ 0.          0.18209344  0.00704017]\n",
      " [ 0.         -0.10167192  0.23348718]\n",
      " [ 0.         -0.05841896  0.12680003]\n",
      " [ 0.         -0.08435847  0.23776838]\n",
      " [ 0.         -0.09528674  0.16885511]\n",
      " [ 0.          0.20925049  0.08519707]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #62 | lambda learn rate = 0.0001\n",
      "Target = [[9.]\n",
      " [7.]]\n",
      "lambda end of trial = [[ 0.          0.51105017 -0.24507213]\n",
      " [ 0.          0.34839978 -0.16963333]\n",
      " [ 0.         -0.16633831  0.22860193]\n",
      " [ 0.         -0.10923508  0.17471945]\n",
      " [ 0.          0.18319229  0.00789483]\n",
      " [ 0.         -0.10070918  0.23423598]\n",
      " [ 0.         -0.05739904  0.12759331]\n",
      " [ 0.         -0.08327762  0.23860904]\n",
      " [ 0.         -0.09423243  0.16967513]\n",
      " [ 0.          0.21026417  0.08598548]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #63 | lambda learn rate = 0.0001\n",
      "Target = [[1.]\n",
      " [1.]]\n",
      "lambda end of trial = [[ 0.          0.51038607 -0.24573622]\n",
      " [ 0.          0.34784462 -0.17018849]\n",
      " [ 0.         -0.16699268  0.22794756]\n",
      " [ 0.         -0.10986392  0.17409062]\n",
      " [ 0.          0.18256746  0.00727   ]\n",
      " [ 0.         -0.10139223  0.23355294]\n",
      " [ 0.         -0.05803536  0.12695699]\n",
      " [ 0.         -0.0838964   0.23799026]\n",
      " [ 0.         -0.09482297  0.16908459]\n",
      " [ 0.          0.20963287  0.08535419]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #64 | lambda learn rate = 0.0001\n",
      "Target = [[7.]\n",
      " [0.]]\n",
      "lambda end of trial = [[ 0.          0.50850959 -0.24573622]\n",
      " [ 0.          0.34606116 -0.17018849]\n",
      " [ 0.         -0.16898845  0.22794756]\n",
      " [ 0.         -0.11177559  0.17409062]\n",
      " [ 0.          0.18072075  0.00727   ]\n",
      " [ 0.         -0.10345078  0.23355294]\n",
      " [ 0.         -0.05982638  0.12695699]\n",
      " [ 0.         -0.08601736  0.23799026]\n",
      " [ 0.         -0.09684465  0.16908459]\n",
      " [ 0.          0.20746762  0.08535419]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #65 | lambda learn rate = 0.0001\n",
      "Target = [[6.]\n",
      " [3.]]\n",
      "lambda end of trial = [[ 0.          0.50745664 -0.24626269]\n",
      " [ 0.          0.34502806 -0.17070504]\n",
      " [ 0.         -0.17017477  0.22735439]\n",
      " [ 0.         -0.11269649  0.17363017]\n",
      " [ 0.          0.17959678  0.00670801]\n",
      " [ 0.         -0.10445     0.23305333]\n",
      " [ 0.         -0.06087406  0.12643315]\n",
      " [ 0.         -0.08715971  0.23741909]\n",
      " [ 0.         -0.09805434  0.16847974]\n",
      " [ 0.          0.20619496  0.08471786]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #66 | lambda learn rate = 0.0001\n",
      "Target = [[5.]\n",
      " [0.]]\n",
      "lambda end of trial = [[ 0.          0.50603473 -0.24626269]\n",
      " [ 0.          0.34348696 -0.17070504]\n",
      " [ 0.         -0.17178259  0.22735439]\n",
      " [ 0.         -0.11426352  0.17363017]\n",
      " [ 0.          0.17821828  0.00670801]\n",
      " [ 0.         -0.10622046  0.23305333]\n",
      " [ 0.         -0.06233881  0.12643315]\n",
      " [ 0.         -0.08876     0.23741909]\n",
      " [ 0.         -0.09957951  0.16847974]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [ 0.          0.20451493  0.08471786]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #67 | lambda learn rate = 0.0001\n",
      "Target = [[5.]\n",
      " [3.]]\n",
      "lambda end of trial = [[ 0.          0.50510707 -0.24681929]\n",
      " [ 0.          0.34243083 -0.17133872]\n",
      " [ 0.         -0.17279728  0.22674558]\n",
      " [ 0.         -0.1153445   0.17298158]\n",
      " [ 0.          0.17708832  0.00603004]\n",
      " [ 0.         -0.10740786  0.23234089]\n",
      " [ 0.         -0.06340184  0.12579533]\n",
      " [ 0.         -0.08984269  0.23676948]\n",
      " [ 0.         -0.10069901  0.16780804]\n",
      " [ 0.          0.20337009  0.08403095]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #68 | lambda learn rate = 0.0001\n",
      "Target = [[3.]\n",
      " [7.]]\n",
      "lambda end of trial = [[ 0.          0.50469751 -0.24777491]\n",
      " [ 0.          0.34205156 -0.17222369]\n",
      " [ 0.         -0.17321384  0.22577362]\n",
      " [ 0.         -0.11570387  0.17214304]\n",
      " [ 0.          0.17664334  0.00499174]\n",
      " [ 0.         -0.10784597  0.23131862]\n",
      " [ 0.         -0.06383193  0.12479178]\n",
      " [ 0.         -0.09034573  0.23559572]\n",
      " [ 0.         -0.10111749  0.1668316 ]\n",
      " [ 0.          0.20291884  0.08297805]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #69 | lambda learn rate = 0.0001\n",
      "Target = [[4.]\n",
      " [2.]]\n",
      "lambda end of trial = [[ 0.          0.50346097 -0.24839319]\n",
      " [ 0.          0.34072227 -0.17288834]\n",
      " [ 0.         -0.17450083  0.22513013]\n",
      " [ 0.         -0.11688583  0.17155206]\n",
      " [ 0.          0.17523826  0.0042892 ]\n",
      " [ 0.         -0.10926836  0.23060743]\n",
      " [ 0.         -0.06504803  0.12418373]\n",
      " [ 0.         -0.09181331  0.23486193]\n",
      " [ 0.         -0.10245387  0.16616341]\n",
      " [ 0.          0.20162047  0.08232887]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #70 | lambda learn rate = 0.0001\n",
      "Target = [[9.]\n",
      " [5.]]\n",
      "lambda end of trial = [[ 0.          0.50553016 -0.24724364]\n",
      " [ 0.          0.34296253 -0.17164375]\n",
      " [ 0.         -0.17232359  0.2263397 ]\n",
      " [ 0.         -0.11483097  0.17269365]\n",
      " [ 0.          0.17737215  0.0054747 ]\n",
      " [ 0.         -0.10716259  0.2317773 ]\n",
      " [ 0.         -0.06310875  0.1252611 ]\n",
      " [ 0.         -0.08972229  0.2360236 ]\n",
      " [ 0.         -0.10048896  0.16725503]\n",
      " [ 0.          0.20364176  0.08345181]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #71 | lambda learn rate = 0.0001\n",
      "Target = [[1.]\n",
      " [8.]]\n",
      "lambda end of trial = [[ 0.          0.50531449 -0.24896895]\n",
      " [ 0.          0.34271012 -0.17366304]\n",
      " [ 0.         -0.17261155  0.2240361 ]\n",
      " [ 0.         -0.11507265  0.17076019]\n",
      " [ 0.          0.17711225  0.00339556]\n",
      " [ 0.         -0.10743008  0.22963732]\n",
      " [ 0.         -0.06337007  0.12317054]\n",
      " [ 0.         -0.0899858   0.23391552]\n",
      " [ 0.         -0.10074905  0.16517424]\n",
      " [ 0.          0.20335426  0.08115182]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #72 | lambda learn rate = 0.0001\n",
      "Target = [[8.]\n",
      " [8.]]\n",
      "lambda end of trial = [[ 0.          0.50746201 -0.24682143]\n",
      " [ 0.          0.34458441 -0.17178875]\n",
      " [ 0.         -0.17032099  0.22632665]\n",
      " [ 0.         -0.1127921   0.17304074]\n",
      " [ 0.          0.17938181  0.00566512]\n",
      " [ 0.         -0.10509791  0.2319695 ]\n",
      " [ 0.         -0.06106996  0.12547065]\n",
      " [ 0.         -0.08781349  0.23608783]\n",
      " [ 0.         -0.0985811   0.16734219]\n",
      " [ 0.          0.20566226  0.08345982]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #73 | lambda learn rate = 0.0001\n",
      "Target = [[3.]\n",
      " [2.]]\n",
      "lambda end of trial = [[ 0.          0.5061307  -0.24770897]\n",
      " [ 0.          0.34330874 -0.1726392 ]\n",
      " [ 0.         -0.17151858  0.22552826]\n",
      " [ 0.         -0.1139145   0.17229247]\n",
      " [ 0.          0.17813154  0.0048316 ]\n",
      " [ 0.         -0.10650677  0.23103026]\n",
      " [ 0.         -0.06242319  0.12456849]\n",
      " [ 0.         -0.08909454  0.23523379]\n",
      " [ 0.         -0.09984032  0.16650271]\n",
      " [ 0.          0.20431831  0.08256386]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #74 | lambda learn rate = 0.0001\n",
      "Target = [[8.]\n",
      " [0.]]\n",
      "lambda end of trial = [[ 0.          0.50492868 -0.24770897]\n",
      " [ 0.          0.34233946 -0.1726392 ]\n",
      " [ 0.         -0.17267751  0.22552826]\n",
      " [ 0.         -0.11508736  0.17229247]\n",
      " [ 0.          0.17691785  0.0048316 ]\n",
      " [ 0.         -0.10786412  0.23103026]\n",
      " [ 0.         -0.06359719  0.12456849]\n",
      " [ 0.         -0.09039775  0.23523379]\n",
      " [ 0.         -0.10103524  0.16650271]\n",
      " [ 0.          0.20289036  0.08256386]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #75 | lambda learn rate = 0.0001\n",
      "Target = [[4.]\n",
      " [5.]]\n",
      "lambda end of trial = [[ 0.          0.50422223 -0.24859204]\n",
      " [ 0.          0.34169613 -0.17344337]\n",
      " [ 0.         -0.17333833  0.22470224]\n",
      " [ 0.         -0.11570787  0.17151685]\n",
      " [ 0.          0.17621446  0.00395237]\n",
      " [ 0.         -0.10865068  0.23004705]\n",
      " [ 0.         -0.06425466  0.12374665]\n",
      " [ 0.         -0.09104247  0.23442788]\n",
      " [ 0.         -0.1017718   0.165582  ]\n",
      " [ 0.          0.20210336  0.08158011]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #76 | lambda learn rate = 0.0001\n",
      "Target = [[2.]\n",
      " [5.]]\n",
      "lambda end of trial = [[ 0.          0.5035931  -0.25016486]\n",
      " [ 0.          0.34112545 -0.17487007]\n",
      " [ 0.         -0.17390496  0.22328566]\n",
      " [ 0.         -0.11627455  0.17010014]\n",
      " [ 0.          0.17561591  0.00245599]\n",
      " [ 0.         -0.10932289  0.22836654]\n",
      " [ 0.         -0.06483186  0.12230365]\n",
      " [ 0.         -0.09165945  0.23288543]\n",
      " [ 0.         -0.10236778  0.16409205]\n",
      " [ 0.          0.2015015   0.08007547]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #77 | lambda learn rate = 0.0001\n",
      "Target = [[4.]\n",
      " [0.]]\n",
      "lambda end of trial = [[ 0.          0.50184674 -0.25016486]\n",
      " [ 0.          0.33960494 -0.17487007]\n",
      " [ 0.         -0.17536023  0.22328566]\n",
      " [ 0.         -0.11780806  0.17010014]\n",
      " [ 0.          0.17403401  0.00245599]\n",
      " [ 0.         -0.1108903   0.22836654]\n",
      " [ 0.         -0.06641829  0.12230365]\n",
      " [ 0.         -0.09337822  0.23288543]\n",
      " [ 0.         -0.10393697  0.16409205]\n",
      " [ 0.          0.1997369   0.08007547]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #78 | lambda learn rate = 0.0001\n",
      "Target = [[8.]\n",
      " [4.]]\n",
      "lambda end of trial = [[ 0.          0.50306034 -0.24955806]\n",
      " [ 0.          0.34084387 -0.1742506 ]\n",
      " [ 0.         -0.17405564  0.22393796]\n",
      " [ 0.         -0.11657323  0.17071755]\n",
      " [ 0.          0.17526406  0.00307102]\n",
      " [ 0.         -0.1097116   0.22895589]\n",
      " [ 0.         -0.06510931  0.12295814]\n",
      " [ 0.         -0.09241796  0.23336557]\n",
      " [ 0.         -0.10270913  0.16470597]\n",
      " [ 0.          0.20093432  0.08067418]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #79 | lambda learn rate = 0.0001\n",
      "Target = [[1.]\n",
      " [6.]]\n",
      "lambda end of trial = [[ 0.          0.50270317 -0.25170111]\n",
      " [ 0.          0.34052128 -0.17618618]\n",
      " [ 0.         -0.17438674  0.22195136]\n",
      " [ 0.         -0.11692631  0.1685991 ]\n",
      " [ 0.          0.17494431  0.00115249]\n",
      " [ 0.         -0.11004284  0.22696841]\n",
      " [ 0.         -0.0654499   0.12091456]\n",
      " [ 0.         -0.09275236  0.23135916]\n",
      " [ 0.         -0.103033    0.16276275]\n",
      " [ 0.          0.20059607  0.07864468]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #80 | lambda learn rate = 0.0001\n",
      "Target = [[1.]\n",
      " [6.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda end of trial = [[ 0.00000000e+00  5.02484312e-01 -2.53014236e-01]\n",
      " [ 0.00000000e+00  3.40291704e-01 -1.77563604e-01]\n",
      " [ 0.00000000e+00 -1.74600125e-01  2.20671061e-01]\n",
      " [ 0.00000000e+00 -1.17162226e-01  1.67183582e-01]\n",
      " [ 0.00000000e+00  1.74721569e-01 -1.83929316e-04]\n",
      " [ 0.00000000e+00 -1.10278621e-01  2.25553738e-01]\n",
      " [ 0.00000000e+00 -6.56705423e-02  1.19590726e-01]\n",
      " [ 0.00000000e+00 -9.29837392e-02  2.29970883e-01]\n",
      " [ 0.00000000e+00 -1.03248245e-01  1.61471308e-01]\n",
      " [ 0.00000000e+00  2.00354402e-01  7.71946568e-02]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #81 | lambda learn rate = 0.0001\n",
      "Target = [[1.]\n",
      " [0.]]\n",
      "lambda end of trial = [[ 0.00000000e+00  5.01899703e-01 -2.53014236e-01]\n",
      " [ 0.00000000e+00  3.39708908e-01 -1.77563604e-01]\n",
      " [ 0.00000000e+00 -1.75200571e-01  2.20671061e-01]\n",
      " [ 0.00000000e+00 -1.17743189e-01  1.67183582e-01]\n",
      " [ 0.00000000e+00  1.74090704e-01 -1.83929316e-04]\n",
      " [ 0.00000000e+00 -1.10860294e-01  2.25553738e-01]\n",
      " [ 0.00000000e+00 -6.62898175e-02  1.19590726e-01]\n",
      " [ 0.00000000e+00 -9.35630486e-02  2.29970883e-01]\n",
      " [ 0.00000000e+00 -1.03810722e-01  1.61471308e-01]\n",
      " [ 0.00000000e+00  1.99836559e-01  7.71946568e-02]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #82 | lambda learn rate = 0.0001\n",
      "Target = [[6.]\n",
      " [9.]]\n",
      "lambda end of trial = [[ 0.          0.50382837 -0.25012123]\n",
      " [ 0.          0.34166313 -0.17463227]\n",
      " [ 0.         -0.17321568  0.2236484 ]\n",
      " [ 0.         -0.11597108  0.16984174]\n",
      " [ 0.          0.17605665  0.00276499]\n",
      " [ 0.         -0.1088195   0.22861492]\n",
      " [ 0.         -0.06429044  0.12258979]\n",
      " [ 0.         -0.09150232  0.23306198]\n",
      " [ 0.         -0.10201499  0.16416491]\n",
      " [ 0.          0.20162202  0.07987286]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #83 | lambda learn rate = 0.0001\n",
      "Target = [[3.]\n",
      " [4.]]\n",
      "lambda end of trial = [[ 0.          0.50313024 -0.25105208]\n",
      " [ 0.          0.34106445 -0.17543051]\n",
      " [ 0.         -0.17389865  0.22273777]\n",
      " [ 0.         -0.11669378  0.16887815]\n",
      " [ 0.          0.17531539  0.00177664]\n",
      " [ 0.         -0.10952863  0.22766943]\n",
      " [ 0.         -0.06488818  0.12179281]\n",
      " [ 0.         -0.09216475  0.23217874]\n",
      " [ 0.         -0.10273003  0.16321152]\n",
      " [ 0.          0.20093387  0.07895532]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #84 | lambda learn rate = 0.0001\n",
      "Target = [[1.]\n",
      " [1.]]\n",
      "lambda end of trial = [[ 0.          0.50254103 -0.25164128]\n",
      " [ 0.          0.34050762 -0.17598734]\n",
      " [ 0.         -0.17443745  0.22219897]\n",
      " [ 0.         -0.11726661  0.16830532]\n",
      " [ 0.          0.17472109  0.00118234]\n",
      " [ 0.         -0.11013433  0.22706372]\n",
      " [ 0.         -0.06543487  0.12124611]\n",
      " [ 0.         -0.09270531  0.23163818]\n",
      " [ 0.         -0.10331462  0.16262693]\n",
      " [ 0.          0.20034611  0.07836756]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #85 | lambda learn rate = 0.0001\n",
      "Target = [[4.]\n",
      " [6.]]\n",
      "lambda end of trial = [[ 0.          0.50253076 -0.25165669]\n",
      " [ 0.          0.34046729 -0.17604784]\n",
      " [ 0.         -0.17448973  0.22212055]\n",
      " [ 0.         -0.11730239  0.16825164]\n",
      " [ 0.          0.17462372  0.00103628]\n",
      " [ 0.         -0.11022538  0.22692715]\n",
      " [ 0.         -0.06548447  0.12117171]\n",
      " [ 0.         -0.09281085  0.23147987]\n",
      " [ 0.         -0.10337278  0.16253968]\n",
      " [ 0.          0.20022757  0.07818974]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #86 | lambda learn rate = 0.0001\n",
      "Target = [[0.]\n",
      " [4.]]\n",
      "lambda end of trial = [[ 0.          0.50253076 -0.25350438]\n",
      " [ 0.          0.34046729 -0.17766283]\n",
      " [ 0.         -0.17448973  0.22015345]\n",
      " [ 0.         -0.11730239  0.16637192]\n",
      " [ 0.          0.17462372 -0.00081668]\n",
      " [ 0.         -0.11022538  0.2252601 ]\n",
      " [ 0.         -0.06548447  0.11945561]\n",
      " [ 0.         -0.09281085  0.22978146]\n",
      " [ 0.         -0.10337278  0.16098644]\n",
      " [ 0.          0.20022757  0.07615167]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #87 | lambda learn rate = 0.0001\n",
      "Target = [[3.]\n",
      " [3.]]\n",
      "lambda end of trial = [[ 0.          0.50171702 -0.25431812]\n",
      " [ 0.          0.33971699 -0.17841313]\n",
      " [ 0.         -0.1752313   0.21941188]\n",
      " [ 0.         -0.11811256  0.16556175]\n",
      " [ 0.          0.17380185 -0.00163854]\n",
      " [ 0.         -0.11099995  0.22448553]\n",
      " [ 0.         -0.06628674  0.11865333]\n",
      " [ 0.         -0.0937122   0.22888011]\n",
      " [ 0.         -0.10419871  0.16016051]\n",
      " [ 0.          0.1993902   0.0753143 ]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #88 | lambda learn rate = 0.0001\n",
      "Target = [[2.]\n",
      " [4.]]\n",
      "lambda end of trial = [[ 0.          0.50118487 -0.25538242]\n",
      " [ 0.          0.33916577 -0.17951556]\n",
      " [ 0.         -0.17575602  0.21836243]\n",
      " [ 0.         -0.11866902  0.16444884]\n",
      " [ 0.          0.17317498 -0.00289229]\n",
      " [ 0.         -0.11162254  0.22324035]\n",
      " [ 0.         -0.06681807  0.11759067]\n",
      " [ 0.         -0.09433268  0.22763914]\n",
      " [ 0.         -0.10474495  0.15906804]\n",
      " [ 0.          0.19871255  0.07395901]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #89 | lambda learn rate = 0.0001\n",
      "Target = [[5.]\n",
      " [0.]]\n",
      "lambda end of trial = [[ 0.          0.49979321 -0.25538242]\n",
      " [ 0.          0.33794776 -0.17951556]\n",
      " [ 0.         -0.17706037  0.21836243]\n",
      " [ 0.         -0.12007156  0.16444884]\n",
      " [ 0.          0.17171822 -0.00289229]\n",
      " [ 0.         -0.11300014  0.22324035]\n",
      " [ 0.         -0.06804122  0.11759067]\n",
      " [ 0.         -0.09566206  0.22763914]\n",
      " [ 0.         -0.10617829  0.15906804]\n",
      " [ 0.          0.197311    0.07395901]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #90 | lambda learn rate = 0.0001\n",
      "Target = [[0.]\n",
      " [3.]]\n",
      "lambda end of trial = [[ 0.          0.49979321 -0.25684457]\n",
      " [ 0.          0.33794776 -0.18108298]\n",
      " [ 0.         -0.17706037  0.21685527]\n",
      " [ 0.         -0.12007156  0.16293483]\n",
      " [ 0.          0.17171822 -0.0044381 ]\n",
      " [ 0.         -0.11300014  0.22160046]\n",
      " [ 0.         -0.06804122  0.11613146]\n",
      " [ 0.         -0.09566206  0.22599404]\n",
      " [ 0.         -0.10617829  0.15762163]\n",
      " [ 0.          0.197311    0.07246267]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #91 | lambda learn rate = 0.0001\n",
      "Target = [[6.]\n",
      " [7.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda end of trial = [[ 0.          0.5017624  -0.25454719]\n",
      " [ 0.          0.33973167 -0.17900175]\n",
      " [ 0.         -0.17502966  0.21922442]\n",
      " [ 0.         -0.11824854  0.16506168]\n",
      " [ 0.          0.17341431 -0.00245932]\n",
      " [ 0.         -0.11132056  0.22355997]\n",
      " [ 0.         -0.06612719  0.11836449]\n",
      " [ 0.         -0.09373516  0.22824208]\n",
      " [ 0.         -0.10431967  0.15979002]\n",
      " [ 0.          0.19902044  0.07445701]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #92 | lambda learn rate = 0.0001\n",
      "Target = [[2.]\n",
      " [5.]]\n",
      "lambda end of trial = [[ 0.          0.50133376 -0.2556188 ]\n",
      " [ 0.          0.33927312 -0.18014813]\n",
      " [ 0.         -0.17543442  0.21821253]\n",
      " [ 0.         -0.11868041  0.163982  ]\n",
      " [ 0.          0.17295104 -0.00361751]\n",
      " [ 0.         -0.111794    0.22237637]\n",
      " [ 0.         -0.06651071  0.1174057 ]\n",
      " [ 0.         -0.09419263  0.22709842]\n",
      " [ 0.         -0.10476363  0.15868013]\n",
      " [ 0.          0.19854795  0.0732758 ]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #93 | lambda learn rate = 0.0001\n",
      "Target = [[6.]\n",
      " [2.]]\n",
      "lambda end of trial = [[ 0.          0.50098002 -0.25573671]\n",
      " [ 0.          0.33894815 -0.18025645]\n",
      " [ 0.         -0.17576014  0.21810396]\n",
      " [ 0.         -0.11898541  0.16388034]\n",
      " [ 0.          0.17259211 -0.00373715]\n",
      " [ 0.         -0.11211876  0.22226811]\n",
      " [ 0.         -0.06686759  0.11728674]\n",
      " [ 0.         -0.09451961  0.22698942]\n",
      " [ 0.         -0.10514616  0.15855262]\n",
      " [ 0.          0.19802507  0.07310151]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #94 | lambda learn rate = 0.0001\n",
      "Target = [[6.]\n",
      " [0.]]\n",
      "lambda end of trial = [[ 0.          0.49979681 -0.25573671]\n",
      " [ 0.          0.3377391  -0.18025645]\n",
      " [ 0.         -0.1769624   0.21810396]\n",
      " [ 0.         -0.12013215  0.16388034]\n",
      " [ 0.          0.17127527 -0.00373715]\n",
      " [ 0.         -0.11335985  0.22226811]\n",
      " [ 0.         -0.06792289  0.11728674]\n",
      " [ 0.         -0.09573601  0.22698942]\n",
      " [ 0.         -0.10627183  0.15855262]\n",
      " [ 0.          0.19662708  0.07310151]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #95 | lambda learn rate = 0.0001\n",
      "Target = [[4.]\n",
      " [4.]]\n",
      "lambda end of trial = [[ 0.          0.49952868 -0.25600484]\n",
      " [ 0.          0.33752537 -0.18047019]\n",
      " [ 0.         -0.17719003  0.21787633]\n",
      " [ 0.         -0.1203789   0.16363359]\n",
      " [ 0.          0.17103626 -0.00397616]\n",
      " [ 0.         -0.11363295  0.22199501]\n",
      " [ 0.         -0.06809973  0.11710991]\n",
      " [ 0.         -0.09606323  0.2266622 ]\n",
      " [ 0.         -0.10646565  0.15835881]\n",
      " [ 0.          0.19628369  0.07275812]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #96 | lambda learn rate = 0.0001\n",
      "Target = [[2.]\n",
      " [8.]]\n",
      "lambda end of trial = [[ 0.          0.49960041 -0.25571791]\n",
      " [ 0.          0.33762151 -0.1800856 ]\n",
      " [ 0.         -0.17709959  0.2182381 ]\n",
      " [ 0.         -0.12028645  0.1640034 ]\n",
      " [ 0.          0.17111096 -0.00367737]\n",
      " [ 0.         -0.11355854  0.22229266]\n",
      " [ 0.         -0.06801313  0.11745628]\n",
      " [ 0.         -0.09601133  0.22686981]\n",
      " [ 0.         -0.10640036  0.15861997]\n",
      " [ 0.          0.19633457  0.07296162]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #97 | lambda learn rate = 0.0001\n",
      "Target = [[1.]\n",
      " [6.]]\n",
      "lambda end of trial = [[ 0.          0.49939228 -0.2569667 ]\n",
      " [ 0.          0.33741618 -0.18131761]\n",
      " [ 0.         -0.17728759  0.21711008]\n",
      " [ 0.         -0.12045928  0.16296637]\n",
      " [ 0.          0.1709131  -0.0048645 ]\n",
      " [ 0.         -0.11375268  0.2211278 ]\n",
      " [ 0.         -0.06818828  0.11640541]\n",
      " [ 0.         -0.09619368  0.22577571]\n",
      " [ 0.         -0.10659124  0.15747466]\n",
      " [ 0.          0.19614275  0.07181073]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #98 | lambda learn rate = 0.0001\n",
      "Target = [[6.]\n",
      " [8.]]\n",
      "lambda end of trial = [[ 0.          0.50175239 -0.25381989]\n",
      " [ 0.          0.33984166 -0.17808363]\n",
      " [ 0.         -0.17491523  0.22027323]\n",
      " [ 0.         -0.11817875  0.16600709]\n",
      " [ 0.          0.17343046 -0.00150803]\n",
      " [ 0.         -0.11154956  0.2240653 ]\n",
      " [ 0.         -0.06571853  0.1196984 ]\n",
      " [ 0.         -0.09393414  0.22878842]\n",
      " [ 0.         -0.10418874  0.16067799]\n",
      " [ 0.          0.19853174  0.07499605]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "+++++++++++++++++++++++++++++++++++\n",
      "Session #5\n",
      "target at trial 0 = [[1.]\n",
      " [1.]]\n",
      "K MATX INIT= [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "A VECT INIT = [-0. -0.]\n",
      "lambda\n",
      "[[ 0.          0.53020654 -0.2322202 ]\n",
      " [ 0.          0.36705474 -0.15737009]\n",
      " [ 0.         -0.14629582  0.24261404]\n",
      " [ 0.         -0.08877213  0.18799136]\n",
      " [ 0.          0.20486852  0.02360278]\n",
      " [ 0.         -0.07854344  0.25002723]\n",
      " [ 0.         -0.03748972  0.14111247]\n",
      " [ 0.         -0.0597867   0.25435404]\n",
      " [ 0.         -0.07409235  0.18348285]\n",
      " [ 0.          0.23653843  0.10488391]]\n",
      "a\n",
      "[-0. -0.]\n",
      "K\n",
      "[[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #0 | lambda learn rate = 0.0001\n",
      "Target = [[1.]\n",
      " [1.]]\n",
      "lambda end of trial = [[ 0.          0.52960768 -0.23281906]\n",
      " [ 0.          0.36643869 -0.15798614]\n",
      " [ 0.         -0.14690886  0.242001  ]\n",
      " [ 0.         -0.08939992  0.18736357]\n",
      " [ 0.          0.20422596  0.02296021]\n",
      " [ 0.         -0.07919526  0.24937541]\n",
      " [ 0.         -0.0381558   0.14044639]\n",
      " [ 0.         -0.0604424   0.25369833]\n",
      " [ 0.         -0.07473481  0.1828404 ]\n",
      " [ 0.          0.23593339  0.10427888]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #1 | lambda learn rate = 0.0001\n",
      "Target = [[1.]\n",
      " [0.]]\n",
      "lambda end of trial = [[ 0.          0.52893896 -0.23281906]\n",
      " [ 0.          0.3657845  -0.15798614]\n",
      " [ 0.         -0.1475454   0.242001  ]\n",
      " [ 0.         -0.09004198  0.18736357]\n",
      " [ 0.          0.20365651  0.02296021]\n",
      " [ 0.         -0.07990399  0.24937541]\n",
      " [ 0.         -0.03874118  0.14044639]\n",
      " [ 0.         -0.06104248  0.25369833]\n",
      " [ 0.         -0.07531347  0.1828404 ]\n",
      " [ 0.          0.2352921   0.10427888]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #2 | lambda learn rate = 0.0001\n",
      "Target = [[5.]\n",
      " [1.]]\n",
      "lambda end of trial = [[ 0.          0.52552939 -0.23350097]\n",
      " [ 0.          0.36238232 -0.15866658]\n",
      " [ 0.         -0.15098562  0.24131296]\n",
      " [ 0.         -0.09320885  0.18673019]\n",
      " [ 0.          0.20025094  0.0222791 ]\n",
      " [ 0.         -0.08339471  0.24867727]\n",
      " [ 0.         -0.04192631  0.13980937]\n",
      " [ 0.         -0.06496466  0.2529139 ]\n",
      " [ 0.         -0.07893171  0.18211675]\n",
      " [ 0.          0.23179247  0.10357895]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #3 | lambda learn rate = 0.0001\n",
      "Target = [[6.]\n",
      " [4.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda end of trial = [[ 0.          0.52207899 -0.23580124]\n",
      " [ 0.          0.35906002 -0.16088145]\n",
      " [ 0.         -0.1544624   0.23899511]\n",
      " [ 0.         -0.09638099  0.18461543]\n",
      " [ 0.          0.19704933  0.02014469]\n",
      " [ 0.         -0.08681406  0.2463977 ]\n",
      " [ 0.         -0.04520592  0.13762296]\n",
      " [ 0.         -0.06841852  0.25061132]\n",
      " [ 0.         -0.08226935  0.17989165]\n",
      " [ 0.          0.22843785  0.10134253]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #4 | lambda learn rate = 0.0001\n",
      "Target = [[8.]\n",
      " [4.]]\n",
      "lambda end of trial = [[ 0.          0.51844728 -0.2376171 ]\n",
      " [ 0.          0.35480789 -0.16300751]\n",
      " [ 0.         -0.15806524  0.23719369]\n",
      " [ 0.         -0.10039866  0.1826066 ]\n",
      " [ 0.          0.19299476  0.01811741]\n",
      " [ 0.         -0.09086874  0.24437036]\n",
      " [ 0.         -0.049097    0.13567742]\n",
      " [ 0.         -0.07249801  0.24857158]\n",
      " [ 0.         -0.08602274  0.17801496]\n",
      " [ 0.          0.22448177  0.09936449]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #5 | lambda learn rate = 0.0001\n",
      "Target = [[8.]\n",
      " [5.]]\n",
      "lambda end of trial = [[ 0.          0.51547701 -0.23947351]\n",
      " [ 0.          0.35184877 -0.16485696]\n",
      " [ 0.         -0.16091106  0.23541505]\n",
      " [ 0.         -0.10316504  0.18087761]\n",
      " [ 0.          0.19004709  0.01627511]\n",
      " [ 0.         -0.09365014  0.24263198]\n",
      " [ 0.         -0.05180895  0.13398245]\n",
      " [ 0.         -0.0754718   0.24671296]\n",
      " [ 0.         -0.088658    0.17636792]\n",
      " [ 0.          0.22157002  0.09754465]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #6 | lambda learn rate = 0.0001\n",
      "Target = [[8.]\n",
      " [4.]]\n",
      "lambda end of trial = [[ 0.          0.51325503 -0.24058451]\n",
      " [ 0.          0.34971798 -0.16592236]\n",
      " [ 0.         -0.16323325  0.23425395]\n",
      " [ 0.         -0.10544752  0.17973637]\n",
      " [ 0.          0.18787429  0.01518871]\n",
      " [ 0.         -0.09595205  0.24148103]\n",
      " [ 0.         -0.05408576  0.13284405]\n",
      " [ 0.         -0.07792897  0.24548438]\n",
      " [ 0.         -0.09079633  0.17529876]\n",
      " [ 0.          0.21915218  0.09633573]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #7 | lambda learn rate = 0.0001\n",
      "Target = [[4.]\n",
      " [6.]]\n",
      "lambda end of trial = [[ 0.          0.5117175  -0.2428908 ]\n",
      " [ 0.          0.34818894 -0.16821591]\n",
      " [ 0.         -0.16501068  0.23158781]\n",
      " [ 0.         -0.10698255  0.17743382]\n",
      " [ 0.          0.18622181  0.01270999]\n",
      " [ 0.         -0.09742567  0.2392706 ]\n",
      " [ 0.         -0.05571737  0.13039664]\n",
      " [ 0.         -0.07961097  0.24296138]\n",
      " [ 0.         -0.09237488  0.17293093]\n",
      " [ 0.          0.21740535  0.09371548]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #8 | lambda learn rate = 0.0001\n",
      "Target = [[9.]\n",
      " [1.]]\n",
      "lambda end of trial = [[ 0.          0.50992059 -0.24309045]\n",
      " [ 0.          0.3464865  -0.16840507]\n",
      " [ 0.         -0.16684844  0.23138362]\n",
      " [ 0.         -0.10864799  0.17724877]\n",
      " [ 0.          0.18426675  0.01249276]\n",
      " [ 0.         -0.09915712  0.23907822]\n",
      " [ 0.         -0.05740983  0.13020858]\n",
      " [ 0.         -0.08157884  0.24274273]\n",
      " [ 0.         -0.09415004  0.17273369]\n",
      " [ 0.          0.21547674  0.09350119]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #9 | lambda learn rate = 0.0001\n",
      "Target = [[2.]\n",
      " [3.]]\n",
      "lambda end of trial = [[ 0.          0.50895887 -0.24453304]\n",
      " [ 0.          0.3455774  -0.16976872]\n",
      " [ 0.         -0.16778129  0.22998434]\n",
      " [ 0.         -0.10970628  0.17566134]\n",
      " [ 0.          0.1833137   0.01106319]\n",
      " [ 0.         -0.10018729  0.23753296]\n",
      " [ 0.         -0.05831809  0.1288462 ]\n",
      " [ 0.         -0.08260539  0.24120291]\n",
      " [ 0.         -0.09513967  0.17124924]\n",
      " [ 0.          0.21438069  0.09185712]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #10 | lambda learn rate = 0.0001\n",
      "Target = [[6.]\n",
      " [8.]]\n",
      "lambda end of trial = [[ 0.          0.50838529 -0.24529782]\n",
      " [ 0.          0.3450075  -0.17052858]\n",
      " [ 0.         -0.16829994  0.22929281]\n",
      " [ 0.         -0.11029093  0.17488181]\n",
      " [ 0.          0.18272698  0.0102809 ]\n",
      " [ 0.         -0.10083892  0.23666412]\n",
      " [ 0.         -0.0588849   0.12809046]\n",
      " [ 0.         -0.08328062  0.2403026 ]\n",
      " [ 0.         -0.09579024  0.17038182]\n",
      " [ 0.          0.21367995  0.09092279]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #11 | lambda learn rate = 0.0001\n",
      "Target = [[1.]\n",
      " [5.]]\n",
      "lambda end of trial = [[ 0.          0.50792609 -0.24759378]\n",
      " [ 0.          0.34452045 -0.17296385]\n",
      " [ 0.         -0.16876257  0.22697968]\n",
      " [ 0.         -0.11077104  0.17248122]\n",
      " [ 0.          0.18227709  0.00803146]\n",
      " [ 0.         -0.10133238  0.23419683]\n",
      " [ 0.         -0.05935252  0.12575234]\n",
      " [ 0.         -0.0837503   0.23795422]\n",
      " [ 0.         -0.09628897  0.16788814]\n",
      " [ 0.          0.21316716  0.08835889]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #12 | lambda learn rate = 0.0001\n",
      "Target = [[4.]\n",
      " [6.]]\n",
      "lambda end of trial = [[ 0.          0.50696144 -0.24904076]\n",
      " [ 0.          0.34356933 -0.17439052]\n",
      " [ 0.         -0.16964201  0.22566052]\n",
      " [ 0.         -0.11161612  0.17121361]\n",
      " [ 0.          0.18130296  0.00657026]\n",
      " [ 0.         -0.10236717  0.23264464]\n",
      " [ 0.         -0.06031061  0.12431521]\n",
      " [ 0.         -0.08469861  0.23653174]\n",
      " [ 0.         -0.09719628  0.16652717]\n",
      " [ 0.          0.21213434  0.08680966]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #13 | lambda learn rate = 0.0001\n",
      "Target = [[2.]\n",
      " [1.]]\n",
      "lambda end of trial = [[ 0.          0.50583959 -0.24960169]\n",
      " [ 0.          0.342515   -0.17491768]\n",
      " [ 0.         -0.17083559  0.22506373]\n",
      " [ 0.         -0.1127614   0.17064097]\n",
      " [ 0.          0.18018904  0.0060133 ]\n",
      " [ 0.         -0.10347874  0.23208886]\n",
      " [ 0.         -0.06140094  0.12377005]\n",
      " [ 0.         -0.08593206  0.23591502]\n",
      " [ 0.         -0.09834912  0.16595075]\n",
      " [ 0.          0.21096705  0.08622601]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #14 | lambda learn rate = 0.0001\n",
      "Target = [[1.]\n",
      " [9.]]\n",
      "lambda end of trial = [[ 0.          0.50561082 -0.25166068]\n",
      " [ 0.          0.3422954  -0.17689414]\n",
      " [ 0.         -0.17107827  0.22287962]\n",
      " [ 0.         -0.1129745   0.16872308]\n",
      " [ 0.          0.17993807  0.00375461]\n",
      " [ 0.         -0.103702    0.2300796 ]\n",
      " [ 0.         -0.06164566  0.12156753]\n",
      " [ 0.         -0.08615109  0.23394369]\n",
      " [ 0.         -0.09859995  0.16369335]\n",
      " [ 0.          0.21070626  0.08387883]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #15 | lambda learn rate = 0.0001\n",
      "Target = [[8.]\n",
      " [4.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda end of trial = [[ 0.          0.50587683 -0.25152767]\n",
      " [ 0.          0.34265136 -0.17671616]\n",
      " [ 0.         -0.17072227  0.22305762]\n",
      " [ 0.         -0.11266578  0.16887744]\n",
      " [ 0.          0.18019879  0.00388497]\n",
      " [ 0.         -0.10346142  0.23019988]\n",
      " [ 0.         -0.06135236  0.12171418]\n",
      " [ 0.         -0.08596191  0.23403828]\n",
      " [ 0.         -0.09836954  0.16380855]\n",
      " [ 0.          0.21090222  0.08397681]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #16 | lambda learn rate = 0.0001\n",
      "Target = [[1.]\n",
      " [8.]]\n",
      "lambda end of trial = [[ 0.          0.50566883 -0.25319163]\n",
      " [ 0.          0.34244566 -0.17836178]\n",
      " [ 0.         -0.17093166  0.2213825 ]\n",
      " [ 0.         -0.11286316  0.16729841]\n",
      " [ 0.          0.17999528  0.00225692]\n",
      " [ 0.         -0.10369967  0.2282939 ]\n",
      " [ 0.         -0.06155808  0.12006841]\n",
      " [ 0.         -0.08618172  0.2322798 ]\n",
      " [ 0.         -0.09855844  0.16229735]\n",
      " [ 0.          0.21067584  0.08216577]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #17 | lambda learn rate = 0.0001\n",
      "Target = [[9.]\n",
      " [4.]]\n",
      "lambda end of trial = [[ 0.          0.50672238 -0.25272339]\n",
      " [ 0.          0.34355262 -0.1778698 ]\n",
      " [ 0.         -0.16990132  0.22184042]\n",
      " [ 0.         -0.11179977  0.16777103]\n",
      " [ 0.          0.18105902  0.00272969]\n",
      " [ 0.         -0.1027462   0.22871767]\n",
      " [ 0.         -0.06056568  0.12050948]\n",
      " [ 0.         -0.08514936  0.23273862]\n",
      " [ 0.         -0.09758615  0.16272948]\n",
      " [ 0.          0.21167584  0.08261021]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #18 | lambda learn rate = 0.0001\n",
      "Target = [[5.]\n",
      " [6.]]\n",
      "lambda end of trial = [[ 0.          0.50650741 -0.25298135]\n",
      " [ 0.          0.34335334 -0.17810893]\n",
      " [ 0.         -0.17019986  0.22148217]\n",
      " [ 0.         -0.11202933  0.16749556]\n",
      " [ 0.          0.18080931  0.00243003]\n",
      " [ 0.         -0.10303272  0.22837384]\n",
      " [ 0.         -0.06073136  0.12031067]\n",
      " [ 0.         -0.08540067  0.23243705]\n",
      " [ 0.         -0.09783957  0.16242537]\n",
      " [ 0.          0.21134468  0.08221282]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #19 | lambda learn rate = 0.0001\n",
      "Target = [[5.]\n",
      " [3.]]\n",
      "lambda end of trial = [[ 0.          0.50576745 -0.25342533]\n",
      " [ 0.          0.34268931 -0.17850735]\n",
      " [ 0.         -0.17093638  0.22104026]\n",
      " [ 0.         -0.1127879   0.16704041]\n",
      " [ 0.          0.18010921  0.00200997]\n",
      " [ 0.         -0.103807    0.22790927]\n",
      " [ 0.         -0.06154014  0.11982539]\n",
      " [ 0.         -0.08616033  0.23198126]\n",
      " [ 0.         -0.09860116  0.16196842]\n",
      " [ 0.          0.21049165  0.081701  ]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #20 | lambda learn rate = 0.0001\n",
      "Target = [[1.]\n",
      " [2.]]\n",
      "lambda end of trial = [[ 0.          0.50527318 -0.25441387]\n",
      " [ 0.          0.34216953 -0.17954691]\n",
      " [ 0.         -0.17149155  0.21992994]\n",
      " [ 0.         -0.11331968  0.16597685]\n",
      " [ 0.          0.17956979  0.00093114]\n",
      " [ 0.         -0.10439197  0.22673933]\n",
      " [ 0.         -0.06205997  0.11878573]\n",
      " [ 0.         -0.0867772   0.23074751]\n",
      " [ 0.         -0.0991584   0.16085394]\n",
      " [ 0.          0.20992598  0.08056967]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #21 | lambda learn rate = 0.0001\n",
      "Target = [[0.]\n",
      " [1.]]\n",
      "lambda end of trial = [[ 0.00000000e+00  5.05273177e-01 -2.55013586e-01]\n",
      " [ 0.00000000e+00  3.42169532e-01 -1.80186718e-01]\n",
      " [ 0.00000000e+00 -1.71491547e-01  2.19298441e-01]\n",
      " [ 0.00000000e+00 -1.13319680e-01  1.65339157e-01]\n",
      " [ 0.00000000e+00  1.79569793e-01  2.30195666e-04]\n",
      " [ 0.00000000e+00 -1.04391968e-01  2.26089863e-01]\n",
      " [ 0.00000000e+00 -6.20599744e-02  1.18118665e-01]\n",
      " [ 0.00000000e+00 -8.67772045e-02  2.30039268e-01]\n",
      " [ 0.00000000e+00 -9.91583974e-02  1.60254511e-01]\n",
      " [ 0.00000000e+00  2.09925985e-01  7.99062587e-02]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #22 | lambda learn rate = 0.0001\n",
      "Target = [[0.]\n",
      " [1.]]\n",
      "lambda end of trial = [[ 0.00000000e+00  5.05273177e-01 -2.55679003e-01]\n",
      " [ 0.00000000e+00  3.42169532e-01 -1.80761281e-01]\n",
      " [ 0.00000000e+00 -1.71491547e-01  2.18646218e-01]\n",
      " [ 0.00000000e+00 -1.13319680e-01  1.64681109e-01]\n",
      " [ 0.00000000e+00  1.79569793e-01 -4.26022531e-04]\n",
      " [ 0.00000000e+00 -1.04391968e-01  2.25503826e-01]\n",
      " [ 0.00000000e+00 -6.20599744e-02  1.17499766e-01]\n",
      " [ 0.00000000e+00 -8.67772045e-02  2.29410570e-01]\n",
      " [ 0.00000000e+00 -9.91583974e-02  1.59679877e-01]\n",
      " [ 0.00000000e+00  2.09925985e-01  7.92636384e-02]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #23 | lambda learn rate = 0.0001\n",
      "Target = [[8.]\n",
      " [0.]]\n",
      "lambda end of trial = [[ 0.00000000e+00  5.04145486e-01 -2.55679003e-01]\n",
      " [ 0.00000000e+00  3.41289848e-01 -1.80761281e-01]\n",
      " [ 0.00000000e+00 -1.72612436e-01  2.18646218e-01]\n",
      " [ 0.00000000e+00 -1.14521421e-01  1.64681109e-01]\n",
      " [ 0.00000000e+00  1.78542033e-01 -4.26022531e-04]\n",
      " [ 0.00000000e+00 -1.05566152e-01  2.25503826e-01]\n",
      " [ 0.00000000e+00 -6.32655149e-02  1.17499766e-01]\n",
      " [ 0.00000000e+00 -8.79411065e-02  2.29410570e-01]\n",
      " [ 0.00000000e+00 -1.00134626e-01  1.59679877e-01]\n",
      " [ 0.00000000e+00  2.08777978e-01  7.92636384e-02]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #24 | lambda learn rate = 0.0001\n",
      "Target = [[7.]\n",
      " [7.]]\n",
      "lambda end of trial = [[ 0.          0.5056797  -0.25414479]\n",
      " [ 0.          0.34272543 -0.1793257 ]\n",
      " [ 0.         -0.17118713  0.22007152]\n",
      " [ 0.         -0.11309604  0.16610649]\n",
      " [ 0.          0.17993284  0.00096478]\n",
      " [ 0.         -0.10407441  0.22699557]\n",
      " [ 0.         -0.06162535  0.11913993]\n",
      " [ 0.         -0.08636148  0.2309902 ]\n",
      " [ 0.         -0.0986946   0.1611199 ]\n",
      " [ 0.          0.2101747   0.08066036]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #25 | lambda learn rate = 0.0001\n",
      "Target = [[0.]\n",
      " [3.]]\n",
      "lambda end of trial = [[ 0.00000000e+00  5.05679700e-01 -2.55419971e-01]\n",
      " [ 0.00000000e+00  3.42725429e-01 -1.80544578e-01]\n",
      " [ 0.00000000e+00 -1.71187130e-01  2.18745098e-01]\n",
      " [ 0.00000000e+00 -1.13096039e-01  1.64719105e-01]\n",
      " [ 0.00000000e+00  1.79932839e-01 -4.05856883e-04]\n",
      " [ 0.00000000e+00 -1.04074412e-01  2.25521222e-01]\n",
      " [ 0.00000000e+00 -6.16253539e-02  1.17740536e-01]\n",
      " [ 0.00000000e+00 -8.63614791e-02  2.29564583e-01]\n",
      " [ 0.00000000e+00 -9.86946024e-02  1.59753670e-01]\n",
      " [ 0.00000000e+00  2.10174696e-01  7.92656910e-02]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #26 | lambda learn rate = 0.0001\n",
      "Target = [[3.]\n",
      " [5.]]\n",
      "lambda end of trial = [[ 0.          0.50516674 -0.25627491]\n",
      " [ 0.          0.34220954 -0.18140439]\n",
      " [ 0.         -0.17167126  0.21793821]\n",
      " [ 0.         -0.1136554   0.16378684]\n",
      " [ 0.          0.17939495 -0.00130233]\n",
      " [ 0.         -0.10456171  0.22470906]\n",
      " [ 0.         -0.06212091  0.1169146 ]\n",
      " [ 0.         -0.08692961  0.22861769]\n",
      " [ 0.         -0.09925115  0.15882609]\n",
      " [ 0.          0.20952956  0.07819046]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #27 | lambda learn rate = 0.0001\n",
      "Target = [[8.]\n",
      " [5.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda end of trial = [[ 0.          0.50643108 -0.2554847 ]\n",
      " [ 0.          0.34368978 -0.18047924]\n",
      " [ 0.         -0.17037167  0.21875045]\n",
      " [ 0.         -0.11225404  0.16466269]\n",
      " [ 0.          0.18054092 -0.0005861 ]\n",
      " [ 0.         -0.10333724  0.22547435]\n",
      " [ 0.         -0.06076932  0.11775935]\n",
      " [ 0.         -0.08544755  0.22954398]\n",
      " [ 0.         -0.09789084  0.15967628]\n",
      " [ 0.          0.21073188  0.07894191]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #28 | lambda learn rate = 0.0001\n",
      "Target = [[3.]\n",
      " [5.]]\n",
      "lambda end of trial = [[ 0.          0.50591526 -0.25634439]\n",
      " [ 0.          0.34323953 -0.18122967]\n",
      " [ 0.         -0.17092695  0.217825  ]\n",
      " [ 0.         -0.11272893  0.1638712 ]\n",
      " [ 0.          0.18003903 -0.00142259]\n",
      " [ 0.         -0.10385523  0.22461104]\n",
      " [ 0.         -0.06117577  0.11708192]\n",
      " [ 0.         -0.08592073  0.22875535]\n",
      " [ 0.         -0.09839972  0.15882815]\n",
      " [ 0.          0.21017637  0.07801606]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #29 | lambda learn rate = 0.0001\n",
      "Target = [[9.]\n",
      " [2.]]\n",
      "lambda end of trial = [[ 0.          0.50613413 -0.25629575]\n",
      " [ 0.          0.34344162 -0.18118476]\n",
      " [ 0.         -0.17076112  0.21786185]\n",
      " [ 0.         -0.11250591  0.16392076]\n",
      " [ 0.          0.18018829 -0.00138942]\n",
      " [ 0.         -0.10370179  0.22464513]\n",
      " [ 0.         -0.06098768  0.11712372]\n",
      " [ 0.         -0.08578082  0.22878644]\n",
      " [ 0.         -0.09830211  0.15884984]\n",
      " [ 0.          0.21017774  0.07801636]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #30 | lambda learn rate = 0.0001\n",
      "Target = [[8.]\n",
      " [1.]]\n",
      "lambda end of trial = [[ 0.          0.50517297 -0.2564159 ]\n",
      " [ 0.          0.34266078 -0.18128236]\n",
      " [ 0.         -0.17162886  0.21775338]\n",
      " [ 0.         -0.11339983  0.16380902]\n",
      " [ 0.          0.17925204 -0.00150645]\n",
      " [ 0.         -0.10467164  0.2245239 ]\n",
      " [ 0.         -0.06177782  0.11702495]\n",
      " [ 0.         -0.08679343  0.22865986]\n",
      " [ 0.         -0.0991114   0.15874868]\n",
      " [ 0.          0.20922358  0.07789709]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #31 | lambda learn rate = 0.0001\n",
      "Target = [[5.]\n",
      " [3.]]\n",
      "lambda end of trial = [[ 0.          0.50419762 -0.25700111]\n",
      " [ 0.          0.34176845 -0.18181776]\n",
      " [ 0.         -0.17250023  0.21723056]\n",
      " [ 0.         -0.11418162  0.16333995]\n",
      " [ 0.          0.17833096 -0.0020591 ]\n",
      " [ 0.         -0.10549011  0.22403282]\n",
      " [ 0.         -0.0624734   0.11660761]\n",
      " [ 0.         -0.08764042  0.22815167]\n",
      " [ 0.         -0.09998888  0.15822219]\n",
      " [ 0.          0.2082849   0.07733388]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #32 | lambda learn rate = 0.0001\n",
      "Target = [[2.]\n",
      " [1.]]\n",
      "lambda end of trial = [[ 0.          0.50311657 -0.25754164]\n",
      " [ 0.          0.34071662 -0.18234367]\n",
      " [ 0.         -0.17357832  0.21669152]\n",
      " [ 0.         -0.11532627  0.16276762]\n",
      " [ 0.          0.17727318 -0.00258799]\n",
      " [ 0.         -0.10676659  0.22339458]\n",
      " [ 0.         -0.06348375  0.11610243]\n",
      " [ 0.         -0.08878898  0.22757739]\n",
      " [ 0.         -0.1010244   0.15770443]\n",
      " [ 0.          0.20727376  0.07682831]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #33 | lambda learn rate = 0.0001\n",
      "Target = [[6.]\n",
      " [7.]]\n",
      "lambda end of trial = [[ 0.          0.50453243 -0.25588979]\n",
      " [ 0.          0.34194221 -0.18091382]\n",
      " [ 0.         -0.17225877  0.21823099]\n",
      " [ 0.         -0.11410506  0.16419237]\n",
      " [ 0.          0.17853463 -0.0011163 ]\n",
      " [ 0.         -0.10558187  0.22477676]\n",
      " [ 0.         -0.06221956  0.11757732]\n",
      " [ 0.         -0.08754687  0.22902652]\n",
      " [ 0.         -0.09967786  0.1592754 ]\n",
      " [ 0.          0.20851934  0.07828149]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #34 | lambda learn rate = 0.0001\n",
      "Target = [[3.]\n",
      " [9.]]\n",
      "lambda end of trial = [[ 0.00000000e+00  5.04723114e-01 -2.55317745e-01]\n",
      " [ 0.00000000e+00  3.42160044e-01 -1.80260321e-01]\n",
      " [ 0.00000000e+00 -1.72044876e-01  2.18872663e-01]\n",
      " [ 0.00000000e+00 -1.13886538e-01  1.64847938e-01]\n",
      " [ 0.00000000e+00  1.78738574e-01 -5.04474712e-04]\n",
      " [ 0.00000000e+00 -1.05416278e-01  2.25273529e-01]\n",
      " [ 0.00000000e+00 -6.20212262e-02  1.18172320e-01]\n",
      " [ 0.00000000e+00 -8.73512598e-02  2.29613345e-01]\n",
      " [ 0.00000000e+00 -9.94844938e-02  1.59855488e-01]\n",
      " [ 0.00000000e+00  2.08690875e-01  7.87960943e-02]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #35 | lambda learn rate = 0.0001\n",
      "Target = [[0.]\n",
      " [3.]]\n",
      "lambda end of trial = [[ 0.          0.50472311 -0.25689197]\n",
      " [ 0.          0.34216004 -0.18152907]\n",
      " [ 0.         -0.17204488  0.21727444]\n",
      " [ 0.         -0.11388654  0.16339734]\n",
      " [ 0.          0.17873857 -0.00210546]\n",
      " [ 0.         -0.10541628  0.22384165]\n",
      " [ 0.         -0.06202123  0.1166213 ]\n",
      " [ 0.         -0.08735126  0.22813019]\n",
      " [ 0.         -0.09948449  0.15843183]\n",
      " [ 0.          0.20869087  0.07717264]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #36 | lambda learn rate = 0.0001\n",
      "Target = [[8.]\n",
      " [8.]]\n",
      "lambda end of trial = [[ 0.          0.50782741 -0.25378767]\n",
      " [ 0.          0.34522541 -0.17846371]\n",
      " [ 0.         -0.16910772  0.2202116 ]\n",
      " [ 0.         -0.11072922  0.16655466]\n",
      " [ 0.          0.18175051  0.00090648]\n",
      " [ 0.         -0.10270214  0.22655579]\n",
      " [ 0.         -0.0590318   0.11961072]\n",
      " [ 0.         -0.08463435  0.2308471 ]\n",
      " [ 0.         -0.09654083  0.1613755 ]\n",
      " [ 0.          0.21178106  0.08026282]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #37 | lambda learn rate = 0.0001\n",
      "Target = [[4.]\n",
      " [8.]]\n",
      "lambda end of trial = [[ 0.          0.50786503 -0.25371243]\n",
      " [ 0.          0.34535946 -0.1781956 ]\n",
      " [ 0.         -0.16906511  0.22029682]\n",
      " [ 0.         -0.1106966   0.1666199 ]\n",
      " [ 0.          0.18182272  0.0010509 ]\n",
      " [ 0.         -0.10266792  0.22662422]\n",
      " [ 0.         -0.05894581  0.11978271]\n",
      " [ 0.         -0.08457281  0.23097019]\n",
      " [ 0.         -0.09646568  0.1615258 ]\n",
      " [ 0.          0.2118193   0.08033929]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #38 | lambda learn rate = 0.0001\n",
      "Target = [[0.]\n",
      " [1.]]\n",
      "lambda end of trial = [[ 0.00000000e+00  5.07865034e-01 -2.54343612e-01]\n",
      " [ 0.00000000e+00  3.45359461e-01 -1.78898602e-01]\n",
      " [ 0.00000000e+00 -1.69065108e-01  2.19665955e-01]\n",
      " [ 0.00000000e+00 -1.10696602e-01  1.65917471e-01]\n",
      " [ 0.00000000e+00  1.81822721e-01  3.87881589e-04]\n",
      " [ 0.00000000e+00 -1.02667920e-01  2.25961734e-01]\n",
      " [ 0.00000000e+00 -5.89458127e-02  1.19162839e-01]\n",
      " [ 0.00000000e+00 -8.45728072e-02  2.30352994e-01]\n",
      " [ 0.00000000e+00 -9.64656763e-02  1.60942609e-01]\n",
      " [ 0.00000000e+00  2.11819297e-01  7.97113336e-02]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #39 | lambda learn rate = 0.0001\n",
      "Target = [[8.]\n",
      " [1.]]\n",
      "lambda end of trial = [[ 0.00000000e+00  5.06666866e-01 -2.54493383e-01]\n",
      " [ 0.00000000e+00  3.44292790e-01 -1.79031935e-01]\n",
      " [ 0.00000000e+00 -1.70232658e-01  2.19520011e-01]\n",
      " [ 0.00000000e+00 -1.11837981e-01  1.65774799e-01]\n",
      " [ 0.00000000e+00  1.80757730e-01  2.54757755e-04]\n",
      " [ 0.00000000e+00 -1.03815055e-01  2.25818342e-01]\n",
      " [ 0.00000000e+00 -5.99694292e-02  1.19034887e-01]\n",
      " [ 0.00000000e+00 -8.56506316e-02  2.30218266e-01]\n",
      " [ 0.00000000e+00 -9.76463065e-02  1.60795031e-01]\n",
      " [ 0.00000000e+00  2.10695474e-01  7.95708557e-02]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #40 | lambda learn rate = 0.0001\n",
      "Target = [[6.]\n",
      " [1.]]\n",
      "lambda end of trial = [[ 0.00000000e+00  5.05216829e-01 -2.54735056e-01]\n",
      " [ 0.00000000e+00  3.42771295e-01 -1.79285518e-01]\n",
      " [ 0.00000000e+00 -1.71911259e-01  2.19240245e-01]\n",
      " [ 0.00000000e+00 -1.13285100e-01  1.65533612e-01]\n",
      " [ 0.00000000e+00  1.79139706e-01 -1.49128191e-05]\n",
      " [ 0.00000000e+00 -1.05414702e-01  2.25551734e-01]\n",
      " [ 0.00000000e+00 -6.15382316e-02  1.18773420e-01]\n",
      " [ 0.00000000e+00 -8.73226204e-02  2.29939601e-01]\n",
      " [ 0.00000000e+00 -9.91845571e-02  1.60538656e-01]\n",
      " [ 0.00000000e+00  2.09058201e-01  7.92979769e-02]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #41 | lambda learn rate = 0.0001\n",
      "Target = [[7.]\n",
      " [9.]]\n",
      "lambda end of trial = [[ 0.          0.50754335 -0.25174381]\n",
      " [ 0.          0.34503889 -0.17637004]\n",
      " [ 0.         -0.16976056  0.22200543]\n",
      " [ 0.         -0.1109866   0.16848883]\n",
      " [ 0.          0.18156589  0.00310446]\n",
      " [ 0.         -0.10317513  0.22843118]\n",
      " [ 0.         -0.05934863  0.12158863]\n",
      " [ 0.         -0.0854618   0.23233209]\n",
      " [ 0.         -0.09689151  0.16348685]\n",
      " [ 0.          0.21121427  0.08207006]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #42 | lambda learn rate = 0.0001\n",
      "Target = [[8.]\n",
      " [8.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda end of trial = [[ 0.          0.50919499 -0.25009218]\n",
      " [ 0.          0.34706057 -0.17434836]\n",
      " [ 0.         -0.16801008  0.22375591]\n",
      " [ 0.         -0.1094205   0.17005493]\n",
      " [ 0.          0.18354515  0.00508373]\n",
      " [ 0.         -0.10139415  0.23021216]\n",
      " [ 0.         -0.0577559   0.12318135]\n",
      " [ 0.         -0.08371119  0.2340827 ]\n",
      " [ 0.         -0.0951783   0.16520007]\n",
      " [ 0.          0.21296505  0.08382084]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #43 | lambda learn rate = 0.0001\n",
      "Target = [[7.]\n",
      " [6.]]\n",
      "lambda end of trial = [[ 0.          0.50919845 -0.25008921]\n",
      " [ 0.          0.34710489 -0.17431037]\n",
      " [ 0.         -0.16801226  0.22375404]\n",
      " [ 0.         -0.10943775  0.17004014]\n",
      " [ 0.          0.18349353  0.00503948]\n",
      " [ 0.         -0.10140817  0.23020015]\n",
      " [ 0.         -0.05778243  0.12315861]\n",
      " [ 0.         -0.08376273  0.23403852]\n",
      " [ 0.         -0.09510319  0.16526445]\n",
      " [ 0.          0.21292459  0.08378616]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #44 | lambda learn rate = 0.0001\n",
      "Target = [[0.]\n",
      " [5.]]\n",
      "lambda end of trial = [[ 0.          0.50919845 -0.25221237]\n",
      " [ 0.          0.34710489 -0.176264  ]\n",
      " [ 0.         -0.16801226  0.22180182]\n",
      " [ 0.         -0.10943775  0.16816719]\n",
      " [ 0.          0.18349353  0.00289154]\n",
      " [ 0.         -0.10140817  0.22806508]\n",
      " [ 0.         -0.05778243  0.12124995]\n",
      " [ 0.         -0.08376273  0.23176779]\n",
      " [ 0.         -0.09510319  0.16323931]\n",
      " [ 0.          0.21292459  0.08172629]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #45 | lambda learn rate = 0.0001\n",
      "Target = [[7.]\n",
      " [9.]]\n",
      "lambda end of trial = [[ 0.          0.51060408 -0.25040513]\n",
      " [ 0.          0.34842443 -0.17456744]\n",
      " [ 0.         -0.16661625  0.22359669]\n",
      " [ 0.         -0.10800938  0.17000366]\n",
      " [ 0.          0.18495166  0.00476629]\n",
      " [ 0.         -0.0999458   0.22994526]\n",
      " [ 0.         -0.05646236  0.12294719]\n",
      " [ 0.         -0.08225541  0.23370577]\n",
      " [ 0.         -0.09385271  0.16484707]\n",
      " [ 0.          0.21410473  0.0832436 ]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #46 | lambda learn rate = 0.0001\n",
      "Target = [[0.]\n",
      " [7.]]\n",
      "lambda end of trial = [[ 0.          0.51060408 -0.25280328]\n",
      " [ 0.          0.34842443 -0.17673369]\n",
      " [ 0.         -0.16661625  0.22137205]\n",
      " [ 0.         -0.10800938  0.16775495]\n",
      " [ 0.          0.18495166  0.0026831 ]\n",
      " [ 0.         -0.0999458   0.22790567]\n",
      " [ 0.         -0.05646236  0.12064273]\n",
      " [ 0.         -0.08225541  0.23138399]\n",
      " [ 0.         -0.09385271  0.16258045]\n",
      " [ 0.          0.21410473  0.08068819]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #47 | lambda learn rate = 0.0001\n",
      "Target = [[9.]\n",
      " [1.]]\n",
      "lambda end of trial = [[ 0.          0.50911484 -0.25296875]\n",
      " [ 0.          0.34715078 -0.17687521]\n",
      " [ 0.         -0.1679851   0.22121996]\n",
      " [ 0.         -0.10940439  0.16759995]\n",
      " [ 0.          0.18346971  0.00251844]\n",
      " [ 0.         -0.10153092  0.22772954]\n",
      " [ 0.         -0.05775815  0.12049875]\n",
      " [ 0.         -0.08376755  0.23121597]\n",
      " [ 0.         -0.09509299  0.16244264]\n",
      " [ 0.          0.21256231  0.08051681]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #48 | lambda learn rate = 0.0001\n",
      "Target = [[2.]\n",
      " [2.]]\n",
      "lambda end of trial = [[ 0.          0.50816203 -0.25392157]\n",
      " [ 0.          0.34638813 -0.17763787]\n",
      " [ 0.         -0.16883966  0.2203654 ]\n",
      " [ 0.         -0.11028314  0.16672121]\n",
      " [ 0.          0.18260486  0.00165359]\n",
      " [ 0.         -0.10239602  0.22686444]\n",
      " [ 0.         -0.05856768  0.11968922]\n",
      " [ 0.         -0.0846697   0.23031382]\n",
      " [ 0.         -0.09588498  0.16165065]\n",
      " [ 0.          0.21169994  0.07965444]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #49 | lambda learn rate = 0.0001\n",
      "Target = [[7.]\n",
      " [8.]]\n",
      "lambda end of trial = [[ 0.          0.50947234 -0.25242407]\n",
      " [ 0.          0.34765215 -0.17619327]\n",
      " [ 0.         -0.16743422  0.22197162]\n",
      " [ 0.         -0.10911757  0.16805329]\n",
      " [ 0.          0.1838079   0.00302849]\n",
      " [ 0.         -0.10119925  0.22823218]\n",
      " [ 0.         -0.05723994  0.12120663]\n",
      " [ 0.         -0.08339368  0.23177213]\n",
      " [ 0.         -0.09461499  0.16310206]\n",
      " [ 0.          0.21293861  0.08107006]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #50 | lambda learn rate = 0.0001\n",
      "Target = [[1.]\n",
      " [6.]]\n",
      "lambda end of trial = [[ 0.          0.50912084 -0.25453306]\n",
      " [ 0.          0.34734552 -0.17803306]\n",
      " [ 0.         -0.16773188  0.22018564]\n",
      " [ 0.         -0.10942769  0.16619252]\n",
      " [ 0.          0.18349753  0.00116626]\n",
      " [ 0.         -0.10153466  0.22621973]\n",
      " [ 0.         -0.05755772  0.11929995]\n",
      " [ 0.         -0.08373321  0.22973494]\n",
      " [ 0.         -0.0949189   0.16127863]\n",
      " [ 0.          0.2125861   0.07895497]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #51 | lambda learn rate = 0.0001\n",
      "Target = [[2.]\n",
      " [1.]]\n",
      "lambda end of trial = [[ 0.          0.50803544 -0.25507576]\n",
      " [ 0.          0.34631153 -0.17855006]\n",
      " [ 0.         -0.16878793  0.21965762]\n",
      " [ 0.         -0.11057991  0.16561641]\n",
      " [ 0.          0.18258058  0.00070779]\n",
      " [ 0.         -0.10269262  0.22564075]\n",
      " [ 0.         -0.05858117  0.11878822]\n",
      " [ 0.         -0.08473672  0.22923319]\n",
      " [ 0.         -0.09593548  0.16077034]\n",
      " [ 0.          0.21148956  0.07840671]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #52 | lambda learn rate = 0.0001\n",
      "Target = [[6.]\n",
      " [0.]]\n",
      "lambda end of trial = [[ 0.          0.50601753 -0.25507576]\n",
      " [ 0.          0.34426344 -0.17855006]\n",
      " [ 0.         -0.17067239  0.21965762]\n",
      " [ 0.         -0.11263493  0.16561641]\n",
      " [ 0.          0.18055571  0.00070779]\n",
      " [ 0.         -0.10479436  0.22564075]\n",
      " [ 0.         -0.06065951  0.11878822]\n",
      " [ 0.         -0.08681848  0.22923319]\n",
      " [ 0.         -0.0978839   0.16077034]\n",
      " [ 0.          0.20922359  0.07840671]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #53 | lambda learn rate = 0.0001\n",
      "Target = [[1.]\n",
      " [7.]]\n",
      "lambda end of trial = [[ 0.          0.50579464 -0.25663596]\n",
      " [ 0.          0.3440552  -0.18000773]\n",
      " [ 0.         -0.17092513  0.21788839]\n",
      " [ 0.         -0.11285002  0.16411081]\n",
      " [ 0.          0.18031998 -0.00094239]\n",
      " [ 0.         -0.10501703  0.22408208]\n",
      " [ 0.         -0.06086579  0.11734431]\n",
      " [ 0.         -0.08705485  0.22757863]\n",
      " [ 0.         -0.0981011   0.15924996]\n",
      " [ 0.          0.20896742  0.07661347]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #54 | lambda learn rate = 0.0001\n",
      "Target = [[2.]\n",
      " [6.]]\n",
      "lambda end of trial = [[ 0.          0.50544657 -0.25768017]\n",
      " [ 0.          0.34368967 -0.18110433]\n",
      " [ 0.         -0.17127766  0.21683081]\n",
      " [ 0.         -0.11321108  0.16302761]\n",
      " [ 0.          0.1799826  -0.0019545 ]\n",
      " [ 0.         -0.10538965  0.22296421]\n",
      " [ 0.         -0.06122744  0.11625935]\n",
      " [ 0.         -0.08738801  0.22657915]\n",
      " [ 0.         -0.09842536  0.15827717]\n",
      " [ 0.          0.20855608  0.07537946]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #55 | lambda learn rate = 0.0001\n",
      "Target = [[3.]\n",
      " [1.]]\n",
      "lambda end of trial = [[ 0.          0.50419183 -0.25809841]\n",
      " [ 0.          0.34255559 -0.18148236]\n",
      " [ 0.         -0.1724206   0.21644983]\n",
      " [ 0.         -0.11441586  0.16262602]\n",
      " [ 0.          0.17877392 -0.00235739]\n",
      " [ 0.         -0.10664798  0.22254476]\n",
      " [ 0.         -0.06242512  0.11586013]\n",
      " [ 0.         -0.08867016  0.22615176]\n",
      " [ 0.         -0.09955273  0.15790138]\n",
      " [ 0.          0.2073062   0.07496283]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #56 | lambda learn rate = 0.0001\n",
      "Target = [[9.]\n",
      " [7.]]\n",
      "lambda end of trial = [[ 0.00000000e+00  5.07786396e-01 -2.55302639e-01]\n",
      " [ 0.00000000e+00  3.45844093e-01 -1.78924634e-01]\n",
      " [ 0.00000000e+00 -1.68679346e-01  2.19359694e-01]\n",
      " [ 0.00000000e+00 -1.10543800e-01  1.65637625e-01]\n",
      " [ 0.00000000e+00  1.82293834e-01  3.80319530e-04]\n",
      " [ 0.00000000e+00 -1.02800415e-01  2.25537315e-01]\n",
      " [ 0.00000000e+00 -5.86787678e-02  1.18773952e-01]\n",
      " [ 0.00000000e+00 -8.50210581e-02  2.28989953e-01]\n",
      " [ 0.00000000e+00 -9.56604566e-02  1.60928709e-01]\n",
      " [ 0.00000000e+00  2.10873769e-01  7.77376085e-02]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #57 | lambda learn rate = 0.0001\n",
      "Target = [[2.]\n",
      " [5.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda end of trial = [[ 0.          0.50722637 -0.2567027 ]\n",
      " [ 0.          0.34535525 -0.18014673]\n",
      " [ 0.         -0.16921279  0.21802608]\n",
      " [ 0.         -0.11101307  0.16446446]\n",
      " [ 0.          0.18182195 -0.00079938]\n",
      " [ 0.         -0.1033067   0.22427161]\n",
      " [ 0.         -0.05922006  0.11742073]\n",
      " [ 0.         -0.08559521  0.22755457]\n",
      " [ 0.         -0.09618047  0.15962868]\n",
      " [ 0.          0.21036541  0.07646672]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #58 | lambda learn rate = 0.0001\n",
      "Target = [[2.]\n",
      " [1.]]\n",
      "lambda end of trial = [[ 0.          0.50638558 -0.2571231 ]\n",
      " [ 0.          0.34436109 -0.18064381]\n",
      " [ 0.         -0.17012538  0.21756978]\n",
      " [ 0.         -0.11197757  0.1639822 ]\n",
      " [ 0.          0.18084911 -0.0012858 ]\n",
      " [ 0.         -0.10433219  0.22375886]\n",
      " [ 0.         -0.06020892  0.1169263 ]\n",
      " [ 0.         -0.08648489  0.22710973]\n",
      " [ 0.         -0.09717808  0.15912987]\n",
      " [ 0.          0.20942169  0.07599486]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #59 | lambda learn rate = 0.0001\n",
      "Target = [[0.]\n",
      " [6.]]\n",
      "lambda end of trial = [[ 0.          0.50638558 -0.25888813]\n",
      " [ 0.          0.34436109 -0.18233535]\n",
      " [ 0.         -0.17012538  0.2158455 ]\n",
      " [ 0.         -0.11197757  0.16241224]\n",
      " [ 0.          0.18084911 -0.00298733]\n",
      " [ 0.         -0.10433219  0.22190106]\n",
      " [ 0.         -0.06020892  0.11537133]\n",
      " [ 0.         -0.08648489  0.22504423]\n",
      " [ 0.         -0.09717808  0.1573225 ]\n",
      " [ 0.          0.20942169  0.07402667]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #60 | lambda learn rate = 0.0001\n",
      "Target = [[6.]\n",
      " [6.]]\n",
      "lambda end of trial = [[ 0.          0.50700209 -0.25827162]\n",
      " [ 0.          0.34495287 -0.18174358]\n",
      " [ 0.         -0.16954001  0.21643087]\n",
      " [ 0.         -0.11131688  0.16307294]\n",
      " [ 0.          0.18151776 -0.00231868]\n",
      " [ 0.         -0.10374004  0.22249321]\n",
      " [ 0.         -0.05955895  0.11602129]\n",
      " [ 0.         -0.0857901   0.22573902]\n",
      " [ 0.         -0.09671659  0.15778399]\n",
      " [ 0.          0.20995668  0.07456166]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #61 | lambda learn rate = 0.0001\n",
      "Target = [[0.]\n",
      " [1.]]\n",
      "lambda end of trial = [[ 0.          0.50700209 -0.258856  ]\n",
      " [ 0.          0.34495287 -0.18237286]\n",
      " [ 0.         -0.16954001  0.21578335]\n",
      " [ 0.         -0.11131688  0.16246855]\n",
      " [ 0.          0.18151776 -0.00294384]\n",
      " [ 0.         -0.10374004  0.2218145 ]\n",
      " [ 0.         -0.05955895  0.11535717]\n",
      " [ 0.         -0.0857901   0.22506449]\n",
      " [ 0.         -0.09671659  0.15719697]\n",
      " [ 0.          0.20995668  0.07393274]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #62 | lambda learn rate = 0.0001\n",
      "Target = [[8.]\n",
      " [1.]]\n",
      "lambda end of trial = [[ 0.          0.50606631 -0.25897298]\n",
      " [ 0.          0.34397332 -0.1824953 ]\n",
      " [ 0.         -0.17069816  0.21563858]\n",
      " [ 0.         -0.11231397  0.16234392]\n",
      " [ 0.          0.1804224  -0.00308076]\n",
      " [ 0.         -0.10462921  0.22170335]\n",
      " [ 0.         -0.06053345  0.11523536]\n",
      " [ 0.         -0.08696719  0.22491735]\n",
      " [ 0.         -0.09778743  0.15706311]\n",
      " [ 0.          0.20875518  0.07378256]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #63 | lambda learn rate = 0.0001\n",
      "Target = [[3.]\n",
      " [8.]]\n",
      "lambda end of trial = [[ 0.          0.50624476 -0.2584971 ]\n",
      " [ 0.          0.34417665 -0.1819531 ]\n",
      " [ 0.         -0.17048197  0.21621508]\n",
      " [ 0.         -0.11214947  0.16278257]\n",
      " [ 0.          0.18059289 -0.00262613]\n",
      " [ 0.         -0.10444261  0.22220094]\n",
      " [ 0.         -0.06035159  0.11572034]\n",
      " [ 0.         -0.08679938  0.22536484]\n",
      " [ 0.         -0.09763379  0.15747282]\n",
      " [ 0.          0.20889005  0.07414221]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #64 | lambda learn rate = 0.0001\n",
      "Target = [[6.]\n",
      " [6.]]\n",
      "lambda end of trial = [[ 0.          0.50680292 -0.25793894]\n",
      " [ 0.          0.34469843 -0.18143132]\n",
      " [ 0.         -0.1698868   0.21681026]\n",
      " [ 0.         -0.11156137  0.16337067]\n",
      " [ 0.          0.18110282 -0.0021162 ]\n",
      " [ 0.         -0.10388163  0.22276192]\n",
      " [ 0.         -0.05966044  0.11641149]\n",
      " [ 0.         -0.08627414  0.22589007]\n",
      " [ 0.         -0.09702511  0.1580815 ]\n",
      " [ 0.          0.20942597  0.07467813]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #65 | lambda learn rate = 0.0001\n",
      "Target = [[0.]\n",
      " [1.]]\n",
      "lambda end of trial = [[ 0.          0.50680292 -0.25860792]\n",
      " [ 0.          0.34469843 -0.18208899]\n",
      " [ 0.         -0.1698868   0.21624852]\n",
      " [ 0.         -0.11156137  0.16271975]\n",
      " [ 0.          0.18110282 -0.00280129]\n",
      " [ 0.         -0.10388163  0.22210952]\n",
      " [ 0.         -0.05966044  0.11571801]\n",
      " [ 0.         -0.08627414  0.22522861]\n",
      " [ 0.         -0.09702511  0.15739874]\n",
      " [ 0.          0.20942597  0.07403957]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #66 | lambda learn rate = 0.0001\n",
      "Target = [[3.]\n",
      " [4.]]\n",
      "lambda end of trial = [[ 0.          0.50617028 -0.25945144]\n",
      " [ 0.          0.34405912 -0.1829414 ]\n",
      " [ 0.         -0.17051483  0.21541114]\n",
      " [ 0.         -0.11221372  0.16184995]\n",
      " [ 0.          0.18040217 -0.00373548]\n",
      " [ 0.         -0.10458585  0.22117056]\n",
      " [ 0.         -0.06023692  0.11494936]\n",
      " [ 0.         -0.08696748  0.22430417]\n",
      " [ 0.         -0.09766323  0.15654792]\n",
      " [ 0.          0.20865979  0.07301801]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #67 | lambda learn rate = 0.0001\n",
      "Target = [[5.]\n",
      " [2.]]\n",
      "lambda end of trial = [[ 0.          0.50515149 -0.25985896]\n",
      " [ 0.          0.34313639 -0.18331049]\n",
      " [ 0.         -0.17159995  0.21497709]\n",
      " [ 0.         -0.11334797  0.16139626]\n",
      " [ 0.          0.17915024 -0.00423626]\n",
      " [ 0.         -0.10582604  0.22067448]\n",
      " [ 0.         -0.06133056  0.11451191]\n",
      " [ 0.         -0.08802926  0.22387946]\n",
      " [ 0.         -0.0986667   0.15614653]\n",
      " [ 0.          0.20748689  0.07254885]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #68 | lambda learn rate = 0.0001\n",
      "Target = [[5.]\n",
      " [0.]]\n",
      "lambda end of trial = [[ 0.          0.50305121 -0.25985896]\n",
      " [ 0.          0.34113809 -0.18331049]\n",
      " [ 0.         -0.17343351  0.21497709]\n",
      " [ 0.         -0.1152878   0.16139626]\n",
      " [ 0.          0.17724011 -0.00423626]\n",
      " [ 0.         -0.10769635  0.22067448]\n",
      " [ 0.         -0.06320144  0.11451191]\n",
      " [ 0.         -0.08994231  0.22387946]\n",
      " [ 0.         -0.10048954  0.15614653]\n",
      " [ 0.          0.20569648  0.07254885]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #69 | lambda learn rate = 0.0001\n",
      "Target = [[7.]\n",
      " [1.]]\n",
      "lambda end of trial = [[ 0.          0.50237511 -0.25995554]\n",
      " [ 0.          0.34056144 -0.18339287]\n",
      " [ 0.         -0.17414757  0.21487508]\n",
      " [ 0.         -0.11584786  0.16131625]\n",
      " [ 0.          0.17655741 -0.00433379]\n",
      " [ 0.         -0.10841906  0.22057124]\n",
      " [ 0.         -0.06372622  0.11443694]\n",
      " [ 0.         -0.09075475  0.22376339]\n",
      " [ 0.         -0.10118919  0.15604658]\n",
      " [ 0.          0.20488249  0.07243256]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #70 | lambda learn rate = 0.0001\n",
      "Target = [[4.]\n",
      " [5.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda end of trial = [[ 0.          0.50231961 -0.26002492]\n",
      " [ 0.          0.34056123 -0.18339313]\n",
      " [ 0.         -0.1741763   0.21483917]\n",
      " [ 0.         -0.11586519  0.16129458]\n",
      " [ 0.          0.17654058 -0.00435482]\n",
      " [ 0.         -0.10847379  0.22050283]\n",
      " [ 0.         -0.06372857  0.114434  ]\n",
      " [ 0.         -0.09084552  0.22364993]\n",
      " [ 0.         -0.10119698  0.15603684]\n",
      " [ 0.          0.20477086  0.07229303]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #71 | lambda learn rate = 0.0001\n",
      "Target = [[1.]\n",
      " [9.]]\n",
      "lambda end of trial = [[ 0.          0.50237415 -0.25953406]\n",
      " [ 0.          0.34062404 -0.18282787]\n",
      " [ 0.         -0.17411831  0.21536115]\n",
      " [ 0.         -0.11581036  0.16178803]\n",
      " [ 0.          0.1766072  -0.00375529]\n",
      " [ 0.         -0.10840975  0.22107915]\n",
      " [ 0.         -0.06366798  0.1149793 ]\n",
      " [ 0.         -0.09079005  0.22414918]\n",
      " [ 0.         -0.1011342   0.15660193]\n",
      " [ 0.          0.20482407  0.07277189]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #72 | lambda learn rate = 0.0001\n",
      "Target = [[1.]\n",
      " [0.]]\n",
      "lambda end of trial = [[ 0.          0.50180764 -0.25953406]\n",
      " [ 0.          0.34004241 -0.18282787]\n",
      " [ 0.         -0.17462234  0.21536115]\n",
      " [ 0.         -0.11635097  0.16178803]\n",
      " [ 0.          0.1760257  -0.00375529]\n",
      " [ 0.         -0.10906023  0.22107915]\n",
      " [ 0.         -0.06425098  0.1149793 ]\n",
      " [ 0.         -0.09136486  0.22414918]\n",
      " [ 0.         -0.10169406  0.15660193]\n",
      " [ 0.          0.20417578  0.07277189]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #73 | lambda learn rate = 0.0001\n",
      "Target = [[6.]\n",
      " [7.]]\n",
      "lambda end of trial = [[ 0.          0.50361514 -0.25742531]\n",
      " [ 0.          0.34169076 -0.18090479]\n",
      " [ 0.         -0.17283059  0.21745152]\n",
      " [ 0.         -0.11468725  0.16372903]\n",
      " [ 0.          0.17767044 -0.00183642]\n",
      " [ 0.         -0.10739659  0.22302005]\n",
      " [ 0.         -0.06265692  0.11683904]\n",
      " [ 0.         -0.08982909  0.22594091]\n",
      " [ 0.         -0.09994241  0.15864552]\n",
      " [ 0.          0.20561074  0.074446  ]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #74 | lambda learn rate = 0.0001\n",
      "Target = [[0.]\n",
      " [5.]]\n",
      "lambda end of trial = [[ 0.          0.50361514 -0.25905428]\n",
      " [ 0.          0.34169076 -0.18258467]\n",
      " [ 0.         -0.17283059  0.2157427 ]\n",
      " [ 0.         -0.11468725  0.1620501 ]\n",
      " [ 0.          0.17767044 -0.0035357 ]\n",
      " [ 0.         -0.10739659  0.22129083]\n",
      " [ 0.         -0.06265692  0.11506467]\n",
      " [ 0.         -0.08982909  0.22412316]\n",
      " [ 0.         -0.09994241  0.15710583]\n",
      " [ 0.          0.20561074  0.07277614]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #75 | lambda learn rate = 0.0001\n",
      "Target = [[8.]\n",
      " [2.]]\n",
      "lambda end of trial = [[ 0.          0.50370018 -0.25903302]\n",
      " [ 0.          0.34190421 -0.1825313 ]\n",
      " [ 0.         -0.17270741  0.2157735 ]\n",
      " [ 0.         -0.11453116  0.16208912]\n",
      " [ 0.          0.1778599  -0.00348833]\n",
      " [ 0.         -0.10724985  0.22132752]\n",
      " [ 0.         -0.06244467  0.11511773]\n",
      " [ 0.         -0.08972146  0.22415007]\n",
      " [ 0.         -0.09974458  0.15715529]\n",
      " [ 0.          0.20567235  0.07279154]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #76 | lambda learn rate = 0.0001\n",
      "Target = [[7.]\n",
      " [1.]]\n",
      "lambda end of trial = [[ 0.          0.50289032 -0.25914871]\n",
      " [ 0.          0.34109127 -0.18264744]\n",
      " [ 0.         -0.17360677  0.21564502]\n",
      " [ 0.         -0.11550075  0.16195061]\n",
      " [ 0.          0.17686219 -0.00363086]\n",
      " [ 0.         -0.10827417  0.22118119]\n",
      " [ 0.         -0.06319816  0.11501009]\n",
      " [ 0.         -0.09072541  0.22400664]\n",
      " [ 0.         -0.10056163  0.15703856]\n",
      " [ 0.          0.20461838  0.07264098]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #77 | lambda learn rate = 0.0001\n",
      "Target = [[2.]\n",
      " [2.]]\n",
      "lambda end of trial = [[ 0.          0.50211268 -0.25992636]\n",
      " [ 0.          0.34026466 -0.18347405]\n",
      " [ 0.         -0.17444823  0.21480356]\n",
      " [ 0.         -0.11632075  0.1611306 ]\n",
      " [ 0.          0.1760789  -0.00441416]\n",
      " [ 0.         -0.10906789  0.22038747]\n",
      " [ 0.         -0.0639935   0.11421475]\n",
      " [ 0.         -0.09154149  0.22319056]\n",
      " [ 0.         -0.10126368  0.15633652]\n",
      " [ 0.          0.20383206  0.07185465]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #78 | lambda learn rate = 0.0001\n",
      "Target = [[8.]\n",
      " [5.]]\n",
      "lambda end of trial = [[ 0.          0.50435461 -0.25852515]\n",
      " [ 0.          0.34274622 -0.18192308]\n",
      " [ 0.         -0.17251713  0.2160105 ]\n",
      " [ 0.         -0.11410695  0.16251423]\n",
      " [ 0.          0.17830452 -0.00302314]\n",
      " [ 0.         -0.10687676  0.22175692]\n",
      " [ 0.         -0.0615468   0.11574394]\n",
      " [ 0.         -0.08925041  0.22462249]\n",
      " [ 0.         -0.09903246  0.15773103]\n",
      " [ 0.          0.20617626  0.07331978]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #79 | lambda learn rate = 0.0001\n",
      "Target = [[9.]\n",
      " [2.]]\n",
      "lambda end of trial = [[ 0.          0.50482523 -0.25842057]\n",
      " [ 0.          0.34341224 -0.18177507]\n",
      " [ 0.         -0.17198701  0.2161283 ]\n",
      " [ 0.         -0.11346345  0.16265723]\n",
      " [ 0.          0.17882778 -0.00290686]\n",
      " [ 0.         -0.1062899   0.22188734]\n",
      " [ 0.         -0.06094434  0.11587782]\n",
      " [ 0.         -0.08867023  0.22475142]\n",
      " [ 0.         -0.09840577  0.15787029]\n",
      " [ 0.          0.20662638  0.07341981]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #80 | lambda learn rate = 0.0001\n",
      "Target = [[5.]\n",
      " [8.]]\n",
      "lambda end of trial = [[ 0.          0.50593777 -0.25664051]\n",
      " [ 0.          0.34440776 -0.18018224]\n",
      " [ 0.         -0.17091607  0.21784181]\n",
      " [ 0.         -0.1122932   0.16452962]\n",
      " [ 0.          0.17997127 -0.00107728]\n",
      " [ 0.         -0.10525326  0.22354597]\n",
      " [ 0.         -0.05975431  0.11778188]\n",
      " [ 0.         -0.08759747  0.22646783]\n",
      " [ 0.         -0.09721699  0.15977234]\n",
      " [ 0.          0.20763691  0.07503665]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #81 | lambda learn rate = 0.0001\n",
      "Target = [[2.]\n",
      " [8.]]\n",
      "lambda end of trial = [[ 0.          0.50593811 -0.25663915]\n",
      " [ 0.          0.34441385 -0.1801579 ]\n",
      " [ 0.         -0.17092593  0.21780235]\n",
      " [ 0.         -0.11229912  0.16450594]\n",
      " [ 0.          0.17995825 -0.00112938]\n",
      " [ 0.         -0.10525707  0.22353072]\n",
      " [ 0.         -0.05976327  0.11774604]\n",
      " [ 0.         -0.08764849  0.22626376]\n",
      " [ 0.         -0.09723371  0.15970548]\n",
      " [ 0.          0.2075997   0.07488781]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #82 | lambda learn rate = 0.0001\n",
      "Target = [[3.]\n",
      " [1.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda end of trial = [[ 0.          0.50468531 -0.25705674]\n",
      " [ 0.          0.34308132 -0.18060208]\n",
      " [ 0.         -0.17216531  0.21738922]\n",
      " [ 0.         -0.11353712  0.16409328]\n",
      " [ 0.          0.17870459 -0.00154726]\n",
      " [ 0.         -0.10665218  0.22306568]\n",
      " [ 0.         -0.06104241  0.11731966]\n",
      " [ 0.         -0.08894531  0.22583149]\n",
      " [ 0.         -0.09834897  0.15933372]\n",
      " [ 0.          0.20618715  0.07441696]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #83 | lambda learn rate = 0.0001\n",
      "Target = [[1.]\n",
      " [5.]]\n",
      "lambda end of trial = [[ 0.          0.50440991 -0.25843374]\n",
      " [ 0.          0.34282245 -0.18189643]\n",
      " [ 0.         -0.17241856  0.21612296]\n",
      " [ 0.         -0.11378081  0.16287479]\n",
      " [ 0.          0.17840965 -0.00302199]\n",
      " [ 0.         -0.10693747  0.2216392 ]\n",
      " [ 0.         -0.06130449  0.11600924]\n",
      " [ 0.         -0.08923041  0.224406  ]\n",
      " [ 0.         -0.09861033  0.15802694]\n",
      " [ 0.          0.20590784  0.07302043]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #84 | lambda learn rate = 0.0001\n",
      "Target = [[4.]\n",
      " [1.]]\n",
      "lambda end of trial = [[ 0.          0.50313343 -0.25875286]\n",
      " [ 0.          0.34159651 -0.18220291]\n",
      " [ 0.         -0.17367861  0.21580794]\n",
      " [ 0.         -0.11505721  0.16255569]\n",
      " [ 0.          0.1770743  -0.00335582]\n",
      " [ 0.         -0.10835376  0.22128513]\n",
      " [ 0.         -0.06257685  0.11569115]\n",
      " [ 0.         -0.09055246  0.22407548]\n",
      " [ 0.         -0.09987819  0.15770997]\n",
      " [ 0.          0.20461733  0.0726978 ]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #85 | lambda learn rate = 0.0001\n",
      "Target = [[7.]\n",
      " [2.]]\n",
      "lambda end of trial = [[ 0.          0.50265379 -0.2588899 ]\n",
      " [ 0.          0.34121881 -0.18231083]\n",
      " [ 0.         -0.17415955  0.21567053]\n",
      " [ 0.         -0.11556648  0.16241018]\n",
      " [ 0.          0.17654553 -0.0035069 ]\n",
      " [ 0.         -0.10883506  0.22114762]\n",
      " [ 0.         -0.06305035  0.11555587]\n",
      " [ 0.         -0.09112505  0.22391189]\n",
      " [ 0.         -0.10022582  0.15761065]\n",
      " [ 0.          0.20394109  0.07250459]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #86 | lambda learn rate = 0.0001\n",
      "Target = [[8.]\n",
      " [4.]]\n",
      "lambda end of trial = [[ 0.          0.50418862 -0.25812249]\n",
      " [ 0.          0.34289758 -0.18147144]\n",
      " [ 0.         -0.1726041   0.21644826]\n",
      " [ 0.         -0.11408248  0.16315218]\n",
      " [ 0.          0.17808809 -0.00273562]\n",
      " [ 0.         -0.10731128  0.22190951]\n",
      " [ 0.         -0.06154806  0.11630701]\n",
      " [ 0.         -0.08978527  0.22458177]\n",
      " [ 0.         -0.09882538  0.15831087]\n",
      " [ 0.          0.20546079  0.07326444]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #87 | lambda learn rate = 0.0001\n",
      "Target = [[8.]\n",
      " [0.]]\n",
      "lambda end of trial = [[ 0.          0.5034839  -0.25812249]\n",
      " [ 0.          0.34214454 -0.18147144]\n",
      " [ 0.         -0.17337538  0.21644826]\n",
      " [ 0.         -0.11475813  0.16315218]\n",
      " [ 0.          0.17730192 -0.00273562]\n",
      " [ 0.         -0.10814208  0.22190951]\n",
      " [ 0.         -0.06231122  0.11630701]\n",
      " [ 0.         -0.09056186  0.22458177]\n",
      " [ 0.         -0.09964708  0.15831087]\n",
      " [ 0.          0.20460365  0.07326444]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #88 | lambda learn rate = 0.0001\n",
      "Target = [[6.]\n",
      " [6.]]\n",
      "lambda end of trial = [[ 0.          0.50459193 -0.25701446]\n",
      " [ 0.          0.3431998  -0.18041618]\n",
      " [ 0.         -0.17235838  0.21746526]\n",
      " [ 0.         -0.11369531  0.16421501]\n",
      " [ 0.          0.17834687 -0.00169067]\n",
      " [ 0.         -0.10710244  0.22294915]\n",
      " [ 0.         -0.06122377  0.11739447]\n",
      " [ 0.         -0.08960366  0.22553997]\n",
      " [ 0.         -0.09857096  0.15938699]\n",
      " [ 0.          0.20557214  0.07423293]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #89 | lambda learn rate = 0.0001\n",
      "Target = [[4.]\n",
      " [8.]]\n",
      "lambda end of trial = [[ 0.          0.50510383 -0.25599065]\n",
      " [ 0.          0.34378234 -0.1792511 ]\n",
      " [ 0.         -0.17189681  0.21838841]\n",
      " [ 0.         -0.11315975  0.16528612]\n",
      " [ 0.          0.17889434 -0.00059573]\n",
      " [ 0.         -0.10653718  0.22407968]\n",
      " [ 0.         -0.06071129  0.11841942]\n",
      " [ 0.         -0.08911602  0.22651525]\n",
      " [ 0.         -0.09809983  0.16032926]\n",
      " [ 0.          0.20603487  0.07515838]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #90 | lambda learn rate = 0.0001\n",
      "Target = [[0.]\n",
      " [6.]]\n",
      "lambda end of trial = [[ 0.          0.50510383 -0.25765292]\n",
      " [ 0.          0.34378234 -0.18100199]\n",
      " [ 0.         -0.17189681  0.21680123]\n",
      " [ 0.         -0.11315975  0.16356814]\n",
      " [ 0.          0.17889434 -0.00250853]\n",
      " [ 0.         -0.10653718  0.22243099]\n",
      " [ 0.         -0.06071129  0.11684511]\n",
      " [ 0.         -0.08911602  0.22467885]\n",
      " [ 0.         -0.09809983  0.15839856]\n",
      " [ 0.          0.20603487  0.07343358]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #91 | lambda learn rate = 0.0001\n",
      "Target = [[6.]\n",
      " [5.]]\n",
      "lambda end of trial = [[ 0.          0.50546985 -0.2573479 ]\n",
      " [ 0.          0.34429351 -0.18057602]\n",
      " [ 0.         -0.17147884  0.21714953]\n",
      " [ 0.         -0.11270193  0.16394965]\n",
      " [ 0.          0.17934173 -0.00213572]\n",
      " [ 0.         -0.10611368  0.2227839 ]\n",
      " [ 0.         -0.06024123  0.11723683]\n",
      " [ 0.         -0.08875676  0.22497824]\n",
      " [ 0.         -0.09775779  0.15868359]\n",
      " [ 0.          0.20645308  0.07378208]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #92 | lambda learn rate = 0.0001\n",
      "Target = [[9.]\n",
      " [8.]]\n",
      "lambda end of trial = [[ 0.          0.5094137  -0.25384226]\n",
      " [ 0.          0.34843449 -0.17689515]\n",
      " [ 0.         -0.16733988  0.22082861]\n",
      " [ 0.         -0.10868967  0.16751611]\n",
      " [ 0.          0.18325551  0.0013432 ]\n",
      " [ 0.         -0.10217409  0.22628576]\n",
      " [ 0.         -0.05612864  0.12089247]\n",
      " [ 0.         -0.08463124  0.22864536]\n",
      " [ 0.         -0.09358968  0.16238857]\n",
      " [ 0.          0.21056509  0.0774372 ]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #93 | lambda learn rate = 0.0001\n",
      "Target = [[5.]\n",
      " [2.]]\n",
      "lambda end of trial = [[ 0.          0.50799757 -0.25440871]\n",
      " [ 0.          0.34708931 -0.17743322]\n",
      " [ 0.         -0.16865441  0.2203028 ]\n",
      " [ 0.         -0.11005194  0.1669712 ]\n",
      " [ 0.          0.18184757  0.00078003]\n",
      " [ 0.         -0.10371291  0.22567023]\n",
      " [ 0.         -0.05742661  0.12037328]\n",
      " [ 0.         -0.08603166  0.22808519]\n",
      " [ 0.         -0.09479464  0.16190659]\n",
      " [ 0.          0.20917469  0.07688104]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #94 | lambda learn rate = 0.0001\n",
      "Target = [[5.]\n",
      " [0.]]\n",
      "lambda end of trial = [[ 0.          0.50616259 -0.25440871]\n",
      " [ 0.          0.34523121 -0.17743322]\n",
      " [ 0.         -0.17044196  0.2203028 ]\n",
      " [ 0.         -0.11186827  0.1669712 ]\n",
      " [ 0.          0.18010641  0.00078003]\n",
      " [ 0.         -0.10540241  0.22567023]\n",
      " [ 0.         -0.05915317  0.12037328]\n",
      " [ 0.         -0.08771152  0.22808519]\n",
      " [ 0.         -0.0965018   0.16190659]\n",
      " [ 0.          0.20748424  0.07688104]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #95 | lambda learn rate = 0.0001\n",
      "Target = [[0.]\n",
      " [8.]]\n",
      "lambda end of trial = [[ 0.          0.50616259 -0.25600036]\n",
      " [ 0.          0.34523121 -0.17898836]\n",
      " [ 0.         -0.17044196  0.2190331 ]\n",
      " [ 0.         -0.11186827  0.16547646]\n",
      " [ 0.          0.18010641 -0.00075275]\n",
      " [ 0.         -0.10540241  0.22421235]\n",
      " [ 0.         -0.05915317  0.11892388]\n",
      " [ 0.         -0.08771152  0.22655076]\n",
      " [ 0.         -0.0965018   0.16034639]\n",
      " [ 0.          0.20748424  0.07538227]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #96 | lambda learn rate = 0.0001\n",
      "Target = [[2.]\n",
      " [2.]]\n",
      "lambda end of trial = [[ 0.          0.50535312 -0.25680983]\n",
      " [ 0.          0.34445761 -0.17976197]\n",
      " [ 0.         -0.17126491  0.21821014]\n",
      " [ 0.         -0.11273002  0.16461471]\n",
      " [ 0.          0.17929455 -0.00156461]\n",
      " [ 0.         -0.10626677  0.22334799]\n",
      " [ 0.         -0.05999874  0.1180783 ]\n",
      " [ 0.         -0.08851901  0.22574326]\n",
      " [ 0.         -0.09733703  0.15951116]\n",
      " [ 0.          0.20656607  0.0744641 ]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #97 | lambda learn rate = 0.0001\n",
      "Target = [[0.]\n",
      " [6.]]\n",
      "lambda end of trial = [[ 0.          0.50535312 -0.25816709]\n",
      " [ 0.          0.34445761 -0.1811214 ]\n",
      " [ 0.         -0.17126491  0.21678595]\n",
      " [ 0.         -0.11273002  0.16316921]\n",
      " [ 0.          0.17929455 -0.00289079]\n",
      " [ 0.         -0.10626677  0.22181398]\n",
      " [ 0.         -0.05999874  0.11660957]\n",
      " [ 0.         -0.08851901  0.22429766]\n",
      " [ 0.         -0.09733703  0.15789422]\n",
      " [ 0.          0.20656607  0.0730161 ]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #98 | lambda learn rate = 0.0001\n",
      "Target = [[9.]\n",
      " [3.]]\n",
      "lambda end of trial = [[ 0.          0.50658344 -0.25775698]\n",
      " [ 0.          0.34561664 -0.18073506]\n",
      " [ 0.         -0.16994946  0.21722444]\n",
      " [ 0.         -0.11151215  0.16357516]\n",
      " [ 0.          0.18043664 -0.00251009]\n",
      " [ 0.         -0.10502719  0.22222718]\n",
      " [ 0.         -0.05861023  0.11707241]\n",
      " [ 0.         -0.08736402  0.22468266]\n",
      " [ 0.         -0.09601962  0.15833336]\n",
      " [ 0.          0.20758532  0.07335585]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "+++++++++++++++++++++++++++++++++++\n",
      "Session #6\n",
      "target at trial 0 = [[1.]\n",
      " [1.]]\n",
      "K MATX INIT= [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "A VECT INIT = [-0. -0.]\n",
      "lambda\n",
      "[[ 0.          0.53020654 -0.2322202 ]\n",
      " [ 0.          0.36705474 -0.15737009]\n",
      " [ 0.         -0.14629582  0.24261404]\n",
      " [ 0.         -0.08877213  0.18799136]\n",
      " [ 0.          0.20486852  0.02360278]\n",
      " [ 0.         -0.07854344  0.25002723]\n",
      " [ 0.         -0.03748972  0.14111247]\n",
      " [ 0.         -0.0597867   0.25435404]\n",
      " [ 0.         -0.07409235  0.18348285]\n",
      " [ 0.          0.23653843  0.10488391]]\n",
      "a\n",
      "[-0. -0.]\n",
      "K\n",
      "[[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #0 | lambda learn rate = 0.0001\n",
      "Target = [[1.]\n",
      " [1.]]\n",
      "lambda end of trial = [[ 0.          0.5295144  -0.23291234]\n",
      " [ 0.          0.36630317 -0.15812166]\n",
      " [ 0.         -0.14698202  0.24192784]\n",
      " [ 0.         -0.08943258  0.1873309 ]\n",
      " [ 0.          0.20413015  0.02286441]\n",
      " [ 0.         -0.07929074  0.24927993]\n",
      " [ 0.         -0.03811982  0.14048238]\n",
      " [ 0.         -0.06043641  0.25370432]\n",
      " [ 0.         -0.07475953  0.18281567]\n",
      " [ 0.          0.23578705  0.10413253]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #1 | lambda learn rate = 0.0001\n",
      "Target = [[9.]\n",
      " [1.]]\n",
      "lambda end of trial = [[ 0.          0.52396291 -0.23352917]\n",
      " [ 0.          0.36020928 -0.15879876]\n",
      " [ 0.         -0.15342992  0.24121141]\n",
      " [ 0.         -0.09515494  0.18669509]\n",
      " [ 0.          0.19834631  0.02222176]\n",
      " [ 0.         -0.08487868  0.24865905]\n",
      " [ 0.         -0.04414093  0.13981337]\n",
      " [ 0.         -0.06717471  0.25295562]\n",
      " [ 0.         -0.08062389  0.18216407]\n",
      " [ 0.          0.22897401  0.10337553]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #2 | lambda learn rate = 0.0001\n",
      "Target = [[8.]\n",
      " [5.]]\n",
      "lambda end of trial = [[ 0.          0.5206343  -0.23560955]\n",
      " [ 0.          0.3565218  -0.16110344]\n",
      " [ 0.         -0.15735005  0.23876133]\n",
      " [ 0.         -0.09913954  0.18420471]\n",
      " [ 0.          0.19448416  0.01980791]\n",
      " [ 0.         -0.08884736  0.24617862]\n",
      " [ 0.         -0.04822586  0.13726029]\n",
      " [ 0.         -0.07099437  0.25056834]\n",
      " [ 0.         -0.08466346  0.17963935]\n",
      " [ 0.          0.22460669  0.10064596]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #3 | lambda learn rate = 0.0001\n",
      "Target = [[7.]\n",
      " [6.]]\n",
      "lambda end of trial = [[ 0.          0.51789098 -0.23796097]\n",
      " [ 0.          0.353647   -0.16356756]\n",
      " [ 0.         -0.1601917   0.23632563]\n",
      " [ 0.         -0.10186229  0.18187093]\n",
      " [ 0.          0.19148711  0.01723901]\n",
      " [ 0.         -0.09166253  0.24376562]\n",
      " [ 0.         -0.05098198  0.1348979 ]\n",
      " [ 0.         -0.07413039  0.24788032]\n",
      " [ 0.         -0.08778417  0.17696445]\n",
      " [ 0.          0.22150364  0.09798619]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #4 | lambda learn rate = 0.0001\n",
      "Target = [[4.]\n",
      " [5.]]\n",
      "lambda end of trial = [[ 0.          0.51595516 -0.24038074]\n",
      " [ 0.          0.35164603 -0.16606876]\n",
      " [ 0.         -0.16221726  0.23379368]\n",
      " [ 0.         -0.10381353  0.17943188]\n",
      " [ 0.          0.18941442  0.01464815]\n",
      " [ 0.         -0.09361166  0.24132921]\n",
      " [ 0.         -0.05297755  0.13240343]\n",
      " [ 0.         -0.07614553  0.24536139]\n",
      " [ 0.         -0.08991905  0.17429585]\n",
      " [ 0.          0.21944565  0.09541372]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #5 | lambda learn rate = 0.0001\n",
      "Target = [[7.]\n",
      " [8.]]\n",
      "lambda end of trial = [[ 0.          0.51434377 -0.24222234]\n",
      " [ 0.          0.35013382 -0.16779701]\n",
      " [ 0.         -0.16365002  0.23215624]\n",
      " [ 0.         -0.10512089  0.17793775]\n",
      " [ 0.          0.1877582   0.01275533]\n",
      " [ 0.         -0.09521724  0.23949426]\n",
      " [ 0.         -0.054416    0.13075949]\n",
      " [ 0.         -0.07781958  0.2434482 ]\n",
      " [ 0.         -0.09131832  0.17269668]\n",
      " [ 0.          0.21793913  0.09369197]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #6 | lambda learn rate = 0.0001\n",
      "Target = [[5.]\n",
      " [3.]]\n",
      "lambda end of trial = [[ 0.          0.51245119 -0.24335788]\n",
      " [ 0.          0.3484203  -0.16882512]\n",
      " [ 0.         -0.16549116  0.23105155]\n",
      " [ 0.         -0.10688978  0.17687642]\n",
      " [ 0.          0.18582385  0.01159472]\n",
      " [ 0.         -0.097068    0.23838381]\n",
      " [ 0.         -0.05629104  0.12963447]\n",
      " [ 0.         -0.0798834   0.2422099 ]\n",
      " [ 0.         -0.09324793  0.17153892]\n",
      " [ 0.          0.21585213  0.09243977]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #7 | lambda learn rate = 0.0001\n",
      "Target = [[9.]\n",
      " [5.]]\n",
      "lambda end of trial = [[ 0.          0.51167893 -0.24378692]\n",
      " [ 0.          0.34758019 -0.16929184]\n",
      " [ 0.         -0.16624497  0.23063277]\n",
      " [ 0.         -0.10770332  0.17642445]\n",
      " [ 0.          0.18489426  0.01107828]\n",
      " [ 0.         -0.0979668   0.23788447]\n",
      " [ 0.         -0.05719159  0.12913417]\n",
      " [ 0.         -0.08079743  0.24170211]\n",
      " [ 0.         -0.09406933  0.17108258]\n",
      " [ 0.          0.21483754  0.09187611]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #8 | lambda learn rate = 0.0001\n",
      "Target = [[9.]\n",
      " [1.]]\n",
      "lambda end of trial = [[ 0.          0.51030179 -0.24393993]\n",
      " [ 0.          0.34636477 -0.16942689]\n",
      " [ 0.         -0.16776249  0.23046416]\n",
      " [ 0.         -0.10926392  0.17625105]\n",
      " [ 0.          0.18338533  0.01091063]\n",
      " [ 0.         -0.09931169  0.23773504]\n",
      " [ 0.         -0.05858747  0.12897907]\n",
      " [ 0.         -0.08229811  0.24153537]\n",
      " [ 0.         -0.09546135  0.17092791]\n",
      " [ 0.          0.21319968  0.09169413]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #9 | lambda learn rate = 0.0001\n",
      "Target = [[5.]\n",
      " [8.]]\n",
      "lambda end of trial = [[ 0.          0.50953984 -0.24515906]\n",
      " [ 0.          0.34560573 -0.17064135]\n",
      " [ 0.         -0.16852058  0.22925121]\n",
      " [ 0.         -0.11002024  0.17504095]\n",
      " [ 0.          0.18265686  0.00974508]\n",
      " [ 0.         -0.10011563  0.23644874]\n",
      " [ 0.         -0.05943631  0.12762092]\n",
      " [ 0.         -0.08317208  0.24013701]\n",
      " [ 0.         -0.09625404  0.16965961]\n",
      " [ 0.          0.21228293  0.09022733]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #10 | lambda learn rate = 0.0001\n",
      "Target = [[9.]\n",
      " [0.]]\n",
      "lambda end of trial = [[ 0.          0.50819021 -0.24515906]\n",
      " [ 0.          0.34421552 -0.17064135]\n",
      " [ 0.         -0.16986664  0.22925121]\n",
      " [ 0.         -0.11117011  0.17504095]\n",
      " [ 0.          0.18143452  0.00974508]\n",
      " [ 0.         -0.10131489  0.23644874]\n",
      " [ 0.         -0.06060058  0.12762092]\n",
      " [ 0.         -0.0845117   0.24013701]\n",
      " [ 0.         -0.0973155   0.16965961]\n",
      " [ 0.          0.21098621  0.09022733]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #11 | lambda learn rate = 0.0001\n",
      "Target = [[4.]\n",
      " [2.]]\n",
      "lambda end of trial = [[ 0.          0.50648306 -0.24601263]\n",
      " [ 0.          0.34264937 -0.17142442]\n",
      " [ 0.         -0.17140921  0.22847992]\n",
      " [ 0.         -0.11272008  0.17426596]\n",
      " [ 0.          0.1797748   0.00891521]\n",
      " [ 0.         -0.10297186  0.23562026]\n",
      " [ 0.         -0.06218656  0.12682793]\n",
      " [ 0.         -0.08630456  0.23924058]\n",
      " [ 0.         -0.09877268  0.16893102]\n",
      " [ 0.          0.20922013  0.08934429]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #12 | lambda learn rate = 0.0001\n",
      "Target = [[4.]\n",
      " [5.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda end of trial = [[ 0.          0.50557244 -0.24715091]\n",
      " [ 0.          0.34175051 -0.172548  ]\n",
      " [ 0.         -0.17232755  0.227332  ]\n",
      " [ 0.         -0.11369988  0.17304122]\n",
      " [ 0.          0.17875378  0.00763894]\n",
      " [ 0.         -0.10388812  0.23447494]\n",
      " [ 0.         -0.06312449  0.12565551]\n",
      " [ 0.         -0.08732479  0.23796529]\n",
      " [ 0.         -0.09966435  0.16781644]\n",
      " [ 0.          0.2082057   0.08807625]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #13 | lambda learn rate = 0.0001\n",
      "Target = [[8.]\n",
      " [7.]]\n",
      "lambda end of trial = [[ 0.          0.50664485 -0.24621255]\n",
      " [ 0.          0.34275557 -0.17166857]\n",
      " [ 0.         -0.1711917   0.22832587]\n",
      " [ 0.         -0.11266124  0.17395002]\n",
      " [ 0.          0.17988253  0.00862659]\n",
      " [ 0.         -0.10278415  0.23544091]\n",
      " [ 0.         -0.06216451  0.1264955 ]\n",
      " [ 0.         -0.08623384  0.23891987]\n",
      " [ 0.         -0.09858982  0.16875665]\n",
      " [ 0.          0.2091527   0.08890488]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #14 | lambda learn rate = 0.0001\n",
      "Target = [[9.]\n",
      " [2.]]\n",
      "lambda end of trial = [[ 0.          0.50643861 -0.24625838]\n",
      " [ 0.          0.34264226 -0.17169375]\n",
      " [ 0.         -0.17136504  0.22828734]\n",
      " [ 0.         -0.11279969  0.17391926]\n",
      " [ 0.          0.17966436  0.00857811]\n",
      " [ 0.         -0.10311784  0.23536676]\n",
      " [ 0.         -0.06233885  0.12645675]\n",
      " [ 0.         -0.0865746   0.23884415]\n",
      " [ 0.         -0.09887137  0.16869408]\n",
      " [ 0.          0.2088655   0.08884105]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #15 | lambda learn rate = 0.0001\n",
      "Target = [[1.]\n",
      " [2.]]\n",
      "lambda end of trial = [[ 0.          0.50585191 -0.24743177]\n",
      " [ 0.          0.34212967 -0.17271892]\n",
      " [ 0.         -0.17191503  0.22718737]\n",
      " [ 0.         -0.1133315   0.17285563]\n",
      " [ 0.          0.17914346  0.00753631]\n",
      " [ 0.         -0.10370284  0.23419677]\n",
      " [ 0.         -0.06289071  0.12535303]\n",
      " [ 0.         -0.08715959  0.23767418]\n",
      " [ 0.         -0.09939385  0.16764911]\n",
      " [ 0.          0.20831138  0.08773282]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #16 | lambda learn rate = 0.0001\n",
      "Target = [[4.]\n",
      " [9.]]\n",
      "lambda end of trial = [[ 0.          0.50558382 -0.24803497]\n",
      " [ 0.          0.34190957 -0.17321417]\n",
      " [ 0.         -0.17213816  0.22668533]\n",
      " [ 0.         -0.11361728  0.17221263]\n",
      " [ 0.          0.17884797  0.00687146]\n",
      " [ 0.         -0.10400806  0.23351003]\n",
      " [ 0.         -0.06314728  0.12477575]\n",
      " [ 0.         -0.08741373  0.23710235]\n",
      " [ 0.         -0.0995972   0.16719159]\n",
      " [ 0.          0.20798961  0.08700882]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #17 | lambda learn rate = 0.0001\n",
      "Target = [[6.]\n",
      " [5.]]\n",
      "lambda end of trial = [[ 0.          0.50516746 -0.24838194]\n",
      " [ 0.          0.34156244 -0.17350344]\n",
      " [ 0.         -0.17247972  0.22640069]\n",
      " [ 0.         -0.11401356  0.1718824 ]\n",
      " [ 0.          0.17834366  0.00645121]\n",
      " [ 0.         -0.10459895  0.23301762]\n",
      " [ 0.         -0.06357315  0.12442085]\n",
      " [ 0.         -0.08791569  0.23668405]\n",
      " [ 0.         -0.09992129  0.16692151]\n",
      " [ 0.          0.20749947  0.08660037]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #18 | lambda learn rate = 0.0001\n",
      "Target = [[8.]\n",
      " [1.]]\n",
      "lambda end of trial = [[ 0.          0.50428667 -0.24849204]\n",
      " [ 0.          0.34069552 -0.17361181]\n",
      " [ 0.         -0.17335367  0.22629145]\n",
      " [ 0.         -0.11479138  0.17178517]\n",
      " [ 0.          0.17742699  0.00633662]\n",
      " [ 0.         -0.1055035   0.23290455]\n",
      " [ 0.         -0.0645639   0.12429701]\n",
      " [ 0.         -0.08883242  0.23656946]\n",
      " [ 0.         -0.1008193   0.16680926]\n",
      " [ 0.          0.20653685  0.08648004]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #19 | lambda learn rate = 0.0001\n",
      "Target = [[9.]\n",
      " [3.]]\n",
      "lambda end of trial = [[ 0.          0.50478945 -0.24832444]\n",
      " [ 0.          0.34133554 -0.17339846]\n",
      " [ 0.         -0.17277295  0.22648502]\n",
      " [ 0.         -0.11410996  0.17201231]\n",
      " [ 0.          0.17794508  0.00650932]\n",
      " [ 0.         -0.10505031  0.23305561]\n",
      " [ 0.         -0.063788    0.12455564]\n",
      " [ 0.         -0.08833451  0.23673543]\n",
      " [ 0.         -0.10018754  0.16701985]\n",
      " [ 0.          0.20704905  0.08665078]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #20 | lambda learn rate = 0.0001\n",
      "Target = [[8.]\n",
      " [7.]]\n",
      "lambda end of trial = [[ 0.          0.50620805 -0.24708316]\n",
      " [ 0.          0.34285285 -0.17207082]\n",
      " [ 0.         -0.17127265  0.22779779]\n",
      " [ 0.         -0.11269066  0.1732542 ]\n",
      " [ 0.          0.17927992  0.00767731]\n",
      " [ 0.         -0.10363656  0.23429264]\n",
      " [ 0.         -0.06242063  0.1257521 ]\n",
      " [ 0.         -0.08685028  0.23803413]\n",
      " [ 0.         -0.09862358  0.16838832]\n",
      " [ 0.          0.20837786  0.08781348]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #21 | lambda learn rate = 0.0001\n",
      "Target = [[2.]\n",
      " [7.]]\n",
      "lambda end of trial = [[ 0.          0.50571959 -0.24879278]\n",
      " [ 0.          0.34226607 -0.17412454]\n",
      " [ 0.         -0.17180757  0.22592555]\n",
      " [ 0.         -0.1132555   0.17127724]\n",
      " [ 0.          0.17870999  0.00568254]\n",
      " [ 0.         -0.10422518  0.23223249]\n",
      " [ 0.         -0.06299371  0.12374631]\n",
      " [ 0.         -0.08749452  0.23577929]\n",
      " [ 0.         -0.09914613  0.16655939]\n",
      " [ 0.          0.20776517  0.08566909]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #22 | lambda learn rate = 0.0001\n",
      "Target = [[0.]\n",
      " [3.]]\n",
      "lambda end of trial = [[ 0.          0.50571959 -0.25036608]\n",
      " [ 0.          0.34226607 -0.17561551]\n",
      " [ 0.         -0.17180757  0.2245259 ]\n",
      " [ 0.         -0.1132555   0.16994093]\n",
      " [ 0.          0.17870999  0.00417841]\n",
      " [ 0.         -0.10422518  0.23072267]\n",
      " [ 0.         -0.06299371  0.12233018]\n",
      " [ 0.         -0.08749452  0.23426724]\n",
      " [ 0.         -0.09914613  0.16502311]\n",
      " [ 0.          0.20776517  0.08406921]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #23 | lambda learn rate = 0.0001\n",
      "Target = [[3.]\n",
      " [4.]]\n",
      "lambda end of trial = [[ 0.          0.50499973 -0.2513259 ]\n",
      " [ 0.          0.34149407 -0.17664484]\n",
      " [ 0.         -0.17248575  0.22362167]\n",
      " [ 0.         -0.11396025  0.16900127]\n",
      " [ 0.          0.17785574  0.00303941]\n",
      " [ 0.         -0.10510236  0.2295531 ]\n",
      " [ 0.         -0.06375284  0.121318  ]\n",
      " [ 0.         -0.08832618  0.23315837]\n",
      " [ 0.         -0.09984209  0.16409516]\n",
      " [ 0.          0.2068691   0.08287444]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #24 | lambda learn rate = 0.0001\n",
      "Target = [[4.]\n",
      " [1.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda end of trial = [[ 0.          0.5034761  -0.2517068 ]\n",
      " [ 0.          0.34006073 -0.17700318]\n",
      " [ 0.         -0.17396135  0.22325277]\n",
      " [ 0.         -0.11545022  0.16862877]\n",
      " [ 0.          0.1763968   0.00267467]\n",
      " [ 0.         -0.10663494  0.22916995]\n",
      " [ 0.         -0.06519183  0.12095825]\n",
      " [ 0.         -0.09004563  0.23272851]\n",
      " [ 0.         -0.10132719  0.16372389]\n",
      " [ 0.          0.20519886  0.08245688]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #25 | lambda learn rate = 0.0001\n",
      "Target = [[5.]\n",
      " [9.]]\n",
      "lambda end of trial = [[ 0.          0.50421755 -0.25037219]\n",
      " [ 0.          0.34085449 -0.1755744 ]\n",
      " [ 0.         -0.17318082  0.22465774]\n",
      " [ 0.         -0.11463952  0.17008804]\n",
      " [ 0.          0.17701233  0.00378263]\n",
      " [ 0.         -0.10584583  0.23059035]\n",
      " [ 0.         -0.06449653  0.12220978]\n",
      " [ 0.         -0.08941555  0.23386265]\n",
      " [ 0.         -0.10053843  0.16514365]\n",
      " [ 0.          0.20590597  0.08372968]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #26 | lambda learn rate = 0.0001\n",
      "Target = [[4.]\n",
      " [6.]]\n",
      "lambda end of trial = [[ 0.          0.50379023 -0.25101318]\n",
      " [ 0.          0.3404484  -0.17618354]\n",
      " [ 0.         -0.17355477  0.2240968 ]\n",
      " [ 0.         -0.11507729  0.16943139]\n",
      " [ 0.          0.17658092  0.00313552]\n",
      " [ 0.         -0.10627681  0.22994388]\n",
      " [ 0.         -0.06488009  0.12163444]\n",
      " [ 0.         -0.08985986  0.23319619]\n",
      " [ 0.         -0.10088446  0.16462461]\n",
      " [ 0.          0.2054795   0.08308997]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #27 | lambda learn rate = 0.0001\n",
      "Target = [[5.]\n",
      " [4.]]\n",
      "lambda end of trial = [[ 0.          0.5032413  -0.25145232]\n",
      " [ 0.          0.33988114 -0.17663735]\n",
      " [ 0.         -0.17405156  0.22369937]\n",
      " [ 0.         -0.11568369  0.16894627]\n",
      " [ 0.          0.17595256  0.00263283]\n",
      " [ 0.         -0.10685829  0.2294787 ]\n",
      " [ 0.         -0.06542859  0.12119565]\n",
      " [ 0.         -0.09042794  0.23274173]\n",
      " [ 0.         -0.10143411  0.16418488]\n",
      " [ 0.          0.20483665  0.0825757 ]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #28 | lambda learn rate = 0.0001\n",
      "Target = [[4.]\n",
      " [4.]]\n",
      "lambda end of trial = [[ 0.          0.50241669 -0.25227693]\n",
      " [ 0.          0.33912717 -0.17739132]\n",
      " [ 0.         -0.17486086  0.22289007]\n",
      " [ 0.         -0.11646287  0.16816708]\n",
      " [ 0.          0.17504804  0.0017283 ]\n",
      " [ 0.         -0.10769273  0.22864426]\n",
      " [ 0.         -0.06617375  0.12045048]\n",
      " [ 0.         -0.09120553  0.23196414]\n",
      " [ 0.         -0.10216857  0.16345043]\n",
      " [ 0.          0.20400686  0.0817459 ]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #29 | lambda learn rate = 0.0001\n",
      "Target = [[8.]\n",
      " [5.]]\n",
      "lambda end of trial = [[ 0.          0.5039077  -0.25134505]\n",
      " [ 0.          0.34059109 -0.17647637]\n",
      " [ 0.         -0.1734424   0.22377661]\n",
      " [ 0.         -0.11501251  0.16907356]\n",
      " [ 0.          0.17653661  0.00265866]\n",
      " [ 0.         -0.10647518  0.22940522]\n",
      " [ 0.         -0.0647459   0.12134289]\n",
      " [ 0.         -0.08987412  0.23279626]\n",
      " [ 0.         -0.10067722  0.16438253]\n",
      " [ 0.          0.20556427  0.08271928]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #30 | lambda learn rate = 0.0001\n",
      "Target = [[7.]\n",
      " [7.]]\n",
      "lambda end of trial = [[ 0.          0.50530347 -0.24994928]\n",
      " [ 0.          0.34192554 -0.17514192]\n",
      " [ 0.         -0.17207034  0.22514867]\n",
      " [ 0.         -0.11365496  0.17043111]\n",
      " [ 0.          0.17785822  0.00398027]\n",
      " [ 0.         -0.10530578  0.23057463]\n",
      " [ 0.         -0.06358335  0.12250544]\n",
      " [ 0.         -0.08880195  0.23386844]\n",
      " [ 0.         -0.09931135  0.1657484 ]\n",
      " [ 0.          0.20673029  0.0838853 ]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #31 | lambda learn rate = 0.0001\n",
      "Target = [[1.]\n",
      " [1.]]\n",
      "lambda end of trial = [[ 0.          0.50474529 -0.25050746]\n",
      " [ 0.          0.3413334  -0.17573406]\n",
      " [ 0.         -0.17266746  0.22455155]\n",
      " [ 0.         -0.11421219  0.16987388]\n",
      " [ 0.          0.17727826  0.00340031]\n",
      " [ 0.         -0.10591854  0.22996186]\n",
      " [ 0.         -0.06410902  0.12197977]\n",
      " [ 0.         -0.08942373  0.23324666]\n",
      " [ 0.         -0.09995073  0.16510901]\n",
      " [ 0.          0.20609877  0.08325378]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #32 | lambda learn rate = 0.0001\n",
      "Target = [[9.]\n",
      " [5.]]\n",
      "lambda end of trial = [[ 0.          0.50654715 -0.24950643]\n",
      " [ 0.          0.34305956 -0.17477508]\n",
      " [ 0.         -0.17081974  0.22557806]\n",
      " [ 0.         -0.11238152  0.17089091]\n",
      " [ 0.          0.17910728  0.00441643]\n",
      " [ 0.         -0.10415199  0.23094328]\n",
      " [ 0.         -0.06225684  0.12300876]\n",
      " [ 0.         -0.08763009  0.23424313]\n",
      " [ 0.         -0.09826143  0.16604752]\n",
      " [ 0.          0.20763775  0.08410877]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #33 | lambda learn rate = 0.0001\n",
      "Target = [[2.]\n",
      " [2.]]\n",
      "lambda end of trial = [[ 0.          0.50569361 -0.25035997]\n",
      " [ 0.          0.34214823 -0.17568641]\n",
      " [ 0.         -0.17171471  0.22468309]\n",
      " [ 0.         -0.11333068  0.16994176]\n",
      " [ 0.          0.17820539  0.00351454]\n",
      " [ 0.         -0.10514928  0.22994599]\n",
      " [ 0.         -0.06317057  0.12209503]\n",
      " [ 0.         -0.08862933  0.23324388]\n",
      " [ 0.         -0.09917637  0.16513257]\n",
      " [ 0.          0.2066255   0.08309652]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #34 | lambda learn rate = 0.0001\n",
      "Target = [[5.]\n",
      " [9.]]\n",
      "lambda end of trial = [[ 0.          0.50626448 -0.2493324 ]\n",
      " [ 0.          0.34270583 -0.17468273]\n",
      " [ 0.         -0.17125991  0.22550174]\n",
      " [ 0.         -0.11282113  0.17085894]\n",
      " [ 0.          0.17880079  0.00458625]\n",
      " [ 0.         -0.10463776  0.23086672]\n",
      " [ 0.         -0.06262387  0.12307909]\n",
      " [ 0.         -0.08808028  0.23423218]\n",
      " [ 0.         -0.09857959  0.16620678]\n",
      " [ 0.          0.20713951  0.08402174]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #35 | lambda learn rate = 0.0001\n",
      "Target = [[1.]\n",
      " [9.]]\n",
      "lambda end of trial = [[ 0.          0.50604759 -0.25128443]\n",
      " [ 0.          0.34247915 -0.17672284]\n",
      " [ 0.         -0.17150397  0.22330519]\n",
      " [ 0.         -0.11303877  0.16890022]\n",
      " [ 0.          0.17858506  0.00264475]\n",
      " [ 0.         -0.10485889  0.22887659]\n",
      " [ 0.         -0.06283115  0.12121355]\n",
      " [ 0.         -0.08829687  0.2322829 ]\n",
      " [ 0.         -0.09879065  0.16430722]\n",
      " [ 0.          0.2068683   0.08158084]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #36 | lambda learn rate = 0.0001\n",
      "Target = [[1.]\n",
      " [8.]]\n",
      "lambda end of trial = [[ 0.          0.50586026 -0.25278306]\n",
      " [ 0.          0.3422642  -0.17844246]\n",
      " [ 0.         -0.17169229  0.22179862]\n",
      " [ 0.         -0.11324239  0.16727124]\n",
      " [ 0.          0.17839459  0.00112099]\n",
      " [ 0.         -0.10504757  0.22736717]\n",
      " [ 0.         -0.06301444  0.11974727]\n",
      " [ 0.         -0.08852477  0.23045964]\n",
      " [ 0.         -0.09898051  0.16278836]\n",
      " [ 0.          0.20664528  0.0797967 ]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #37 | lambda learn rate = 0.0001\n",
      "Target = [[5.]\n",
      " [7.]]\n",
      "lambda end of trial = [[ 0.          0.5060436  -0.25252638]\n",
      " [ 0.          0.34260987 -0.17795852]\n",
      " [ 0.         -0.1713982   0.22221035]\n",
      " [ 0.         -0.11301769  0.16758582]\n",
      " [ 0.          0.17858988  0.00139439]\n",
      " [ 0.         -0.10486626  0.227621  ]\n",
      " [ 0.         -0.06286294  0.11995937]\n",
      " [ 0.         -0.08833938  0.2307192 ]\n",
      " [ 0.         -0.09867458  0.16321666]\n",
      " [ 0.          0.20676598  0.07996568]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #38 | lambda learn rate = 0.0001\n",
      "Target = [[6.]\n",
      " [7.]]\n",
      "lambda end of trial = [[ 0.          0.50675339 -0.25169829]\n",
      " [ 0.          0.34326399 -0.17719538]\n",
      " [ 0.         -0.17080263  0.22290518]\n",
      " [ 0.         -0.1124285   0.1682732 ]\n",
      " [ 0.          0.17928211  0.002202  ]\n",
      " [ 0.         -0.10409613  0.22851949]\n",
      " [ 0.         -0.06210169  0.12084749]\n",
      " [ 0.         -0.08768711  0.23148018]\n",
      " [ 0.         -0.09790564  0.16411375]\n",
      " [ 0.          0.20731734  0.08060893]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #39 | lambda learn rate = 0.0001\n",
      "Target = [[1.]\n",
      " [1.]]\n",
      "lambda end of trial = [[ 0.          0.50613539 -0.25231629]\n",
      " [ 0.          0.34268151 -0.17777786]\n",
      " [ 0.         -0.17137527  0.22233253]\n",
      " [ 0.         -0.1129698   0.1677319 ]\n",
      " [ 0.          0.17877572  0.00169561]\n",
      " [ 0.         -0.10465492  0.22796069]\n",
      " [ 0.         -0.06266411  0.12028507]\n",
      " [ 0.         -0.08824653  0.23092075]\n",
      " [ 0.         -0.09843308  0.16358631]\n",
      " [ 0.          0.20676458  0.08005618]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #40 | lambda learn rate = 0.0001\n",
      "Target = [[8.]\n",
      " [9.]]\n",
      "lambda end of trial = [[ 0.          0.50898077 -0.24911524]\n",
      " [ 0.          0.3451729  -0.17497505]\n",
      " [ 0.         -0.16879322  0.22523735]\n",
      " [ 0.         -0.11049819  0.17051247]\n",
      " [ 0.          0.18142241  0.00467313]\n",
      " [ 0.         -0.10194143  0.23101337]\n",
      " [ 0.         -0.05987744  0.12342007]\n",
      " [ 0.         -0.08531367  0.23422023]\n",
      " [ 0.         -0.09582094  0.16652498]\n",
      " [ 0.          0.20967657  0.08333216]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================\n",
      "Trial #41 | lambda learn rate = 0.0001\n",
      "Target = [[3.]\n",
      " [0.]]\n",
      "lambda end of trial = [[ 0.          0.50739463 -0.24911524]\n",
      " [ 0.          0.34348601 -0.17497505]\n",
      " [ 0.         -0.17059933  0.22523735]\n",
      " [ 0.         -0.1124385   0.17051247]\n",
      " [ 0.          0.17975782  0.00467313]\n",
      " [ 0.         -0.10364502  0.23101337]\n",
      " [ 0.         -0.06168579  0.12342007]\n",
      " [ 0.         -0.08712477  0.23422023]\n",
      " [ 0.         -0.0974269   0.16652498]\n",
      " [ 0.          0.20785725  0.08333216]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #42 | lambda learn rate = 0.0001\n",
      "Target = [[2.]\n",
      " [2.]]\n",
      "lambda end of trial = [[ 0.          0.50640304 -0.25010683]\n",
      " [ 0.          0.34256106 -0.17589999]\n",
      " [ 0.         -0.17152559  0.22431108]\n",
      " [ 0.         -0.11327951  0.16967147]\n",
      " [ 0.          0.17892109  0.0038364 ]\n",
      " [ 0.         -0.10465411  0.23000428]\n",
      " [ 0.         -0.06266536  0.12244051]\n",
      " [ 0.         -0.0880672   0.2332778 ]\n",
      " [ 0.         -0.09838547  0.16556641]\n",
      " [ 0.          0.20679822  0.08227313]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #43 | lambda learn rate = 0.0001\n",
      "Target = [[2.]\n",
      " [9.]]\n",
      "lambda end of trial = [[ 0.          0.50622855 -0.25089206]\n",
      " [ 0.          0.34239338 -0.17665457]\n",
      " [ 0.         -0.17173077  0.22338777]\n",
      " [ 0.         -0.11346611  0.16883177]\n",
      " [ 0.          0.17872188  0.00293994]\n",
      " [ 0.         -0.10484799  0.22913181]\n",
      " [ 0.         -0.06285888  0.12156965]\n",
      " [ 0.         -0.08827856  0.23232667]\n",
      " [ 0.         -0.0985585   0.16478778]\n",
      " [ 0.          0.2065683   0.08123851]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #44 | lambda learn rate = 0.0001\n",
      "Target = [[7.]\n",
      " [4.]]\n",
      "lambda end of trial = [[ 0.          0.50602769 -0.25100683]\n",
      " [ 0.          0.34237901 -0.17666279]\n",
      " [ 0.         -0.17189786  0.22329229]\n",
      " [ 0.         -0.11348099  0.16882326]\n",
      " [ 0.          0.17858557  0.00286205]\n",
      " [ 0.         -0.10504005  0.22902206]\n",
      " [ 0.         -0.06286284  0.12156739]\n",
      " [ 0.         -0.08845432  0.23222623]\n",
      " [ 0.         -0.09872084  0.16469501]\n",
      " [ 0.          0.20631731  0.08109508]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #45 | lambda learn rate = 0.0001\n",
      "Target = [[3.]\n",
      " [5.]]\n",
      "lambda end of trial = [[ 0.          0.50537555 -0.25209373]\n",
      " [ 0.          0.34176713 -0.17768258]\n",
      " [ 0.         -0.17250457  0.2222811 ]\n",
      " [ 0.         -0.11411476  0.16776697]\n",
      " [ 0.          0.17794612  0.0017963 ]\n",
      " [ 0.         -0.10561816  0.22805853]\n",
      " [ 0.         -0.0634836   0.12053279]\n",
      " [ 0.         -0.08905241  0.23122942]\n",
      " [ 0.         -0.09934729  0.16365093]\n",
      " [ 0.          0.20559308  0.07988804]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #46 | lambda learn rate = 0.0001\n",
      "Target = [[9.]\n",
      " [3.]]\n",
      "lambda end of trial = [[ 0.          0.5064279  -0.25174295]\n",
      " [ 0.          0.34272787 -0.17736233]\n",
      " [ 0.         -0.17152615  0.22260724]\n",
      " [ 0.         -0.1131288   0.16809563]\n",
      " [ 0.          0.17882558  0.00208945]\n",
      " [ 0.         -0.10468743  0.22836878]\n",
      " [ 0.         -0.0625247   0.12085242]\n",
      " [ 0.         -0.08814349  0.23153239]\n",
      " [ 0.         -0.09827656  0.16400784]\n",
      " [ 0.          0.206575    0.08021535]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #47 | lambda learn rate = 0.0001\n",
      "Target = [[3.]\n",
      " [8.]]\n",
      "lambda end of trial = [[ 0.          0.50629009 -0.25211044]\n",
      " [ 0.          0.34256975 -0.17778398]\n",
      " [ 0.         -0.17168076  0.22219495]\n",
      " [ 0.         -0.11328987  0.16766613]\n",
      " [ 0.          0.17870298  0.00176251]\n",
      " [ 0.         -0.10483308  0.2279804 ]\n",
      " [ 0.         -0.06267209  0.12045938]\n",
      " [ 0.         -0.08829365  0.23113197]\n",
      " [ 0.         -0.09839542  0.16369087]\n",
      " [ 0.          0.2063462   0.07960521]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #48 | lambda learn rate = 0.0001\n",
      "Target = [[8.]\n",
      " [1.]]\n",
      "lambda end of trial = [[ 0.          0.5055385  -0.25220439]\n",
      " [ 0.          0.34180666 -0.17787936]\n",
      " [ 0.         -0.17256609  0.22208428]\n",
      " [ 0.         -0.1141414   0.16755969]\n",
      " [ 0.          0.17795701  0.00166926]\n",
      " [ 0.         -0.10577302  0.2278629 ]\n",
      " [ 0.         -0.0634658   0.12036016]\n",
      " [ 0.         -0.08915808  0.23102392]\n",
      " [ 0.         -0.09918644  0.16359199]\n",
      " [ 0.          0.20530847  0.07947549]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #49 | lambda learn rate = 0.0001\n",
      "Target = [[5.]\n",
      " [9.]]\n",
      "lambda end of trial = [[ 0.          0.50642801 -0.25060326]\n",
      " [ 0.          0.34265099 -0.17635958]\n",
      " [ 0.         -0.17178635  0.22348781]\n",
      " [ 0.         -0.1132572   0.16915125]\n",
      " [ 0.          0.17875635  0.00310808]\n",
      " [ 0.         -0.10478765  0.22963658]\n",
      " [ 0.         -0.0626414   0.12184408]\n",
      " [ 0.         -0.08836561  0.23245035]\n",
      " [ 0.         -0.0982922   0.16520163]\n",
      " [ 0.          0.20614764  0.080986  ]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #50 | lambda learn rate = 0.0001\n",
      "Target = [[7.]\n",
      " [9.]]\n",
      "lambda end of trial = [[ 0.          0.50820965 -0.24831259]\n",
      " [ 0.          0.34455723 -0.1739087 ]\n",
      " [ 0.         -0.17001999  0.22575884]\n",
      " [ 0.         -0.11135905  0.17159173]\n",
      " [ 0.          0.18056301  0.00543093]\n",
      " [ 0.         -0.10318667  0.23169498]\n",
      " [ 0.         -0.06068459  0.12435999]\n",
      " [ 0.         -0.08671257  0.2345757 ]\n",
      " [ 0.         -0.09652549  0.16747311]\n",
      " [ 0.          0.20777111  0.08307333]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #51 | lambda learn rate = 0.0001\n",
      "Target = [[2.]\n",
      " [8.]]\n",
      "lambda end of trial = [[ 0.          0.50784978 -0.24975207]\n",
      " [ 0.          0.3442507  -0.17513481]\n",
      " [ 0.         -0.1704189   0.22416319]\n",
      " [ 0.         -0.11173666  0.17008129]\n",
      " [ 0.          0.18014622  0.00376376]\n",
      " [ 0.         -0.10357561  0.23013922]\n",
      " [ 0.         -0.0610592   0.12286152]\n",
      " [ 0.         -0.08712559  0.23292361]\n",
      " [ 0.         -0.09689284  0.1660037 ]\n",
      " [ 0.          0.20735011  0.08138932]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #52 | lambda learn rate = 0.0001\n",
      "Target = [[2.]\n",
      " [8.]]\n",
      "lambda end of trial = [[ 0.          0.50755635 -0.25092582]\n",
      " [ 0.          0.34401671 -0.17607076]\n",
      " [ 0.         -0.17067557  0.22313652]\n",
      " [ 0.         -0.1120221   0.1689395 ]\n",
      " [ 0.          0.17988019  0.00269964]\n",
      " [ 0.         -0.10388098  0.22891773]\n",
      " [ 0.         -0.06133487  0.12175884]\n",
      " [ 0.         -0.08740994  0.23178619]\n",
      " [ 0.         -0.09716575  0.16491205]\n",
      " [ 0.          0.20706009  0.08022925]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #53 | lambda learn rate = 0.0001\n",
      "Target = [[6.]\n",
      " [0.]]\n",
      "lambda end of trial = [[ 0.          0.50604797 -0.25092582]\n",
      " [ 0.          0.34261379 -0.17607076]\n",
      " [ 0.         -0.17232718  0.22313652]\n",
      " [ 0.         -0.11360664  0.1689395 ]\n",
      " [ 0.          0.17812171  0.00269964]\n",
      " [ 0.         -0.10541372  0.22891773]\n",
      " [ 0.         -0.06295559  0.12175884]\n",
      " [ 0.         -0.08898252  0.23178619]\n",
      " [ 0.         -0.09878184  0.16491205]\n",
      " [ 0.          0.20522895  0.08022925]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #54 | lambda learn rate = 0.0001\n",
      "Target = [[8.]\n",
      " [1.]]\n",
      "lambda end of trial = [[ 0.          0.50542962 -0.25100311]\n",
      " [ 0.          0.34204689 -0.17614162]\n",
      " [ 0.         -0.17299574  0.22305295]\n",
      " [ 0.         -0.11424671  0.16885949]\n",
      " [ 0.          0.17747013  0.00261819]\n",
      " [ 0.         -0.10611319  0.22883029]\n",
      " [ 0.         -0.06359525  0.12167888]\n",
      " [ 0.         -0.08976245  0.23168869]\n",
      " [ 0.         -0.09935692  0.16484016]\n",
      " [ 0.          0.20445145  0.08013206]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #55 | lambda learn rate = 0.0001\n",
      "Target = [[4.]\n",
      " [1.]]\n",
      "lambda end of trial = [[ 0.          0.50388826 -0.25138845]\n",
      " [ 0.          0.34065698 -0.17648909]\n",
      " [ 0.         -0.17460886  0.22264967]\n",
      " [ 0.         -0.11564156  0.16851078]\n",
      " [ 0.          0.17594173  0.00223609]\n",
      " [ 0.         -0.10745867  0.22849392]\n",
      " [ 0.         -0.06501784  0.12132323]\n",
      " [ 0.         -0.09123894  0.23131957]\n",
      " [ 0.         -0.10067233  0.16451131]\n",
      " [ 0.          0.20280645  0.07972081]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #56 | lambda learn rate = 0.0001\n",
      "Target = [[7.]\n",
      " [3.]]\n",
      "lambda end of trial = [[ 0.          0.50398568 -0.2513467 ]\n",
      " [ 0.          0.34080777 -0.17642447]\n",
      " [ 0.         -0.17445305  0.22271645]\n",
      " [ 0.         -0.1155108   0.16856682]\n",
      " [ 0.          0.1759939   0.00225845]\n",
      " [ 0.         -0.10740588  0.22851655]\n",
      " [ 0.         -0.06486698  0.12138789]\n",
      " [ 0.         -0.091125    0.2313684 ]\n",
      " [ 0.         -0.10050968  0.16458102]\n",
      " [ 0.          0.20286074  0.07974408]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #57 | lambda learn rate = 0.0001\n",
      "Target = [[4.]\n",
      " [1.]]\n",
      "lambda end of trial = [[ 0.          0.50281076 -0.25164043]\n",
      " [ 0.          0.33949208 -0.1767534 ]\n",
      " [ 0.         -0.17555621  0.22244066]\n",
      " [ 0.         -0.11663433  0.16828594]\n",
      " [ 0.          0.1746619   0.00192545]\n",
      " [ 0.         -0.10872259  0.22818737]\n",
      " [ 0.         -0.06600811  0.1211026 ]\n",
      " [ 0.         -0.09235972  0.23105972]\n",
      " [ 0.         -0.10177517  0.16426464]\n",
      " [ 0.          0.20159875  0.07942858]]\n",
      "a = [0. 0.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #58 | lambda learn rate = 0.0001\n",
      "Target = [[8.]\n",
      " [5.]]\n",
      "lambda end of trial = [[ 0.          0.50452929 -0.25056634]\n",
      " [ 0.          0.34121482 -0.17567668]\n",
      " [ 0.         -0.17386931  0.22349497]\n",
      " [ 0.         -0.11500433  0.16930468]\n",
      " [ 0.          0.17629099  0.00294363]\n",
      " [ 0.         -0.1071021   0.22920018]\n",
      " [ 0.         -0.06429938  0.12217056]\n",
      " [ 0.         -0.09085704  0.2319989 ]\n",
      " [ 0.         -0.10033913  0.16516217]\n",
      " [ 0.          0.20336648  0.08053341]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #59 | lambda learn rate = 0.0001\n",
      "Target = [[9.]\n",
      " [5.]]\n",
      "lambda end of trial = [[ 0.          0.50654538 -0.2494463 ]\n",
      " [ 0.          0.34347793 -0.1744194 ]\n",
      " [ 0.         -0.17179723  0.22464612]\n",
      " [ 0.         -0.11283206  0.1705115 ]\n",
      " [ 0.          0.17834258  0.0040834 ]\n",
      " [ 0.         -0.10506173  0.23033371]\n",
      " [ 0.         -0.06211756  0.12338268]\n",
      " [ 0.         -0.08906146  0.23299644]\n",
      " [ 0.         -0.098245    0.16632558]\n",
      " [ 0.          0.20532473  0.08162133]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #60 | lambda learn rate = 0.0001\n",
      "Target = [[2.]\n",
      " [3.]]\n",
      "lambda end of trial = [[ 0.          0.50578848 -0.25058164]\n",
      " [ 0.          0.3427514  -0.17550919]\n",
      " [ 0.         -0.17251941  0.22356286]\n",
      " [ 0.         -0.11355001  0.16943457]\n",
      " [ 0.          0.17755647  0.00290425]\n",
      " [ 0.         -0.10580955  0.22921199]\n",
      " [ 0.         -0.06286227  0.12226561]\n",
      " [ 0.         -0.08986126  0.23179674]\n",
      " [ 0.         -0.0990658   0.16509438]\n",
      " [ 0.          0.20439753  0.08023054]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #61 | lambda learn rate = 0.0001\n",
      "Target = [[8.]\n",
      " [8.]]\n",
      "lambda end of trial = [[ 0.          0.50833808 -0.24803205]\n",
      " [ 0.          0.34494826 -0.17331234]\n",
      " [ 0.         -0.17023437  0.2258479 ]\n",
      " [ 0.         -0.11101311  0.17197148]\n",
      " [ 0.          0.17969327  0.00504104]\n",
      " [ 0.         -0.1036072   0.23141434]\n",
      " [ 0.         -0.06051566  0.12461222]\n",
      " [ 0.         -0.08757023  0.23408777]\n",
      " [ 0.         -0.09692278  0.1672374 ]\n",
      " [ 0.          0.20680981  0.08264281]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #62 | lambda learn rate = 0.0001\n",
      "Target = [[7.]\n",
      " [3.]]\n",
      "lambda end of trial = [[ 0.          0.50780877 -0.24825889]\n",
      " [ 0.          0.34443198 -0.1735336 ]\n",
      " [ 0.         -0.17081955  0.22559711]\n",
      " [ 0.         -0.1115795   0.17172874]\n",
      " [ 0.          0.17919349  0.00482686]\n",
      " [ 0.         -0.10412416  0.23119278]\n",
      " [ 0.         -0.06106546  0.12437659]\n",
      " [ 0.         -0.0881502   0.23383921]\n",
      " [ 0.         -0.09749523  0.16699206]\n",
      " [ 0.          0.20615067  0.08236032]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #63 | lambda learn rate = 0.0001\n",
      "Target = [[1.]\n",
      " [4.]]\n",
      "lambda end of trial = [[ 0.          0.50747921 -0.24957713]\n",
      " [ 0.          0.34407155 -0.17497531]\n",
      " [ 0.         -0.171116    0.22441128]\n",
      " [ 0.         -0.11194713  0.17025822]\n",
      " [ 0.          0.17883183  0.00338019]\n",
      " [ 0.         -0.10447597  0.22978554]\n",
      " [ 0.         -0.06141609  0.12297411]\n",
      " [ 0.         -0.08851232  0.23239071]\n",
      " [ 0.         -0.09785475  0.165554  ]\n",
      " [ 0.          0.20576591  0.08082129]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #64 | lambda learn rate = 0.0001\n",
      "Target = [[9.]\n",
      " [2.]]\n",
      "lambda end of trial = [[ 0.          0.50753487 -0.24956476]\n",
      " [ 0.          0.34414076 -0.17495993]\n",
      " [ 0.         -0.17096524  0.22444479]\n",
      " [ 0.         -0.11177353  0.1702968 ]\n",
      " [ 0.          0.17900036  0.00341765]\n",
      " [ 0.         -0.10431395  0.22982155]\n",
      " [ 0.         -0.06119926  0.12302229]\n",
      " [ 0.         -0.08841334  0.2324127 ]\n",
      " [ 0.         -0.09774434  0.16557853]\n",
      " [ 0.          0.20570419  0.08080757]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #65 | lambda learn rate = 0.0001\n",
      "Target = [[9.]\n",
      " [6.]]\n",
      "lambda end of trial = [[ 0.          0.5095237  -0.24823887]\n",
      " [ 0.          0.34617418 -0.17360432]\n",
      " [ 0.         -0.16894843  0.22578933]\n",
      " [ 0.         -0.10989821  0.17154701]\n",
      " [ 0.          0.18092494  0.0047007 ]\n",
      " [ 0.         -0.10236911  0.23111811]\n",
      " [ 0.         -0.05927718  0.12430368]\n",
      " [ 0.         -0.08677861  0.23350252]\n",
      " [ 0.         -0.09584435  0.16684519]\n",
      " [ 0.          0.20751132  0.08201232]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #66 | lambda learn rate = 0.0001\n",
      "Target = [[8.]\n",
      " [1.]]\n",
      "lambda end of trial = [[ 0.          0.50816002 -0.24840933]\n",
      " [ 0.          0.34502494 -0.17374798]\n",
      " [ 0.         -0.17020325  0.22563247]\n",
      " [ 0.         -0.11111837  0.17139449]\n",
      " [ 0.          0.1796684   0.00454363]\n",
      " [ 0.         -0.10374847  0.23094569]\n",
      " [ 0.         -0.06047089  0.12415446]\n",
      " [ 0.         -0.08839353  0.23330065]\n",
      " [ 0.         -0.09724751  0.1666698 ]\n",
      " [ 0.          0.20594609  0.08181667]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #67 | lambda learn rate = 0.0001\n",
      "Target = [[9.]\n",
      " [5.]]\n",
      "lambda end of trial = [[ 0.          0.50939493 -0.24772327]\n",
      " [ 0.          0.34625922 -0.17306226]\n",
      " [ 0.         -0.16897627  0.22631413]\n",
      " [ 0.         -0.10973329  0.17216398]\n",
      " [ 0.          0.18100352  0.00528536]\n",
      " [ 0.         -0.10252842  0.23162349]\n",
      " [ 0.         -0.059245    0.12483551]\n",
      " [ 0.         -0.08710261  0.23401783]\n",
      " [ 0.         -0.09588852  0.16742479]\n",
      " [ 0.          0.20723147  0.08253077]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #68 | lambda learn rate = 0.0001\n",
      "Target = [[5.]\n",
      " [5.]]\n",
      "lambda end of trial = [[ 0.          0.50876332 -0.24835488]\n",
      " [ 0.          0.34570898 -0.17361251]\n",
      " [ 0.         -0.16955262  0.22573779]\n",
      " [ 0.         -0.11035856  0.17153871]\n",
      " [ 0.          0.18033162  0.00461346]\n",
      " [ 0.         -0.10321495  0.23093696]\n",
      " [ 0.         -0.05984693  0.12423358]\n",
      " [ 0.         -0.08782731  0.23329313]\n",
      " [ 0.         -0.09658836  0.16672495]\n",
      " [ 0.          0.20645617  0.08175547]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #69 | lambda learn rate = 0.0001\n",
      "Target = [[6.]\n",
      " [1.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda end of trial = [[ 0.          0.50735108 -0.24859025]\n",
      " [ 0.          0.34430975 -0.17384571]\n",
      " [ 0.         -0.17099967  0.22549661]\n",
      " [ 0.         -0.11184354  0.17129121]\n",
      " [ 0.          0.17883832  0.00436458]\n",
      " [ 0.         -0.10475186  0.23068081]\n",
      " [ 0.         -0.06139057  0.12397631]\n",
      " [ 0.         -0.08938563  0.23303341]\n",
      " [ 0.         -0.09794453  0.16649892]\n",
      " [ 0.          0.20484545  0.08148702]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #70 | lambda learn rate = 0.0001\n",
      "Target = [[5.]\n",
      " [1.]]\n",
      "lambda end of trial = [[ 0.          0.50563455 -0.24893356]\n",
      " [ 0.          0.34293422 -0.17412082]\n",
      " [ 0.         -0.17233491  0.22522956]\n",
      " [ 0.         -0.11346247  0.17096742]\n",
      " [ 0.          0.17751092  0.0040991 ]\n",
      " [ 0.         -0.10616036  0.23039911]\n",
      " [ 0.         -0.06281853  0.12369071]\n",
      " [ 0.         -0.0909142   0.23272769]\n",
      " [ 0.         -0.09954545  0.16617874]\n",
      " [ 0.          0.20316661  0.08115125]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #71 | lambda learn rate = 0.0001\n",
      "Target = [[9.]\n",
      " [4.]]\n",
      "lambda end of trial = [[ 0.          0.5070422  -0.24830793]\n",
      " [ 0.          0.34428488 -0.17352052]\n",
      " [ 0.         -0.17095683  0.22584204]\n",
      " [ 0.         -0.11200102  0.17161696]\n",
      " [ 0.          0.17885969  0.00469855]\n",
      " [ 0.         -0.10484731  0.23098269]\n",
      " [ 0.         -0.06131334  0.12435969]\n",
      " [ 0.         -0.08969225  0.23327078]\n",
      " [ 0.         -0.09816718  0.1667913 ]\n",
      " [ 0.          0.20445836  0.08172536]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #72 | lambda learn rate = 0.0001\n",
      "Target = [[3.]\n",
      " [0.]]\n",
      "lambda end of trial = [[ 0.          0.50566689 -0.24830793]\n",
      " [ 0.          0.34274977 -0.17352052]\n",
      " [ 0.         -0.17230149  0.22584204]\n",
      " [ 0.         -0.11339338  0.17161696]\n",
      " [ 0.          0.17738601  0.00469855]\n",
      " [ 0.         -0.10637883  0.23098269]\n",
      " [ 0.         -0.06259234  0.12435969]\n",
      " [ 0.         -0.09115098  0.23327078]\n",
      " [ 0.         -0.09960676  0.1667913 ]\n",
      " [ 0.          0.20310348  0.08172536]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #73 | lambda learn rate = 0.0001\n",
      "Target = [[3.]\n",
      " [4.]]\n",
      "lambda end of trial = [[ 0.          0.50482313 -0.24943295]\n",
      " [ 0.          0.34197413 -0.17455471]\n",
      " [ 0.         -0.17315859  0.22469924]\n",
      " [ 0.         -0.11418709  0.17055867]\n",
      " [ 0.          0.17651544  0.00353779]\n",
      " [ 0.         -0.10720049  0.22988714]\n",
      " [ 0.         -0.06338812  0.12329865]\n",
      " [ 0.         -0.09198333  0.23216098]\n",
      " [ 0.         -0.10046055  0.16565292]\n",
      " [ 0.          0.20226029  0.08060111]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #74 | lambda learn rate = 0.0001\n",
      "Target = [[1.]\n",
      " [1.]]\n",
      "lambda end of trial = [[ 0.          0.50432035 -0.24993573]\n",
      " [ 0.          0.34152233 -0.17500651]\n",
      " [ 0.         -0.17367492  0.22418292]\n",
      " [ 0.         -0.11471706  0.17002871]\n",
      " [ 0.          0.17593811  0.00296046]\n",
      " [ 0.         -0.10773863  0.22934901]\n",
      " [ 0.         -0.06393864  0.12274812]\n",
      " [ 0.         -0.09249579  0.23164853]\n",
      " [ 0.         -0.10098579  0.16512767]\n",
      " [ 0.          0.20170235  0.08004317]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #75 | lambda learn rate = 0.0001\n",
      "Target = [[8.]\n",
      " [1.]]\n",
      "lambda end of trial = [[ 0.          0.50401664 -0.2499737 ]\n",
      " [ 0.          0.34135662 -0.17502722]\n",
      " [ 0.         -0.17398278  0.22414443]\n",
      " [ 0.         -0.11496076  0.16999824]\n",
      " [ 0.          0.17570546  0.00293138]\n",
      " [ 0.         -0.10805957  0.22930889]\n",
      " [ 0.         -0.06427821  0.12270568]\n",
      " [ 0.         -0.09286258  0.23160268]\n",
      " [ 0.         -0.10124684  0.16509504]\n",
      " [ 0.          0.20128265  0.07999071]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #76 | lambda learn rate = 0.0001\n",
      "Target = [[5.]\n",
      " [2.]]\n",
      "lambda end of trial = [[ 0.          0.50290291 -0.25041919]\n",
      " [ 0.          0.34032022 -0.17544179]\n",
      " [ 0.         -0.17513189  0.22368479]\n",
      " [ 0.         -0.11610826  0.16953924]\n",
      " [ 0.          0.17449206  0.00244602]\n",
      " [ 0.         -0.10925514  0.22883066]\n",
      " [ 0.         -0.06532742  0.12228599]\n",
      " [ 0.         -0.09418255  0.23107469]\n",
      " [ 0.         -0.10239324  0.16463648]\n",
      " [ 0.          0.19996637  0.0794642 ]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #77 | lambda learn rate = 0.0001\n",
      "Target = [[3.]\n",
      " [0.]]\n",
      "lambda end of trial = [[ 0.          0.50164057 -0.25041919]\n",
      " [ 0.          0.33904817 -0.17544179]\n",
      " [ 0.         -0.17635683  0.22368479]\n",
      " [ 0.         -0.11734845  0.16953924]\n",
      " [ 0.          0.17311338  0.00244602]\n",
      " [ 0.         -0.11049187  0.22883066]\n",
      " [ 0.         -0.06663285  0.12228599]\n",
      " [ 0.         -0.09560316  0.23107469]\n",
      " [ 0.         -0.10359578  0.16463648]\n",
      " [ 0.          0.19860589  0.0794642 ]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #78 | lambda learn rate = 0.0001\n",
      "Target = [[0.]\n",
      " [8.]]\n",
      "lambda end of trial = [[ 0.00000000e+00  5.01640572e-01 -2.52404176e-01]\n",
      " [ 0.00000000e+00  3.39048173e-01 -1.77186993e-01]\n",
      " [ 0.00000000e+00 -1.76356828e-01  2.21818156e-01]\n",
      " [ 0.00000000e+00 -1.17348453e-01  1.67291908e-01]\n",
      " [ 0.00000000e+00  1.73113381e-01  1.94029297e-04]\n",
      " [ 0.00000000e+00 -1.10491873e-01  2.26757917e-01]\n",
      " [ 0.00000000e+00 -6.66328464e-02  1.20281475e-01]\n",
      " [ 0.00000000e+00 -9.56031624e-02  2.28903163e-01]\n",
      " [ 0.00000000e+00 -1.03595777e-01  1.62328672e-01]\n",
      " [ 0.00000000e+00  1.98605892e-01  7.72416400e-02]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #79 | lambda learn rate = 0.0001\n",
      "Target = [[2.]\n",
      " [1.]]\n",
      "lambda end of trial = [[ 0.00000000e+00  5.00742578e-01 -2.52853173e-01]\n",
      " [ 0.00000000e+00  3.38162261e-01 -1.77629949e-01]\n",
      " [ 0.00000000e+00 -1.77365172e-01  2.21313984e-01]\n",
      " [ 0.00000000e+00 -1.18248186e-01  1.66842041e-01]\n",
      " [ 0.00000000e+00  1.72132885e-01 -2.96218374e-04]\n",
      " [ 0.00000000e+00 -1.11456758e-01  2.26275475e-01]\n",
      " [ 0.00000000e+00 -6.75161831e-02  1.19839807e-01]\n",
      " [ 0.00000000e+00 -9.66675701e-02  2.28370959e-01]\n",
      " [ 0.00000000e+00 -1.04459320e-01  1.61896900e-01]\n",
      " [ 0.00000000e+00  1.97548914e-01  7.67131505e-02]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #80 | lambda learn rate = 0.0001\n",
      "Target = [[0.]\n",
      " [5.]]\n",
      "lambda end of trial = [[ 0.          0.50074258 -0.25476495]\n",
      " [ 0.          0.33816226 -0.17936062]\n",
      " [ 0.         -0.17736517  0.21924059]\n",
      " [ 0.         -0.11824819  0.16492603]\n",
      " [ 0.          0.17213289 -0.00215402]\n",
      " [ 0.         -0.11145676  0.22449437]\n",
      " [ 0.         -0.06751618  0.11805898]\n",
      " [ 0.         -0.09666757  0.22648456]\n",
      " [ 0.         -0.10445932  0.16004698]\n",
      " [ 0.          0.19754891  0.07459294]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #81 | lambda learn rate = 0.0001\n",
      "Target = [[1.]\n",
      " [8.]]\n",
      "lambda end of trial = [[ 0.          0.50068067 -0.2552602 ]\n",
      " [ 0.          0.338109   -0.17978669]\n",
      " [ 0.         -0.1774383   0.21865555]\n",
      " [ 0.         -0.11831478  0.16439331]\n",
      " [ 0.          0.17206334 -0.00271041]\n",
      " [ 0.         -0.11153415  0.22387521]\n",
      " [ 0.         -0.06759175  0.11745447]\n",
      " [ 0.         -0.09676331  0.22571863]\n",
      " [ 0.         -0.10452355  0.15953318]\n",
      " [ 0.          0.1974476   0.07378241]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #82 | lambda learn rate = 0.0001\n",
      "Target = [[3.]\n",
      " [1.]]\n",
      "lambda end of trial = [[ 0.          0.49964561 -0.25560522]\n",
      " [ 0.          0.33710623 -0.18012094]\n",
      " [ 0.         -0.17834386  0.2183537 ]\n",
      " [ 0.         -0.11927404  0.16407356]\n",
      " [ 0.          0.17105828 -0.00304543]\n",
      " [ 0.         -0.11258564  0.22352472]\n",
      " [ 0.         -0.06852144  0.11714457]\n",
      " [ 0.         -0.09780518  0.22537134]\n",
      " [ 0.         -0.10556747  0.1591852 ]\n",
      " [ 0.          0.19628392  0.07339452]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #83 | lambda learn rate = 0.0001\n",
      "Target = [[8.]\n",
      " [2.]]\n",
      "lambda end of trial = [[ 0.          0.50077549 -0.25532275]\n",
      " [ 0.          0.33823181 -0.17983955]\n",
      " [ 0.         -0.17715607  0.21865064]\n",
      " [ 0.         -0.11807419  0.16437352]\n",
      " [ 0.          0.17201027 -0.00280743]\n",
      " [ 0.         -0.11156206  0.22378061]\n",
      " [ 0.         -0.06757685  0.11738072]\n",
      " [ 0.         -0.09675053  0.22563501]\n",
      " [ 0.         -0.10452824  0.15944501]\n",
      " [ 0.          0.19729403  0.07364704]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #84 | lambda learn rate = 0.0001\n",
      "Target = [[7.]\n",
      " [3.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda end of trial = [[ 0.          0.50149356 -0.25501501]\n",
      " [ 0.          0.33901578 -0.17950356]\n",
      " [ 0.         -0.17653636  0.21891624]\n",
      " [ 0.         -0.11730779  0.16470197]\n",
      " [ 0.          0.17278873 -0.0024738 ]\n",
      " [ 0.         -0.11075794  0.22412524]\n",
      " [ 0.         -0.06680162  0.11771296]\n",
      " [ 0.         -0.09613409  0.22589919]\n",
      " [ 0.         -0.10378629  0.15976299]\n",
      " [ 0.          0.19793772  0.07392291]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #85 | lambda learn rate = 0.0001\n",
      "Target = [[3.]\n",
      " [4.]]\n",
      "lambda end of trial = [[ 0.          0.5009895  -0.25568709]\n",
      " [ 0.          0.33853779 -0.18014087]\n",
      " [ 0.         -0.17702722  0.21826175]\n",
      " [ 0.         -0.11779461  0.16405289]\n",
      " [ 0.          0.17226362 -0.00317395]\n",
      " [ 0.         -0.11130844  0.22339124]\n",
      " [ 0.         -0.06724708  0.11711901]\n",
      " [ 0.         -0.0966905   0.22515732]\n",
      " [ 0.         -0.10433173  0.15903574]\n",
      " [ 0.          0.19738443  0.07318519]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #86 | lambda learn rate = 0.0001\n",
      "Target = [[7.]\n",
      " [5.]]\n",
      "lambda end of trial = [[ 0.          0.50276422 -0.25441943]\n",
      " [ 0.          0.34026201 -0.17890929]\n",
      " [ 0.         -0.17529587  0.21949843]\n",
      " [ 0.         -0.11616927  0.16521384]\n",
      " [ 0.          0.17370327 -0.00214563]\n",
      " [ 0.         -0.10962028  0.22459707]\n",
      " [ 0.         -0.06560901  0.11828906]\n",
      " [ 0.         -0.09512546  0.22627521]\n",
      " [ 0.         -0.10255693  0.16030345]\n",
      " [ 0.          0.19890478  0.07427115]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #87 | lambda learn rate = 0.0001\n",
      "Target = [[2.]\n",
      " [5.]]\n",
      "lambda end of trial = [[ 0.          0.50237853 -0.25538366]\n",
      " [ 0.          0.33989269 -0.1798326 ]\n",
      " [ 0.         -0.17565817  0.21859267]\n",
      " [ 0.         -0.11650806  0.16436686]\n",
      " [ 0.          0.17337068 -0.0029771 ]\n",
      " [ 0.         -0.11001257  0.22361635]\n",
      " [ 0.         -0.06593693  0.11746927]\n",
      " [ 0.         -0.09551614  0.2252985 ]\n",
      " [ 0.         -0.10288836  0.1594749 ]\n",
      " [ 0.          0.19848034  0.07321006]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #88 | lambda learn rate = 0.0001\n",
      "Target = [[4.]\n",
      " [3.]]\n",
      "lambda end of trial = [[ 0.          0.50171045 -0.25588471]\n",
      " [ 0.          0.3392878  -0.18028627]\n",
      " [ 0.         -0.17624981  0.21814894]\n",
      " [ 0.         -0.11708842  0.16393159]\n",
      " [ 0.          0.17279623 -0.00340794]\n",
      " [ 0.         -0.11064405  0.22314273]\n",
      " [ 0.         -0.06650974  0.11703966]\n",
      " [ 0.         -0.0961104   0.22485281]\n",
      " [ 0.         -0.10353714  0.15898831]\n",
      " [ 0.          0.19786659  0.07274975]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #89 | lambda learn rate = 0.0001\n",
      "Target = [[4.]\n",
      " [0.]]\n",
      "lambda end of trial = [[ 0.          0.50042864 -0.25588471]\n",
      " [ 0.          0.3379513  -0.18028627]\n",
      " [ 0.         -0.17747249  0.21814894]\n",
      " [ 0.         -0.11837704  0.16393159]\n",
      " [ 0.          0.17168143 -0.00340794]\n",
      " [ 0.         -0.11195637  0.22314273]\n",
      " [ 0.         -0.06772487  0.11703966]\n",
      " [ 0.         -0.09737991  0.22485281]\n",
      " [ 0.         -0.10479156  0.15898831]\n",
      " [ 0.          0.19654837  0.07274975]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #90 | lambda learn rate = 0.0001\n",
      "Target = [[5.]\n",
      " [4.]]\n",
      "lambda end of trial = [[ 0.          0.50048097 -0.25584285]\n",
      " [ 0.          0.33804723 -0.18020952]\n",
      " [ 0.         -0.17741932  0.21819148]\n",
      " [ 0.         -0.11831617  0.16398029]\n",
      " [ 0.          0.17171431 -0.00338163]\n",
      " [ 0.         -0.11188412  0.22320054]\n",
      " [ 0.         -0.06755587  0.11717486]\n",
      " [ 0.         -0.0973353   0.22488849]\n",
      " [ 0.         -0.10471662  0.15904826]\n",
      " [ 0.          0.19651263  0.07272116]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #91 | lambda learn rate = 0.0001\n",
      "Target = [[2.]\n",
      " [9.]]\n",
      "lambda end of trial = [[ 0.          0.50065343 -0.25506679]\n",
      " [ 0.          0.33824099 -0.17933763]\n",
      " [ 0.         -0.17726726  0.21887575]\n",
      " [ 0.         -0.11813016  0.16481734]\n",
      " [ 0.          0.17189207 -0.00258175]\n",
      " [ 0.         -0.11171059  0.22398142]\n",
      " [ 0.         -0.06741042  0.11782939]\n",
      " [ 0.         -0.09718648  0.22555819]\n",
      " [ 0.         -0.10456353  0.15973716]\n",
      " [ 0.          0.19667895  0.0734696 ]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #92 | lambda learn rate = 0.0001\n",
      "Target = [[8.]\n",
      " [1.]]\n",
      "lambda end of trial = [[ 0.          0.50122655 -0.25499515]\n",
      " [ 0.          0.33888877 -0.17925665]\n",
      " [ 0.         -0.17675352  0.21893997]\n",
      " [ 0.         -0.11751525  0.1648942 ]\n",
      " [ 0.          0.17248103 -0.00250813]\n",
      " [ 0.         -0.11114166  0.22405253]\n",
      " [ 0.         -0.06683429  0.11790141]\n",
      " [ 0.         -0.09667988  0.22562151]\n",
      " [ 0.         -0.10402306  0.15980472]\n",
      " [ 0.          0.19705124  0.07351614]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #93 | lambda learn rate = 0.0001\n",
      "Target = [[3.]\n",
      " [0.]]\n",
      "lambda end of trial = [[ 0.          0.49985994 -0.25499515]\n",
      " [ 0.          0.33757774 -0.17925665]\n",
      " [ 0.         -0.17816751  0.21893997]\n",
      " [ 0.         -0.11881465  0.1648942 ]\n",
      " [ 0.          0.17117472 -0.00250813]\n",
      " [ 0.         -0.11262877  0.22405253]\n",
      " [ 0.         -0.06820181  0.11790141]\n",
      " [ 0.         -0.09808648  0.22562151]\n",
      " [ 0.         -0.10555941  0.15980472]\n",
      " [ 0.          0.19554969  0.07351614]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #94 | lambda learn rate = 0.0001\n",
      "Target = [[2.]\n",
      " [0.]]\n",
      "lambda end of trial = [[ 0.          0.49882613 -0.25499515]\n",
      " [ 0.          0.33655703 -0.17925665]\n",
      " [ 0.         -0.17921184  0.21893997]\n",
      " [ 0.         -0.11985281  0.1648942 ]\n",
      " [ 0.          0.17010955 -0.00250813]\n",
      " [ 0.         -0.11366616  0.22405253]\n",
      " [ 0.         -0.06921728  0.11790141]\n",
      " [ 0.         -0.09914282  0.22562151]\n",
      " [ 0.         -0.10662714  0.15980472]\n",
      " [ 0.          0.19447688  0.07351614]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #95 | lambda learn rate = 0.0001\n",
      "Target = [[5.]\n",
      " [3.]]\n",
      "lambda end of trial = [[ 0.          0.49871473 -0.25506199]\n",
      " [ 0.          0.3364836  -0.17930071]\n",
      " [ 0.         -0.17925479  0.2189142 ]\n",
      " [ 0.         -0.12003195  0.16478672]\n",
      " [ 0.          0.16997758 -0.00258731]\n",
      " [ 0.         -0.11376497  0.22399325]\n",
      " [ 0.         -0.06931544  0.11784251]\n",
      " [ 0.         -0.09927421  0.22554268]\n",
      " [ 0.         -0.10675544  0.15972774]\n",
      " [ 0.          0.19426501  0.07338901]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #96 | lambda learn rate = 0.0001\n",
      "Target = [[8.]\n",
      " [5.]]\n",
      "lambda end of trial = [[ 0.          0.50136026 -0.25340853]\n",
      " [ 0.          0.33938602 -0.1774867 ]\n",
      " [ 0.         -0.1760943   0.22088951]\n",
      " [ 0.         -0.11692371  0.16672937]\n",
      " [ 0.          0.17270409 -0.00088324]\n",
      " [ 0.         -0.1108977   0.22578529]\n",
      " [ 0.         -0.06623496  0.11976781]\n",
      " [ 0.         -0.09670327  0.22714951]\n",
      " [ 0.         -0.10394271  0.16148569]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [ 0.          0.1969768   0.07508388]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #97 | lambda learn rate = 0.0001\n",
      "Target = [[5.]\n",
      " [9.]]\n",
      "lambda end of trial = [[ 0.          0.50279224 -0.25083098]\n",
      " [ 0.          0.34075534 -0.17502192]\n",
      " [ 0.         -0.17482897  0.22316709]\n",
      " [ 0.         -0.11555447  0.16919401]\n",
      " [ 0.          0.17399335  0.00143742]\n",
      " [ 0.         -0.10956561  0.22818306]\n",
      " [ 0.         -0.06491861  0.12213724]\n",
      " [ 0.         -0.09530925  0.22965875]\n",
      " [ 0.         -0.10260603  0.16389172]\n",
      " [ 0.          0.19830037  0.0774663 ]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #98 | lambda learn rate = 0.0001\n",
      "Target = [[9.]\n",
      " [4.]]\n",
      "lambda end of trial = [[ 0.          0.50496519 -0.24986522]\n",
      " [ 0.          0.34321496 -0.17392876]\n",
      " [ 0.         -0.17270015  0.22411324]\n",
      " [ 0.         -0.11332721  0.1701839 ]\n",
      " [ 0.          0.17629637  0.00246099]\n",
      " [ 0.         -0.10767428  0.22902365]\n",
      " [ 0.         -0.06251969  0.12320343]\n",
      " [ 0.         -0.09308979  0.23064518]\n",
      " [ 0.         -0.10052721  0.16481564]\n",
      " [ 0.          0.20063813  0.07850531]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "+++++++++++++++++++++++++++++++++++\n",
      "Session #7\n",
      "target at trial 0 = [[1.]\n",
      " [1.]]\n",
      "K MATX INIT= [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "A VECT INIT = [-0. -0.]\n",
      "lambda\n",
      "[[ 0.          0.53020654 -0.2322202 ]\n",
      " [ 0.          0.36705474 -0.15737009]\n",
      " [ 0.         -0.14629582  0.24261404]\n",
      " [ 0.         -0.08877213  0.18799136]\n",
      " [ 0.          0.20486852  0.02360278]\n",
      " [ 0.         -0.07854344  0.25002723]\n",
      " [ 0.         -0.03748972  0.14111247]\n",
      " [ 0.         -0.0597867   0.25435404]\n",
      " [ 0.         -0.07409235  0.18348285]\n",
      " [ 0.          0.23653843  0.10488391]]\n",
      "a\n",
      "[-0. -0.]\n",
      "K\n",
      "[[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #0 | lambda learn rate = 0.0001\n",
      "Target = [[1.]\n",
      " [1.]]\n",
      "lambda end of trial = [[ 0.          0.52958814 -0.23283859]\n",
      " [ 0.          0.36641977 -0.15800506]\n",
      " [ 0.         -0.14682859  0.24208127]\n",
      " [ 0.         -0.08937446  0.18738902]\n",
      " [ 0.          0.20418202  0.02291628]\n",
      " [ 0.         -0.07915564  0.24941504]\n",
      " [ 0.         -0.03814692  0.14045528]\n",
      " [ 0.         -0.06043845  0.25370228]\n",
      " [ 0.         -0.07476362  0.18281158]\n",
      " [ 0.          0.23586584  0.10421133]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #1 | lambda learn rate = 0.0001\n",
      "Target = [[4.]\n",
      " [1.]]\n",
      "lambda end of trial = [[ 0.          0.52699611 -0.2334866 ]\n",
      " [ 0.          0.36404832 -0.15859792]\n",
      " [ 0.         -0.14962675  0.24138173]\n",
      " [ 0.         -0.09186424  0.18676658]\n",
      " [ 0.          0.20115533  0.02215961]\n",
      " [ 0.         -0.08171222  0.24877589]\n",
      " [ 0.         -0.04079358  0.13979361]\n",
      " [ 0.         -0.0628216   0.25310649]\n",
      " [ 0.         -0.07732768  0.18217057]\n",
      " [ 0.          0.23320538  0.10354621]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #2 | lambda learn rate = 0.0001\n",
      "Target = [[5.]\n",
      " [6.]]\n",
      "lambda end of trial = [[ 0.          0.52411387 -0.23694528]\n",
      " [ 0.          0.36125471 -0.16195025]\n",
      " [ 0.         -0.15249223  0.23794316]\n",
      " [ 0.         -0.09448073  0.1836268 ]\n",
      " [ 0.          0.19836865  0.01881559]\n",
      " [ 0.         -0.08434527  0.24561623]\n",
      " [ 0.         -0.04363182  0.13638772]\n",
      " [ 0.         -0.06585553  0.24946578]\n",
      " [ 0.         -0.0801917   0.17873374]\n",
      " [ 0.          0.23019916  0.09993874]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #3 | lambda learn rate = 0.0001\n",
      "Target = [[9.]\n",
      " [9.]]\n",
      "lambda end of trial = [[ 0.          0.52015839 -0.24090076]\n",
      " [ 0.          0.35723138 -0.16597358]\n",
      " [ 0.         -0.15660728  0.23382811]\n",
      " [ 0.         -0.09869527  0.17941225]\n",
      " [ 0.          0.19405859  0.01450552]\n",
      " [ 0.         -0.08878124  0.24118027]\n",
      " [ 0.         -0.04774791  0.13227163]\n",
      " [ 0.         -0.07040809  0.24491322]\n",
      " [ 0.         -0.08428225  0.17464319]\n",
      " [ 0.          0.22599753  0.09573711]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #4 | lambda learn rate = 0.0001\n",
      "Target = [[6.]\n",
      " [8.]]\n",
      "lambda end of trial = [[ 0.          0.51798999 -0.24379196]\n",
      " [ 0.          0.3551818  -0.16870636]\n",
      " [ 0.         -0.15874663  0.23097564]\n",
      " [ 0.         -0.10075055  0.17667188]\n",
      " [ 0.          0.19160674  0.01123639]\n",
      " [ 0.         -0.09095603  0.23828055]\n",
      " [ 0.         -0.05009923  0.12913654]\n",
      " [ 0.         -0.07278678  0.24174163]\n",
      " [ 0.         -0.08657262  0.17158936]\n",
      " [ 0.          0.22367592  0.09264164]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #5 | lambda learn rate = 0.0001\n",
      "Target = [[6.]\n",
      " [3.]]\n",
      "lambda end of trial = [[ 0.          0.515015   -0.24527946]\n",
      " [ 0.          0.35224127 -0.17017662]\n",
      " [ 0.         -0.16112144  0.22978823]\n",
      " [ 0.         -0.10353479  0.17527976]\n",
      " [ 0.          0.18887074  0.00986839]\n",
      " [ 0.         -0.09365799  0.23692956]\n",
      " [ 0.         -0.0527864   0.12779295]\n",
      " [ 0.         -0.07532364  0.2404732 ]\n",
      " [ 0.         -0.08912959  0.17031088]\n",
      " [ 0.          0.2206761   0.09114172]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #6 | lambda learn rate = 0.0001\n",
      "Target = [[9.]\n",
      " [7.]]\n",
      "lambda end of trial = [[ 0.          0.51407338 -0.24601183]\n",
      " [ 0.          0.3515232  -0.17073513]\n",
      " [ 0.         -0.16197172  0.2291269 ]\n",
      " [ 0.         -0.1044252   0.17458722]\n",
      " [ 0.          0.18802707  0.0092122 ]\n",
      " [ 0.         -0.09467991  0.23613474]\n",
      " [ 0.         -0.05368482  0.12709418]\n",
      " [ 0.         -0.07623644  0.23976325]\n",
      " [ 0.         -0.09004237  0.16960093]\n",
      " [ 0.          0.21958496  0.09029306]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #7 | lambda learn rate = 0.0001\n",
      "Target = [[7.]\n",
      " [9.]]\n",
      "lambda end of trial = [[ 0.          0.51371444 -0.24647333]\n",
      " [ 0.          0.35121241 -0.17113471]\n",
      " [ 0.         -0.1624444   0.22851918]\n",
      " [ 0.         -0.10475941  0.17415753]\n",
      " [ 0.          0.18767168  0.00875528]\n",
      " [ 0.         -0.09510284  0.23559097]\n",
      " [ 0.         -0.05406925  0.12659991]\n",
      " [ 0.         -0.07664375  0.23923956]\n",
      " [ 0.         -0.09036578  0.16918512]\n",
      " [ 0.          0.21910472  0.08967561]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #8 | lambda learn rate = 0.0001\n",
      "Target = [[5.]\n",
      " [3.]]\n",
      "lambda end of trial = [[ 0.          0.51206307 -0.24746415]\n",
      " [ 0.          0.34948931 -0.17216857]\n",
      " [ 0.         -0.16407141  0.22754297]\n",
      " [ 0.         -0.10630707  0.17322893]\n",
      " [ 0.          0.18614345  0.00783834]\n",
      " [ 0.         -0.09695995  0.2344767 ]\n",
      " [ 0.         -0.05560331  0.12567948]\n",
      " [ 0.         -0.07851529  0.23811663]\n",
      " [ 0.         -0.09203053  0.16818627]\n",
      " [ 0.          0.21739724  0.08865112]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #9 | lambda learn rate = 0.0001\n",
      "Target = [[2.]\n",
      " [2.]]\n",
      "lambda end of trial = [[ 0.          0.51110179 -0.24842542]\n",
      " [ 0.          0.34847033 -0.17318755]\n",
      " [ 0.         -0.16487739  0.22673699]\n",
      " [ 0.         -0.10728718  0.17224882]\n",
      " [ 0.          0.1851288   0.00682369]\n",
      " [ 0.         -0.09788471  0.23355194]\n",
      " [ 0.         -0.05653967  0.12474313]\n",
      " [ 0.         -0.07956502  0.2370669 ]\n",
      " [ 0.         -0.09294166  0.16727515]\n",
      " [ 0.          0.21636546  0.08761935]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #10 | lambda learn rate = 0.0001\n",
      "Target = [[2.]\n",
      " [5.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda end of trial = [[ 0.          0.51034004 -0.25032981]\n",
      " [ 0.          0.34780579 -0.17484889]\n",
      " [ 0.         -0.1656851   0.22471771]\n",
      " [ 0.         -0.1079588   0.17056978]\n",
      " [ 0.          0.18436871  0.00492346]\n",
      " [ 0.         -0.09862256  0.23170732]\n",
      " [ 0.         -0.05729784  0.12284768]\n",
      " [ 0.         -0.08035814  0.23508411]\n",
      " [ 0.         -0.09369402  0.16539425]\n",
      " [ 0.          0.21558901  0.08567821]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #11 | lambda learn rate = 0.0001\n",
      "Target = [[5.]\n",
      " [5.]]\n",
      "lambda end of trial = [[ 0.          0.50957938 -0.25109047]\n",
      " [ 0.          0.34701889 -0.17563579]\n",
      " [ 0.         -0.16642246  0.22398035]\n",
      " [ 0.         -0.1086884   0.16984018]\n",
      " [ 0.          0.1836311   0.00418585]\n",
      " [ 0.         -0.09943679  0.23089309]\n",
      " [ 0.         -0.05803443  0.1221111 ]\n",
      " [ 0.         -0.08115065  0.2342916 ]\n",
      " [ 0.         -0.09450542  0.16458284]\n",
      " [ 0.          0.21476373  0.08485293]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #12 | lambda learn rate = 0.0001\n",
      "Target = [[5.]\n",
      " [1.]]\n",
      "lambda end of trial = [[ 0.          0.50775167 -0.25145602]\n",
      " [ 0.          0.34525784 -0.175988  ]\n",
      " [ 0.         -0.16803812  0.22365722]\n",
      " [ 0.         -0.11023941  0.16952997]\n",
      " [ 0.          0.18186862  0.00383335]\n",
      " [ 0.         -0.10122668  0.23053511]\n",
      " [ 0.         -0.05978299  0.12176139]\n",
      " [ 0.         -0.08297127  0.23392747]\n",
      " [ 0.         -0.09623876  0.16423617]\n",
      " [ 0.          0.21305798  0.08451178]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #13 | lambda learn rate = 0.0001\n",
      "Target = [[5.]\n",
      " [5.]]\n",
      "lambda end of trial = [[ 0.          0.50711344 -0.25209425]\n",
      " [ 0.          0.34456327 -0.17668257]\n",
      " [ 0.         -0.16874349  0.22295185]\n",
      " [ 0.         -0.11085035  0.16891904]\n",
      " [ 0.          0.18112054  0.00308527]\n",
      " [ 0.         -0.1019488   0.22981299]\n",
      " [ 0.         -0.0604191   0.12112528]\n",
      " [ 0.         -0.08377884  0.2331199 ]\n",
      " [ 0.         -0.09692116  0.16355378]\n",
      " [ 0.          0.2123234   0.08377721]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #14 | lambda learn rate = 0.0001\n",
      "Target = [[6.]\n",
      " [3.]]\n",
      "lambda end of trial = [[ 0.          0.50621246 -0.25254474]\n",
      " [ 0.          0.34381353 -0.17705744]\n",
      " [ 0.         -0.16959505  0.22252607]\n",
      " [ 0.         -0.11184675  0.16842083]\n",
      " [ 0.          0.1802208   0.0026354 ]\n",
      " [ 0.         -0.1028321   0.22937134]\n",
      " [ 0.         -0.06137584  0.12064691]\n",
      " [ 0.         -0.08465951  0.23267956]\n",
      " [ 0.         -0.09781478  0.16310697]\n",
      " [ 0.          0.21125736  0.08324419]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #15 | lambda learn rate = 0.0001\n",
      "Target = [[9.]\n",
      " [2.]]\n",
      "lambda end of trial = [[ 0.          0.50607558 -0.25257516]\n",
      " [ 0.          0.34369268 -0.17708429]\n",
      " [ 0.         -0.16974468  0.22249282]\n",
      " [ 0.         -0.11192546  0.16840334]\n",
      " [ 0.          0.18001075  0.00258872]\n",
      " [ 0.         -0.1029121   0.22935356]\n",
      " [ 0.         -0.06143335  0.12063413]\n",
      " [ 0.         -0.08488916  0.23262853]\n",
      " [ 0.         -0.09793554  0.16308013]\n",
      " [ 0.          0.21097727  0.08318195]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #16 | lambda learn rate = 0.0001\n",
      "Target = [[1.]\n",
      " [1.]]\n",
      "lambda end of trial = [[ 0.          0.50556253 -0.25308821]\n",
      " [ 0.          0.34311784 -0.17765913]\n",
      " [ 0.         -0.17035495  0.22188255]\n",
      " [ 0.         -0.11245204  0.16787677]\n",
      " [ 0.          0.1794864   0.00206437]\n",
      " [ 0.         -0.1034799   0.22878576]\n",
      " [ 0.         -0.06200451  0.12006297]\n",
      " [ 0.         -0.08549225  0.23202544]\n",
      " [ 0.         -0.09848947  0.1625262 ]\n",
      " [ 0.          0.21038146  0.08258614]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #17 | lambda learn rate = 0.0001\n",
      "Target = [[0.]\n",
      " [1.]]\n",
      "lambda end of trial = [[ 0.          0.50556253 -0.25368258]\n",
      " [ 0.          0.34311784 -0.17823673]\n",
      " [ 0.         -0.17035495  0.22127087]\n",
      " [ 0.         -0.11245204  0.16726544]\n",
      " [ 0.          0.1794864   0.00147953]\n",
      " [ 0.         -0.1034799   0.22817667]\n",
      " [ 0.         -0.06200451  0.11952329]\n",
      " [ 0.         -0.08549225  0.23142738]\n",
      " [ 0.         -0.09848947  0.16193442]\n",
      " [ 0.          0.21038146  0.08197203]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #18 | lambda learn rate = 0.0001\n",
      "Target = [[3.]\n",
      " [6.]]\n",
      "lambda end of trial = [[ 0.00000000e+00  5.04974129e-01 -2.54859370e-01]\n",
      " [ 0.00000000e+00  3.42624201e-01 -1.79224011e-01]\n",
      " [ 0.00000000e+00 -1.70837345e-01  2.20306089e-01]\n",
      " [ 0.00000000e+00 -1.12988075e-01  1.66193369e-01]\n",
      " [ 0.00000000e+00  1.78967965e-01  4.42653177e-04]\n",
      " [ 0.00000000e+00 -1.04105773e-01  2.26924922e-01]\n",
      " [ 0.00000000e+00 -6.25328731e-02  1.18466555e-01]\n",
      " [ 0.00000000e+00 -8.60390751e-02  2.30333732e-01]\n",
      " [ 0.00000000e+00 -9.90113056e-02  1.60890753e-01]\n",
      " [ 0.00000000e+00  2.09773381e-01  8.07558685e-02]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #19 | lambda learn rate = 0.0001\n",
      "Target = [[0.]\n",
      " [6.]]\n",
      "lambda end of trial = [[ 0.          0.50497413 -0.25682078]\n",
      " [ 0.          0.3426242  -0.18122254]\n",
      " [ 0.         -0.17083735  0.21838528]\n",
      " [ 0.         -0.11298808  0.16426777]\n",
      " [ 0.          0.17896797 -0.00172456]\n",
      " [ 0.         -0.10410577  0.22511411]\n",
      " [ 0.         -0.06253287  0.1164076 ]\n",
      " [ 0.         -0.08603908  0.22826126]\n",
      " [ 0.         -0.09901131  0.15912948]\n",
      " [ 0.          0.20977338  0.07877929]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #20 | lambda learn rate = 0.0001\n",
      "Target = [[3.]\n",
      " [4.]]\n",
      "lambda end of trial = [[ 0.          0.50434426 -0.25766061]\n",
      " [ 0.          0.34201904 -0.18202943]\n",
      " [ 0.         -0.17143988  0.21758189]\n",
      " [ 0.         -0.11353838  0.16353403]\n",
      " [ 0.          0.17826704 -0.00265913]\n",
      " [ 0.         -0.10467198  0.22435917]\n",
      " [ 0.         -0.06317033  0.11555767]\n",
      " [ 0.         -0.08667665  0.22741116]\n",
      " [ 0.         -0.09958566  0.15836367]\n",
      " [ 0.          0.2090326   0.07779158]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #21 | lambda learn rate = 0.0001\n",
      "Target = [[9.]\n",
      " [5.]]\n",
      "lambda end of trial = [[ 0.          0.50655359 -0.2564332 ]\n",
      " [ 0.          0.34397136 -0.1809448 ]\n",
      " [ 0.         -0.16927174  0.21878642]\n",
      " [ 0.         -0.11142576  0.16470771]\n",
      " [ 0.          0.18034307 -0.00150578]\n",
      " [ 0.         -0.10251754  0.22555608]\n",
      " [ 0.         -0.06097481  0.1167774 ]\n",
      " [ 0.         -0.08459181  0.2285694 ]\n",
      " [ 0.         -0.0973744   0.15959215]\n",
      " [ 0.          0.21100813  0.0788891 ]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #22 | lambda learn rate = 0.0001\n",
      "Target = [[1.]\n",
      " [3.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda end of trial = [[ 0.          0.50615348 -0.25763354]\n",
      " [ 0.          0.34361143 -0.18202459]\n",
      " [ 0.         -0.1696592   0.21762406]\n",
      " [ 0.         -0.11181567  0.16353799]\n",
      " [ 0.          0.17994655 -0.00269535]\n",
      " [ 0.         -0.10292776  0.22432543]\n",
      " [ 0.         -0.06132946  0.11571342]\n",
      " [ 0.         -0.08496622  0.22744617]\n",
      " [ 0.         -0.0977858   0.15835793]\n",
      " [ 0.          0.21055451  0.07752826]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #23 | lambda learn rate = 0.0001\n",
      "Target = [[5.]\n",
      " [8.]]\n",
      "lambda end of trial = [[ 0.          0.50687418 -0.25648042]\n",
      " [ 0.          0.34433379 -0.18086882]\n",
      " [ 0.         -0.16900874  0.21866479]\n",
      " [ 0.         -0.11113338  0.16462965]\n",
      " [ 0.          0.18065477 -0.0015622 ]\n",
      " [ 0.         -0.10222897  0.22544349]\n",
      " [ 0.         -0.06061457  0.11685725]\n",
      " [ 0.         -0.08421004  0.22865605]\n",
      " [ 0.         -0.09710205  0.15945194]\n",
      " [ 0.          0.21123003  0.07860909]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #24 | lambda learn rate = 0.0001\n",
      "Target = [[4.]\n",
      " [9.]]\n",
      "lambda end of trial = [[ 0.          0.50731422 -0.25549032]\n",
      " [ 0.          0.34480308 -0.17981292]\n",
      " [ 0.         -0.16858386  0.21962078]\n",
      " [ 0.         -0.11070868  0.16558523]\n",
      " [ 0.          0.1810979  -0.00056516]\n",
      " [ 0.         -0.10177519  0.2264645 ]\n",
      " [ 0.         -0.06013863  0.11792813]\n",
      " [ 0.         -0.083813    0.2295494 ]\n",
      " [ 0.         -0.0966916   0.16037544]\n",
      " [ 0.          0.21159189  0.07942326]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #25 | lambda learn rate = 0.0001\n",
      "Target = [[6.]\n",
      " [5.]]\n",
      "lambda end of trial = [[ 0.          0.50710579 -0.25566401]\n",
      " [ 0.          0.34466968 -0.17992408]\n",
      " [ 0.         -0.16872169  0.21950592]\n",
      " [ 0.         -0.11096777  0.16536932]\n",
      " [ 0.          0.18080749 -0.00080717]\n",
      " [ 0.         -0.10203066  0.2262516 ]\n",
      " [ 0.         -0.06032421  0.11777348]\n",
      " [ 0.         -0.08408332  0.22932413]\n",
      " [ 0.         -0.09687414  0.16022333]\n",
      " [ 0.          0.21131772  0.07919479]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #26 | lambda learn rate = 0.0001\n",
      "Target = [[2.]\n",
      " [0.]]\n",
      "lambda end of trial = [[ 0.          0.50584877 -0.25566401]\n",
      " [ 0.          0.34361227 -0.17992408]\n",
      " [ 0.         -0.16989272  0.21950592]\n",
      " [ 0.         -0.11206255  0.16536932]\n",
      " [ 0.          0.17966219 -0.00080717]\n",
      " [ 0.         -0.10303535  0.2262516 ]\n",
      " [ 0.         -0.06144361  0.11777348]\n",
      " [ 0.         -0.08518777  0.22932413]\n",
      " [ 0.         -0.09795417  0.16022333]\n",
      " [ 0.          0.2101874   0.07919479]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #27 | lambda learn rate = 0.0001\n",
      "Target = [[3.]\n",
      " [1.]]\n",
      "lambda end of trial = [[ 0.          0.50477025 -0.25602352]\n",
      " [ 0.          0.34251974 -0.18028826]\n",
      " [ 0.         -0.17121571  0.21906492]\n",
      " [ 0.         -0.1132532   0.16497244]\n",
      " [ 0.          0.1783958  -0.0012293 ]\n",
      " [ 0.         -0.10416489  0.22587509]\n",
      " [ 0.         -0.06266029  0.11736792]\n",
      " [ 0.         -0.08647152  0.22889622]\n",
      " [ 0.         -0.09912884  0.15983177]\n",
      " [ 0.          0.20890692  0.07876797]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #28 | lambda learn rate = 0.0001\n",
      "Target = [[6.]\n",
      " [6.]]\n",
      "lambda end of trial = [[ 0.          0.50527768 -0.25551608]\n",
      " [ 0.          0.34319797 -0.17961003]\n",
      " [ 0.         -0.17071423  0.2195664 ]\n",
      " [ 0.         -0.11265246  0.16557318]\n",
      " [ 0.          0.17896572 -0.00065938]\n",
      " [ 0.         -0.10368911  0.22635088]\n",
      " [ 0.         -0.06203978  0.11798843]\n",
      " [ 0.         -0.08588154  0.22948619]\n",
      " [ 0.         -0.09859477  0.16036584]\n",
      " [ 0.          0.20934659  0.07920764]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #29 | lambda learn rate = 0.0001\n",
      "Target = [[4.]\n",
      " [0.]]\n",
      "lambda end of trial = [[ 0.          0.50344561 -0.25551608]\n",
      " [ 0.          0.34132418 -0.17961003]\n",
      " [ 0.         -0.17260702  0.2195664 ]\n",
      " [ 0.         -0.11437431  0.16557318]\n",
      " [ 0.          0.17714321 -0.00065938]\n",
      " [ 0.         -0.1057034   0.22635088]\n",
      " [ 0.         -0.06407047  0.11798843]\n",
      " [ 0.         -0.08778891  0.22948619]\n",
      " [ 0.         -0.1003921   0.16036584]\n",
      " [ 0.          0.2073315   0.07920764]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #30 | lambda learn rate = 0.0001\n",
      "Target = [[6.]\n",
      " [0.]]\n",
      "lambda end of trial = [[ 0.          0.50186139 -0.25551608]\n",
      " [ 0.          0.3398676  -0.17961003]\n",
      " [ 0.         -0.17419196  0.2195664 ]\n",
      " [ 0.         -0.11582548  0.16557318]\n",
      " [ 0.          0.17547626 -0.00065938]\n",
      " [ 0.         -0.10716794  0.22635088]\n",
      " [ 0.         -0.06542904  0.11798843]\n",
      " [ 0.         -0.08929888  0.22948619]\n",
      " [ 0.         -0.10194772  0.16036584]\n",
      " [ 0.          0.20562754  0.07920764]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #31 | lambda learn rate = 0.0001\n",
      "Target = [[3.]\n",
      " [5.]]\n",
      "lambda end of trial = [[ 0.          0.50135361 -0.25636239]\n",
      " [ 0.          0.33933353 -0.18050014]\n",
      " [ 0.         -0.17469858  0.21872204]\n",
      " [ 0.         -0.11627206  0.16482887]\n",
      " [ 0.          0.17495502 -0.00152811]\n",
      " [ 0.         -0.1077001   0.22546395]\n",
      " [ 0.         -0.0659356   0.11714417]\n",
      " [ 0.         -0.0898256   0.22860833]\n",
      " [ 0.         -0.1024212   0.15957671]\n",
      " [ 0.          0.20512969  0.07837789]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #32 | lambda learn rate = 0.0001\n",
      "Target = [[2.]\n",
      " [5.]]\n",
      "lambda end of trial = [[ 0.          0.50090146 -0.25749276]\n",
      " [ 0.          0.33889461 -0.18159744]\n",
      " [ 0.         -0.17508242  0.21776244]\n",
      " [ 0.         -0.1167308   0.16368203]\n",
      " [ 0.          0.17448984 -0.00269106]\n",
      " [ 0.         -0.1081737   0.22427996]\n",
      " [ 0.         -0.06640356  0.11597427]\n",
      " [ 0.         -0.09028061  0.22747079]\n",
      " [ 0.         -0.10285906  0.15848206]\n",
      " [ 0.          0.20464449  0.07716488]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #33 | lambda learn rate = 0.0001\n",
      "Target = [[7.]\n",
      " [3.]]\n",
      "lambda end of trial = [[ 0.          0.50129433 -0.25732439]\n",
      " [ 0.          0.3392143  -0.18146043]\n",
      " [ 0.         -0.17466524  0.21794124]\n",
      " [ 0.         -0.11636682  0.16383802]\n",
      " [ 0.          0.17477327 -0.00256959]\n",
      " [ 0.         -0.10790452  0.22439532]\n",
      " [ 0.         -0.06596112  0.11616389]\n",
      " [ 0.         -0.08996852  0.22760454]\n",
      " [ 0.         -0.1024971   0.15863718]\n",
      " [ 0.          0.20492983  0.07728717]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #34 | lambda learn rate = 0.0001\n",
      "Target = [[6.]\n",
      " [2.]]\n",
      "lambda end of trial = [[ 0.          0.50069247 -0.25752501]\n",
      " [ 0.          0.3386614  -0.18164473]\n",
      " [ 0.         -0.17521297  0.21775866]\n",
      " [ 0.         -0.11683847  0.1636808 ]\n",
      " [ 0.          0.17432286 -0.00271973]\n",
      " [ 0.         -0.10843191  0.22421952]\n",
      " [ 0.         -0.06646512  0.11599589]\n",
      " [ 0.         -0.09062182  0.22738678]\n",
      " [ 0.         -0.10312987  0.15842626]\n",
      " [ 0.          0.20427221  0.07706796]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #35 | lambda learn rate = 0.0001\n",
      "Target = [[2.]\n",
      " [6.]]\n",
      "lambda end of trial = [[ 0.          0.50038619 -0.25844386]\n",
      " [ 0.          0.33834224 -0.1826022 ]\n",
      " [ 0.         -0.17552778  0.21681425]\n",
      " [ 0.         -0.11714215  0.16276976]\n",
      " [ 0.          0.17404909 -0.00354103]\n",
      " [ 0.         -0.10878708  0.223154  ]\n",
      " [ 0.         -0.06675542  0.11512498]\n",
      " [ 0.         -0.09096478  0.2263579 ]\n",
      " [ 0.         -0.10344645  0.1574765 ]\n",
      " [ 0.          0.20388732  0.0759133 ]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #36 | lambda learn rate = 0.0001\n",
      "Target = [[9.]\n",
      " [7.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda end of trial = [[ 0.          0.50443304 -0.25529631]\n",
      " [ 0.          0.3429556  -0.17901403]\n",
      " [ 0.         -0.17118843  0.22018929]\n",
      " [ 0.         -0.11272449  0.16620572]\n",
      " [ 0.          0.17764029 -0.00074788]\n",
      " [ 0.         -0.10470205  0.22633125]\n",
      " [ 0.         -0.06226669  0.11861622]\n",
      " [ 0.         -0.08649163  0.22983702]\n",
      " [ 0.         -0.09876195  0.16112001]\n",
      " [ 0.          0.20830893  0.07935233]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #37 | lambda learn rate = 0.0001\n",
      "Target = [[0.]\n",
      " [0.]]\n",
      "lambda end of trial = [[ 0.          0.50443304 -0.25529631]\n",
      " [ 0.          0.3429556  -0.17901403]\n",
      " [ 0.         -0.17118843  0.22018929]\n",
      " [ 0.         -0.11272449  0.16620572]\n",
      " [ 0.          0.17764029 -0.00074788]\n",
      " [ 0.         -0.10470205  0.22633125]\n",
      " [ 0.         -0.06226669  0.11861622]\n",
      " [ 0.         -0.08649163  0.22983702]\n",
      " [ 0.         -0.09876195  0.16112001]\n",
      " [ 0.          0.20830893  0.07935233]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #38 | lambda learn rate = 0.0001\n",
      "Target = [[6.]\n",
      " [2.]]\n",
      "lambda end of trial = [[ 0.          0.50359833 -0.25557454]\n",
      " [ 0.          0.34205693 -0.17931359]\n",
      " [ 0.         -0.17222704  0.21984309]\n",
      " [ 0.         -0.11354727  0.16593145]\n",
      " [ 0.          0.1767335  -0.00105014]\n",
      " [ 0.         -0.1055999   0.22603197]\n",
      " [ 0.         -0.06318752  0.11830927]\n",
      " [ 0.         -0.08743529  0.22952246]\n",
      " [ 0.         -0.0995989   0.16084102]\n",
      " [ 0.          0.20744994  0.079066  ]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #39 | lambda learn rate = 0.0001\n",
      "Target = [[5.]\n",
      " [7.]]\n",
      "lambda end of trial = [[ 0.00000000e+00  5.04043368e-01 -2.54951494e-01]\n",
      " [ 0.00000000e+00  3.42454121e-01 -1.78757517e-01]\n",
      " [ 0.00000000e+00 -1.71786112e-01  2.20460384e-01]\n",
      " [ 0.00000000e+00 -1.13091968e-01  1.66568880e-01]\n",
      " [ 0.00000000e+00  1.77185220e-01 -4.17729601e-04]\n",
      " [ 0.00000000e+00 -1.05148324e-01  2.26664167e-01]\n",
      " [ 0.00000000e+00 -6.26988595e-02  1.18993399e-01]\n",
      " [ 0.00000000e+00 -8.70901928e-02  2.30005606e-01]\n",
      " [ 0.00000000e+00 -9.91534052e-02  1.61464714e-01]\n",
      " [ 0.00000000e+00  2.07721007e-01  7.94454948e-02]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #40 | lambda learn rate = 0.0001\n",
      "Target = [[3.]\n",
      " [3.]]\n",
      "lambda end of trial = [[ 0.          0.50313832 -0.25585654]\n",
      " [ 0.          0.34152296 -0.17968867]\n",
      " [ 0.         -0.17267459  0.21957191]\n",
      " [ 0.         -0.11400119  0.16565966]\n",
      " [ 0.          0.17637364 -0.00122931]\n",
      " [ 0.         -0.10602549  0.225787  ]\n",
      " [ 0.         -0.06357378  0.11811847]\n",
      " [ 0.         -0.0878997   0.2291961 ]\n",
      " [ 0.         -0.10004567  0.16057245]\n",
      " [ 0.          0.20674787  0.07847236]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #41 | lambda learn rate = 0.0001\n",
      "Target = [[5.]\n",
      " [1.]]\n",
      "lambda end of trial = [[ 0.          0.50181297 -0.25612161]\n",
      " [ 0.          0.34009805 -0.17997366]\n",
      " [ 0.         -0.17410613  0.2192856 ]\n",
      " [ 0.         -0.11536303  0.16538729]\n",
      " [ 0.          0.17503515 -0.00149701]\n",
      " [ 0.         -0.10741354  0.22550939]\n",
      " [ 0.         -0.06500037  0.11783316]\n",
      " [ 0.         -0.08942946  0.22889015]\n",
      " [ 0.         -0.10132716  0.16031615]\n",
      " [ 0.          0.20525174  0.07817313]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #42 | lambda learn rate = 0.0001\n",
      "Target = [[7.]\n",
      " [2.]]\n",
      "lambda end of trial = [[ 0.          0.50136131 -0.25625066]\n",
      " [ 0.          0.33966156 -0.18009837]\n",
      " [ 0.         -0.17454003  0.21916163]\n",
      " [ 0.         -0.11583689  0.1652519 ]\n",
      " [ 0.          0.17458304 -0.00162618]\n",
      " [ 0.         -0.1078534   0.22538372]\n",
      " [ 0.         -0.06547017  0.11769893]\n",
      " [ 0.         -0.08996505  0.22873712]\n",
      " [ 0.         -0.10181543  0.16017664]\n",
      " [ 0.          0.20459663  0.07798596]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #43 | lambda learn rate = 0.0001\n",
      "Target = [[1.]\n",
      " [3.]]\n",
      "lambda end of trial = [[ 0.          0.50094395 -0.25750274]\n",
      " [ 0.          0.33926684 -0.18128253]\n",
      " [ 0.         -0.1749181   0.21802741]\n",
      " [ 0.         -0.1162106   0.16413078]\n",
      " [ 0.          0.17415183 -0.00291981]\n",
      " [ 0.         -0.10823951  0.22422538]\n",
      " [ 0.         -0.06587745  0.1164771 ]\n",
      " [ 0.         -0.09041315  0.22739281]\n",
      " [ 0.         -0.10221322  0.1589833 ]\n",
      " [ 0.          0.2041755   0.07672257]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #44 | lambda learn rate = 0.0001\n",
      "Target = [[8.]\n",
      " [5.]]\n",
      "lambda end of trial = [[ 0.          0.50298003 -0.25623018]\n",
      " [ 0.          0.34126251 -0.18003524]\n",
      " [ 0.         -0.17285257  0.21931836]\n",
      " [ 0.         -0.11449745  0.1652015 ]\n",
      " [ 0.          0.17613319 -0.00168146]\n",
      " [ 0.         -0.10630717  0.22543309]\n",
      " [ 0.         -0.06400982  0.11764437]\n",
      " [ 0.         -0.08842112  0.22863783]\n",
      " [ 0.         -0.10046023  0.16007891]\n",
      " [ 0.          0.20612504  0.07794103]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #45 | lambda learn rate = 0.0001\n",
      "Target = [[6.]\n",
      " [7.]]\n",
      "lambda end of trial = [[ 0.          0.5040864  -0.25493942]\n",
      " [ 0.          0.34240961 -0.17869695]\n",
      " [ 0.         -0.17168719  0.22067798]\n",
      " [ 0.         -0.1134868   0.16638059]\n",
      " [ 0.          0.17714023 -0.00050658]\n",
      " [ 0.         -0.10524197  0.22667582]\n",
      " [ 0.         -0.06280128  0.11905433]\n",
      " [ 0.         -0.08751533  0.22969459]\n",
      " [ 0.         -0.09933674  0.16138965]\n",
      " [ 0.          0.20704608  0.07901557]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #46 | lambda learn rate = 0.0001\n",
      "Target = [[0.]\n",
      " [9.]]\n",
      "lambda end of trial = [[ 0.          0.5040864  -0.25633981]\n",
      " [ 0.          0.34240961 -0.18015698]\n",
      " [ 0.         -0.17168719  0.21909692]\n",
      " [ 0.         -0.1134868   0.16484797]\n",
      " [ 0.          0.17714023 -0.00186809]\n",
      " [ 0.         -0.10524197  0.2252017 ]\n",
      " [ 0.         -0.06280128  0.11766914]\n",
      " [ 0.         -0.08751533  0.22805489]\n",
      " [ 0.         -0.09933674  0.16016648]\n",
      " [ 0.          0.20704608  0.07712812]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #47 | lambda learn rate = 0.0001\n",
      "Target = [[4.]\n",
      " [8.]]\n",
      "lambda end of trial = [[ 0.          0.5044677  -0.25557722]\n",
      " [ 0.          0.34281877 -0.17933868]\n",
      " [ 0.         -0.1713028   0.2198657 ]\n",
      " [ 0.         -0.11308665  0.16564828]\n",
      " [ 0.          0.17752122 -0.00110611]\n",
      " [ 0.         -0.10483815  0.22600935]\n",
      " [ 0.         -0.06239331  0.11848508]\n",
      " [ 0.         -0.08711593  0.22885371]\n",
      " [ 0.         -0.09894277  0.16095442]\n",
      " [ 0.          0.20737839  0.07779275]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #48 | lambda learn rate = 0.0001\n",
      "Target = [[6.]\n",
      " [9.]]\n",
      "lambda end of trial = [[ 0.          0.50611445 -0.2531071 ]\n",
      " [ 0.          0.34451193 -0.17679892]\n",
      " [ 0.         -0.16981742  0.22209376]\n",
      " [ 0.         -0.11138701  0.16819775]\n",
      " [ 0.          0.17917186  0.00136986]\n",
      " [ 0.         -0.1031937   0.22847603]\n",
      " [ 0.         -0.06067372  0.12106446]\n",
      " [ 0.         -0.08561426  0.23110621]\n",
      " [ 0.         -0.09725934  0.16347956]\n",
      " [ 0.          0.2089862   0.08020446]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #49 | lambda learn rate = 0.0001\n",
      "Target = [[9.]\n",
      " [6.]]\n",
      "lambda end of trial = [[ 0.          0.50787724 -0.2519319 ]\n",
      " [ 0.          0.34633804 -0.17558152]\n",
      " [ 0.         -0.16792409  0.22335598]\n",
      " [ 0.         -0.1094314   0.16950148]\n",
      " [ 0.          0.1811049   0.00265855]\n",
      " [ 0.         -0.1012522   0.22977036]\n",
      " [ 0.         -0.05873668  0.12235582]\n",
      " [ 0.         -0.08370042  0.2323821 ]\n",
      " [ 0.         -0.09539488  0.16472254]\n",
      " [ 0.          0.21077636  0.0813979 ]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #50 | lambda learn rate = 0.0001\n",
      "Target = [[6.]\n",
      " [0.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda end of trial = [[ 0.          0.50610714 -0.2519319 ]\n",
      " [ 0.          0.34458028 -0.17558152]\n",
      " [ 0.         -0.16985353  0.22335598]\n",
      " [ 0.         -0.11116444  0.16950148]\n",
      " [ 0.          0.17903484  0.00265855]\n",
      " [ 0.         -0.10332771  0.22977036]\n",
      " [ 0.         -0.06059724  0.12235582]\n",
      " [ 0.         -0.08576232  0.2323821 ]\n",
      " [ 0.         -0.09730597  0.16472254]\n",
      " [ 0.          0.2087486   0.0813979 ]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #51 | lambda learn rate = 0.0001\n",
      "Target = [[9.]\n",
      " [9.]]\n",
      "lambda end of trial = [[ 0.          0.50914469 -0.24889435]\n",
      " [ 0.          0.34801123 -0.17215057]\n",
      " [ 0.         -0.16684354  0.22636597]\n",
      " [ 0.         -0.1078347   0.17283122]\n",
      " [ 0.          0.18215168  0.00577539]\n",
      " [ 0.         -0.09997725  0.23312082]\n",
      " [ 0.         -0.05780296  0.12515011]\n",
      " [ 0.         -0.08252759  0.23561683]\n",
      " [ 0.         -0.09418058  0.16784794]\n",
      " [ 0.          0.21186331  0.08451261]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #52 | lambda learn rate = 0.0001\n",
      "Target = [[7.]\n",
      " [7.]]\n",
      "lambda end of trial = [[ 0.          0.50911732 -0.24892172]\n",
      " [ 0.          0.34802989 -0.17213191]\n",
      " [ 0.         -0.16689227  0.22631725]\n",
      " [ 0.         -0.10778034  0.17288559]\n",
      " [ 0.          0.18213468  0.00575838]\n",
      " [ 0.         -0.10000361  0.23309446]\n",
      " [ 0.         -0.05768159  0.12527148]\n",
      " [ 0.         -0.08256329  0.23558112]\n",
      " [ 0.         -0.09412898  0.16789954]\n",
      " [ 0.          0.21177386  0.08442317]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #53 | lambda learn rate = 0.0001\n",
      "Target = [[3.]\n",
      " [2.]]\n",
      "lambda end of trial = [[ 0.          0.50809158 -0.24960555]\n",
      " [ 0.          0.346782   -0.17296383]\n",
      " [ 0.         -0.16799972  0.22557895]\n",
      " [ 0.         -0.10903008  0.17205242]\n",
      " [ 0.          0.18092846  0.00495424]\n",
      " [ 0.         -0.10107311  0.23238146]\n",
      " [ 0.         -0.05879785  0.1245273 ]\n",
      " [ 0.         -0.08372468  0.23480687]\n",
      " [ 0.         -0.09518467  0.16719574]\n",
      " [ 0.          0.21049321  0.0835694 ]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #54 | lambda learn rate = 0.0001\n",
      "Target = [[2.]\n",
      " [8.]]\n",
      "lambda end of trial = [[ 0.          0.50777187 -0.2508844 ]\n",
      " [ 0.          0.34637199 -0.17460387]\n",
      " [ 0.         -0.16834228  0.22420871]\n",
      " [ 0.         -0.1093932   0.17059995]\n",
      " [ 0.          0.1805968   0.00362757]\n",
      " [ 0.         -0.10142337  0.2309804 ]\n",
      " [ 0.         -0.0592138   0.12286349]\n",
      " [ 0.         -0.08413171  0.23317872]\n",
      " [ 0.         -0.09559395  0.16555863]\n",
      " [ 0.          0.21005453  0.08181467]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #55 | lambda learn rate = 0.0001\n",
      "Target = [[9.]\n",
      " [8.]]\n",
      "lambda end of trial = [[ 0.          0.51006907 -0.24884245]\n",
      " [ 0.          0.34867845 -0.17255369]\n",
      " [ 0.         -0.16617845  0.22613211]\n",
      " [ 0.         -0.10712846  0.17261306]\n",
      " [ 0.          0.18260606  0.00541359]\n",
      " [ 0.         -0.09922295  0.23293633]\n",
      " [ 0.         -0.05705612  0.12478143]\n",
      " [ 0.         -0.08187765  0.23518233]\n",
      " [ 0.         -0.09340048  0.16750838]\n",
      " [ 0.          0.21187763  0.0834352 ]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #56 | lambda learn rate = 0.0001\n",
      "Target = [[7.]\n",
      " [9.]]\n",
      "lambda end of trial = [[ 0.          0.51081634 -0.24788167]\n",
      " [ 0.          0.34948036 -0.17152266]\n",
      " [ 0.         -0.16538362  0.22715405]\n",
      " [ 0.         -0.10639742  0.17355296]\n",
      " [ 0.          0.18322035  0.00620338]\n",
      " [ 0.         -0.098577    0.23376683]\n",
      " [ 0.         -0.05629931  0.12575448]\n",
      " [ 0.         -0.08122236  0.23602485]\n",
      " [ 0.         -0.09259842  0.16853959]\n",
      " [ 0.          0.21252539  0.08426804]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #57 | lambda learn rate = 0.0001\n",
      "Target = [[1.]\n",
      " [1.]]\n",
      "lambda end of trial = [[ 0.          0.51024035 -0.24845766]\n",
      " [ 0.          0.34894384 -0.17205918]\n",
      " [ 0.         -0.16593984  0.22659782]\n",
      " [ 0.         -0.106904    0.17304638]\n",
      " [ 0.          0.18264303  0.00562607]\n",
      " [ 0.         -0.09911784  0.23322599]\n",
      " [ 0.         -0.05687156  0.12518223]\n",
      " [ 0.         -0.08175561  0.2354916 ]\n",
      " [ 0.         -0.09312394  0.16801408]\n",
      " [ 0.          0.21196612  0.08370877]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #58 | lambda learn rate = 0.0001\n",
      "Target = [[0.]\n",
      " [2.]]\n",
      "lambda end of trial = [[ 0.          0.51024035 -0.2496529 ]\n",
      " [ 0.          0.34894384 -0.17339377]\n",
      " [ 0.         -0.16593984  0.22552355]\n",
      " [ 0.         -0.106904    0.17195234]\n",
      " [ 0.          0.18264303  0.00443183]\n",
      " [ 0.         -0.09911784  0.23209678]\n",
      " [ 0.         -0.05687156  0.12395651]\n",
      " [ 0.         -0.08175561  0.2343768 ]\n",
      " [ 0.         -0.09312394  0.16686963]\n",
      " [ 0.          0.21196612  0.08241025]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #59 | lambda learn rate = 0.0001\n",
      "Target = [[1.]\n",
      " [4.]]\n",
      "lambda end of trial = [[ 0.          0.50979835 -0.25142088]\n",
      " [ 0.          0.3485664  -0.17490351]\n",
      " [ 0.         -0.16631748  0.224013  ]\n",
      " [ 0.         -0.10727255  0.17047811]\n",
      " [ 0.          0.1822192   0.00273649]\n",
      " [ 0.         -0.09953474  0.2304292 ]\n",
      " [ 0.         -0.05733115  0.12211814]\n",
      " [ 0.         -0.08223078  0.23247614]\n",
      " [ 0.         -0.09355327  0.16515231]\n",
      " [ 0.          0.21150617  0.08057046]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #60 | lambda learn rate = 0.0001\n",
      "Target = [[6.]\n",
      " [6.]]\n",
      "lambda end of trial = [[ 0.          0.50952186 -0.25169738]\n",
      " [ 0.          0.3484118  -0.17505811]\n",
      " [ 0.         -0.16656536  0.22376512]\n",
      " [ 0.         -0.10756932  0.17018135]\n",
      " [ 0.          0.18196343  0.00248072]\n",
      " [ 0.         -0.09979632  0.23016763]\n",
      " [ 0.         -0.05759624  0.12185305]\n",
      " [ 0.         -0.08256809  0.23213882]\n",
      " [ 0.         -0.09386738  0.1648382 ]\n",
      " [ 0.          0.21112883  0.08019312]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #61 | lambda learn rate = 0.0001\n",
      "Target = [[2.]\n",
      " [7.]]\n",
      "lambda end of trial = [[ 0.          0.50907323 -0.25326758]\n",
      " [ 0.          0.3479602  -0.17663873]\n",
      " [ 0.         -0.16701269  0.22219947]\n",
      " [ 0.         -0.10802648  0.16858129]\n",
      " [ 0.          0.18154831  0.0010278 ]\n",
      " [ 0.         -0.10029455  0.2284238 ]\n",
      " [ 0.         -0.05803665  0.12031163]\n",
      " [ 0.         -0.08304677  0.23046344]\n",
      " [ 0.         -0.09429722  0.16333376]\n",
      " [ 0.          0.21063538  0.07846603]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #62 | lambda learn rate = 0.0001\n",
      "Target = [[1.]\n",
      " [5.]]\n",
      "lambda end of trial = [[ 0.          0.50868815 -0.255193  ]\n",
      " [ 0.          0.3476231  -0.1783242 ]\n",
      " [ 0.         -0.16739021  0.22031188]\n",
      " [ 0.         -0.108418    0.1666237 ]\n",
      " [ 0.          0.18117651 -0.00083116]\n",
      " [ 0.         -0.10065616  0.22661575]\n",
      " [ 0.         -0.05839636  0.11851305]\n",
      " [ 0.         -0.08346403  0.22837714]\n",
      " [ 0.         -0.09466397  0.1615    ]\n",
      " [ 0.          0.21025461  0.07656216]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #63 | lambda learn rate = 0.0001\n",
      "Target = [[5.]\n",
      " [4.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda end of trial = [[ 0.          0.50788572 -0.25583494]\n",
      " [ 0.          0.34676019 -0.17901453]\n",
      " [ 0.         -0.16811021  0.21973588]\n",
      " [ 0.         -0.10912048  0.16606171]\n",
      " [ 0.          0.18034726 -0.00149456]\n",
      " [ 0.         -0.10147412  0.22596138]\n",
      " [ 0.         -0.05912294  0.11793179]\n",
      " [ 0.         -0.08433151  0.22768316]\n",
      " [ 0.         -0.09543603  0.16088235]\n",
      " [ 0.          0.20936246  0.07584845]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #64 | lambda learn rate = 0.0001\n",
      "Target = [[4.]\n",
      " [2.]]\n",
      "lambda end of trial = [[ 0.          0.50669734 -0.25642913]\n",
      " [ 0.          0.34537308 -0.17970808]\n",
      " [ 0.         -0.16944064  0.21907067]\n",
      " [ 0.         -0.11040063  0.16542164]\n",
      " [ 0.          0.17912303 -0.00210667]\n",
      " [ 0.         -0.10280957  0.22529366]\n",
      " [ 0.         -0.06040121  0.11729265]\n",
      " [ 0.         -0.08562822  0.2270348 ]\n",
      " [ 0.         -0.09663633  0.1602822 ]\n",
      " [ 0.          0.2081143   0.07522437]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #65 | lambda learn rate = 0.0001\n",
      "Target = [[4.]\n",
      " [3.]]\n",
      "lambda end of trial = [[ 0.          0.50569051 -0.25718425]\n",
      " [ 0.          0.34438666 -0.1804479 ]\n",
      " [ 0.         -0.17046312  0.21830381]\n",
      " [ 0.         -0.11149056  0.16460418]\n",
      " [ 0.          0.17809061 -0.00288099]\n",
      " [ 0.         -0.10389645  0.2244785 ]\n",
      " [ 0.         -0.06138374  0.11655575]\n",
      " [ 0.         -0.086821    0.22614021]\n",
      " [ 0.         -0.09756095  0.15958874]\n",
      " [ 0.          0.20698652  0.07437853]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #66 | lambda learn rate = 0.0001\n",
      "Target = [[6.]\n",
      " [9.]]\n",
      "lambda end of trial = [[ 0.00000000e+00  5.07687704e-01 -2.54188463e-01]\n",
      " [ 0.00000000e+00  3.46122828e-01 -1.77843649e-01]\n",
      " [ 0.00000000e+00 -1.68673822e-01  2.20987752e-01]\n",
      " [ 0.00000000e+00 -1.09527805e-01  1.67548323e-01]\n",
      " [ 0.00000000e+00  1.79693423e-01 -4.76771647e-04]\n",
      " [ 0.00000000e+00 -1.02249848e-01  2.26948409e-01]\n",
      " [ 0.00000000e+00 -5.93459245e-02  1.19612480e-01]\n",
      " [ 0.00000000e+00 -8.49229279e-02  2.28987322e-01]\n",
      " [ 0.00000000e+00 -9.56347319e-02  1.62478059e-01]\n",
      " [ 0.00000000e+00  2.08642278e-01  7.68621685e-02]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #67 | lambda learn rate = 0.0001\n",
      "Target = [[1.]\n",
      " [9.]]\n",
      "lambda end of trial = [[ 0.          0.50761359 -0.25485546]\n",
      " [ 0.          0.34603705 -0.17861561]\n",
      " [ 0.         -0.16877062  0.2201166 ]\n",
      " [ 0.         -0.109609    0.1668176 ]\n",
      " [ 0.          0.17961434 -0.00118852]\n",
      " [ 0.         -0.10234336  0.22610682]\n",
      " [ 0.         -0.05941943  0.11895095]\n",
      " [ 0.         -0.08501061  0.22819816]\n",
      " [ 0.         -0.09572433  0.16167164]\n",
      " [ 0.          0.20855875  0.07611043]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #68 | lambda learn rate = 0.0001\n",
      "Target = [[0.]\n",
      " [6.]]\n",
      "lambda end of trial = [[ 0.          0.50761359 -0.25680567]\n",
      " [ 0.          0.34603705 -0.180494  ]\n",
      " [ 0.         -0.16877062  0.21835769]\n",
      " [ 0.         -0.109609    0.16488377]\n",
      " [ 0.          0.17961434 -0.00337645]\n",
      " [ 0.         -0.10234336  0.22406512]\n",
      " [ 0.         -0.05941943  0.11719147]\n",
      " [ 0.         -0.08501061  0.22619357]\n",
      " [ 0.         -0.09572433  0.15994845]\n",
      " [ 0.          0.20855875  0.07422414]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #69 | lambda learn rate = 0.0001\n",
      "Target = [[5.]\n",
      " [8.]]\n",
      "lambda end of trial = [[ 0.          0.50829155 -0.25572094]\n",
      " [ 0.          0.34682351 -0.17923567]\n",
      " [ 0.         -0.16801113  0.21957287]\n",
      " [ 0.         -0.1088251   0.166138  ]\n",
      " [ 0.          0.18022352 -0.00240177]\n",
      " [ 0.         -0.1017012   0.22509257]\n",
      " [ 0.         -0.05862351  0.11846494]\n",
      " [ 0.         -0.08431549  0.22730577]\n",
      " [ 0.         -0.09497828  0.16114214]\n",
      " [ 0.          0.20924231  0.07531783]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #70 | lambda learn rate = 0.0001\n",
      "Target = [[0.]\n",
      " [7.]]\n",
      "lambda end of trial = [[ 0.          0.50829155 -0.25749485]\n",
      " [ 0.          0.34682351 -0.18067106]\n",
      " [ 0.         -0.16801113  0.21786036]\n",
      " [ 0.         -0.1088251   0.16467955]\n",
      " [ 0.          0.18022352 -0.00421415]\n",
      " [ 0.         -0.1017012   0.22326503]\n",
      " [ 0.         -0.05862351  0.11665251]\n",
      " [ 0.         -0.08431549  0.22561067]\n",
      " [ 0.         -0.09497828  0.15946231]\n",
      " [ 0.          0.20924231  0.0736579 ]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #71 | lambda learn rate = 0.0001\n",
      "Target = [[0.]\n",
      " [2.]]\n",
      "lambda end of trial = [[ 0.          0.50829155 -0.25879633]\n",
      " [ 0.          0.34682351 -0.18179034]\n",
      " [ 0.         -0.16801113  0.21674414]\n",
      " [ 0.         -0.1088251   0.16350384]\n",
      " [ 0.          0.18022352 -0.00538245]\n",
      " [ 0.         -0.1017012   0.22209791]\n",
      " [ 0.         -0.05862351  0.11556865]\n",
      " [ 0.         -0.08431549  0.22443392]\n",
      " [ 0.         -0.09497828  0.1582554 ]\n",
      " [ 0.          0.20924231  0.07247058]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #72 | lambda learn rate = 0.0001\n",
      "Target = [[7.]\n",
      " [1.]]\n",
      "lambda end of trial = [[ 0.          0.50671478 -0.25902158]\n",
      " [ 0.          0.34536114 -0.18199925]\n",
      " [ 0.         -0.16966222  0.21650827]\n",
      " [ 0.         -0.11042588  0.16327516]\n",
      " [ 0.          0.1786298  -0.00561013]\n",
      " [ 0.         -0.10339698  0.22185565]\n",
      " [ 0.         -0.06022701  0.11533958]\n",
      " [ 0.         -0.08584954  0.22421477]\n",
      " [ 0.         -0.09640673  0.15805134]\n",
      " [ 0.          0.20766478  0.07224522]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #73 | lambda learn rate = 0.0001\n",
      "Target = [[2.]\n",
      " [4.]]\n",
      "lambda end of trial = [[ 0.          0.50615076 -0.26014962]\n",
      " [ 0.          0.34478299 -0.18315555]\n",
      " [ 0.         -0.17025993  0.21531285]\n",
      " [ 0.         -0.11099775  0.16213141]\n",
      " [ 0.          0.17797414 -0.00692144]\n",
      " [ 0.         -0.10403839  0.22057283]\n",
      " [ 0.         -0.06089126  0.11401107]\n",
      " [ 0.         -0.08658991  0.22273404]\n",
      " [ 0.         -0.09700789  0.15684903]\n",
      " [ 0.          0.20707223  0.07106013]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #74 | lambda learn rate = 0.0001\n",
      "Target = [[8.]\n",
      " [1.]]\n",
      "lambda end of trial = [[ 0.          0.50521326 -0.26026681]\n",
      " [ 0.          0.34399529 -0.18325401]\n",
      " [ 0.         -0.17097813  0.21522308]\n",
      " [ 0.         -0.11188378  0.16202065]\n",
      " [ 0.          0.17713756 -0.00702602]\n",
      " [ 0.         -0.10487201  0.22046862]\n",
      " [ 0.         -0.06189099  0.11388611]\n",
      " [ 0.         -0.087523    0.2226174 ]\n",
      " [ 0.         -0.09782345  0.15674709]\n",
      " [ 0.          0.20617751  0.07094829]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #75 | lambda learn rate = 0.0001\n",
      "Target = [[1.]\n",
      " [5.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda end of trial = [[ 0.          0.50496587 -0.26150375]\n",
      " [ 0.          0.34377425 -0.18435921]\n",
      " [ 0.         -0.17122304  0.21399852]\n",
      " [ 0.         -0.11213419  0.16076862]\n",
      " [ 0.          0.17690434 -0.00819212]\n",
      " [ 0.         -0.10515443  0.21905652]\n",
      " [ 0.         -0.06212429  0.11271963]\n",
      " [ 0.         -0.08777321  0.22136631]\n",
      " [ 0.         -0.09806694  0.15552963]\n",
      " [ 0.          0.20590539  0.06958769]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #76 | lambda learn rate = 0.0001\n",
      "Target = [[9.]\n",
      " [5.]]\n",
      "lambda end of trial = [[ 0.          0.50772201 -0.25997256]\n",
      " [ 0.          0.34667443 -0.182748  ]\n",
      " [ 0.         -0.16839592  0.21556914]\n",
      " [ 0.         -0.10921247  0.1623918 ]\n",
      " [ 0.          0.17970115 -0.00663834]\n",
      " [ 0.         -0.1026854   0.2204282 ]\n",
      " [ 0.         -0.05915975  0.1143666 ]\n",
      " [ 0.         -0.08495965  0.22292941]\n",
      " [ 0.         -0.09530494  0.15706407]\n",
      " [ 0.          0.20855187  0.07105795]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #77 | lambda learn rate = 0.0001\n",
      "Target = [[3.]\n",
      " [9.]]\n",
      "lambda end of trial = [[ 0.          0.50824034 -0.25841758]\n",
      " [ 0.          0.34719269 -0.18119322]\n",
      " [ 0.         -0.16792452  0.21698334]\n",
      " [ 0.         -0.10866835  0.16402416]\n",
      " [ 0.          0.18020788 -0.00511813]\n",
      " [ 0.         -0.10222322  0.22181474]\n",
      " [ 0.         -0.05865093  0.11589306]\n",
      " [ 0.         -0.08442279  0.22453999]\n",
      " [ 0.         -0.09471579  0.15883152]\n",
      " [ 0.          0.20902997  0.07249225]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #78 | lambda learn rate = 0.0001\n",
      "Target = [[1.]\n",
      " [8.]]\n",
      "lambda end of trial = [[ 0.          0.50815053 -0.25913608]\n",
      " [ 0.          0.34711709 -0.18179798]\n",
      " [ 0.         -0.16800602  0.21633135]\n",
      " [ 0.         -0.10873693  0.16347556]\n",
      " [ 0.          0.1801387  -0.0056716 ]\n",
      " [ 0.         -0.10229886  0.22120961]\n",
      " [ 0.         -0.05871646  0.1153688 ]\n",
      " [ 0.         -0.08451124  0.22383235]\n",
      " [ 0.         -0.09478183  0.15830322]\n",
      " [ 0.          0.20893387  0.07172345]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #79 | lambda learn rate = 0.0001\n",
      "Target = [[2.]\n",
      " [0.]]\n",
      "lambda end of trial = [[ 0.          0.50714086 -0.25913608]\n",
      " [ 0.          0.3461603  -0.18179798]\n",
      " [ 0.         -0.16901454  0.21633135]\n",
      " [ 0.         -0.10974118  0.16347556]\n",
      " [ 0.          0.17917724 -0.0056716 ]\n",
      " [ 0.         -0.10321796  0.22120961]\n",
      " [ 0.         -0.05971173  0.1153688 ]\n",
      " [ 0.         -0.08555334  0.22383235]\n",
      " [ 0.         -0.095692    0.15830322]\n",
      " [ 0.          0.2079697   0.07172345]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #80 | lambda learn rate = 0.0001\n",
      "Target = [[3.]\n",
      " [5.]]\n",
      "lambda end of trial = [[ 0.          0.50674874 -0.2597896 ]\n",
      " [ 0.          0.34585362 -0.18230911]\n",
      " [ 0.         -0.16939407  0.21569881]\n",
      " [ 0.         -0.11010304  0.16287246]\n",
      " [ 0.          0.17885457 -0.00620937]\n",
      " [ 0.         -0.10365558  0.22048024]\n",
      " [ 0.         -0.06002929  0.11483953]\n",
      " [ 0.         -0.08586973  0.22330503]\n",
      " [ 0.         -0.09607065  0.15767215]\n",
      " [ 0.          0.20759886  0.07110539]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #81 | lambda learn rate = 0.0001\n",
      "Target = [[8.]\n",
      " [9.]]\n",
      "lambda end of trial = [[ 0.          0.5107321  -0.25530833]\n",
      " [ 0.          0.34942897 -0.17828683]\n",
      " [ 0.         -0.16565882  0.21990096]\n",
      " [ 0.         -0.10617278  0.167294  ]\n",
      " [ 0.          0.18251275 -0.00209392]\n",
      " [ 0.         -0.09991894  0.22468396]\n",
      " [ 0.         -0.05616741  0.11918415]\n",
      " [ 0.         -0.08187456  0.2277996 ]\n",
      " [ 0.         -0.09210203  0.16213684]\n",
      " [ 0.          0.2114938   0.0754872 ]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #82 | lambda learn rate = 0.0001\n",
      "Target = [[3.]\n",
      " [5.]]\n",
      "lambda end of trial = [[ 0.          0.51013101 -0.25631013]\n",
      " [ 0.          0.34885172 -0.17924892]\n",
      " [ 0.         -0.16628853  0.21885144]\n",
      " [ 0.         -0.10672896  0.16636703]\n",
      " [ 0.          0.18193085 -0.00306376]\n",
      " [ 0.         -0.10054752  0.22363632]\n",
      " [ 0.         -0.05673196  0.11824323]\n",
      " [ 0.         -0.08250844  0.22674312]\n",
      " [ 0.         -0.09264094  0.16123866]\n",
      " [ 0.          0.21088686  0.07447563]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #83 | lambda learn rate = 0.0001\n",
      "Target = [[2.]\n",
      " [1.]]\n",
      "lambda end of trial = [[ 0.          0.50910498 -0.25682315]\n",
      " [ 0.          0.34780448 -0.17977254]\n",
      " [ 0.         -0.16725834  0.21836654]\n",
      " [ 0.         -0.10778294  0.16584004]\n",
      " [ 0.          0.18090271 -0.00357782]\n",
      " [ 0.         -0.1016658   0.22307719]\n",
      " [ 0.         -0.05769591  0.11776125]\n",
      " [ 0.         -0.08361175  0.22619147]\n",
      " [ 0.         -0.0936801   0.16071908]\n",
      " [ 0.          0.20978182  0.07392311]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #84 | lambda learn rate = 0.0001\n",
      "Target = [[2.]\n",
      " [8.]]\n",
      "lambda end of trial = [[ 0.          0.50902707 -0.25713476]\n",
      " [ 0.          0.34770533 -0.18016915]\n",
      " [ 0.         -0.16737801  0.21788786]\n",
      " [ 0.         -0.10788186  0.16544437]\n",
      " [ 0.          0.18075934 -0.00415133]\n",
      " [ 0.         -0.1017747   0.22264159]\n",
      " [ 0.         -0.05779187  0.11737742]\n",
      " [ 0.         -0.08374012  0.22567802]\n",
      " [ 0.         -0.0938028   0.16022828]\n",
      " [ 0.          0.20964399  0.07337178]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #85 | lambda learn rate = 0.0001\n",
      "Target = [[9.]\n",
      " [9.]]\n",
      "lambda end of trial = [[ 0.00000000e+00  5.12705475e-01 -2.53456356e-01]\n",
      " [ 0.00000000e+00  3.51830282e-01 -1.76044193e-01]\n",
      " [ 0.00000000e+00 -1.63260921e-01  2.22004943e-01]\n",
      " [ 0.00000000e+00 -1.03805124e-01  1.69521102e-01]\n",
      " [ 0.00000000e+00  1.84844353e-01 -6.63176245e-05]\n",
      " [ 0.00000000e+00 -9.76622099e-02  2.26754077e-01]\n",
      " [ 0.00000000e+00 -5.34613096e-02  1.21707982e-01]\n",
      " [ 0.00000000e+00 -8.00008593e-02  2.29417273e-01]\n",
      " [ 0.00000000e+00 -8.99523398e-02  1.64078737e-01]\n",
      " [ 0.00000000e+00  2.13581664e-01  7.73094577e-02]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #86 | lambda learn rate = 0.0001\n",
      "Target = [[8.]\n",
      " [8.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda end of trial = [[ 0.          0.5140156  -0.25214623]\n",
      " [ 0.          0.35310434 -0.17477014]\n",
      " [ 0.         -0.16211889  0.22314698]\n",
      " [ 0.         -0.10255017  0.17077606]\n",
      " [ 0.          0.18593705  0.00102638]\n",
      " [ 0.         -0.09652478  0.2278915 ]\n",
      " [ 0.         -0.05217562  0.12299367]\n",
      " [ 0.         -0.07879777  0.23062037]\n",
      " [ 0.         -0.08870685  0.16532422]\n",
      " [ 0.          0.21465426  0.07838206]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #87 | lambda learn rate = 0.0001\n",
      "Target = [[6.]\n",
      " [3.]]\n",
      "lambda end of trial = [[ 0.00000000e+00  5.12600388e-01 -2.52853837e-01]\n",
      " [ 0.00000000e+00  3.51750471e-01 -1.75447070e-01]\n",
      " [ 0.00000000e+00 -1.63524058e-01  2.22444392e-01]\n",
      " [ 0.00000000e+00 -1.03888431e-01  1.70106927e-01]\n",
      " [ 0.00000000e+00  1.84323034e-01  2.19370933e-04]\n",
      " [ 0.00000000e+00 -9.80165940e-02  2.27145597e-01]\n",
      " [ 0.00000000e+00 -5.35966738e-02  1.22283144e-01]\n",
      " [ 0.00000000e+00 -8.03497296e-02  2.29844384e-01]\n",
      " [ 0.00000000e+00 -9.02760336e-02  1.64539633e-01]\n",
      " [ 0.00000000e+00  2.13078320e-01  7.75940862e-02]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #88 | lambda learn rate = 0.0001\n",
      "Target = [[1.]\n",
      " [7.]]\n",
      "lambda end of trial = [[ 0.          0.51239694 -0.25427797]\n",
      " [ 0.          0.35152687 -0.17701228]\n",
      " [ 0.         -0.16371731  0.22109165]\n",
      " [ 0.         -0.10409258  0.16867786]\n",
      " [ 0.          0.18409881 -0.00135022]\n",
      " [ 0.         -0.09823529  0.22561472]\n",
      " [ 0.         -0.05379434  0.12089946]\n",
      " [ 0.         -0.0805776   0.2282493 ]\n",
      " [ 0.         -0.09051533  0.16286459]\n",
      " [ 0.          0.21284964  0.07599336]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #89 | lambda learn rate = 0.0001\n",
      "Target = [[1.]\n",
      " [1.]]\n",
      "lambda end of trial = [[ 0.          0.51185021 -0.25482471]\n",
      " [ 0.          0.35098156 -0.17755759]\n",
      " [ 0.         -0.16428141  0.22052754]\n",
      " [ 0.         -0.10459238  0.16817807]\n",
      " [ 0.          0.18355455 -0.00189448]\n",
      " [ 0.         -0.09881354  0.22503647]\n",
      " [ 0.         -0.05436448  0.12032932]\n",
      " [ 0.         -0.0811765   0.2276504 ]\n",
      " [ 0.         -0.09114809  0.16223183]\n",
      " [ 0.          0.21226358  0.0754073 ]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #90 | lambda learn rate = 0.0001\n",
      "Target = [[6.]\n",
      " [1.]]\n",
      "lambda end of trial = [[ 0.          0.50998898 -0.25513491]\n",
      " [ 0.          0.34923412 -0.17784883]\n",
      " [ 0.         -0.16601106  0.22023927]\n",
      " [ 0.         -0.10635915  0.16788361]\n",
      " [ 0.          0.18137505 -0.00225773]\n",
      " [ 0.         -0.1008117   0.22470344]\n",
      " [ 0.         -0.05631961  0.12000347]\n",
      " [ 0.         -0.08323573  0.2273072 ]\n",
      " [ 0.         -0.09320113  0.16188965]\n",
      " [ 0.          0.2099345   0.07501912]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #91 | lambda learn rate = 0.0001\n",
      "Target = [[2.]\n",
      " [7.]]\n",
      "lambda end of trial = [[ 0.          0.50977372 -0.25588832]\n",
      " [ 0.          0.34904661 -0.17850512]\n",
      " [ 0.         -0.16622921  0.21947575]\n",
      " [ 0.         -0.10658887  0.16707959]\n",
      " [ 0.          0.18114063 -0.0030782 ]\n",
      " [ 0.         -0.10102988  0.22393978]\n",
      " [ 0.         -0.05654278  0.11922235]\n",
      " [ 0.         -0.08347935  0.22645452]\n",
      " [ 0.         -0.09342739  0.16109775]\n",
      " [ 0.          0.20967444  0.07410892]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #92 | lambda learn rate = 0.0001\n",
      "Target = [[2.]\n",
      " [5.]]\n",
      "lambda end of trial = [[ 0.          0.50931774 -0.25702827]\n",
      " [ 0.          0.34865126 -0.17949351]\n",
      " [ 0.         -0.1666906   0.21832225]\n",
      " [ 0.         -0.10704448  0.16594055]\n",
      " [ 0.          0.18067283 -0.00424768]\n",
      " [ 0.         -0.10147875  0.22281761]\n",
      " [ 0.         -0.05699506  0.11809165]\n",
      " [ 0.         -0.08394339  0.22529444]\n",
      " [ 0.         -0.09386196  0.16001132]\n",
      " [ 0.          0.20917918  0.07287076]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #93 | lambda learn rate = 0.0001\n",
      "Target = [[0.]\n",
      " [8.]]\n",
      "lambda end of trial = [[ 0.          0.50931774 -0.25809418]\n",
      " [ 0.          0.34865126 -0.18050332]\n",
      " [ 0.         -0.1666906   0.21726226]\n",
      " [ 0.         -0.10704448  0.16480815]\n",
      " [ 0.          0.18067283 -0.00540708]\n",
      " [ 0.         -0.10147875  0.22190747]\n",
      " [ 0.         -0.05699506  0.11712361]\n",
      " [ 0.         -0.08394339  0.2242201 ]\n",
      " [ 0.         -0.09386196  0.15906192]\n",
      " [ 0.          0.20917918  0.07172966]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #94 | lambda learn rate = 0.0001\n",
      "Target = [[1.]\n",
      " [3.]]\n",
      "lambda end of trial = [[ 0.          0.50892905 -0.25926024]\n",
      " [ 0.          0.34825167 -0.18170206]\n",
      " [ 0.         -0.16709005  0.21606392]\n",
      " [ 0.         -0.10741979  0.16368222]\n",
      " [ 0.          0.18023105 -0.00673243]\n",
      " [ 0.         -0.10190804  0.22061962]\n",
      " [ 0.         -0.05734212  0.11608243]\n",
      " [ 0.         -0.08432254  0.22308263]\n",
      " [ 0.         -0.09430446  0.15773442]\n",
      " [ 0.          0.20874322  0.07042179]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #95 | lambda learn rate = 0.0001\n",
      "Target = [[6.]\n",
      " [8.]]\n",
      "lambda end of trial = [[ 0.          0.5103674  -0.25734245]\n",
      " [ 0.          0.34968291 -0.17979374]\n",
      " [ 0.         -0.16538444  0.21833807]\n",
      " [ 0.         -0.10563228  0.16606556]\n",
      " [ 0.          0.18175495 -0.00470056]\n",
      " [ 0.         -0.10050048  0.22249637]\n",
      " [ 0.         -0.05570635  0.11826346]\n",
      " [ 0.         -0.08289271  0.22498908]\n",
      " [ 0.         -0.09269347  0.1598824 ]\n",
      " [ 0.          0.21024836  0.07242864]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #96 | lambda learn rate = 0.0001\n",
      "Target = [[0.]\n",
      " [4.]]\n",
      "lambda end of trial = [[ 0.          0.5103674  -0.25890354]\n",
      " [ 0.          0.34968291 -0.18135088]\n",
      " [ 0.         -0.16538444  0.2167567 ]\n",
      " [ 0.         -0.10563228  0.16441213]\n",
      " [ 0.          0.18175495 -0.00641348]\n",
      " [ 0.         -0.10050048  0.22107152]\n",
      " [ 0.         -0.05570635  0.11672209]\n",
      " [ 0.         -0.08289271  0.22328481]\n",
      " [ 0.         -0.09269347  0.15820899]\n",
      " [ 0.          0.21024836  0.07071829]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #97 | lambda learn rate = 0.0001\n",
      "Target = [[6.]\n",
      " [7.]]\n",
      "lambda end of trial = [[ 0.          0.51120214 -0.25792969]\n",
      " [ 0.          0.3505084  -0.18038781]\n",
      " [ 0.         -0.16454788  0.21773269]\n",
      " [ 0.         -0.10476066  0.16542903]\n",
      " [ 0.          0.18258715 -0.00544258]\n",
      " [ 0.         -0.09966864  0.22204199]\n",
      " [ 0.         -0.05475111  0.11783654]\n",
      " [ 0.         -0.08214952  0.22415186]\n",
      " [ 0.         -0.09182497  0.15922225]\n",
      " [ 0.          0.21089607  0.07147396]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #98 | lambda learn rate = 0.0001\n",
      "Target = [[2.]\n",
      " [0.]]\n",
      "lambda end of trial = [[ 0.          0.5100368  -0.25792969]\n",
      " [ 0.          0.34931638 -0.18038781]\n",
      " [ 0.         -0.16574282  0.21773269]\n",
      " [ 0.         -0.10584213  0.16542903]\n",
      " [ 0.          0.18143518 -0.00544258]\n",
      " [ 0.         -0.10082722  0.22204199]\n",
      " [ 0.         -0.05583801  0.11783654]\n",
      " [ 0.         -0.08330708  0.22415186]\n",
      " [ 0.         -0.09284141  0.15922225]\n",
      " [ 0.          0.2096695   0.07147396]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "+++++++++++++++++++++++++++++++++++\n",
      "Session #8\n",
      "target at trial 0 = [[1.]\n",
      " [1.]]\n",
      "K MATX INIT= [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "A VECT INIT = [-0. -0.]\n",
      "lambda\n",
      "[[ 0.          0.53020654 -0.2322202 ]\n",
      " [ 0.          0.36705474 -0.15737009]\n",
      " [ 0.         -0.14629582  0.24261404]\n",
      " [ 0.         -0.08877213  0.18799136]\n",
      " [ 0.          0.20486852  0.02360278]\n",
      " [ 0.         -0.07854344  0.25002723]\n",
      " [ 0.         -0.03748972  0.14111247]\n",
      " [ 0.         -0.0597867   0.25435404]\n",
      " [ 0.         -0.07409235  0.18348285]\n",
      " [ 0.          0.23653843  0.10488391]]\n",
      "a\n",
      "[-0. -0.]\n",
      "K\n",
      "[[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #0 | lambda learn rate = 0.0001\n",
      "Target = [[1.]\n",
      " [1.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda end of trial = [[ 0.          0.52950592 -0.23292082]\n",
      " [ 0.          0.36632218 -0.15810265]\n",
      " [ 0.         -0.14693026  0.2419796 ]\n",
      " [ 0.         -0.08942929  0.1873342 ]\n",
      " [ 0.          0.20416264  0.0228969 ]\n",
      " [ 0.         -0.0792209   0.24934977]\n",
      " [ 0.         -0.03814708  0.14045511]\n",
      " [ 0.         -0.06045401  0.25368673]\n",
      " [ 0.         -0.07472103  0.18285417]\n",
      " [ 0.          0.23581264  0.10415812]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #1 | lambda learn rate = 0.0001\n",
      "Target = [[5.]\n",
      " [8.]]\n",
      "lambda end of trial = [[ 0.          0.52598377 -0.23855625]\n",
      " [ 0.          0.36295199 -0.16349495]\n",
      " [ 0.         -0.15053585  0.23621067]\n",
      " [ 0.         -0.09260004  0.182261  ]\n",
      " [ 0.          0.20048462  0.01701207]\n",
      " [ 0.         -0.08311887  0.24311302]\n",
      " [ 0.         -0.0411948   0.13557877]\n",
      " [ 0.         -0.0642028   0.24768866]\n",
      " [ 0.         -0.07821084  0.17727047]\n",
      " [ 0.          0.2323392   0.09860062]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #2 | lambda learn rate = 0.0001\n",
      "Target = [[3.]\n",
      " [0.]]\n",
      "lambda end of trial = [[ 0.          0.52429628 -0.23855625]\n",
      " [ 0.          0.3612585  -0.16349495]\n",
      " [ 0.         -0.15242652  0.23621067]\n",
      " [ 0.         -0.094358    0.182261  ]\n",
      " [ 0.          0.19860407  0.01701207]\n",
      " [ 0.         -0.08515685  0.24311302]\n",
      " [ 0.         -0.04319235  0.13557877]\n",
      " [ 0.         -0.06614729  0.24768866]\n",
      " [ 0.         -0.08001952  0.17727047]\n",
      " [ 0.          0.23044523  0.09860062]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #3 | lambda learn rate = 0.0001\n",
      "Target = [[0.]\n",
      " [4.]]\n",
      "lambda end of trial = [[ 0.          0.52429628 -0.24134503]\n",
      " [ 0.          0.3612585  -0.16570483]\n",
      " [ 0.         -0.15242652  0.23372206]\n",
      " [ 0.         -0.094358    0.17967671]\n",
      " [ 0.          0.19860407  0.01426612]\n",
      " [ 0.         -0.08515685  0.24027523]\n",
      " [ 0.         -0.04319235  0.13314401]\n",
      " [ 0.         -0.06614729  0.24521249]\n",
      " [ 0.         -0.08001952  0.17466944]\n",
      " [ 0.          0.23044523  0.09586004]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #4 | lambda learn rate = 0.0001\n",
      "Target = [[6.]\n",
      " [4.]]\n",
      "lambda end of trial = [[ 0.          0.52122111 -0.24339514]\n",
      " [ 0.          0.35847925 -0.16755767]\n",
      " [ 0.         -0.15529667  0.23180862]\n",
      " [ 0.         -0.09715998  0.17780873]\n",
      " [ 0.          0.19582778  0.01241526]\n",
      " [ 0.         -0.0880585   0.2383408 ]\n",
      " [ 0.         -0.04629755  0.13107387]\n",
      " [ 0.         -0.06919867  0.24317824]\n",
      " [ 0.         -0.0830253   0.17266559]\n",
      " [ 0.          0.22717547  0.09368021]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #5 | lambda learn rate = 0.0001\n",
      "Target = [[3.]\n",
      " [8.]]\n",
      "lambda end of trial = [[ 0.          0.52023777 -0.24601736]\n",
      " [ 0.          0.35740527 -0.17042161]\n",
      " [ 0.         -0.15623499  0.22930644]\n",
      " [ 0.         -0.0981601   0.17514172]\n",
      " [ 0.          0.19482524  0.00974183]\n",
      " [ 0.         -0.08915971  0.23540424]\n",
      " [ 0.         -0.04711661  0.12888971]\n",
      " [ 0.         -0.07017684  0.24056978]\n",
      " [ 0.         -0.08399998  0.17006644]\n",
      " [ 0.          0.22618815  0.09104735]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #6 | lambda learn rate = 0.0001\n",
      "Target = [[9.]\n",
      " [2.]]\n",
      "lambda end of trial = [[ 0.          0.51664523 -0.2468157 ]\n",
      " [ 0.          0.35373166 -0.17123797]\n",
      " [ 0.         -0.15961655  0.22855498]\n",
      " [ 0.         -0.10152161  0.17439472]\n",
      " [ 0.          0.19157244  0.00901899]\n",
      " [ 0.         -0.0929234   0.23456786]\n",
      " [ 0.         -0.05081273  0.12806835]\n",
      " [ 0.         -0.0738429   0.2397551 ]\n",
      " [ 0.         -0.08768894  0.16924667]\n",
      " [ 0.          0.2223997   0.09020548]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #7 | lambda learn rate = 0.0001\n",
      "Target = [[8.]\n",
      " [8.]]\n",
      "lambda end of trial = [[ 0.          0.5157501  -0.24771084]\n",
      " [ 0.          0.3528649  -0.17210473]\n",
      " [ 0.         -0.16037075  0.22780077]\n",
      " [ 0.         -0.1023415   0.17357482]\n",
      " [ 0.          0.19069136  0.0081379 ]\n",
      " [ 0.         -0.09372708  0.23376418]\n",
      " [ 0.         -0.05161792  0.12726317]\n",
      " [ 0.         -0.07467108  0.23892692]\n",
      " [ 0.         -0.08846723  0.16846838]\n",
      " [ 0.          0.22134529  0.08915107]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #8 | lambda learn rate = 0.0001\n",
      "Target = [[4.]\n",
      " [5.]]\n",
      "lambda end of trial = [[ 0.          0.51449609 -0.24927835]\n",
      " [ 0.          0.35166089 -0.17360974]\n",
      " [ 0.         -0.16178993  0.2260268 ]\n",
      " [ 0.         -0.10362545  0.17196989]\n",
      " [ 0.          0.18939028  0.00651156]\n",
      " [ 0.         -0.09510741  0.23203877]\n",
      " [ 0.         -0.05289524  0.12566651]\n",
      " [ 0.         -0.07617458  0.23704754]\n",
      " [ 0.         -0.08964527  0.16699583]\n",
      " [ 0.          0.2199233   0.08737358]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #9 | lambda learn rate = 0.0001\n",
      "Target = [[6.]\n",
      " [3.]]\n",
      "lambda end of trial = [[ 0.          0.51260338 -0.2502247 ]\n",
      " [ 0.          0.34977394 -0.17455321]\n",
      " [ 0.         -0.16332446  0.22525954]\n",
      " [ 0.         -0.10533735  0.17111394]\n",
      " [ 0.          0.18749526  0.00556405]\n",
      " [ 0.         -0.09698609  0.23109943]\n",
      " [ 0.         -0.05513392  0.12454717]\n",
      " [ 0.         -0.07816973  0.23604996]\n",
      " [ 0.         -0.09152853  0.1660542 ]\n",
      " [ 0.          0.21796022  0.08639204]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #10 | lambda learn rate = 0.0001\n",
      "Target = [[6.]\n",
      " [2.]]\n",
      "lambda end of trial = [[ 0.          0.51090903 -0.25078949]\n",
      " [ 0.          0.34817818 -0.17508514]\n",
      " [ 0.         -0.16530306  0.2246    ]\n",
      " [ 0.         -0.1071258   0.17051779]\n",
      " [ 0.          0.18570473  0.0049672 ]\n",
      " [ 0.         -0.09903336  0.23041701]\n",
      " [ 0.         -0.05703496  0.12391349]\n",
      " [ 0.         -0.07991633  0.23546777]\n",
      " [ 0.         -0.09357526  0.16537196]\n",
      " [ 0.          0.21605212  0.08575601]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #11 | lambda learn rate = 0.0001\n",
      "Target = [[8.]\n",
      " [6.]]\n",
      "lambda end of trial = [[ 0.          0.5111414  -0.25061521]\n",
      " [ 0.          0.34839981 -0.17491891]\n",
      " [ 0.         -0.1650662   0.22477765]\n",
      " [ 0.         -0.10693577  0.17066032]\n",
      " [ 0.          0.18587403  0.00509418]\n",
      " [ 0.         -0.09878294  0.23060482]\n",
      " [ 0.         -0.0567339   0.12413929]\n",
      " [ 0.         -0.0798168   0.23554241]\n",
      " [ 0.         -0.09336157  0.16553222]\n",
      " [ 0.          0.21606157  0.0857631 ]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #12 | lambda learn rate = 0.0001\n",
      "Target = [[9.]\n",
      " [2.]]\n",
      "lambda end of trial = [[ 0.          0.50976022 -0.25092214]\n",
      " [ 0.          0.34729136 -0.17516524]\n",
      " [ 0.         -0.16627874  0.22450819]\n",
      " [ 0.         -0.10802282  0.17041875]\n",
      " [ 0.          0.18450286  0.00478948]\n",
      " [ 0.         -0.10011887  0.23030794]\n",
      " [ 0.         -0.05793575  0.12387221]\n",
      " [ 0.         -0.08123991  0.23522616]\n",
      " [ 0.         -0.0945591   0.16526611]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [ 0.          0.21461377  0.08544136]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #13 | lambda learn rate = 0.0001\n",
      "Target = [[2.]\n",
      " [8.]]\n",
      "lambda end of trial = [[ 0.          0.50942429 -0.25226583]\n",
      " [ 0.          0.34689248 -0.17676074]\n",
      " [ 0.         -0.16666973  0.22294425]\n",
      " [ 0.         -0.10840923  0.16887311]\n",
      " [ 0.          0.18413081  0.00330128]\n",
      " [ 0.         -0.10048698  0.22883551]\n",
      " [ 0.         -0.0583396   0.12225678]\n",
      " [ 0.         -0.08165855  0.23355163]\n",
      " [ 0.         -0.09494037  0.16374104]\n",
      " [ 0.          0.21419725  0.08377527]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #14 | lambda learn rate = 0.0001\n",
      "Target = [[7.]\n",
      " [3.]]\n",
      "lambda end of trial = [[ 0.          0.50838907 -0.2527095 ]\n",
      " [ 0.          0.345838   -0.17721266]\n",
      " [ 0.         -0.1678173   0.22245243]\n",
      " [ 0.         -0.1094392   0.16843169]\n",
      " [ 0.          0.18295177  0.00279597]\n",
      " [ 0.         -0.10169678  0.22831702]\n",
      " [ 0.         -0.05936384  0.12181783]\n",
      " [ 0.         -0.08277782  0.23307194]\n",
      " [ 0.         -0.09589758  0.16333081]\n",
      " [ 0.          0.21290669  0.08322218]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #15 | lambda learn rate = 0.0001\n",
      "Target = [[8.]\n",
      " [6.]]\n",
      "lambda end of trial = [[ 0.          0.50890455 -0.25232289]\n",
      " [ 0.          0.3464736  -0.17673596]\n",
      " [ 0.         -0.16713626  0.22296321]\n",
      " [ 0.         -0.10883664  0.16888361]\n",
      " [ 0.          0.18347624  0.00318932]\n",
      " [ 0.         -0.10122536  0.22867059]\n",
      " [ 0.         -0.05874622  0.12228104]\n",
      " [ 0.         -0.08214675  0.23354524]\n",
      " [ 0.         -0.0954574   0.16366093]\n",
      " [ 0.          0.21341522  0.08360357]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #16 | lambda learn rate = 0.0001\n",
      "Target = [[4.]\n",
      " [1.]]\n",
      "lambda end of trial = [[ 0.          0.50742326 -0.25269321]\n",
      " [ 0.          0.34490983 -0.1771269 ]\n",
      " [ 0.         -0.16901321  0.22249397]\n",
      " [ 0.         -0.1103434   0.16850692]\n",
      " [ 0.          0.18183101  0.00277802]\n",
      " [ 0.         -0.10302315  0.22822114]\n",
      " [ 0.         -0.06025855  0.12190296]\n",
      " [ 0.         -0.08369015  0.23315939]\n",
      " [ 0.         -0.09703641  0.16326618]\n",
      " [ 0.          0.21177924  0.08319458]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #17 | lambda learn rate = 0.0001\n",
      "Target = [[4.]\n",
      " [1.]]\n",
      "lambda end of trial = [[ 0.          0.50575097 -0.25311129]\n",
      " [ 0.          0.34331341 -0.17752601]\n",
      " [ 0.         -0.17045109  0.2221345 ]\n",
      " [ 0.         -0.11203711  0.16808349]\n",
      " [ 0.          0.18023103  0.00237802]\n",
      " [ 0.         -0.10470436  0.22780084]\n",
      " [ 0.         -0.06180017  0.12151755]\n",
      " [ 0.         -0.08529638  0.23275783]\n",
      " [ 0.         -0.09852018  0.16289524]\n",
      " [ 0.          0.20995078  0.08273746]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #18 | lambda learn rate = 0.0001\n",
      "Target = [[5.]\n",
      " [7.]]\n",
      "lambda end of trial = [[ 0.          0.50583721 -0.25299055]\n",
      " [ 0.          0.34341336 -0.17738608]\n",
      " [ 0.         -0.17036843  0.22225023]\n",
      " [ 0.         -0.11199146  0.16814741]\n",
      " [ 0.          0.18030317  0.00247901]\n",
      " [ 0.         -0.10462334  0.22791427]\n",
      " [ 0.         -0.06172761  0.12161913]\n",
      " [ 0.         -0.085295    0.23275978]\n",
      " [ 0.         -0.0984256   0.16302765]\n",
      " [ 0.          0.20998116  0.08278   ]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #19 | lambda learn rate = 0.0001\n",
      "Target = [[5.]\n",
      " [4.]]\n",
      "lambda end of trial = [[ 0.          0.50499466 -0.25366459]\n",
      " [ 0.          0.3425778  -0.17805453]\n",
      " [ 0.         -0.17127851  0.22152217]\n",
      " [ 0.         -0.11282384  0.1674815 ]\n",
      " [ 0.          0.17939468  0.00175222]\n",
      " [ 0.         -0.10558286  0.22714665]\n",
      " [ 0.         -0.06253482  0.12097337]\n",
      " [ 0.         -0.08624341  0.23200105]\n",
      " [ 0.         -0.09915086  0.16244744]\n",
      " [ 0.          0.2090033   0.08199772]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #20 | lambda learn rate = 0.0001\n",
      "Target = [[6.]\n",
      " [1.]]\n",
      "lambda end of trial = [[ 0.          0.50373226 -0.25387499]\n",
      " [ 0.          0.34130545 -0.17826658]\n",
      " [ 0.         -0.17253155  0.22131333]\n",
      " [ 0.         -0.11392999  0.16729714]\n",
      " [ 0.          0.17806627  0.00153082]\n",
      " [ 0.         -0.10686996  0.22693213]\n",
      " [ 0.         -0.06379182  0.12076387]\n",
      " [ 0.         -0.08747     0.23179661]\n",
      " [ 0.         -0.10031448  0.1622535 ]\n",
      " [ 0.          0.20768473  0.08177796]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #21 | lambda learn rate = 0.0001\n",
      "Target = [[3.]\n",
      " [3.]]\n",
      "lambda end of trial = [[ 0.          0.50281112 -0.25479613]\n",
      " [ 0.          0.34036972 -0.17920232]\n",
      " [ 0.         -0.17340016  0.22044472]\n",
      " [ 0.         -0.11485007  0.16637706]\n",
      " [ 0.          0.17717122  0.00063577]\n",
      " [ 0.         -0.10777957  0.22602253]\n",
      " [ 0.         -0.064764    0.11979169]\n",
      " [ 0.         -0.08831113  0.23095548]\n",
      " [ 0.         -0.10126776  0.16130023]\n",
      " [ 0.          0.20679321  0.08088644]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #22 | lambda learn rate = 0.0001\n",
      "Target = [[1.]\n",
      " [5.]]\n",
      "lambda end of trial = [[ 0.          0.50254956 -0.25610391]\n",
      " [ 0.          0.3401146  -0.18047791]\n",
      " [ 0.         -0.17369368  0.2189771 ]\n",
      " [ 0.         -0.11512507  0.16500206]\n",
      " [ 0.          0.17690584 -0.0006911 ]\n",
      " [ 0.         -0.10810489  0.2243959 ]\n",
      " [ 0.         -0.06504483  0.11838752]\n",
      " [ 0.         -0.08861083  0.22945696]\n",
      " [ 0.         -0.10157484  0.15976483]\n",
      " [ 0.          0.20647726  0.07930669]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #23 | lambda learn rate = 0.0001\n",
      "Target = [[6.]\n",
      " [0.]]\n",
      "lambda end of trial = [[ 0.          0.50105469 -0.25610391]\n",
      " [ 0.          0.33850444 -0.18047791]\n",
      " [ 0.         -0.17514955  0.2189771 ]\n",
      " [ 0.         -0.11657514  0.16500206]\n",
      " [ 0.          0.17536421 -0.0006911 ]\n",
      " [ 0.         -0.10985617  0.2243959 ]\n",
      " [ 0.         -0.06637064  0.11838752]\n",
      " [ 0.         -0.09032074  0.22945696]\n",
      " [ 0.         -0.10295463  0.15976483]\n",
      " [ 0.          0.2049702   0.07930669]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #24 | lambda learn rate = 0.0001\n",
      "Target = [[4.]\n",
      " [1.]]\n",
      "lambda end of trial = [[ 0.          0.49968866 -0.25644542]\n",
      " [ 0.          0.33716265 -0.18081336]\n",
      " [ 0.         -0.17652598  0.21863299]\n",
      " [ 0.         -0.11806934  0.16462851]\n",
      " [ 0.          0.174053   -0.0010189 ]\n",
      " [ 0.         -0.11134917  0.22402265]\n",
      " [ 0.         -0.06778497  0.11803394]\n",
      " [ 0.         -0.0918833   0.22906633]\n",
      " [ 0.         -0.10425496  0.15943974]\n",
      " [ 0.          0.20349251  0.07893727]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #25 | lambda learn rate = 0.0001\n",
      "Target = [[1.]\n",
      " [1.]]\n",
      "lambda end of trial = [[ 0.          0.49919162 -0.25694246]\n",
      " [ 0.          0.33666806 -0.18130795]\n",
      " [ 0.         -0.17702397  0.218135  ]\n",
      " [ 0.         -0.11855865  0.1641392 ]\n",
      " [ 0.          0.17356309 -0.0015088 ]\n",
      " [ 0.         -0.11181911  0.22355271]\n",
      " [ 0.         -0.06829367  0.11752523]\n",
      " [ 0.         -0.09237381  0.22857581]\n",
      " [ 0.         -0.104784    0.1589107 ]\n",
      " [ 0.          0.20296243  0.07840719]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #26 | lambda learn rate = 0.0001\n",
      "Target = [[8.]\n",
      " [6.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda end of trial = [[ 0.          0.50181776 -0.25497286]\n",
      " [ 0.          0.3395777  -0.17912573]\n",
      " [ 0.         -0.17428244  0.22019114]\n",
      " [ 0.         -0.11595406  0.16609264]\n",
      " [ 0.          0.17641695  0.00063159]\n",
      " [ 0.         -0.10923643  0.22548972]\n",
      " [ 0.         -0.06573146  0.1194469 ]\n",
      " [ 0.         -0.08961332  0.23064618]\n",
      " [ 0.         -0.10197145  0.16102012]\n",
      " [ 0.          0.2055303   0.08033309]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #27 | lambda learn rate = 0.0001\n",
      "Target = [[8.]\n",
      " [8.]]\n",
      "lambda end of trial = [[ 0.          0.50433745 -0.25245316]\n",
      " [ 0.          0.34264228 -0.17606114]\n",
      " [ 0.         -0.17135075  0.22312284]\n",
      " [ 0.         -0.11259255  0.16945415]\n",
      " [ 0.          0.17902581  0.00324045]\n",
      " [ 0.         -0.10626418  0.22846198]\n",
      " [ 0.         -0.06254364  0.12263471]\n",
      " [ 0.         -0.08660248  0.23365702]\n",
      " [ 0.         -0.0988291   0.16416247]\n",
      " [ 0.          0.20862178  0.08342457]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #28 | lambda learn rate = 0.0001\n",
      "Target = [[9.]\n",
      " [5.]]\n",
      "lambda end of trial = [[ 0.          0.50588684 -0.25159239]\n",
      " [ 0.          0.34432269 -0.17512758]\n",
      " [ 0.         -0.16974198  0.2240166 ]\n",
      " [ 0.         -0.11093901  0.17037278]\n",
      " [ 0.          0.18067476  0.00415653]\n",
      " [ 0.         -0.10472544  0.22931683]\n",
      " [ 0.         -0.06095561  0.12351695]\n",
      " [ 0.         -0.08510244  0.23449038]\n",
      " [ 0.         -0.09743613  0.16493634]\n",
      " [ 0.          0.21010106  0.0842464 ]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #29 | lambda learn rate = 0.0001\n",
      "Target = [[8.]\n",
      " [8.]]\n",
      "lambda end of trial = [[ 0.          0.50750174 -0.24997749]\n",
      " [ 0.          0.34577061 -0.17367966]\n",
      " [ 0.         -0.16800767  0.22575091]\n",
      " [ 0.         -0.10931631  0.17199549]\n",
      " [ 0.          0.18234657  0.00582834]\n",
      " [ 0.         -0.1031538   0.23088847]\n",
      " [ 0.         -0.05953114  0.12494142]\n",
      " [ 0.         -0.08336483  0.23622798]\n",
      " [ 0.         -0.09577652  0.16659595]\n",
      " [ 0.          0.21149979  0.08564512]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #30 | lambda learn rate = 0.0001\n",
      "Target = [[4.]\n",
      " [0.]]\n",
      "lambda end of trial = [[ 0.          0.50581097 -0.24997749]\n",
      " [ 0.          0.34430569 -0.17367966]\n",
      " [ 0.         -0.16952467  0.22575091]\n",
      " [ 0.         -0.11070454  0.17199549]\n",
      " [ 0.          0.18070936  0.00582834]\n",
      " [ 0.         -0.1047099   0.23088847]\n",
      " [ 0.         -0.0609782   0.12494142]\n",
      " [ 0.         -0.08483385  0.23622798]\n",
      " [ 0.         -0.09731827  0.16659595]\n",
      " [ 0.          0.20987828  0.08564512]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #31 | lambda learn rate = 0.0001\n",
      "Target = [[7.]\n",
      " [5.]]\n",
      "lambda end of trial = [[ 0.          0.50565025 -0.25009229]\n",
      " [ 0.          0.34420267 -0.17375325]\n",
      " [ 0.         -0.16961965  0.22568307]\n",
      " [ 0.         -0.11087147  0.17187625]\n",
      " [ 0.          0.1804953   0.00567545]\n",
      " [ 0.         -0.10488021  0.23076682]\n",
      " [ 0.         -0.0610911   0.12486077]\n",
      " [ 0.         -0.08510112  0.23603708]\n",
      " [ 0.         -0.09747386  0.16648482]\n",
      " [ 0.          0.20966053  0.08548958]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #32 | lambda learn rate = 0.0001\n",
      "Target = [[9.]\n",
      " [7.]]\n",
      "lambda end of trial = [[ 0.          0.50750904 -0.24864657]\n",
      " [ 0.          0.34604343 -0.17232154]\n",
      " [ 0.         -0.1679441   0.22698627]\n",
      " [ 0.         -0.1092393   0.17314572]\n",
      " [ 0.          0.18237025  0.00713374]\n",
      " [ 0.         -0.10304382  0.23219512]\n",
      " [ 0.         -0.05921738  0.12631811]\n",
      " [ 0.         -0.08338583  0.23737119]\n",
      " [ 0.         -0.09543386  0.16807148]\n",
      " [ 0.          0.21131196  0.08677403]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #33 | lambda learn rate = 0.0001\n",
      "Target = [[0.]\n",
      " [1.]]\n",
      "lambda end of trial = [[ 0.          0.50750904 -0.24924749]\n",
      " [ 0.          0.34604343 -0.17297307]\n",
      " [ 0.         -0.1679441   0.22642852]\n",
      " [ 0.         -0.1092393   0.17252362]\n",
      " [ 0.          0.18237025  0.00654954]\n",
      " [ 0.         -0.10304382  0.23155562]\n",
      " [ 0.         -0.05921738  0.12569827]\n",
      " [ 0.         -0.08338583  0.23679248]\n",
      " [ 0.         -0.09543386  0.16747631]\n",
      " [ 0.          0.21131196  0.08613003]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #34 | lambda learn rate = 0.0001\n",
      "Target = [[3.]\n",
      " [5.]]\n",
      "lambda end of trial = [[ 0.          0.50680152 -0.25042667]\n",
      " [ 0.          0.34527141 -0.17425976]\n",
      " [ 0.         -0.16874358  0.22509605]\n",
      " [ 0.         -0.11003079  0.17120447]\n",
      " [ 0.          0.18162465  0.00530686]\n",
      " [ 0.         -0.10386069  0.23019417]\n",
      " [ 0.         -0.05998811  0.12441373]\n",
      " [ 0.         -0.08415726  0.23550676]\n",
      " [ 0.         -0.09623468  0.1661416 ]\n",
      " [ 0.          0.2105426   0.08484775]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #35 | lambda learn rate = 0.0001\n",
      "Target = [[8.]\n",
      " [5.]]\n",
      "lambda end of trial = [[ 0.          0.50718467 -0.25018721]\n",
      " [ 0.          0.34566677 -0.17401266]\n",
      " [ 0.         -0.16830201  0.22537203]\n",
      " [ 0.         -0.10960578  0.1714701 ]\n",
      " [ 0.          0.18207426  0.00558787]\n",
      " [ 0.         -0.10351537  0.23040999]\n",
      " [ 0.         -0.05952574  0.1247027 ]\n",
      " [ 0.         -0.08384153  0.23570409]\n",
      " [ 0.         -0.09581238  0.16640555]\n",
      " [ 0.          0.2108537   0.08504219]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #36 | lambda learn rate = 0.0001\n",
      "Target = [[3.]\n",
      " [9.]]\n",
      "lambda end of trial = [[ 0.          0.50698865 -0.25077527]\n",
      " [ 0.          0.34546551 -0.17461642]\n",
      " [ 0.         -0.16849949  0.22477961]\n",
      " [ 0.         -0.10979143  0.17091316]\n",
      " [ 0.          0.18182678  0.0048454 ]\n",
      " [ 0.         -0.1037875   0.22959362]\n",
      " [ 0.         -0.05974697  0.12403903]\n",
      " [ 0.         -0.08409862  0.23493283]\n",
      " [ 0.         -0.09600033  0.16584168]\n",
      " [ 0.          0.21056109  0.08416436]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #37 | lambda learn rate = 0.0001\n",
      "Target = [[3.]\n",
      " [1.]]\n",
      "lambda end of trial = [[ 0.          0.50573299 -0.25119382]\n",
      " [ 0.          0.34410965 -0.17506838]\n",
      " [ 0.         -0.16985034  0.22432932]\n",
      " [ 0.         -0.11104373  0.17049572]\n",
      " [ 0.          0.18059637  0.00443527]\n",
      " [ 0.         -0.10514902  0.22913977]\n",
      " [ 0.         -0.06095213  0.12363731]\n",
      " [ 0.         -0.08564536  0.23441725]\n",
      " [ 0.         -0.09717735  0.16544934]\n",
      " [ 0.          0.2091834   0.08370513]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #38 | lambda learn rate = 0.0001\n",
      "Target = [[8.]\n",
      " [9.]]\n",
      "lambda end of trial = [[ 0.          0.50799989 -0.24864357]\n",
      " [ 0.          0.3460449  -0.17289122]\n",
      " [ 0.         -0.16754993  0.22691729]\n",
      " [ 0.         -0.10900609  0.17278806]\n",
      " [ 0.          0.18240843  0.00647384]\n",
      " [ 0.         -0.10303687  0.23151595]\n",
      " [ 0.         -0.05875951  0.12610401]\n",
      " [ 0.         -0.08374239  0.23655809]\n",
      " [ 0.         -0.09483537  0.16808407]\n",
      " [ 0.          0.2111498   0.08591734]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #39 | lambda learn rate = 0.0001\n",
      "Target = [[9.]\n",
      " [4.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda end of trial = [[ 0.          0.50800257 -0.24864237]\n",
      " [ 0.          0.34610888 -0.17286279]\n",
      " [ 0.         -0.16744161  0.22696543]\n",
      " [ 0.         -0.10880352  0.1728781 ]\n",
      " [ 0.          0.18249582  0.00651268]\n",
      " [ 0.         -0.10296192  0.23154926]\n",
      " [ 0.         -0.05865387  0.12615096]\n",
      " [ 0.         -0.08383269  0.23651795]\n",
      " [ 0.         -0.09475818  0.16811838]\n",
      " [ 0.          0.21108459  0.08588835]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #40 | lambda learn rate = 0.0001\n",
      "Target = [[4.]\n",
      " [7.]]\n",
      "lambda end of trial = [[ 0.          0.50744011 -0.24962669]\n",
      " [ 0.          0.34561184 -0.1737326 ]\n",
      " [ 0.         -0.1679792   0.22602466]\n",
      " [ 0.         -0.1093409   0.17193768]\n",
      " [ 0.          0.18197218  0.00559632]\n",
      " [ 0.         -0.10356467  0.23049445]\n",
      " [ 0.         -0.0591625   0.12526085]\n",
      " [ 0.         -0.08442788  0.23547638]\n",
      " [ 0.         -0.09531712  0.16714024]\n",
      " [ 0.          0.21047184  0.08481605]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #41 | lambda learn rate = 0.0001\n",
      "Target = [[6.]\n",
      " [2.]]\n",
      "lambda end of trial = [[ 0.          0.50626599 -0.25001806]\n",
      " [ 0.          0.34441347 -0.17413206]\n",
      " [ 0.         -0.16918968  0.22562116]\n",
      " [ 0.         -0.11055843  0.17153184]\n",
      " [ 0.          0.18075743  0.0051914 ]\n",
      " [ 0.         -0.10490339  0.23004821]\n",
      " [ 0.         -0.06035698  0.12486269]\n",
      " [ 0.         -0.08562249  0.23507817]\n",
      " [ 0.         -0.09656064  0.16672573]\n",
      " [ 0.          0.20921665  0.08439765]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #42 | lambda learn rate = 0.0001\n",
      "Target = [[3.]\n",
      " [5.]]\n",
      "lambda end of trial = [[ 0.          0.50546466 -0.25135361]\n",
      " [ 0.          0.34368436 -0.17534724]\n",
      " [ 0.         -0.16996238  0.22433332]\n",
      " [ 0.         -0.11127787  0.17033277]\n",
      " [ 0.          0.18000096  0.00393063]\n",
      " [ 0.         -0.10573764  0.22865779]\n",
      " [ 0.         -0.06118866  0.12347655]\n",
      " [ 0.         -0.08633548  0.23388986]\n",
      " [ 0.         -0.09728726  0.16551469]\n",
      " [ 0.          0.20840315  0.08304181]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #43 | lambda learn rate = 0.0001\n",
      "Target = [[9.]\n",
      " [9.]]\n",
      "lambda end of trial = [[ 0.          0.50855702 -0.24826125]\n",
      " [ 0.          0.34678813 -0.17224347]\n",
      " [ 0.         -0.16690981  0.2273859 ]\n",
      " [ 0.         -0.10840388  0.17320676]\n",
      " [ 0.          0.18290781  0.00683748]\n",
      " [ 0.         -0.10264295  0.23175248]\n",
      " [ 0.         -0.05790813  0.12675709]\n",
      " [ 0.         -0.08328942  0.23693593]\n",
      " [ 0.         -0.09431042  0.16849153]\n",
      " [ 0.          0.21159539  0.08623406]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #44 | lambda learn rate = 0.0001\n",
      "Target = [[9.]\n",
      " [7.]]\n",
      "lambda end of trial = [[ 0.          0.50957458 -0.24746981]\n",
      " [ 0.          0.34781814 -0.17144235]\n",
      " [ 0.         -0.1658906   0.22817861]\n",
      " [ 0.         -0.1074138   0.17397683]\n",
      " [ 0.          0.1838966   0.00760654]\n",
      " [ 0.         -0.10177823  0.23242504]\n",
      " [ 0.         -0.05690134  0.12754014]\n",
      " [ 0.         -0.08231628  0.23769281]\n",
      " [ 0.         -0.0932332   0.16932937]\n",
      " [ 0.          0.21236291  0.08683102]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #45 | lambda learn rate = 0.0001\n",
      "Target = [[2.]\n",
      " [0.]]\n",
      "lambda end of trial = [[ 0.          0.50841531 -0.24746981]\n",
      " [ 0.          0.34671564 -0.17144235]\n",
      " [ 0.         -0.16702632  0.22817861]\n",
      " [ 0.         -0.10844639  0.17397683]\n",
      " [ 0.          0.18280758  0.00760654]\n",
      " [ 0.         -0.10279993  0.23242504]\n",
      " [ 0.         -0.05804803  0.12754014]\n",
      " [ 0.         -0.08341823  0.23769281]\n",
      " [ 0.         -0.09430893  0.16932937]\n",
      " [ 0.          0.21114185  0.08683102]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #46 | lambda learn rate = 0.0001\n",
      "Target = [[1.]\n",
      " [6.]]\n",
      "lambda end of trial = [[ 0.          0.50805242 -0.24964717]\n",
      " [ 0.          0.34639413 -0.17337141]\n",
      " [ 0.         -0.1673694   0.22612013]\n",
      " [ 0.         -0.1088169   0.17175377]\n",
      " [ 0.          0.18242851  0.00533209]\n",
      " [ 0.         -0.10318177  0.23013401]\n",
      " [ 0.         -0.05838711  0.12550568]\n",
      " [ 0.         -0.08378096  0.23551642]\n",
      " [ 0.         -0.09465306  0.16726458]\n",
      " [ 0.          0.21078233  0.08467392]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #47 | lambda learn rate = 0.0001\n",
      "Target = [[1.]\n",
      " [2.]]\n",
      "lambda end of trial = [[ 0.          0.5075065  -0.25073901]\n",
      " [ 0.          0.34584167 -0.17447634]\n",
      " [ 0.         -0.16802404  0.22481086]\n",
      " [ 0.         -0.10942387  0.17053984]\n",
      " [ 0.          0.18185358  0.00418223]\n",
      " [ 0.         -0.10375884  0.22897986]\n",
      " [ 0.         -0.0589573   0.12436528]\n",
      " [ 0.         -0.08437788  0.23432258]\n",
      " [ 0.         -0.09526021  0.16605028]\n",
      " [ 0.          0.21012864  0.08336654]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #48 | lambda learn rate = 0.0001\n",
      "Target = [[9.]\n",
      " [3.]]\n",
      "lambda end of trial = [[ 0.          0.50745622 -0.25075577]\n",
      " [ 0.          0.34579066 -0.17449334]\n",
      " [ 0.         -0.16812155  0.22477836]\n",
      " [ 0.         -0.10947667  0.17052224]\n",
      " [ 0.          0.18167263  0.00412192]\n",
      " [ 0.         -0.10382773  0.2289569 ]\n",
      " [ 0.         -0.05890666  0.12438216]\n",
      " [ 0.         -0.08449129  0.23428477]\n",
      " [ 0.         -0.09532035  0.16603023]\n",
      " [ 0.          0.20991506  0.08329534]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #49 | lambda learn rate = 0.0001\n",
      "Target = [[7.]\n",
      " [5.]]\n",
      "lambda end of trial = [[ 0.          0.50730438 -0.25086423]\n",
      " [ 0.          0.34571956 -0.17454413]\n",
      " [ 0.         -0.16823782  0.22469531]\n",
      " [ 0.         -0.10959288  0.17043923]\n",
      " [ 0.          0.18150218  0.00400017]\n",
      " [ 0.         -0.1041132   0.228753  ]\n",
      " [ 0.         -0.05900021  0.12431534]\n",
      " [ 0.         -0.0846874   0.23414469]\n",
      " [ 0.         -0.09540598  0.16596906]\n",
      " [ 0.          0.20967396  0.08312313]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #50 | lambda learn rate = 0.0001\n",
      "Target = [[1.]\n",
      " [1.]]\n",
      "lambda end of trial = [[ 0.          0.50673275 -0.25143586]\n",
      " [ 0.          0.34517801 -0.17508567]\n",
      " [ 0.         -0.16878383  0.22414929]\n",
      " [ 0.         -0.11019299  0.16983912]\n",
      " [ 0.          0.18093022  0.0034282 ]\n",
      " [ 0.         -0.10467676  0.22818943]\n",
      " [ 0.         -0.05954826  0.12376729]\n",
      " [ 0.         -0.08525385  0.23357825]\n",
      " [ 0.         -0.09591925  0.1654558 ]\n",
      " [ 0.          0.20907839  0.08252756]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #51 | lambda learn rate = 0.0001\n",
      "Target = [[5.]\n",
      " [4.]]\n",
      "lambda end of trial = [[ 0.          0.50588449 -0.25211446]\n",
      " [ 0.          0.34433044 -0.17576373]\n",
      " [ 0.         -0.16972433  0.2233969 ]\n",
      " [ 0.         -0.1110584   0.16914679]\n",
      " [ 0.          0.18006585  0.00273671]\n",
      " [ 0.         -0.10552551  0.22751043]\n",
      " [ 0.         -0.06032433  0.12314644]\n",
      " [ 0.         -0.08626825  0.23276673]\n",
      " [ 0.         -0.09680564  0.16474669]\n",
      " [ 0.          0.20819637  0.08182194]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #52 | lambda learn rate = 0.0001\n",
      "Target = [[5.]\n",
      " [0.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda end of trial = [[ 0.          0.50422693 -0.25211446]\n",
      " [ 0.          0.34266705 -0.17576373]\n",
      " [ 0.         -0.17142616  0.2233969 ]\n",
      " [ 0.         -0.11288337  0.16914679]\n",
      " [ 0.          0.17844919  0.00273671]\n",
      " [ 0.         -0.1073271   0.22751043]\n",
      " [ 0.         -0.06195198  0.12314644]\n",
      " [ 0.         -0.08799336  0.23276673]\n",
      " [ 0.         -0.09852108  0.16474669]\n",
      " [ 0.          0.20617724  0.08182194]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #53 | lambda learn rate = 0.0001\n",
      "Target = [[2.]\n",
      " [8.]]\n",
      "lambda end of trial = [[ 0.          0.503998   -0.25303019]\n",
      " [ 0.          0.34241786 -0.17676051]\n",
      " [ 0.         -0.17170254  0.22229136]\n",
      " [ 0.         -0.11311502  0.1682202 ]\n",
      " [ 0.          0.17819242  0.00170966]\n",
      " [ 0.         -0.10755214  0.22661027]\n",
      " [ 0.         -0.06215256  0.12234415]\n",
      " [ 0.         -0.08824863  0.23174564]\n",
      " [ 0.         -0.09875881  0.16379577]\n",
      " [ 0.          0.20588432  0.08065023]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #54 | lambda learn rate = 0.0001\n",
      "Target = [[5.]\n",
      " [2.]]\n",
      "lambda end of trial = [[ 0.          0.50296069 -0.25344511]\n",
      " [ 0.          0.34144121 -0.17715116]\n",
      " [ 0.         -0.17271048  0.22188818]\n",
      " [ 0.         -0.11412885  0.16781467]\n",
      " [ 0.          0.17725223  0.00133358]\n",
      " [ 0.         -0.10856481  0.2262052 ]\n",
      " [ 0.         -0.06312125  0.12195667]\n",
      " [ 0.         -0.08936895  0.23129751]\n",
      " [ 0.         -0.09977742  0.16338832]\n",
      " [ 0.          0.20457811  0.08012775]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #55 | lambda learn rate = 0.0001\n",
      "Target = [[0.]\n",
      " [0.]]\n",
      "lambda end of trial = [[ 0.          0.50296069 -0.25344511]\n",
      " [ 0.          0.34144121 -0.17715116]\n",
      " [ 0.         -0.17271048  0.22188818]\n",
      " [ 0.         -0.11412885  0.16781467]\n",
      " [ 0.          0.17725223  0.00133358]\n",
      " [ 0.         -0.10856481  0.2262052 ]\n",
      " [ 0.         -0.06312125  0.12195667]\n",
      " [ 0.         -0.08936895  0.23129751]\n",
      " [ 0.         -0.09977742  0.16338832]\n",
      " [ 0.          0.20457811  0.08012775]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #56 | lambda learn rate = 0.0001\n",
      "Target = [[2.]\n",
      " [9.]]\n",
      "lambda end of trial = [[ 0.          0.50291755 -0.25363923]\n",
      " [ 0.          0.34143201 -0.17719255]\n",
      " [ 0.         -0.17275725  0.22167772]\n",
      " [ 0.         -0.1141447   0.16774332]\n",
      " [ 0.          0.17719979  0.0010976 ]\n",
      " [ 0.         -0.10861539  0.22597761]\n",
      " [ 0.         -0.06314368  0.12185577]\n",
      " [ 0.         -0.08940856  0.23111926]\n",
      " [ 0.         -0.09977984  0.16337742]\n",
      " [ 0.          0.20450444  0.07979624]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #57 | lambda learn rate = 0.0001\n",
      "Target = [[3.]\n",
      " [8.]]\n",
      "lambda end of trial = [[ 0.          0.50285666 -0.2538016 ]\n",
      " [ 0.          0.34139081 -0.17730243]\n",
      " [ 0.         -0.17282196  0.22150517]\n",
      " [ 0.         -0.11416913  0.16767817]\n",
      " [ 0.          0.17713547  0.00092608]\n",
      " [ 0.         -0.10869018  0.22577815]\n",
      " [ 0.         -0.06317573  0.12177029]\n",
      " [ 0.         -0.08944751  0.2310154 ]\n",
      " [ 0.         -0.0998284   0.16324792]\n",
      " [ 0.          0.20438015  0.07946481]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #58 | lambda learn rate = 0.0001\n",
      "Target = [[5.]\n",
      " [0.]]\n",
      "lambda end of trial = [[ 0.          0.50144295 -0.2538016 ]\n",
      " [ 0.          0.33997256 -0.17730243]\n",
      " [ 0.         -0.17442261  0.22150517]\n",
      " [ 0.         -0.11562187  0.16767817]\n",
      " [ 0.          0.1756098   0.00092608]\n",
      " [ 0.         -0.11030192  0.22577815]\n",
      " [ 0.         -0.06460441  0.12177029]\n",
      " [ 0.         -0.09118541  0.2310154 ]\n",
      " [ 0.         -0.10130599  0.16324792]\n",
      " [ 0.          0.20275913  0.07946481]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #59 | lambda learn rate = 0.0001\n",
      "Target = [[9.]\n",
      " [5.]]\n",
      "lambda end of trial = [[ 0.          0.50403254 -0.25236294]\n",
      " [ 0.          0.34262925 -0.17582649]\n",
      " [ 0.         -0.17199348  0.22285468]\n",
      " [ 0.         -0.11290509  0.1691875 ]\n",
      " [ 0.          0.17814157  0.00233262]\n",
      " [ 0.         -0.10786761  0.22713055]\n",
      " [ 0.         -0.06192169  0.12326069]\n",
      " [ 0.         -0.0888785   0.23229701]\n",
      " [ 0.         -0.09874678  0.1646697 ]\n",
      " [ 0.          0.20526321  0.08085596]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #60 | lambda learn rate = 0.0001\n",
      "Target = [[4.]\n",
      " [1.]]\n",
      "lambda end of trial = [[ 0.          0.50269937 -0.25269623]\n",
      " [ 0.          0.34134634 -0.17614722]\n",
      " [ 0.         -0.173489    0.22248081]\n",
      " [ 0.         -0.11416786  0.16887181]\n",
      " [ 0.          0.17673225  0.00198029]\n",
      " [ 0.         -0.10932626  0.22676588]\n",
      " [ 0.         -0.06328588  0.12291965]\n",
      " [ 0.         -0.09039387  0.23191817]\n",
      " [ 0.         -0.10015734  0.16431706]\n",
      " [ 0.          0.20368917  0.08046245]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #61 | lambda learn rate = 0.0001\n",
      "Target = [[1.]\n",
      " [0.]]\n",
      "lambda end of trial = [[ 0.          0.50208826 -0.25269623]\n",
      " [ 0.          0.34082659 -0.17614722]\n",
      " [ 0.         -0.1740543   0.22248081]\n",
      " [ 0.         -0.11470067  0.16887181]\n",
      " [ 0.          0.17620463  0.00198029]\n",
      " [ 0.         -0.10982984  0.22676588]\n",
      " [ 0.         -0.06382604  0.12291965]\n",
      " [ 0.         -0.09097122  0.23191817]\n",
      " [ 0.         -0.10070415  0.16431706]\n",
      " [ 0.          0.2031353   0.08046245]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #62 | lambda learn rate = 0.0001\n",
      "Target = [[5.]\n",
      " [4.]]\n",
      "lambda end of trial = [[ 0.          0.50162172 -0.25306946]\n",
      " [ 0.          0.34046235 -0.17643861]\n",
      " [ 0.         -0.17445917  0.2221569 ]\n",
      " [ 0.         -0.11512308  0.16853387]\n",
      " [ 0.          0.17578961  0.00164827]\n",
      " [ 0.         -0.11024467  0.22643401]\n",
      " [ 0.         -0.0642081   0.122614  ]\n",
      " [ 0.         -0.09141059  0.23156667]\n",
      " [ 0.         -0.10105584  0.1640357 ]\n",
      " [ 0.          0.2027133   0.08012486]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #63 | lambda learn rate = 0.0001\n",
      "Target = [[9.]\n",
      " [2.]]\n",
      "lambda end of trial = [[ 0.          0.50253984 -0.25286543]\n",
      " [ 0.          0.34138252 -0.17623413]\n",
      " [ 0.         -0.17349819  0.22237046]\n",
      " [ 0.         -0.11411189  0.16875858]\n",
      " [ 0.          0.17671345  0.00185357]\n",
      " [ 0.         -0.10940649  0.22662028]\n",
      " [ 0.         -0.06329662  0.12281655]\n",
      " [ 0.         -0.09057643  0.23175204]\n",
      " [ 0.         -0.10009517  0.16424919]\n",
      " [ 0.          0.2035865   0.0803189 ]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #64 | lambda learn rate = 0.0001\n",
      "Target = [[4.]\n",
      " [4.]]\n",
      "lambda end of trial = [[ 0.          0.50190087 -0.2535044 ]\n",
      " [ 0.          0.34082973 -0.17678692]\n",
      " [ 0.         -0.17409906  0.22176959]\n",
      " [ 0.         -0.11464729  0.16822318]\n",
      " [ 0.          0.17612453  0.00126464]\n",
      " [ 0.         -0.10987111  0.22615566]\n",
      " [ 0.         -0.06384822  0.12226495]\n",
      " [ 0.         -0.09115968  0.23116878]\n",
      " [ 0.         -0.10062673  0.16371763]\n",
      " [ 0.          0.20302406  0.07975646]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #65 | lambda learn rate = 0.0001\n",
      "Target = [[8.]\n",
      " [0.]]\n",
      "lambda end of trial = [[ 0.          0.50130716 -0.2535044 ]\n",
      " [ 0.          0.34021447 -0.17678692]\n",
      " [ 0.         -0.17469619  0.22176959]\n",
      " [ 0.         -0.11522308  0.16822318]\n",
      " [ 0.          0.17557013  0.00126464]\n",
      " [ 0.         -0.11053619  0.22615566]\n",
      " [ 0.         -0.06450318  0.12226495]\n",
      " [ 0.         -0.09187776  0.23116878]\n",
      " [ 0.         -0.10113177  0.16371763]\n",
      " [ 0.          0.20238181  0.07975646]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #66 | lambda learn rate = 0.0001\n",
      "Target = [[1.]\n",
      " [9.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda end of trial = [[ 0.00000000e+00  5.01203186e-01 -2.54440197e-01]\n",
      " [ 0.00000000e+00  3.40118787e-01 -1.77648029e-01]\n",
      " [ 0.00000000e+00 -1.74798716e-01  2.20846824e-01]\n",
      " [ 0.00000000e+00 -1.15333709e-01  1.67227560e-01]\n",
      " [ 0.00000000e+00  1.75457484e-01  2.50829314e-04]\n",
      " [ 0.00000000e+00 -1.10633577e-01  2.25279182e-01]\n",
      " [ 0.00000000e+00 -6.46008931e-02  1.21385545e-01]\n",
      " [ 0.00000000e+00 -9.20087886e-02  2.29989552e-01]\n",
      " [ 0.00000000e+00 -1.01239394e-01  1.62749052e-01]\n",
      " [ 0.00000000e+00  2.02240933e-01  7.84886070e-02]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #67 | lambda learn rate = 0.0001\n",
      "Target = [[3.]\n",
      " [0.]]\n",
      "lambda end of trial = [[ 0.00000000e+00  4.99894885e-01 -2.54440197e-01]\n",
      " [ 0.00000000e+00  3.38743922e-01 -1.77648029e-01]\n",
      " [ 0.00000000e+00 -1.76101523e-01  2.20846824e-01]\n",
      " [ 0.00000000e+00 -1.16796344e-01  1.67227560e-01]\n",
      " [ 0.00000000e+00  1.73984011e-01  2.50829314e-04]\n",
      " [ 0.00000000e+00 -1.12034720e-01  2.25279182e-01]\n",
      " [ 0.00000000e+00 -6.60723281e-02  1.21385545e-01]\n",
      " [ 0.00000000e+00 -9.35635008e-02  2.29989552e-01]\n",
      " [ 0.00000000e+00 -1.02702090e-01  1.62749052e-01]\n",
      " [ 0.00000000e+00  2.00716669e-01  7.84886070e-02]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #68 | lambda learn rate = 0.0001\n",
      "Target = [[5.]\n",
      " [0.]]\n",
      "lambda end of trial = [[ 0.00000000e+00  4.98553819e-01 -2.54440197e-01]\n",
      " [ 0.00000000e+00  3.37476003e-01 -1.77648029e-01]\n",
      " [ 0.00000000e+00 -1.77433033e-01  2.20846824e-01]\n",
      " [ 0.00000000e+00 -1.18090209e-01  1.67227560e-01]\n",
      " [ 0.00000000e+00  1.72632698e-01  2.50829314e-04]\n",
      " [ 0.00000000e+00 -1.13457161e-01  2.25279182e-01]\n",
      " [ 0.00000000e+00 -6.72674406e-02  1.21385545e-01]\n",
      " [ 0.00000000e+00 -9.48146438e-02  2.29989552e-01]\n",
      " [ 0.00000000e+00 -1.03952892e-01  1.62749052e-01]\n",
      " [ 0.00000000e+00  1.99396444e-01  7.84886070e-02]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #69 | lambda learn rate = 0.0001\n",
      "Target = [[6.]\n",
      " [8.]]\n",
      "lambda end of trial = [[ 0.          0.50022427 -0.25221292]\n",
      " [ 0.          0.33925357 -0.17527794]\n",
      " [ 0.         -0.17574063  0.22310336]\n",
      " [ 0.         -0.11635164  0.16954564]\n",
      " [ 0.          0.17420149  0.00234255]\n",
      " [ 0.         -0.11173226  0.22757905]\n",
      " [ 0.         -0.0653457   0.12394786]\n",
      " [ 0.         -0.09321073  0.23212811]\n",
      " [ 0.         -0.10236752  0.16486288]\n",
      " [ 0.          0.20103326  0.08067103]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #70 | lambda learn rate = 0.0001\n",
      "Target = [[1.]\n",
      " [9.]]\n",
      "lambda end of trial = [[ 0.          0.5001169  -0.25317928]\n",
      " [ 0.          0.3391689  -0.17603996]\n",
      " [ 0.         -0.17585606  0.22206451]\n",
      " [ 0.         -0.11646301  0.16854335]\n",
      " [ 0.          0.17408439  0.00128867]\n",
      " [ 0.         -0.11185085  0.22651177]\n",
      " [ 0.         -0.0654314   0.12317664]\n",
      " [ 0.         -0.09332788  0.23107369]\n",
      " [ 0.         -0.10246814  0.16395732]\n",
      " [ 0.          0.200912    0.07957965]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #71 | lambda learn rate = 0.0001\n",
      "Target = [[3.]\n",
      " [8.]]\n",
      "lambda end of trial = [[ 0.          0.50017619 -0.25302117]\n",
      " [ 0.          0.33920943 -0.17593187]\n",
      " [ 0.         -0.17580861  0.22219105]\n",
      " [ 0.         -0.11635311  0.16883642]\n",
      " [ 0.          0.17410959  0.00135588]\n",
      " [ 0.         -0.1118536   0.22650443]\n",
      " [ 0.         -0.06535967  0.1233679 ]\n",
      " [ 0.         -0.09330504  0.23113462]\n",
      " [ 0.         -0.10241217  0.16410658]\n",
      " [ 0.          0.20092578  0.07961641]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #72 | lambda learn rate = 0.0001\n",
      "Target = [[9.]\n",
      " [3.]]\n",
      "lambda end of trial = [[ 0.          0.50193584 -0.25243462]\n",
      " [ 0.          0.34104183 -0.17532107]\n",
      " [ 0.         -0.17408416  0.22276586]\n",
      " [ 0.         -0.11466495  0.16939914]\n",
      " [ 0.          0.17588392  0.00194733]\n",
      " [ 0.         -0.11008569  0.22709374]\n",
      " [ 0.         -0.06369089  0.12392416]\n",
      " [ 0.         -0.09142596  0.23176098]\n",
      " [ 0.         -0.10071057  0.16467378]\n",
      " [ 0.          0.2026071   0.08017684]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #73 | lambda learn rate = 0.0001\n",
      "Target = [[6.]\n",
      " [7.]]\n",
      "lambda end of trial = [[ 0.          0.50272631 -0.25151241]\n",
      " [ 0.          0.34179247 -0.17444533]\n",
      " [ 0.         -0.17319007  0.22380897]\n",
      " [ 0.         -0.11395543  0.17022691]\n",
      " [ 0.          0.17678501  0.00299859]\n",
      " [ 0.         -0.10928098  0.22803256]\n",
      " [ 0.         -0.06286965  0.12488227]\n",
      " [ 0.         -0.09069302  0.23261608]\n",
      " [ 0.         -0.09991558  0.16560127]\n",
      " [ 0.          0.20341767  0.08112251]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #74 | lambda learn rate = 0.0001\n",
      "Target = [[6.]\n",
      " [4.]]\n",
      "lambda end of trial = [[ 0.          0.502593   -0.25160128]\n",
      " [ 0.          0.34168725 -0.17451548]\n",
      " [ 0.         -0.17328268  0.22374723]\n",
      " [ 0.         -0.11410569  0.17012674]\n",
      " [ 0.          0.176513    0.00281726]\n",
      " [ 0.         -0.10958719  0.22782843]\n",
      " [ 0.         -0.06294014  0.12483528]\n",
      " [ 0.         -0.09099496  0.23241478]\n",
      " [ 0.         -0.10009592  0.16548104]\n",
      " [ 0.          0.20309995  0.08091069]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #75 | lambda learn rate = 0.0001\n",
      "Target = [[4.]\n",
      " [3.]]\n",
      "lambda end of trial = [[ 0.          0.50157205 -0.25236699]\n",
      " [ 0.          0.34067035 -0.17527816]\n",
      " [ 0.         -0.1743146   0.22297329]\n",
      " [ 0.         -0.11506147  0.1694099 ]\n",
      " [ 0.          0.17560131  0.00213349]\n",
      " [ 0.         -0.11067263  0.22701434]\n",
      " [ 0.         -0.06401799  0.12402689]\n",
      " [ 0.         -0.09203803  0.23163248]\n",
      " [ 0.         -0.10106427  0.16475478]\n",
      " [ 0.          0.20203401  0.08011124]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #76 | lambda learn rate = 0.0001\n",
      "Target = [[0.]\n",
      " [5.]]\n",
      "lambda end of trial = [[ 0.00000000e+00  5.01572054e-01 -2.54175458e-01]\n",
      " [ 0.00000000e+00  3.40670346e-01 -1.77193400e-01]\n",
      " [ 0.00000000e+00 -1.74314597e-01  2.21140644e-01]\n",
      " [ 0.00000000e+00 -1.15061473e-01  1.67490226e-01]\n",
      " [ 0.00000000e+00  1.75601312e-01  2.27110703e-04]\n",
      " [ 0.00000000e+00 -1.10672632e-01  2.25052709e-01]\n",
      " [ 0.00000000e+00 -6.40179941e-02  1.22241068e-01]\n",
      " [ 0.00000000e+00 -9.20380324e-02  2.29931759e-01]\n",
      " [ 0.00000000e+00 -1.01064274e-01  1.62856348e-01]\n",
      " [ 0.00000000e+00  2.02034006e-01  7.82532977e-02]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #77 | lambda learn rate = 0.0001\n",
      "Target = [[9.]\n",
      " [3.]]\n",
      "lambda end of trial = [[ 0.          0.50320675 -0.25363056]\n",
      " [ 0.          0.34231675 -0.1766446 ]\n",
      " [ 0.         -0.17270075  0.22167859]\n",
      " [ 0.         -0.11352504  0.16800237]\n",
      " [ 0.          0.17720054  0.00076019]\n",
      " [ 0.         -0.10898768  0.22561436]\n",
      " [ 0.         -0.06221529  0.12284197]\n",
      " [ 0.         -0.09058527  0.23041601]\n",
      " [ 0.         -0.09953802  0.1633651 ]\n",
      " [ 0.          0.20361033  0.07877874]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #78 | lambda learn rate = 0.0001\n",
      "Target = [[4.]\n",
      " [3.]]\n",
      "lambda end of trial = [[ 0.00000000e+00  5.02222443e-01 -2.54368789e-01]\n",
      " [ 0.00000000e+00  3.41445720e-01 -1.77297872e-01]\n",
      " [ 0.00000000e+00 -1.73708276e-01  2.20922948e-01]\n",
      " [ 0.00000000e+00 -1.14589494e-01  1.67204031e-01]\n",
      " [ 0.00000000e+00  1.76304025e-01  8.78012911e-05]\n",
      " [ 0.00000000e+00 -1.09901835e-01  2.24928742e-01]\n",
      " [ 0.00000000e+00 -6.31704404e-02  1.22125608e-01]\n",
      " [ 0.00000000e+00 -9.14643173e-02  2.29756729e-01]\n",
      " [ 0.00000000e+00 -1.00541308e-01  1.62612634e-01]\n",
      " [ 0.00000000e+00  2.02545089e-01  7.79798076e-02]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #79 | lambda learn rate = 0.0001\n",
      "Target = [[0.]\n",
      " [3.]]\n",
      "lambda end of trial = [[ 0.          0.50222244 -0.25583546]\n",
      " [ 0.          0.34144572 -0.1786546 ]\n",
      " [ 0.         -0.17370828  0.21947809]\n",
      " [ 0.         -0.11458949  0.16583392]\n",
      " [ 0.          0.17630403 -0.00142921]\n",
      " [ 0.         -0.10990184  0.22342341]\n",
      " [ 0.         -0.06317044  0.1206282 ]\n",
      " [ 0.         -0.09146432  0.2281483 ]\n",
      " [ 0.         -0.10054131  0.16100613]\n",
      " [ 0.          0.20254509  0.07647081]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #80 | lambda learn rate = 0.0001\n",
      "Target = [[7.]\n",
      " [7.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda end of trial = [[ 0.00000000e+00  5.04224234e-01 -2.53833664e-01]\n",
      " [ 0.00000000e+00  3.43223124e-01 -1.76877197e-01]\n",
      " [ 0.00000000e+00 -1.71672439e-01  2.21513927e-01]\n",
      " [ 0.00000000e+00 -1.12629013e-01  1.67794398e-01]\n",
      " [ 0.00000000e+00  1.78228248e-01  4.95014423e-04]\n",
      " [ 0.00000000e+00 -1.07960114e-01  2.25365128e-01]\n",
      " [ 0.00000000e+00 -6.13665094e-02  1.22432132e-01]\n",
      " [ 0.00000000e+00 -8.95391760e-02  2.30073443e-01]\n",
      " [ 0.00000000e+00 -9.86139915e-02  1.62933450e-01]\n",
      " [ 0.00000000e+00  2.04380938e-01  7.83066620e-02]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #81 | lambda learn rate = 0.0001\n",
      "Target = [[1.]\n",
      " [5.]]\n",
      "lambda end of trial = [[ 0.          0.5038663  -0.25562335]\n",
      " [ 0.          0.34285468 -0.1787194 ]\n",
      " [ 0.         -0.17207327  0.21950979]\n",
      " [ 0.         -0.11300089  0.16593499]\n",
      " [ 0.          0.17785861 -0.00135319]\n",
      " [ 0.         -0.10836625  0.22333446]\n",
      " [ 0.         -0.06168911  0.12081912]\n",
      " [ 0.         -0.08993365  0.22810106]\n",
      " [ 0.         -0.09898618  0.16107252]\n",
      " [ 0.          0.2039634   0.07621896]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #82 | lambda learn rate = 0.0001\n",
      "Target = [[6.]\n",
      " [1.]]\n",
      "lambda end of trial = [[ 0.          0.50263385 -0.25582876]\n",
      " [ 0.          0.34181475 -0.17889273]\n",
      " [ 0.         -0.17310118  0.21933847]\n",
      " [ 0.         -0.11405945  0.16575857]\n",
      " [ 0.          0.17664508 -0.00155544]\n",
      " [ 0.         -0.10956498  0.22313467]\n",
      " [ 0.         -0.06283607  0.12062796]\n",
      " [ 0.         -0.09108516  0.22790914]\n",
      " [ 0.         -0.09999807  0.16090387]\n",
      " [ 0.          0.20274194  0.07601538]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #83 | lambda learn rate = 0.0001\n",
      "Target = [[4.]\n",
      " [7.]]\n",
      "lambda end of trial = [[ 0.          0.50293808 -0.25529636]\n",
      " [ 0.          0.34217079 -0.17826966]\n",
      " [ 0.         -0.17281064  0.21984692]\n",
      " [ 0.         -0.11376686  0.1662706 ]\n",
      " [ 0.          0.17696492 -0.00099572]\n",
      " [ 0.         -0.10927204  0.2236473 ]\n",
      " [ 0.         -0.06251671  0.12118685]\n",
      " [ 0.         -0.09079519  0.22841659]\n",
      " [ 0.         -0.09969356  0.16143677]\n",
      " [ 0.          0.20301327  0.07649019]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #84 | lambda learn rate = 0.0001\n",
      "Target = [[7.]\n",
      " [9.]]\n",
      "lambda end of trial = [[ 0.          0.50572358 -0.25171501]\n",
      " [ 0.          0.34493501 -0.17471566]\n",
      " [ 0.         -0.17019799  0.22320604]\n",
      " [ 0.         -0.11118406  0.16959134]\n",
      " [ 0.          0.17968137  0.00249685]\n",
      " [ 0.         -0.10675131  0.22688824]\n",
      " [ 0.         -0.0600007   0.12442171]\n",
      " [ 0.         -0.08812419  0.23185073]\n",
      " [ 0.         -0.09693894  0.16497842]\n",
      " [ 0.          0.2055781   0.07978784]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #85 | lambda learn rate = 0.0001\n",
      "Target = [[2.]\n",
      " [9.]]\n",
      "lambda end of trial = [[ 0.          0.50559381 -0.25229897]\n",
      " [ 0.          0.34483846 -0.17515011]\n",
      " [ 0.         -0.17030784  0.22271171]\n",
      " [ 0.         -0.11131102  0.16902003]\n",
      " [ 0.          0.17953345  0.00183121]\n",
      " [ 0.         -0.10687486  0.22633228]\n",
      " [ 0.         -0.06009327  0.12400515]\n",
      " [ 0.         -0.08826697  0.23120821]\n",
      " [ 0.         -0.09709129  0.16429282]\n",
      " [ 0.          0.20541774  0.0790662 ]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #86 | lambda learn rate = 0.0001\n",
      "Target = [[0.]\n",
      " [8.]]\n",
      "lambda end of trial = [[ 0.00000000e+00  5.05593806e-01 -2.54108319e-01]\n",
      " [ 0.00000000e+00  3.44838464e-01 -1.76717631e-01]\n",
      " [ 0.00000000e+00 -1.70307843e-01  2.20813407e-01]\n",
      " [ 0.00000000e+00 -1.11311016e-01  1.67382408e-01]\n",
      " [ 0.00000000e+00  1.79533450e-01 -3.37510800e-05]\n",
      " [ 0.00000000e+00 -1.06874861e-01  2.24603457e-01]\n",
      " [ 0.00000000e+00 -6.00932688e-02  1.22067655e-01]\n",
      " [ 0.00000000e+00 -8.82669727e-02  2.29250379e-01]\n",
      " [ 0.00000000e+00 -9.70912930e-02  1.62423874e-01]\n",
      " [ 0.00000000e+00  2.05417739e-01  7.71367124e-02]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #87 | lambda learn rate = 0.0001\n",
      "Target = [[1.]\n",
      " [2.]]\n",
      "lambda end of trial = [[ 0.          0.5050513  -0.25519333]\n",
      " [ 0.          0.34433122 -0.17773212]\n",
      " [ 0.         -0.17077392  0.21988126]\n",
      " [ 0.         -0.11182475  0.16635494]\n",
      " [ 0.          0.17903968 -0.00102129]\n",
      " [ 0.         -0.10740822  0.22353674]\n",
      " [ 0.         -0.06057943  0.12109533]\n",
      " [ 0.         -0.08882329  0.22813775]\n",
      " [ 0.         -0.09758739  0.16143168]\n",
      " [ 0.          0.20486912  0.07603948]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #88 | lambda learn rate = 0.0001\n",
      "Target = [[1.]\n",
      " [3.]]\n",
      "lambda end of trial = [[ 0.          0.50462287 -0.25647861]\n",
      " [ 0.          0.34389484 -0.17904127]\n",
      " [ 0.         -0.17124313  0.21847361]\n",
      " [ 0.         -0.11225738  0.16505706]\n",
      " [ 0.          0.17860082 -0.00233787]\n",
      " [ 0.         -0.10784775  0.22221815]\n",
      " [ 0.         -0.06104334  0.1197036 ]\n",
      " [ 0.         -0.08928131  0.22676367]\n",
      " [ 0.         -0.09802551  0.16011731]\n",
      " [ 0.          0.20439157  0.07460682]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #89 | lambda learn rate = 0.0001\n",
      "Target = [[0.]\n",
      " [2.]]\n",
      "lambda end of trial = [[ 0.          0.50462287 -0.2576292 ]\n",
      " [ 0.          0.34389484 -0.18011928]\n",
      " [ 0.         -0.17124313  0.2173956 ]\n",
      " [ 0.         -0.11225738  0.16399689]\n",
      " [ 0.          0.17860082 -0.00344511]\n",
      " [ 0.         -0.10784775  0.2209473 ]\n",
      " [ 0.         -0.06104334  0.11864325]\n",
      " [ 0.         -0.08928131  0.22546158]\n",
      " [ 0.         -0.09802551  0.15902706]\n",
      " [ 0.          0.20439157  0.07332642]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #90 | lambda learn rate = 0.0001\n",
      "Target = [[7.]\n",
      " [3.]]\n",
      "lambda end of trial = [[ 0.          0.5048345  -0.2575385 ]\n",
      " [ 0.          0.34401145 -0.1800693 ]\n",
      " [ 0.         -0.17118407  0.21742091]\n",
      " [ 0.         -0.11224939  0.16400031]\n",
      " [ 0.          0.1786517  -0.0034233 ]\n",
      " [ 0.         -0.10784327  0.22094922]\n",
      " [ 0.         -0.06088596  0.1187107 ]\n",
      " [ 0.         -0.08922793  0.22548446]\n",
      " [ 0.         -0.09794587  0.15906119]\n",
      " [ 0.          0.20435051  0.07330882]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #91 | lambda learn rate = 0.0001\n",
      "Target = [[7.]\n",
      " [7.]]\n",
      "lambda end of trial = [[ 0.          0.50658054 -0.25579246]\n",
      " [ 0.          0.34608907 -0.17799168]\n",
      " [ 0.         -0.16926186  0.21934312]\n",
      " [ 0.         -0.11012457  0.16612513]\n",
      " [ 0.          0.18067496 -0.00140004]\n",
      " [ 0.         -0.1061288   0.22266369]\n",
      " [ 0.         -0.05899203  0.12060463]\n",
      " [ 0.         -0.08740717  0.22730522]\n",
      " [ 0.         -0.09609289  0.16091417]\n",
      " [ 0.          0.20614465  0.07510296]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #92 | lambda learn rate = 0.0001\n",
      "Target = [[9.]\n",
      " [2.]]\n",
      "lambda end of trial = [[ 0.          0.50667678 -0.25577107]\n",
      " [ 0.          0.34623901 -0.17795836]\n",
      " [ 0.         -0.16911644  0.21937544]\n",
      " [ 0.         -0.11004589  0.16614261]\n",
      " [ 0.          0.18074973 -0.00138343]\n",
      " [ 0.         -0.10598864  0.22269483]\n",
      " [ 0.         -0.05883611  0.12063928]\n",
      " [ 0.         -0.087295    0.22733014]\n",
      " [ 0.         -0.09592835  0.16095074]\n",
      " [ 0.          0.2062337   0.07512275]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #93 | lambda learn rate = 0.0001\n",
      "Target = [[0.]\n",
      " [6.]]\n",
      "lambda end of trial = [[ 0.          0.50667678 -0.25733696]\n",
      " [ 0.          0.34623901 -0.17935212]\n",
      " [ 0.         -0.16911644  0.21788631]\n",
      " [ 0.         -0.11004589  0.16480925]\n",
      " [ 0.          0.18074973 -0.00288132]\n",
      " [ 0.         -0.10598864  0.22121308]\n",
      " [ 0.         -0.05883611  0.11922017]\n",
      " [ 0.         -0.087295    0.22563399]\n",
      " [ 0.         -0.09592835  0.15967028]\n",
      " [ 0.          0.2062337   0.07357296]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #94 | lambda learn rate = 0.0001\n",
      "Target = [[6.]\n",
      " [9.]]\n",
      "lambda end of trial = [[ 0.00000000e+00  5.08568713e-01 -2.54499061e-01]\n",
      " [ 0.00000000e+00  3.47979505e-01 -1.76741372e-01]\n",
      " [ 0.00000000e+00 -1.67319996e-01  2.20580984e-01]\n",
      " [ 0.00000000e+00 -1.08218627e-01  1.67550155e-01]\n",
      " [ 0.00000000e+00  1.82386369e-01 -4.26368554e-04]\n",
      " [ 0.00000000e+00 -1.04144171e-01  2.23979786e-01]\n",
      " [ 0.00000000e+00 -5.71238678e-02  1.21788526e-01]\n",
      " [ 0.00000000e+00 -8.55232818e-02  2.28291569e-01]\n",
      " [ 0.00000000e+00 -9.42800714e-02  1.62142694e-01]\n",
      " [ 0.00000000e+00  2.08043572e-01  7.62877725e-02]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #95 | lambda learn rate = 0.0001\n",
      "Target = [[8.]\n",
      " [7.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda end of trial = [[ 0.          0.51037541 -0.2529182 ]\n",
      " [ 0.          0.34948984 -0.17541983]\n",
      " [ 0.         -0.16547901  0.22219185]\n",
      " [ 0.         -0.10666148  0.16891266]\n",
      " [ 0.          0.18409723  0.00107063]\n",
      " [ 0.         -0.10250829  0.22541118]\n",
      " [ 0.         -0.05532106  0.12336598]\n",
      " [ 0.         -0.08383811  0.22976609]\n",
      " [ 0.         -0.09271105  0.16351559]\n",
      " [ 0.          0.20975319  0.07778369]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #96 | lambda learn rate = 0.0001\n",
      "Target = [[2.]\n",
      " [8.]]\n",
      "lambda end of trial = [[ 0.00000000e+00  5.10140450e-01 -2.53858041e-01]\n",
      " [ 0.00000000e+00  3.49254391e-01 -1.76361637e-01]\n",
      " [ 0.00000000e+00 -1.65668747e-01  2.21432901e-01]\n",
      " [ 0.00000000e+00 -1.06856325e-01  1.68133291e-01]\n",
      " [ 0.00000000e+00  1.83863889e-01  1.37280904e-04]\n",
      " [ 0.00000000e+00 -1.02725062e-01  2.24544108e-01]\n",
      " [ 0.00000000e+00 -5.55200987e-02  1.22569839e-01]\n",
      " [ 0.00000000e+00 -8.41181089e-02  2.28646103e-01]\n",
      " [ 0.00000000e+00 -9.29251889e-02  1.62659025e-01]\n",
      " [ 0.00000000e+00  2.09477511e-01  7.66809638e-02]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #97 | lambda learn rate = 0.0001\n",
      "Target = [[9.]\n",
      " [3.]]\n",
      "lambda end of trial = [[ 0.00000000e+00  5.10072790e-01 -2.53880595e-01]\n",
      " [ 0.00000000e+00  3.49203737e-01 -1.76378521e-01]\n",
      " [ 0.00000000e+00 -1.65816049e-01  2.21383801e-01]\n",
      " [ 0.00000000e+00 -1.07030545e-01  1.68075218e-01]\n",
      " [ 0.00000000e+00  1.83733423e-01  9.37922201e-05]\n",
      " [ 0.00000000e+00 -1.02828751e-01  2.24509545e-01]\n",
      " [ 0.00000000e+00 -5.56552502e-02  1.22524789e-01]\n",
      " [ 0.00000000e+00 -8.41793275e-02  2.28625697e-01]\n",
      " [ 0.00000000e+00 -9.31196177e-02  1.62594215e-01]\n",
      " [ 0.00000000e+00  2.09238941e-01  7.66014403e-02]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #98 | lambda learn rate = 0.0001\n",
      "Target = [[6.]\n",
      " [8.]]\n",
      "lambda end of trial = [[ 0.          0.51095398 -0.25270568]\n",
      " [ 0.          0.35008198 -0.17520753]\n",
      " [ 0.         -0.16496461  0.22251905]\n",
      " [ 0.         -0.106173    0.16921861]\n",
      " [ 0.          0.1844543   0.00105496]\n",
      " [ 0.         -0.10194137  0.22569273]\n",
      " [ 0.         -0.0547655   0.12371112]\n",
      " [ 0.         -0.08338521  0.22968452]\n",
      " [ 0.         -0.0922948   0.16369397]\n",
      " [ 0.          0.20999378  0.0776079 ]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "+++++++++++++++++++++++++++++++++++\n",
      "Session #9\n",
      "target at trial 0 = [[1.]\n",
      " [1.]]\n",
      "K MATX INIT= [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "A VECT INIT = [-0. -0.]\n",
      "lambda\n",
      "[[ 0.          0.53020654 -0.2322202 ]\n",
      " [ 0.          0.36705474 -0.15737009]\n",
      " [ 0.         -0.14629582  0.24261404]\n",
      " [ 0.         -0.08877213  0.18799136]\n",
      " [ 0.          0.20486852  0.02360278]\n",
      " [ 0.         -0.07854344  0.25002723]\n",
      " [ 0.         -0.03748972  0.14111247]\n",
      " [ 0.         -0.0597867   0.25435404]\n",
      " [ 0.         -0.07409235  0.18348285]\n",
      " [ 0.          0.23653843  0.10488391]]\n",
      "a\n",
      "[-0. -0.]\n",
      "K\n",
      "[[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #0 | lambda learn rate = 0.0001\n",
      "Target = [[1.]\n",
      " [1.]]\n",
      "lambda end of trial = [[ 0.          0.52956343 -0.2328633 ]\n",
      " [ 0.          0.36644553 -0.1579793 ]\n",
      " [ 0.         -0.14686874  0.24204112]\n",
      " [ 0.         -0.08937236  0.18739113]\n",
      " [ 0.          0.20416984  0.0229041 ]\n",
      " [ 0.         -0.07920234  0.24936833]\n",
      " [ 0.         -0.03811536  0.14048684]\n",
      " [ 0.         -0.06041952  0.25372121]\n",
      " [ 0.         -0.07467831  0.18289689]\n",
      " [ 0.          0.23588042  0.10422591]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #1 | lambda learn rate = 0.0001\n",
      "Target = [[9.]\n",
      " [6.]]\n",
      "lambda end of trial = [[ 0.          0.52313345 -0.23714996]\n",
      " [ 0.          0.36074451 -0.16177998]\n",
      " [ 0.         -0.15315236  0.23785204]\n",
      " [ 0.         -0.09518001  0.18351936]\n",
      " [ 0.          0.19850711  0.01912894]\n",
      " [ 0.         -0.08536722  0.24525841]\n",
      " [ 0.         -0.04464904  0.13613105]\n",
      " [ 0.         -0.06667581  0.24955035]\n",
      " [ 0.         -0.08006785  0.17930387]\n",
      " [ 0.          0.22986409  0.10021501]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #2 | lambda learn rate = 0.0001\n",
      "Target = [[7.]\n",
      " [4.]]\n",
      "lambda end of trial = [[ 0.          0.51910985 -0.23944916]\n",
      " [ 0.          0.35657611 -0.16416193]\n",
      " [ 0.         -0.15701125  0.23564696]\n",
      " [ 0.         -0.09894747  0.18136653]\n",
      " [ 0.          0.19420128  0.01666847]\n",
      " [ 0.         -0.0892198   0.24305694]\n",
      " [ 0.         -0.04868252  0.13382621]\n",
      " [ 0.         -0.07071009  0.24724505]\n",
      " [ 0.         -0.08404579  0.17703076]\n",
      " [ 0.          0.22570621  0.09783908]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #3 | lambda learn rate = 0.0001\n",
      "Target = [[7.]\n",
      " [7.]]\n",
      "lambda end of trial = [[ 0.          0.51674987 -0.24180913]\n",
      " [ 0.          0.35378769 -0.16695034]\n",
      " [ 0.         -0.15950348  0.23315473]\n",
      " [ 0.         -0.10143045  0.17888355]\n",
      " [ 0.          0.19159531  0.01406249]\n",
      " [ 0.         -0.09156659  0.24071014]\n",
      " [ 0.         -0.05095825  0.13155048]\n",
      " [ 0.         -0.07334617  0.24460897]\n",
      " [ 0.         -0.08628639  0.17479016]\n",
      " [ 0.          0.22281397  0.09494684]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #4 | lambda learn rate = 0.0001\n",
      "Target = [[7.]\n",
      " [8.]]\n",
      "lambda end of trial = [[ 0.          0.51527232 -0.24349777]\n",
      " [ 0.          0.35225405 -0.16870307]\n",
      " [ 0.         -0.16112331  0.2313035 ]\n",
      " [ 0.         -0.10301955  0.17706743]\n",
      " [ 0.          0.1900126   0.01225369]\n",
      " [ 0.         -0.09294216  0.23913807]\n",
      " [ 0.         -0.0524935   0.12979591]\n",
      " [ 0.         -0.07481562  0.2429296 ]\n",
      " [ 0.         -0.08793898  0.17290149]\n",
      " [ 0.          0.22123436  0.09314157]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #5 | lambda learn rate = 0.0001\n",
      "Target = [[3.]\n",
      " [9.]]\n",
      "lambda end of trial = [[ 0.          0.51430024 -0.24641402]\n",
      " [ 0.          0.35127814 -0.1716308 ]\n",
      " [ 0.         -0.16216421  0.2281808 ]\n",
      " [ 0.         -0.10390081  0.17442365]\n",
      " [ 0.          0.18903397  0.0093178 ]\n",
      " [ 0.         -0.09390805  0.23624039]\n",
      " [ 0.         -0.05342797  0.12699248]\n",
      " [ 0.         -0.07581513  0.23993105]\n",
      " [ 0.         -0.08895797  0.16984451]\n",
      " [ 0.          0.22013219  0.08983506]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #6 | lambda learn rate = 0.0001\n",
      "Target = [[4.]\n",
      " [0.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda end of trial = [[ 0.          0.51237057 -0.24641402]\n",
      " [ 0.          0.34933847 -0.1716308 ]\n",
      " [ 0.         -0.16433035  0.2281808 ]\n",
      " [ 0.         -0.10586779  0.17442365]\n",
      " [ 0.          0.18705321  0.0093178 ]\n",
      " [ 0.         -0.09607708  0.23624039]\n",
      " [ 0.         -0.05541695  0.12699248]\n",
      " [ 0.         -0.07778868  0.23993105]\n",
      " [ 0.         -0.09096622  0.16984451]\n",
      " [ 0.          0.21817908  0.08983506]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #7 | lambda learn rate = 0.0001\n",
      "Target = [[5.]\n",
      " [3.]]\n",
      "lambda end of trial = [[ 0.          0.51059997 -0.24747639]\n",
      " [ 0.          0.3476009  -0.17267334]\n",
      " [ 0.         -0.16618296  0.22706924]\n",
      " [ 0.         -0.10759836  0.17338531]\n",
      " [ 0.          0.18534487  0.0082928 ]\n",
      " [ 0.         -0.0979538   0.23511435]\n",
      " [ 0.         -0.05707341  0.1259986 ]\n",
      " [ 0.         -0.07961966  0.23883246]\n",
      " [ 0.         -0.09262273  0.1688506 ]\n",
      " [ 0.          0.21630997  0.08871359]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #8 | lambda learn rate = 0.0001\n",
      "Target = [[1.]\n",
      " [5.]]\n",
      "lambda end of trial = [[ 0.          0.51018352 -0.24955862]\n",
      " [ 0.          0.34716302 -0.17486276]\n",
      " [ 0.         -0.16657062  0.22513094]\n",
      " [ 0.         -0.10802848  0.17123472]\n",
      " [ 0.          0.184928    0.00620842]\n",
      " [ 0.         -0.09835899  0.23308842]\n",
      " [ 0.         -0.05752816  0.12372487]\n",
      " [ 0.         -0.08004792  0.23669115]\n",
      " [ 0.         -0.09306084  0.16666005]\n",
      " [ 0.          0.21582394  0.08628344]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #9 | lambda learn rate = 0.0001\n",
      "Target = [[7.]\n",
      " [9.]]\n",
      "lambda end of trial = [[ 0.          0.51076781 -0.24880739]\n",
      " [ 0.          0.34778364 -0.17406481]\n",
      " [ 0.         -0.16612371  0.22570554]\n",
      " [ 0.         -0.10748125  0.1719383 ]\n",
      " [ 0.          0.18541067  0.006829  ]\n",
      " [ 0.         -0.09781896  0.23378275]\n",
      " [ 0.         -0.0568488   0.12459833]\n",
      " [ 0.         -0.07946697  0.23743809]\n",
      " [ 0.         -0.0924513   0.16744376]\n",
      " [ 0.          0.21620761  0.08677673]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #10 | lambda learn rate = 0.0001\n",
      "Target = [[9.]\n",
      " [8.]]\n",
      "lambda end of trial = [[ 0.          0.51186165 -0.24783509]\n",
      " [ 0.          0.34895337 -0.17302505]\n",
      " [ 0.         -0.16491472  0.22678019]\n",
      " [ 0.         -0.10650543  0.1728057 ]\n",
      " [ 0.          0.18645336  0.00775584]\n",
      " [ 0.         -0.09681909  0.23467151]\n",
      " [ 0.         -0.0558529   0.12548357]\n",
      " [ 0.         -0.07856071  0.23824364]\n",
      " [ 0.         -0.09130675  0.16846113]\n",
      " [ 0.          0.21713305  0.08759935]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #11 | lambda learn rate = 0.0001\n",
      "Target = [[1.]\n",
      " [7.]]\n",
      "lambda end of trial = [[ 0.          0.51155154 -0.25000581]\n",
      " [ 0.          0.3486603  -0.17507657]\n",
      " [ 0.         -0.16522232  0.22462696]\n",
      " [ 0.         -0.10681756  0.17062078]\n",
      " [ 0.          0.1862038   0.00600892]\n",
      " [ 0.         -0.09713333  0.23247183]\n",
      " [ 0.         -0.05614779  0.12341935]\n",
      " [ 0.         -0.07888959  0.23594154]\n",
      " [ 0.         -0.09162607  0.16622591]\n",
      " [ 0.          0.21679008  0.08519855]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #12 | lambda learn rate = 0.0001\n",
      "Target = [[6.]\n",
      " [4.]]\n",
      "lambda end of trial = [[ 0.          0.51003748 -0.25101519]\n",
      " [ 0.          0.34723073 -0.17602961]\n",
      " [ 0.         -0.16671775  0.22363001]\n",
      " [ 0.         -0.10819912  0.16969974]\n",
      " [ 0.          0.18475975  0.00504622]\n",
      " [ 0.         -0.09857687  0.23150947]\n",
      " [ 0.         -0.05761989  0.12243796]\n",
      " [ 0.         -0.08026461  0.23502486]\n",
      " [ 0.         -0.09300376  0.16530745]\n",
      " [ 0.          0.21509855  0.08407086]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #13 | lambda learn rate = 0.0001\n",
      "Target = [[9.]\n",
      " [8.]]\n",
      "lambda end of trial = [[ 0.          0.5115886  -0.24963641]\n",
      " [ 0.          0.34879845 -0.17463609]\n",
      " [ 0.         -0.16514658  0.22502661]\n",
      " [ 0.         -0.10684189  0.17090617]\n",
      " [ 0.          0.1861811   0.00630965]\n",
      " [ 0.         -0.09724701  0.23269157]\n",
      " [ 0.         -0.05609133  0.12379667]\n",
      " [ 0.         -0.07885337  0.23627929]\n",
      " [ 0.         -0.09125681  0.1668603 ]\n",
      " [ 0.          0.21670843  0.08550187]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #14 | lambda learn rate = 0.0001\n",
      "Target = [[9.]\n",
      " [8.]]\n",
      "lambda end of trial = [[ 0.          0.51245569 -0.24886566]\n",
      " [ 0.          0.34964096 -0.17388719]\n",
      " [ 0.         -0.16421511  0.22585458]\n",
      " [ 0.         -0.10603991  0.17161903]\n",
      " [ 0.          0.1870363   0.00706982]\n",
      " [ 0.         -0.09634024  0.23349759]\n",
      " [ 0.         -0.05511595  0.12466368]\n",
      " [ 0.         -0.07815451  0.2369005 ]\n",
      " [ 0.         -0.09045402  0.16757389]\n",
      " [ 0.          0.21761598  0.08630857]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #15 | lambda learn rate = 0.0001\n",
      "Target = [[6.]\n",
      " [8.]]\n",
      "lambda end of trial = [[ 0.          0.51208518 -0.24935968]\n",
      " [ 0.          0.34929396 -0.17434986]\n",
      " [ 0.         -0.16457434  0.22537561]\n",
      " [ 0.         -0.10644216  0.1710827 ]\n",
      " [ 0.          0.18672176  0.00665043]\n",
      " [ 0.         -0.096685    0.23303791]\n",
      " [ 0.         -0.05548638  0.12416977]\n",
      " [ 0.         -0.07852812  0.23640235]\n",
      " [ 0.         -0.09074156  0.1671905 ]\n",
      " [ 0.          0.21709746  0.08561722]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #16 | lambda learn rate = 0.0001\n",
      "Target = [[4.]\n",
      " [4.]]\n",
      "lambda end of trial = [[ 0.          0.51093329 -0.25051157]\n",
      " [ 0.          0.34821961 -0.17542421]\n",
      " [ 0.         -0.16573663  0.22421332]\n",
      " [ 0.         -0.10753044  0.16999442]\n",
      " [ 0.          0.18557961  0.00550828]\n",
      " [ 0.         -0.09784274  0.23188017]\n",
      " [ 0.         -0.0565055   0.12315065]\n",
      " [ 0.         -0.07975832  0.23517215]\n",
      " [ 0.         -0.09184953  0.16608253]\n",
      " [ 0.          0.21586559  0.08438535]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #17 | lambda learn rate = 0.0001\n",
      "Target = [[1.]\n",
      " [9.]]\n",
      "lambda end of trial = [[ 0.          0.51074353 -0.25221947]\n",
      " [ 0.          0.34805357 -0.17691858]\n",
      " [ 0.         -0.1659254   0.22251435]\n",
      " [ 0.         -0.10772718  0.16822378]\n",
      " [ 0.          0.18538552  0.00376147]\n",
      " [ 0.         -0.09804453  0.23006406]\n",
      " [ 0.         -0.05668323  0.12155103]\n",
      " [ 0.         -0.07995762  0.23337837]\n",
      " [ 0.         -0.09200141  0.16471557]\n",
      " [ 0.          0.21564919  0.08243771]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #18 | lambda learn rate = 0.0001\n",
      "Target = [[5.]\n",
      " [3.]]\n",
      "lambda end of trial = [[ 0.          0.50922704 -0.25312936]\n",
      " [ 0.          0.346684   -0.17774032]\n",
      " [ 0.         -0.16744508  0.22160254]\n",
      " [ 0.         -0.10896031  0.1674839 ]\n",
      " [ 0.          0.18397743  0.00291661]\n",
      " [ 0.         -0.09947993  0.22920282]\n",
      " [ 0.         -0.05810553  0.12069765]\n",
      " [ 0.         -0.0814881   0.23246008]\n",
      " [ 0.         -0.09326845  0.16395535]\n",
      " [ 0.          0.21400517  0.0814513 ]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #19 | lambda learn rate = 0.0001\n",
      "Target = [[5.]\n",
      " [7.]]\n",
      "lambda end of trial = [[ 0.          0.50907873 -0.25333699]\n",
      " [ 0.          0.34655577 -0.17791984]\n",
      " [ 0.         -0.16754515  0.22146245]\n",
      " [ 0.         -0.10911728  0.16726414]\n",
      " [ 0.          0.18379652  0.00266334]\n",
      " [ 0.         -0.09967272  0.22893291]\n",
      " [ 0.         -0.05823496  0.12051645]\n",
      " [ 0.         -0.08169759  0.2321668 ]\n",
      " [ 0.         -0.09339513  0.163778  ]\n",
      " [ 0.          0.21376408  0.08111377]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #20 | lambda learn rate = 0.0001\n",
      "Target = [[6.]\n",
      " [0.]]\n",
      "lambda end of trial = [[ 0.          0.50651533 -0.25333699]\n",
      " [ 0.          0.34449167 -0.17791984]\n",
      " [ 0.         -0.17009125  0.22146245]\n",
      " [ 0.         -0.11149217  0.16726414]\n",
      " [ 0.          0.18155815  0.00266334]\n",
      " [ 0.         -0.10209118  0.22893291]\n",
      " [ 0.         -0.06044724  0.12051645]\n",
      " [ 0.         -0.08398013  0.2321668 ]\n",
      " [ 0.         -0.09561799  0.163778  ]\n",
      " [ 0.          0.2111859   0.08111377]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #21 | lambda learn rate = 0.0001\n",
      "Target = [[2.]\n",
      " [6.]]\n",
      "lambda end of trial = [[ 0.          0.50608162 -0.2546381 ]\n",
      " [ 0.          0.34407256 -0.17917716]\n",
      " [ 0.         -0.17050681  0.22021578]\n",
      " [ 0.         -0.11191571  0.16599352]\n",
      " [ 0.          0.18112443  0.00136217]\n",
      " [ 0.         -0.10252446  0.22763308]\n",
      " [ 0.         -0.0609165   0.11910867]\n",
      " [ 0.         -0.08443791  0.23079346]\n",
      " [ 0.         -0.09601709  0.1625807 ]\n",
      " [ 0.          0.21074265  0.07978403]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #22 | lambda learn rate = 0.0001\n",
      "Target = [[3.]\n",
      " [7.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda end of trial = [[ 0.          0.50584752 -0.25518434]\n",
      " [ 0.          0.34386537 -0.17966061]\n",
      " [ 0.         -0.17073922  0.2196735 ]\n",
      " [ 0.         -0.11212951  0.16549466]\n",
      " [ 0.          0.18089053  0.00081641]\n",
      " [ 0.         -0.10278834  0.22701737]\n",
      " [ 0.         -0.06115085  0.11856186]\n",
      " [ 0.         -0.08472483  0.23012396]\n",
      " [ 0.         -0.09622473  0.16209619]\n",
      " [ 0.          0.21044798  0.07909646]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #23 | lambda learn rate = 0.0001\n",
      "Target = [[3.]\n",
      " [1.]]\n",
      "lambda end of trial = [[ 0.00000000e+00  5.04448420e-01 -2.55650703e-01]\n",
      " [ 0.00000000e+00  3.42581072e-01 -1.80088711e-01]\n",
      " [ 0.00000000e+00 -1.72051518e-01  2.19236065e-01]\n",
      " [ 0.00000000e+00 -1.13369817e-01  1.65081228e-01]\n",
      " [ 0.00000000e+00  1.79503434e-01  3.54042483e-04]\n",
      " [ 0.00000000e+00 -1.04117518e-01  2.26574304e-01]\n",
      " [ 0.00000000e+00 -6.23963254e-02  1.18146700e-01]\n",
      " [ 0.00000000e+00 -8.60159466e-02  2.29693590e-01]\n",
      " [ 0.00000000e+00 -9.77271575e-02  1.61595381e-01]\n",
      " [ 0.00000000e+00  2.08936487e-01  7.85926327e-02]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #24 | lambda learn rate = 0.0001\n",
      "Target = [[9.]\n",
      " [1.]]\n",
      "lambda end of trial = [[ 0.00000000e+00  5.04132118e-01 -2.55685848e-01]\n",
      " [ 0.00000000e+00  3.42449399e-01 -1.80103341e-01]\n",
      " [ 0.00000000e+00 -1.72276247e-01  2.19211095e-01]\n",
      " [ 0.00000000e+00 -1.13543012e-01  1.65061984e-01]\n",
      " [ 0.00000000e+00  1.79250513e-01  3.25940092e-04]\n",
      " [ 0.00000000e+00 -1.04476581e-01  2.26534409e-01]\n",
      " [ 0.00000000e+00 -6.26845137e-02  1.18114679e-01]\n",
      " [ 0.00000000e+00 -8.63486594e-02  2.29656622e-01]\n",
      " [ 0.00000000e+00 -9.79473602e-02  1.61570914e-01]\n",
      " [ 0.00000000e+00  2.08543792e-01  7.85489999e-02]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #25 | lambda learn rate = 0.0001\n",
      "Target = [[8.]\n",
      " [0.]]\n",
      "lambda end of trial = [[ 0.00000000e+00  5.02967263e-01 -2.55685848e-01]\n",
      " [ 0.00000000e+00  3.41374710e-01 -1.80103341e-01]\n",
      " [ 0.00000000e+00 -1.73423291e-01  2.19211095e-01]\n",
      " [ 0.00000000e+00 -1.14692954e-01  1.65061984e-01]\n",
      " [ 0.00000000e+00  1.78145916e-01  3.25940092e-04]\n",
      " [ 0.00000000e+00 -1.05657073e-01  2.26534409e-01]\n",
      " [ 0.00000000e+00 -6.39275145e-02  1.18114679e-01]\n",
      " [ 0.00000000e+00 -8.76288254e-02  2.29656622e-01]\n",
      " [ 0.00000000e+00 -9.93193543e-02  1.61570914e-01]\n",
      " [ 0.00000000e+00  2.07296534e-01  7.85489999e-02]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #26 | lambda learn rate = 0.0001\n",
      "Target = [[5.]\n",
      " [3.]]\n",
      "lambda end of trial = [[ 0.00000000e+00  5.02134549e-01 -2.56185476e-01]\n",
      " [ 0.00000000e+00  3.40598068e-01 -1.80569327e-01]\n",
      " [ 0.00000000e+00 -1.74277562e-01  2.18698533e-01]\n",
      " [ 0.00000000e+00 -1.15584038e-01  1.64527334e-01]\n",
      " [ 0.00000000e+00  1.77368455e-01 -1.40536495e-04]\n",
      " [ 0.00000000e+00 -1.06583279e-01  2.25978685e-01]\n",
      " [ 0.00000000e+00 -6.48365218e-02  1.17569274e-01]\n",
      " [ 0.00000000e+00 -8.85110929e-02  2.29127262e-01]\n",
      " [ 0.00000000e+00 -1.00152748e-01  1.61070878e-01]\n",
      " [ 0.00000000e+00  2.06329095e-01  7.79685369e-02]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #27 | lambda learn rate = 0.0001\n",
      "Target = [[7.]\n",
      " [6.]]\n",
      "lambda end of trial = [[ 0.          0.50346059 -0.25504887]\n",
      " [ 0.          0.34185843 -0.17948901]\n",
      " [ 0.         -0.17294098  0.21984417]\n",
      " [ 0.         -0.11424677  0.16567356]\n",
      " [ 0.          0.17867683  0.00098093]\n",
      " [ 0.         -0.10530295  0.22707611]\n",
      " [ 0.         -0.0635046   0.11871092]\n",
      " [ 0.         -0.08730037  0.23016502]\n",
      " [ 0.         -0.09902875  0.1620343 ]\n",
      " [ 0.          0.20763416  0.07908716]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #28 | lambda learn rate = 0.0001\n",
      "Target = [[9.]\n",
      " [6.]]\n",
      "lambda end of trial = [[ 0.          0.50617926 -0.25323642]\n",
      " [ 0.          0.34419216 -0.17793319]\n",
      " [ 0.         -0.17060457  0.22140178]\n",
      " [ 0.         -0.11162214  0.16742331]\n",
      " [ 0.          0.18096444  0.002506  ]\n",
      " [ 0.         -0.10270027  0.22881123]\n",
      " [ 0.         -0.06099452  0.12038431]\n",
      " [ 0.         -0.08498084  0.23171138]\n",
      " [ 0.         -0.09644649  0.16375581]\n",
      " [ 0.          0.21032278  0.08087958]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #29 | lambda learn rate = 0.0001\n",
      "Target = [[0.]\n",
      " [9.]]\n",
      "lambda end of trial = [[ 0.          0.50617926 -0.25484963]\n",
      " [ 0.          0.34419216 -0.179329  ]\n",
      " [ 0.         -0.17060457  0.21994955]\n",
      " [ 0.         -0.11162214  0.1658572 ]\n",
      " [ 0.          0.18096444  0.00092332]\n",
      " [ 0.         -0.10270027  0.22720981]\n",
      " [ 0.         -0.06099452  0.11886816]\n",
      " [ 0.         -0.08498084  0.23019473]\n",
      " [ 0.         -0.09644649  0.16223458]\n",
      " [ 0.          0.21032278  0.07911986]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #30 | lambda learn rate = 0.0001\n",
      "Target = [[2.]\n",
      " [1.]]\n",
      "lambda end of trial = [[ 0.00000000e+00  5.05152897e-01 -2.55362812e-01]\n",
      " [ 0.00000000e+00  3.43202101e-01 -1.79824035e-01]\n",
      " [ 0.00000000e+00 -1.71690087e-01  2.19406790e-01]\n",
      " [ 0.00000000e+00 -1.12803296e-01  1.65266629e-01]\n",
      " [ 0.00000000e+00  1.79893802e-01  3.87997365e-04]\n",
      " [ 0.00000000e+00 -1.03782912e-01  2.26668493e-01]\n",
      " [ 0.00000000e+00 -6.20407862e-02  1.18345024e-01]\n",
      " [ 0.00000000e+00 -8.61177482e-02  2.29626275e-01]\n",
      " [ 0.00000000e+00 -9.74815808e-02  1.61717037e-01]\n",
      " [ 0.00000000e+00  2.09217967e-01  7.85674532e-02]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #31 | lambda learn rate = 0.0001\n",
      "Target = [[1.]\n",
      " [6.]]\n",
      "lambda end of trial = [[ 0.          0.50492349 -0.25673924]\n",
      " [ 0.          0.3429676  -0.18123103]\n",
      " [ 0.         -0.17192527  0.21799569]\n",
      " [ 0.         -0.11306249  0.16371145]\n",
      " [ 0.          0.17963662 -0.00115511]\n",
      " [ 0.         -0.10404443  0.22509939]\n",
      " [ 0.         -0.06230663  0.11674996]\n",
      " [ 0.         -0.08637224  0.22809935]\n",
      " [ 0.         -0.09775646  0.16006778]\n",
      " [ 0.          0.20894774  0.07694611]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #32 | lambda learn rate = 0.0001\n",
      "Target = [[2.]\n",
      " [0.]]\n",
      "lambda end of trial = [[ 0.          0.50379349 -0.25673924]\n",
      " [ 0.          0.34196313 -0.18123103]\n",
      " [ 0.         -0.17302394  0.21799569]\n",
      " [ 0.         -0.11415355  0.16371145]\n",
      " [ 0.          0.17854527 -0.00115511]\n",
      " [ 0.         -0.10514102  0.22509939]\n",
      " [ 0.         -0.06337148  0.11674996]\n",
      " [ 0.         -0.08740648  0.22809935]\n",
      " [ 0.         -0.09886221  0.16006778]\n",
      " [ 0.          0.2078458   0.07694611]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #33 | lambda learn rate = 0.0001\n",
      "Target = [[1.]\n",
      " [4.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda end of trial = [[ 0.          0.50345659 -0.25808688]\n",
      " [ 0.          0.34158447 -0.18274568]\n",
      " [ 0.         -0.17339482  0.21651219]\n",
      " [ 0.         -0.11447981  0.16240641]\n",
      " [ 0.          0.17824733 -0.00234684]\n",
      " [ 0.         -0.10553508  0.22352316]\n",
      " [ 0.         -0.06371431  0.11537865]\n",
      " [ 0.         -0.0878157   0.2264625 ]\n",
      " [ 0.         -0.09923997  0.15855675]\n",
      " [ 0.          0.20744752  0.075353  ]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #34 | lambda learn rate = 0.0001\n",
      "Target = [[1.]\n",
      " [1.]]\n",
      "lambda end of trial = [[ 0.          0.50293949 -0.25860397]\n",
      " [ 0.          0.34107277 -0.18325737]\n",
      " [ 0.         -0.17393947  0.21596754]\n",
      " [ 0.         -0.11499679  0.16188943]\n",
      " [ 0.          0.17777154 -0.00282263]\n",
      " [ 0.         -0.1060497   0.22300854]\n",
      " [ 0.         -0.0642589   0.11483406]\n",
      " [ 0.         -0.08836292  0.22591527]\n",
      " [ 0.         -0.09975674  0.15803999]\n",
      " [ 0.          0.20690599  0.07481147]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #35 | lambda learn rate = 0.0001\n",
      "Target = [[6.]\n",
      " [0.]]\n",
      "lambda end of trial = [[ 0.          0.50101101 -0.25860397]\n",
      " [ 0.          0.33936853 -0.18325737]\n",
      " [ 0.         -0.17566116  0.21596754]\n",
      " [ 0.         -0.11682195  0.16188943]\n",
      " [ 0.          0.17595845 -0.00282263]\n",
      " [ 0.         -0.10784305  0.22300854]\n",
      " [ 0.         -0.065918    0.11483406]\n",
      " [ 0.         -0.09000353  0.22591527]\n",
      " [ 0.         -0.10134277  0.15803999]\n",
      " [ 0.          0.20502991  0.07481147]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #36 | lambda learn rate = 0.0001\n",
      "Target = [[2.]\n",
      " [3.]]\n",
      "lambda end of trial = [[ 0.          0.50034776 -0.25959885]\n",
      " [ 0.          0.33872428 -0.18422376]\n",
      " [ 0.         -0.17633199  0.21496129]\n",
      " [ 0.         -0.11738245  0.16104869]\n",
      " [ 0.          0.1753343  -0.00375885]\n",
      " [ 0.         -0.10844766  0.22210162]\n",
      " [ 0.         -0.06651759  0.11393469]\n",
      " [ 0.         -0.09062356  0.22498523]\n",
      " [ 0.         -0.10197444  0.15709248]\n",
      " [ 0.          0.2043615   0.07380884]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #37 | lambda learn rate = 0.0001\n",
      "Target = [[4.]\n",
      " [7.]]\n",
      "lambda end of trial = [[ 0.          0.50093612 -0.25856921]\n",
      " [ 0.          0.33921664 -0.18336213]\n",
      " [ 0.         -0.17580939  0.21587584]\n",
      " [ 0.         -0.11681251  0.16204608]\n",
      " [ 0.          0.17584136 -0.0028715 ]\n",
      " [ 0.         -0.10793672  0.22299576]\n",
      " [ 0.         -0.06592798  0.11496649]\n",
      " [ 0.         -0.09009662  0.22590736]\n",
      " [ 0.         -0.10143014  0.15804501]\n",
      " [ 0.          0.20482007  0.07461136]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #38 | lambda learn rate = 0.0001\n",
      "Target = [[6.]\n",
      " [2.]]\n",
      "lambda end of trial = [[ 0.          0.50035665 -0.25876237]\n",
      " [ 0.          0.3386604  -0.18354754]\n",
      " [ 0.         -0.17636555  0.21569045]\n",
      " [ 0.         -0.11741396  0.1618456 ]\n",
      " [ 0.          0.17525213 -0.00306791]\n",
      " [ 0.         -0.10856426  0.22278659]\n",
      " [ 0.         -0.0664739   0.11478452]\n",
      " [ 0.         -0.0907216   0.22569904]\n",
      " [ 0.         -0.10206093  0.15783475]\n",
      " [ 0.          0.20415109  0.07438836]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #39 | lambda learn rate = 0.0001\n",
      "Target = [[6.]\n",
      " [3.]]\n",
      "lambda end of trial = [[ 0.          0.50023971 -0.25882084]\n",
      " [ 0.          0.33853681 -0.18360934]\n",
      " [ 0.         -0.17647678  0.21563484]\n",
      " [ 0.         -0.11754373  0.16178071]\n",
      " [ 0.          0.17510195 -0.003143  ]\n",
      " [ 0.         -0.10872799  0.22270472]\n",
      " [ 0.         -0.06657804  0.11473245]\n",
      " [ 0.         -0.09091802  0.22560083]\n",
      " [ 0.         -0.1021273   0.15780156]\n",
      " [ 0.          0.20390576  0.0742657 ]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #40 | lambda learn rate = 0.0001\n",
      "Target = [[9.]\n",
      " [0.]]\n",
      "lambda end of trial = [[ 0.          0.50042058 -0.25882084]\n",
      " [ 0.          0.33880841 -0.18360934]\n",
      " [ 0.         -0.17631114  0.21563484]\n",
      " [ 0.         -0.11735466  0.16178071]\n",
      " [ 0.          0.17517172 -0.003143  ]\n",
      " [ 0.         -0.10855313  0.22270472]\n",
      " [ 0.         -0.06635317  0.11473245]\n",
      " [ 0.         -0.09078009  0.22560083]\n",
      " [ 0.         -0.10191575  0.15780156]\n",
      " [ 0.          0.20404797  0.0742657 ]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #41 | lambda learn rate = 0.0001\n",
      "Target = [[2.]\n",
      " [9.]]\n",
      "lambda end of trial = [[ 0.          0.50064681 -0.25780282]\n",
      " [ 0.          0.33903603 -0.18258506]\n",
      " [ 0.         -0.17607446  0.2166999 ]\n",
      " [ 0.         -0.11713185  0.16278338]\n",
      " [ 0.          0.17543326 -0.00196609]\n",
      " [ 0.         -0.10831204  0.22378962]\n",
      " [ 0.         -0.06612254  0.11577028]\n",
      " [ 0.         -0.09057658  0.22651662]\n",
      " [ 0.         -0.10165648  0.15896826]\n",
      " [ 0.          0.20428625  0.07533793]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #42 | lambda learn rate = 0.0001\n",
      "Target = [[6.]\n",
      " [4.]]\n",
      "lambda end of trial = [[ 0.          0.50086361 -0.25765828]\n",
      " [ 0.          0.33921699 -0.18246442]\n",
      " [ 0.         -0.17588126  0.2168287 ]\n",
      " [ 0.         -0.11688966  0.16294484]\n",
      " [ 0.          0.17560041 -0.00185466]\n",
      " [ 0.         -0.10816298  0.22388899]\n",
      " [ 0.         -0.06591314  0.11590988]\n",
      " [ 0.         -0.09043343  0.22661205]\n",
      " [ 0.         -0.10141414  0.15912982]\n",
      " [ 0.          0.20441243  0.07542205]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #43 | lambda learn rate = 0.0001\n",
      "Target = [[4.]\n",
      " [9.]]\n",
      "lambda end of trial = [[ 0.00000000e+00  5.01736976e-01 -2.55693213e-01]\n",
      " [ 0.00000000e+00  3.40167201e-01 -1.80326451e-01]\n",
      " [ 0.00000000e+00 -1.75034572e-01  2.18733734e-01]\n",
      " [ 0.00000000e+00 -1.16038227e-01  1.64860559e-01]\n",
      " [ 0.00000000e+00  1.76555089e-01  2.93369730e-04]\n",
      " [ 0.00000000e+00 -1.07279423e-01  2.25876990e-01]\n",
      " [ 0.00000000e+00 -6.49972896e-02  1.17970544e-01]\n",
      " [ 0.00000000e+00 -8.95716816e-02  2.28550995e-01]\n",
      " [ 0.00000000e+00 -1.00559767e-01  1.61052161e-01]\n",
      " [ 0.00000000e+00  2.05240385e-01  7.72849513e-02]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #44 | lambda learn rate = 0.0001\n",
      "Target = [[5.]\n",
      " [3.]]\n",
      "lambda end of trial = [[ 0.00000000e+00  5.01174252e-01 -2.56030848e-01]\n",
      " [ 0.00000000e+00  3.39573705e-01 -1.80682549e-01]\n",
      " [ 0.00000000e+00 -1.75523414e-01  2.18440429e-01]\n",
      " [ 0.00000000e+00 -1.16642941e-01  1.64497731e-01]\n",
      " [ 0.00000000e+00  1.75881941e-01 -1.10519293e-04]\n",
      " [ 0.00000000e+00 -1.07952810e-01  2.25472957e-01]\n",
      " [ 0.00000000e+00 -6.56328481e-02  1.17589208e-01]\n",
      " [ 0.00000000e+00 -9.02206490e-02  2.28161615e-01]\n",
      " [ 0.00000000e+00 -1.01067049e-01  1.60747793e-01]\n",
      " [ 0.00000000e+00  2.04517036e-01  7.68509416e-02]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #45 | lambda learn rate = 0.0001\n",
      "Target = [[8.]\n",
      " [7.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda end of trial = [[ 0.          0.50408231 -0.2534863 ]\n",
      " [ 0.          0.34231911 -0.17828032]\n",
      " [ 0.         -0.17286267  0.22076858]\n",
      " [ 0.         -0.1136913   0.16708041]\n",
      " [ 0.          0.17897333  0.00259445]\n",
      " [ 0.         -0.10524839  0.22783933]\n",
      " [ 0.         -0.06290819  0.11997328]\n",
      " [ 0.         -0.08735798  0.23066645]\n",
      " [ 0.         -0.09800645  0.16342582]\n",
      " [ 0.          0.20723907  0.07923272]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #46 | lambda learn rate = 0.0001\n",
      "Target = [[6.]\n",
      " [8.]]\n",
      "lambda end of trial = [[ 0.          0.50517838 -0.25202487]\n",
      " [ 0.          0.34348287 -0.17672864]\n",
      " [ 0.         -0.17181875  0.22216048]\n",
      " [ 0.         -0.11249256  0.16867874]\n",
      " [ 0.          0.18002172  0.0039923 ]\n",
      " [ 0.         -0.10411332  0.22935276]\n",
      " [ 0.         -0.0617771   0.1214814 ]\n",
      " [ 0.         -0.0863706   0.23198295]\n",
      " [ 0.         -0.09681449  0.16501509]\n",
      " [ 0.          0.20822649  0.08054929]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #47 | lambda learn rate = 0.0001\n",
      "Target = [[6.]\n",
      " [7.]]\n",
      "lambda end of trial = [[ 0.          0.50563483 -0.25149234]\n",
      " [ 0.          0.34401637 -0.17610622]\n",
      " [ 0.         -0.1713781   0.22267456]\n",
      " [ 0.         -0.11202467  0.16922461]\n",
      " [ 0.          0.18053816  0.00459481]\n",
      " [ 0.         -0.10365436  0.22988821]\n",
      " [ 0.         -0.0613106   0.12202566]\n",
      " [ 0.         -0.08597983  0.23243886]\n",
      " [ 0.         -0.09642464  0.16546992]\n",
      " [ 0.          0.20853592  0.08091028]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #48 | lambda learn rate = 0.0001\n",
      "Target = [[5.]\n",
      " [8.]]\n",
      "lambda end of trial = [[ 0.          0.50586245 -0.25112815]\n",
      " [ 0.          0.34422346 -0.17577487]\n",
      " [ 0.         -0.17115576  0.22303031]\n",
      " [ 0.         -0.11179965  0.16958463]\n",
      " [ 0.          0.18076162  0.00495234]\n",
      " [ 0.         -0.10344843  0.23021769]\n",
      " [ 0.         -0.06108379  0.12238854]\n",
      " [ 0.         -0.08576608  0.23278085]\n",
      " [ 0.         -0.09618141  0.16585909]\n",
      " [ 0.          0.20862371  0.08105075]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #49 | lambda learn rate = 0.0001\n",
      "Target = [[8.]\n",
      " [0.]]\n",
      "lambda end of trial = [[ 0.          0.50457729 -0.25112815]\n",
      " [ 0.          0.34300456 -0.17577487]\n",
      " [ 0.         -0.17238472  0.22303031]\n",
      " [ 0.         -0.11300521  0.16958463]\n",
      " [ 0.          0.1794435   0.00495234]\n",
      " [ 0.         -0.1048131   0.23021769]\n",
      " [ 0.         -0.06242208  0.12238854]\n",
      " [ 0.         -0.0871747   0.23278085]\n",
      " [ 0.         -0.09767333  0.16585909]\n",
      " [ 0.          0.20731786  0.08105075]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #50 | lambda learn rate = 0.0001\n",
      "Target = [[8.]\n",
      " [1.]]\n",
      "lambda end of trial = [[ 0.          0.50385609 -0.2512183 ]\n",
      " [ 0.          0.34251727 -0.17583578]\n",
      " [ 0.         -0.17303136  0.22294948]\n",
      " [ 0.         -0.1135573   0.16951562]\n",
      " [ 0.          0.17870726  0.00486031]\n",
      " [ 0.         -0.10554443  0.23012627]\n",
      " [ 0.         -0.06306238  0.12230851]\n",
      " [ 0.         -0.08787784  0.23269296]\n",
      " [ 0.         -0.09837509  0.16577137]\n",
      " [ 0.          0.20662368  0.08096398]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #51 | lambda learn rate = 0.0001\n",
      "Target = [[7.]\n",
      " [8.]]\n",
      "lambda end of trial = [[ 0.          0.50547736 -0.24936542]\n",
      " [ 0.          0.34393902 -0.17421093]\n",
      " [ 0.         -0.17171234  0.22445693]\n",
      " [ 0.         -0.1123161   0.17093414]\n",
      " [ 0.          0.17995979  0.00629178]\n",
      " [ 0.         -0.10422837  0.23163034]\n",
      " [ 0.         -0.06165446  0.12391756]\n",
      " [ 0.         -0.08633567  0.23445543]\n",
      " [ 0.         -0.09703313  0.16730504]\n",
      " [ 0.          0.20805141  0.08259567]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #52 | lambda learn rate = 0.0001\n",
      "Target = [[8.]\n",
      " [0.]]\n",
      "lambda end of trial = [[ 0.          0.50366134 -0.24936542]\n",
      " [ 0.          0.34236178 -0.17421093]\n",
      " [ 0.         -0.17326517  0.22445693]\n",
      " [ 0.         -0.11396412  0.17093414]\n",
      " [ 0.          0.17850479  0.00629178]\n",
      " [ 0.         -0.10600269  0.23163034]\n",
      " [ 0.         -0.06336846  0.12391756]\n",
      " [ 0.         -0.08819158  0.23445543]\n",
      " [ 0.         -0.09872587  0.16730504]\n",
      " [ 0.          0.20619775  0.08259567]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #53 | lambda learn rate = 0.0001\n",
      "Target = [[8.]\n",
      " [7.]]\n",
      "lambda end of trial = [[ 0.          0.50535509 -0.24788338]\n",
      " [ 0.          0.3438755  -0.17288642]\n",
      " [ 0.         -0.17164154  0.2258776 ]\n",
      " [ 0.         -0.11234477  0.17235107]\n",
      " [ 0.          0.18019569  0.00777132]\n",
      " [ 0.         -0.10450721  0.23293889]\n",
      " [ 0.         -0.06162079  0.12544677]\n",
      " [ 0.         -0.08661522  0.23583475]\n",
      " [ 0.         -0.09715526  0.16867933]\n",
      " [ 0.          0.20763661  0.08385467]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #54 | lambda learn rate = 0.0001\n",
      "Target = [[5.]\n",
      " [8.]]\n",
      "lambda end of trial = [[ 0.          0.50541284 -0.24779099]\n",
      " [ 0.          0.34400391 -0.17268098]\n",
      " [ 0.         -0.17161564  0.22591904]\n",
      " [ 0.         -0.11230506  0.17241462]\n",
      " [ 0.          0.1802655   0.00788302]\n",
      " [ 0.         -0.10450206  0.23294713]\n",
      " [ 0.         -0.06148275  0.12566763]\n",
      " [ 0.         -0.08660856  0.23584541]\n",
      " [ 0.         -0.09707497  0.16880779]\n",
      " [ 0.          0.20758522  0.08377244]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #55 | lambda learn rate = 0.0001\n",
      "Target = [[8.]\n",
      " [2.]]\n",
      "lambda end of trial = [[ 0.          0.50474255 -0.24795856]\n",
      " [ 0.          0.34351001 -0.17280445]\n",
      " [ 0.         -0.17206551  0.22580657]\n",
      " [ 0.         -0.11288935  0.17226854]\n",
      " [ 0.          0.17959219  0.00771469]\n",
      " [ 0.         -0.10518426  0.23277658]\n",
      " [ 0.         -0.06205194  0.12552533]\n",
      " [ 0.         -0.08735578  0.2356586 ]\n",
      " [ 0.         -0.09768963  0.16865412]\n",
      " [ 0.          0.20692784  0.0836081 ]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #56 | lambda learn rate = 0.0001\n",
      "Target = [[3.]\n",
      " [5.]]\n",
      "lambda end of trial = [[ 0.          0.5038079  -0.24951631]\n",
      " [ 0.          0.34269158 -0.17416851]\n",
      " [ 0.         -0.17293589  0.22435594]\n",
      " [ 0.         -0.11380977  0.17073451]\n",
      " [ 0.          0.17861542  0.00608674]\n",
      " [ 0.         -0.10616942  0.23113463]\n",
      " [ 0.         -0.0628606   0.12417758]\n",
      " [ 0.         -0.08829099  0.23409993]\n",
      " [ 0.         -0.09854061  0.16723583]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [ 0.          0.20597656  0.08202263]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #57 | lambda learn rate = 0.0001\n",
      "Target = [[3.]\n",
      " [2.]]\n",
      "lambda end of trial = [[ 0.          0.50280323 -0.25018609]\n",
      " [ 0.          0.34149795 -0.17496426]\n",
      " [ 0.         -0.17385519  0.22374307]\n",
      " [ 0.         -0.11482905  0.17005499]\n",
      " [ 0.          0.1775575   0.00538146]\n",
      " [ 0.         -0.10724782  0.2304157 ]\n",
      " [ 0.         -0.06385373  0.12351549]\n",
      " [ 0.         -0.08944595  0.23332995]\n",
      " [ 0.         -0.09965457  0.16649318]\n",
      " [ 0.          0.20484408  0.08126764]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #58 | lambda learn rate = 0.0001\n",
      "Target = [[9.]\n",
      " [9.]]\n",
      "lambda end of trial = [[ 0.          0.50587586 -0.24711346]\n",
      " [ 0.          0.34517991 -0.1712823 ]\n",
      " [ 0.         -0.17023714  0.22736112]\n",
      " [ 0.         -0.11117557  0.17370847]\n",
      " [ 0.          0.1814167   0.00924066]\n",
      " [ 0.         -0.10330503  0.23435849]\n",
      " [ 0.         -0.06008875  0.12728047]\n",
      " [ 0.         -0.08573349  0.23704241]\n",
      " [ 0.         -0.09621547  0.16993229]\n",
      " [ 0.          0.20841827  0.08484183]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #59 | lambda learn rate = 0.0001\n",
      "Target = [[6.]\n",
      " [1.]]\n",
      "lambda end of trial = [[ 0.          0.50412234 -0.24740572]\n",
      " [ 0.          0.34367342 -0.17153338]\n",
      " [ 0.         -0.17193663  0.22707787]\n",
      " [ 0.         -0.11286105  0.17342755]\n",
      " [ 0.          0.17981547  0.00897378]\n",
      " [ 0.         -0.10483161  0.23410406]\n",
      " [ 0.         -0.06164178  0.12702163]\n",
      " [ 0.         -0.08759595  0.236732  ]\n",
      " [ 0.         -0.097836    0.1696622 ]\n",
      " [ 0.          0.20668088  0.08455226]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #60 | lambda learn rate = 0.0001\n",
      "Target = [[2.]\n",
      " [8.]]\n",
      "lambda end of trial = [[ 0.          0.50368379 -0.24915992]\n",
      " [ 0.          0.34321992 -0.17334738]\n",
      " [ 0.         -0.17234689  0.22543681]\n",
      " [ 0.         -0.11334061  0.17150934]\n",
      " [ 0.          0.17938143  0.0072376 ]\n",
      " [ 0.         -0.10528151  0.23230443]\n",
      " [ 0.         -0.06207791  0.12527714]\n",
      " [ 0.         -0.08807079  0.23483262]\n",
      " [ 0.         -0.0982697   0.16792739]\n",
      " [ 0.          0.20616416  0.08248539]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #61 | lambda learn rate = 0.0001\n",
      "Target = [[8.]\n",
      " [4.]]\n",
      "lambda end of trial = [[ 0.          0.50399123 -0.2490062 ]\n",
      " [ 0.          0.34355143 -0.17318163]\n",
      " [ 0.         -0.17198377  0.22561837]\n",
      " [ 0.         -0.11311414  0.17162257]\n",
      " [ 0.          0.1797054   0.00739958]\n",
      " [ 0.         -0.1050125   0.23243893]\n",
      " [ 0.         -0.06178007  0.12542606]\n",
      " [ 0.         -0.08775664  0.2349897 ]\n",
      " [ 0.         -0.09795062  0.16808692]\n",
      " [ 0.          0.20637992  0.08259327]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #62 | lambda learn rate = 0.0001\n",
      "Target = [[7.]\n",
      " [4.]]\n",
      "lambda end of trial = [[ 0.          0.50371905 -0.24916173]\n",
      " [ 0.          0.34339541 -0.17327078]\n",
      " [ 0.         -0.17215282  0.22552177]\n",
      " [ 0.         -0.11323584  0.17155303]\n",
      " [ 0.          0.17956614  0.00732   ]\n",
      " [ 0.         -0.10533145  0.23225667]\n",
      " [ 0.         -0.06202463  0.12528631]\n",
      " [ 0.         -0.08798574  0.23485878]\n",
      " [ 0.         -0.09810271  0.16800002]\n",
      " [ 0.          0.2060895   0.08242732]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #63 | lambda learn rate = 0.0001\n",
      "Target = [[1.]\n",
      " [7.]]\n",
      "lambda end of trial = [[ 0.          0.50337843 -0.25154611]\n",
      " [ 0.          0.34309295 -0.17538796]\n",
      " [ 0.         -0.17244976  0.22344321]\n",
      " [ 0.         -0.11352584  0.16952307]\n",
      " [ 0.          0.1792583   0.00516516]\n",
      " [ 0.         -0.10566564  0.22991735]\n",
      " [ 0.         -0.06231556  0.12324981]\n",
      " [ 0.         -0.08830033  0.23265666]\n",
      " [ 0.         -0.09843481  0.16567528]\n",
      " [ 0.          0.20574986  0.08004984]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #64 | lambda learn rate = 0.0001\n",
      "Target = [[9.]\n",
      " [8.]]\n",
      "lambda end of trial = [[ 0.          0.50611845 -0.24911053]\n",
      " [ 0.          0.34617366 -0.17264955]\n",
      " [ 0.         -0.16932689  0.2262191 ]\n",
      " [ 0.         -0.11028429  0.17240444]\n",
      " [ 0.          0.18253661  0.00807921]\n",
      " [ 0.         -0.10283591  0.23243267]\n",
      " [ 0.         -0.05925446  0.12597078]\n",
      " [ 0.         -0.08539872  0.23523587]\n",
      " [ 0.         -0.09553387  0.16825389]\n",
      " [ 0.          0.20867768  0.08265235]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #65 | lambda learn rate = 0.0001\n",
      "Target = [[9.]\n",
      " [9.]]\n",
      "lambda end of trial = [[ 0.          0.50823773 -0.24699125]\n",
      " [ 0.          0.34853174 -0.17029147]\n",
      " [ 0.         -0.16687183  0.22867416]\n",
      " [ 0.         -0.10784556  0.17484317]\n",
      " [ 0.          0.18490092  0.01044352]\n",
      " [ 0.         -0.10039468  0.2348739 ]\n",
      " [ 0.         -0.05698177  0.12824348]\n",
      " [ 0.         -0.08312563  0.23750895]\n",
      " [ 0.         -0.093276    0.17051176]\n",
      " [ 0.          0.21125499  0.08522966]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #66 | lambda learn rate = 0.0001\n",
      "Target = [[8.]\n",
      " [7.]]\n",
      "lambda end of trial = [[ 0.          0.50836834 -0.24687696]\n",
      " [ 0.          0.34870965 -0.1701358 ]\n",
      " [ 0.         -0.16669346  0.22883023]\n",
      " [ 0.         -0.10768475  0.17498388]\n",
      " [ 0.          0.18509316  0.01061173]\n",
      " [ 0.         -0.10037463  0.23489145]\n",
      " [ 0.         -0.05686774  0.12834325]\n",
      " [ 0.         -0.08301681  0.23760418]\n",
      " [ 0.         -0.09316367  0.17061005]\n",
      " [ 0.          0.21128045  0.08525193]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #67 | lambda learn rate = 0.0001\n",
      "Target = [[2.]\n",
      " [1.]]\n",
      "lambda end of trial = [[ 0.          0.50730536 -0.24740845]\n",
      " [ 0.          0.34756572 -0.17070776]\n",
      " [ 0.         -0.16771043  0.22832175]\n",
      " [ 0.         -0.10880156  0.17442547]\n",
      " [ 0.          0.18378574  0.00995802]\n",
      " [ 0.         -0.10155844  0.23429954]\n",
      " [ 0.         -0.05793611  0.12780907]\n",
      " [ 0.         -0.08417121  0.23702698]\n",
      " [ 0.         -0.09434327  0.17002025]\n",
      " [ 0.          0.21009295  0.08465818]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #68 | lambda learn rate = 0.0001\n",
      "Target = [[3.]\n",
      " [0.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda end of trial = [[ 0.          0.50569228 -0.24740845]\n",
      " [ 0.          0.34613803 -0.17070776]\n",
      " [ 0.         -0.16931845  0.22832175]\n",
      " [ 0.         -0.11042611  0.17442547]\n",
      " [ 0.          0.18222906  0.00995802]\n",
      " [ 0.         -0.10320075  0.23429954]\n",
      " [ 0.         -0.05943688  0.12780907]\n",
      " [ 0.         -0.08587514  0.23702698]\n",
      " [ 0.         -0.09605476  0.17002025]\n",
      " [ 0.          0.20861279  0.08465818]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #69 | lambda learn rate = 0.0001\n",
      "Target = [[4.]\n",
      " [3.]]\n",
      "lambda end of trial = [[ 0.          0.50443877 -0.24834859]\n",
      " [ 0.          0.34495673 -0.17159374]\n",
      " [ 0.         -0.17060065  0.2273601 ]\n",
      " [ 0.         -0.11176928  0.1734181 ]\n",
      " [ 0.          0.18097776  0.00901955]\n",
      " [ 0.         -0.10441051  0.23339222]\n",
      " [ 0.         -0.06066601  0.12688722]\n",
      " [ 0.         -0.0871147   0.23609731]\n",
      " [ 0.         -0.09739981  0.16901147]\n",
      " [ 0.          0.20724384  0.08363147]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #70 | lambda learn rate = 0.0001\n",
      "Target = [[0.]\n",
      " [7.]]\n",
      "lambda end of trial = [[ 0.          0.50443877 -0.25143537]\n",
      " [ 0.          0.34495673 -0.1743949 ]\n",
      " [ 0.         -0.17060065  0.22459629]\n",
      " [ 0.         -0.11176928  0.17043509]\n",
      " [ 0.          0.18097776  0.00597824]\n",
      " [ 0.         -0.10441051  0.23045674]\n",
      " [ 0.         -0.06066601  0.12404192]\n",
      " [ 0.         -0.0871147   0.23316468]\n",
      " [ 0.         -0.09739981  0.16618109]\n",
      " [ 0.          0.20724384  0.08065686]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #71 | lambda learn rate = 0.0001\n",
      "Target = [[9.]\n",
      " [9.]]\n",
      "lambda end of trial = [[ 0.          0.50757647 -0.24829766]\n",
      " [ 0.          0.34837775 -0.17097389]\n",
      " [ 0.         -0.16756836  0.22762859]\n",
      " [ 0.         -0.10863194  0.17357244]\n",
      " [ 0.          0.18400247  0.00900296]\n",
      " [ 0.         -0.10143781  0.23342945]\n",
      " [ 0.         -0.05767287  0.12703506]\n",
      " [ 0.         -0.08408536  0.23619402]\n",
      " [ 0.         -0.09412681  0.16945408]\n",
      " [ 0.          0.21012459  0.08353761]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #72 | lambda learn rate = 0.0001\n",
      "Target = [[6.]\n",
      " [7.]]\n",
      "lambda end of trial = [[ 0.          0.50718084 -0.24875923]\n",
      " [ 0.          0.34806199 -0.17134227]\n",
      " [ 0.         -0.1679741   0.22715523]\n",
      " [ 0.         -0.10898143  0.1731647 ]\n",
      " [ 0.          0.18360721  0.00854182]\n",
      " [ 0.         -0.10189054  0.23290126]\n",
      " [ 0.         -0.05794934  0.12671251]\n",
      " [ 0.         -0.08445677  0.23576071]\n",
      " [ 0.         -0.09447918  0.16904299]\n",
      " [ 0.          0.2096561   0.08299104]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #73 | lambda learn rate = 0.0001\n",
      "Target = [[6.]\n",
      " [7.]]\n",
      "lambda end of trial = [[ 0.          0.50682963 -0.24916898]\n",
      " [ 0.          0.34769914 -0.1717656 ]\n",
      " [ 0.         -0.16830117  0.22677364]\n",
      " [ 0.         -0.10941376  0.17266031]\n",
      " [ 0.          0.18318818  0.00805295]\n",
      " [ 0.         -0.10239215  0.23231605]\n",
      " [ 0.         -0.05830029  0.12630307]\n",
      " [ 0.         -0.08498268  0.23514715]\n",
      " [ 0.         -0.0948566   0.16860266]\n",
      " [ 0.          0.20920419  0.08246381]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #74 | lambda learn rate = 0.0001\n",
      "Target = [[6.]\n",
      " [0.]]\n",
      "lambda end of trial = [[ 0.          0.50494068 -0.24916898]\n",
      " [ 0.          0.34599416 -0.1717656 ]\n",
      " [ 0.         -0.17008351  0.22677364]\n",
      " [ 0.         -0.11119116  0.17266031]\n",
      " [ 0.          0.18106127  0.00805295]\n",
      " [ 0.         -0.10416274  0.23231605]\n",
      " [ 0.         -0.06014255  0.12630307]\n",
      " [ 0.         -0.08706391  0.23514715]\n",
      " [ 0.         -0.0966052   0.16860266]\n",
      " [ 0.          0.20735742  0.08246381]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #75 | lambda learn rate = 0.0001\n",
      "Target = [[8.]\n",
      " [5.]]\n",
      "lambda end of trial = [[ 0.          0.50528227 -0.24895548]\n",
      " [ 0.          0.34641687 -0.17150141]\n",
      " [ 0.         -0.16973352  0.22699238]\n",
      " [ 0.         -0.11074394  0.17293983]\n",
      " [ 0.          0.18148088  0.00831521]\n",
      " [ 0.         -0.10383236  0.23252254]\n",
      " [ 0.         -0.05958759  0.12664992]\n",
      " [ 0.         -0.08668284  0.23538532]\n",
      " [ 0.         -0.09621166  0.16884862]\n",
      " [ 0.          0.20765334  0.08264875]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #76 | lambda learn rate = 0.0001\n",
      "Target = [[4.]\n",
      " [9.]]\n",
      "lambda end of trial = [[ 0.          0.5050308  -0.24952129]\n",
      " [ 0.          0.34621267 -0.17196085]\n",
      " [ 0.         -0.16991358  0.22658724]\n",
      " [ 0.         -0.11096008  0.17245351]\n",
      " [ 0.          0.18127534  0.00785274]\n",
      " [ 0.         -0.10408027  0.23196472]\n",
      " [ 0.         -0.05976555  0.1262495 ]\n",
      " [ 0.         -0.08695298  0.23477751]\n",
      " [ 0.         -0.09640159  0.16842129]\n",
      " [ 0.          0.20734251  0.08194939]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #77 | lambda learn rate = 0.0001\n",
      "Target = [[5.]\n",
      " [6.]]\n",
      "lambda end of trial = [[ 0.          0.50462581 -0.25000728]\n",
      " [ 0.          0.3458401  -0.17240793]\n",
      " [ 0.         -0.17035898  0.22605277]\n",
      " [ 0.         -0.11142021  0.17190135]\n",
      " [ 0.          0.18078022  0.0072586 ]\n",
      " [ 0.         -0.10460044  0.23134052]\n",
      " [ 0.         -0.06020621  0.12572071]\n",
      " [ 0.         -0.0875072   0.23411244]\n",
      " [ 0.         -0.0968016   0.16794128]\n",
      " [ 0.          0.20678565  0.08128116]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #78 | lambda learn rate = 0.0001\n",
      "Target = [[0.]\n",
      " [8.]]\n",
      "lambda end of trial = [[ 0.          0.50462581 -0.25249323]\n",
      " [ 0.          0.3458401  -0.17498657]\n",
      " [ 0.         -0.17035898  0.22356167]\n",
      " [ 0.         -0.11142021  0.16944843]\n",
      " [ 0.          0.18078022  0.00464645]\n",
      " [ 0.         -0.10460044  0.22883545]\n",
      " [ 0.         -0.06020621  0.12322823]\n",
      " [ 0.         -0.0875072   0.23133929]\n",
      " [ 0.         -0.0968016   0.16510673]\n",
      " [ 0.          0.20678565  0.07800618]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #79 | lambda learn rate = 0.0001\n",
      "Target = [[4.]\n",
      " [4.]]\n",
      "lambda end of trial = [[ 0.          0.50396547 -0.25315357]\n",
      " [ 0.          0.34516511 -0.17566157]\n",
      " [ 0.         -0.17102733  0.22289331]\n",
      " [ 0.         -0.1121028   0.16876585]\n",
      " [ 0.          0.18007276  0.00393898]\n",
      " [ 0.         -0.10529216  0.22814373]\n",
      " [ 0.         -0.06090839  0.12252605]\n",
      " [ 0.         -0.08819571  0.23065078]\n",
      " [ 0.         -0.09748218  0.16442615]\n",
      " [ 0.          0.20600872  0.07722925]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #80 | lambda learn rate = 0.0001\n",
      "Target = [[7.]\n",
      " [1.]]\n",
      "lambda end of trial = [[ 0.          0.50281855 -0.25331742]\n",
      " [ 0.          0.34419154 -0.17580065]\n",
      " [ 0.         -0.17211669  0.22273769]\n",
      " [ 0.         -0.11319834  0.16860934]\n",
      " [ 0.          0.17897251  0.0037818 ]\n",
      " [ 0.         -0.10648444  0.22797341]\n",
      " [ 0.         -0.06201489  0.12236798]\n",
      " [ 0.         -0.08947331  0.23046827]\n",
      " [ 0.         -0.09850975  0.16427935]\n",
      " [ 0.          0.20488897  0.07706928]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #81 | lambda learn rate = 0.0001\n",
      "Target = [[7.]\n",
      " [4.]]\n",
      "lambda end of trial = [[ 0.          0.5028525  -0.25329802]\n",
      " [ 0.          0.34428606 -0.17574664]\n",
      " [ 0.         -0.17202898  0.22278781]\n",
      " [ 0.         -0.11309653  0.16866752]\n",
      " [ 0.          0.17899528  0.00379481]\n",
      " [ 0.         -0.10641862  0.22801102]\n",
      " [ 0.         -0.06188667  0.12244125]\n",
      " [ 0.         -0.08941167  0.23050349]\n",
      " [ 0.         -0.09834822  0.16437165]\n",
      " [ 0.          0.20493301  0.07709445]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #82 | lambda learn rate = 0.0001\n",
      "Target = [[4.]\n",
      " [1.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda end of trial = [[ 0.          0.50133819 -0.25367659]\n",
      " [ 0.          0.34280684 -0.17611645]\n",
      " [ 0.         -0.17350449  0.22241893]\n",
      " [ 0.         -0.1145042   0.1683156 ]\n",
      " [ 0.          0.17744622  0.00340754]\n",
      " [ 0.         -0.10804114  0.22760539]\n",
      " [ 0.         -0.06350463  0.12203676]\n",
      " [ 0.         -0.09103694  0.23009717]\n",
      " [ 0.         -0.09980831  0.16400663]\n",
      " [ 0.          0.20330381  0.07668715]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #83 | lambda learn rate = 0.0001\n",
      "Target = [[0.]\n",
      " [3.]]\n",
      "lambda end of trial = [[ 0.          0.50133819 -0.25521488]\n",
      " [ 0.          0.34280684 -0.17756145]\n",
      " [ 0.         -0.17350449  0.22084593]\n",
      " [ 0.         -0.1145042   0.16672241]\n",
      " [ 0.          0.17744622  0.0017733 ]\n",
      " [ 0.         -0.10804114  0.22613186]\n",
      " [ 0.         -0.06350463  0.12048042]\n",
      " [ 0.         -0.09103694  0.22849228]\n",
      " [ 0.         -0.09980831  0.16250311]\n",
      " [ 0.          0.20330381  0.07510889]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #84 | lambda learn rate = 0.0001\n",
      "Target = [[5.]\n",
      " [6.]]\n",
      "lambda end of trial = [[ 0.          0.50152942 -0.25498541]\n",
      " [ 0.          0.34311774 -0.17718837]\n",
      " [ 0.         -0.17322343  0.22118319]\n",
      " [ 0.         -0.11428363  0.1669871 ]\n",
      " [ 0.          0.17766401  0.00203464]\n",
      " [ 0.         -0.10788639  0.22631756]\n",
      " [ 0.         -0.063299    0.12072718]\n",
      " [ 0.         -0.09086815  0.22869482]\n",
      " [ 0.         -0.09962242  0.16272618]\n",
      " [ 0.          0.20348881  0.07533089]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #85 | lambda learn rate = 0.0001\n",
      "Target = [[6.]\n",
      " [2.]]\n",
      "lambda end of trial = [[ 0.          0.50081631 -0.25522311]\n",
      " [ 0.          0.34251708 -0.17738859]\n",
      " [ 0.         -0.17389587  0.22095905]\n",
      " [ 0.         -0.11495302  0.16676397]\n",
      " [ 0.          0.17695275  0.00179755]\n",
      " [ 0.         -0.10852678  0.2261041 ]\n",
      " [ 0.         -0.06397958  0.12050031]\n",
      " [ 0.         -0.0915713   0.22846044]\n",
      " [ 0.         -0.10024358  0.16251913]\n",
      " [ 0.          0.2027799   0.07509459]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #86 | lambda learn rate = 0.0001\n",
      "Target = [[4.]\n",
      " [9.]]\n",
      "lambda end of trial = [[ 0.          0.50139816 -0.25391394]\n",
      " [ 0.          0.34315615 -0.17595068]\n",
      " [ 0.         -0.17326761  0.22237264]\n",
      " [ 0.         -0.11434043  0.16814228]\n",
      " [ 0.          0.17761219  0.00328128]\n",
      " [ 0.         -0.10804351  0.22719146]\n",
      " [ 0.         -0.0633492   0.12191867]\n",
      " [ 0.         -0.09098082  0.22978901]\n",
      " [ 0.         -0.09961661  0.1639298 ]\n",
      " [ 0.          0.20329886  0.07626225]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #87 | lambda learn rate = 0.0001\n",
      "Target = [[3.]\n",
      " [5.]]\n",
      "lambda end of trial = [[ 0.          0.50090282 -0.25473952]\n",
      " [ 0.          0.34270543 -0.17670187]\n",
      " [ 0.         -0.17377176  0.22153239]\n",
      " [ 0.         -0.1147764   0.16741567]\n",
      " [ 0.          0.17710971  0.00244382]\n",
      " [ 0.         -0.10859236  0.2262767 ]\n",
      " [ 0.         -0.06377839  0.12120335]\n",
      " [ 0.         -0.0915297   0.22887422]\n",
      " [ 0.         -0.10006726  0.16317871]\n",
      " [ 0.          0.20270422  0.07527119]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #88 | lambda learn rate = 0.0001\n",
      "Target = [[0.]\n",
      " [7.]]\n",
      "lambda end of trial = [[ 0.00000000e+00  5.00902817e-01 -2.56794176e-01]\n",
      " [ 0.00000000e+00  3.42705430e-01 -1.78821558e-01]\n",
      " [ 0.00000000e+00 -1.73771759e-01  2.19473339e-01]\n",
      " [ 0.00000000e+00 -1.14776396e-01  1.65418312e-01]\n",
      " [ 0.00000000e+00  1.77109711e-01  3.39072524e-04]\n",
      " [ 0.00000000e+00 -1.08592364e-01  2.24164933e-01]\n",
      " [ 0.00000000e+00 -6.37783949e-02  1.19322037e-01]\n",
      " [ 0.00000000e+00 -9.15296988e-02  2.26632184e-01]\n",
      " [ 0.00000000e+00 -1.00067265e-01  1.61105596e-01]\n",
      " [ 0.00000000e+00  2.02704224e-01  7.32046289e-02]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #89 | lambda learn rate = 0.0001\n",
      "Target = [[8.]\n",
      " [3.]]\n",
      "lambda end of trial = [[ 0.          0.50165195 -0.25651325]\n",
      " [ 0.          0.34357223 -0.17849651]\n",
      " [ 0.         -0.17297737  0.21977123]\n",
      " [ 0.         -0.11395565  0.16572609]\n",
      " [ 0.          0.17786901  0.00062381]\n",
      " [ 0.         -0.10787391  0.22443435]\n",
      " [ 0.         -0.06295719  0.11962999]\n",
      " [ 0.         -0.09074857  0.22692511]\n",
      " [ 0.         -0.09928035  0.16140069]\n",
      " [ 0.          0.20341359  0.07347064]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #90 | lambda learn rate = 0.0001\n",
      "Target = [[0.]\n",
      " [8.]]\n",
      "lambda end of trial = [[ 0.          0.50165195 -0.25782843]\n",
      " [ 0.          0.34357223 -0.179539  ]\n",
      " [ 0.         -0.17297737  0.21847082]\n",
      " [ 0.         -0.11395565  0.16427569]\n",
      " [ 0.          0.17786901 -0.00092799]\n",
      " [ 0.         -0.10787391  0.22298537]\n",
      " [ 0.         -0.06295719  0.1183961 ]\n",
      " [ 0.         -0.09074857  0.22559266]\n",
      " [ 0.         -0.09928035  0.15991707]\n",
      " [ 0.          0.20341359  0.07210279]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #91 | lambda learn rate = 0.0001\n",
      "Target = [[9.]\n",
      " [1.]]\n",
      "lambda end of trial = [[ 0.          0.50190424 -0.2578004 ]\n",
      " [ 0.          0.34377082 -0.17951693]\n",
      " [ 0.         -0.17272752  0.21849858]\n",
      " [ 0.         -0.11370384  0.16430367]\n",
      " [ 0.          0.17815074 -0.00089668]\n",
      " [ 0.         -0.10759812  0.22301601]\n",
      " [ 0.         -0.06271621  0.11842287]\n",
      " [ 0.         -0.0906348   0.2256053 ]\n",
      " [ 0.         -0.09910097  0.15993701]\n",
      " [ 0.          0.20356369  0.07211947]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #92 | lambda learn rate = 0.0001\n",
      "Target = [[1.]\n",
      " [5.]]\n",
      "lambda end of trial = [[ 0.          0.50161663 -0.25923848]\n",
      " [ 0.          0.34345982 -0.18107191]\n",
      " [ 0.         -0.17303355  0.21696844]\n",
      " [ 0.         -0.1140047   0.16279941]\n",
      " [ 0.          0.17782761 -0.00251234]\n",
      " [ 0.         -0.10791773  0.221418  ]\n",
      " [ 0.         -0.06303061  0.11685089]\n",
      " [ 0.         -0.09094392  0.22405967]\n",
      " [ 0.         -0.09937908  0.15854642]\n",
      " [ 0.          0.20322293  0.07041563]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #93 | lambda learn rate = 0.0001\n",
      "Target = [[2.]\n",
      " [1.]]\n",
      "lambda end of trial = [[ 0.          0.50076339 -0.2596651 ]\n",
      " [ 0.          0.34258624 -0.1815087 ]\n",
      " [ 0.         -0.17393064  0.2165199 ]\n",
      " [ 0.         -0.11493357  0.16233497]\n",
      " [ 0.          0.17705147 -0.00290041]\n",
      " [ 0.         -0.10885133  0.2209512 ]\n",
      " [ 0.         -0.06391769  0.11640735]\n",
      " [ 0.         -0.0918636   0.22359984]\n",
      " [ 0.         -0.10030187  0.15808503]\n",
      " [ 0.          0.20234165  0.06997499]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #94 | lambda learn rate = 0.0001\n",
      "Target = [[2.]\n",
      " [9.]]\n",
      "lambda end of trial = [[ 0.          0.50103182 -0.2584572 ]\n",
      " [ 0.          0.34285098 -0.18031739]\n",
      " [ 0.         -0.17370352  0.21754193]\n",
      " [ 0.         -0.11469451  0.16341076]\n",
      " [ 0.          0.17728952 -0.00182919]\n",
      " [ 0.         -0.10859079  0.22212361]\n",
      " [ 0.         -0.06365667  0.11758195]\n",
      " [ 0.         -0.0916396   0.22460782]\n",
      " [ 0.         -0.10004504  0.15924077]\n",
      " [ 0.          0.20257662  0.07103235]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #95 | lambda learn rate = 0.0001\n",
      "Target = [[8.]\n",
      " [6.]]\n",
      "lambda end of trial = [[ 0.00000000e+00  5.03571275e-01 -2.56552606e-01]\n",
      " [ 0.00000000e+00  3.45485535e-01 -1.78341467e-01]\n",
      " [ 0.00000000e+00 -1.71035829e-01  2.19542695e-01]\n",
      " [ 0.00000000e+00 -1.11947145e-01  1.65471285e-01]\n",
      " [ 0.00000000e+00  1.79872634e-01  1.08146085e-04]\n",
      " [ 0.00000000e+00 -1.06182241e-01  2.23930027e-01]\n",
      " [ 0.00000000e+00 -6.12164496e-02  1.19412110e-01]\n",
      " [ 0.00000000e+00 -8.90682325e-02  2.26536343e-01]\n",
      " [ 0.00000000e+00 -9.75972072e-02  1.61076643e-01]\n",
      " [ 0.00000000e+00  2.05001660e-01  7.28511368e-02]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #96 | lambda learn rate = 0.0001\n",
      "Target = [[4.]\n",
      " [3.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda end of trial = [[ 0.          0.50277727 -0.25714811]\n",
      " [ 0.          0.34458434 -0.17901736]\n",
      " [ 0.         -0.17196402  0.21884655]\n",
      " [ 0.         -0.11278748  0.16484103]\n",
      " [ 0.          0.17903755 -0.00051817]\n",
      " [ 0.         -0.10712369  0.22322394]\n",
      " [ 0.         -0.06206737  0.11877392]\n",
      " [ 0.         -0.08992528  0.22589355]\n",
      " [ 0.         -0.09843053  0.16045165]\n",
      " [ 0.          0.20408576  0.07216421]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #97 | lambda learn rate = 0.0001\n",
      "Target = [[2.]\n",
      " [2.]]\n",
      "lambda end of trial = [[ 0.          0.50194466 -0.25798072]\n",
      " [ 0.          0.34382008 -0.17978162]\n",
      " [ 0.         -0.17276329  0.21804728]\n",
      " [ 0.         -0.11351935  0.16410916]\n",
      " [ 0.          0.17823341 -0.0013223 ]\n",
      " [ 0.         -0.10789451  0.22245312]\n",
      " [ 0.         -0.06285354  0.11798775]\n",
      " [ 0.         -0.09082408  0.22499475]\n",
      " [ 0.         -0.09915717  0.15972501]\n",
      " [ 0.          0.20326391  0.07134236]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n",
      "\n",
      "=========================================\n",
      "Trial #98 | lambda learn rate = 0.0001\n",
      "Target = [[9.]\n",
      " [1.]]\n",
      "lambda end of trial = [[ 0.          0.5022332  -0.25794866]\n",
      " [ 0.          0.34402059 -0.17975934]\n",
      " [ 0.         -0.17253616  0.21807252]\n",
      " [ 0.         -0.11324942  0.16413916]\n",
      " [ 0.          0.1784102  -0.00130266]\n",
      " [ 0.         -0.10762693  0.22248285]\n",
      " [ 0.         -0.06258968  0.11801707]\n",
      " [ 0.         -0.09064475  0.22501468]\n",
      " [ 0.         -0.09890748  0.15975275]\n",
      " [ 0.          0.20340151  0.07135765]]\n",
      "a = [0. 0.]\n",
      "k = [[0.96849562 0.67678515 0.0647642  0.11511703 0.58496007 0.25748733\n",
      "  0.16338584 0.31507077 0.14550369 0.81974453]\n",
      " [0.04608913 0.04563795 0.7098581  0.59575723 0.47647688 0.8658459\n",
      "  0.50139103 0.91823527 0.60480768 0.86432389]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "NUM_TRIALS = 100\n",
    "NUM_RUNS = 2 # Has to be >1 # 2 = goes through the trail for target once\n",
    "NUM_SESSIONS = 10\n",
    "# rate_list = [5e-3, 1e-3, 5e-4, 1e-4]\n",
    "rate_list = [1e-4]\n",
    "A_RATE = 5e-5\n",
    "K_RATE = 5e-5\n",
    "ADAPT_TRIALS = NUM_TRIALS\n",
    "ADAPT_DEC = False\n",
    "KW_only = True\n",
    "\n",
    "# initialization\n",
    "cursor_start = np.zeros( (NUM_DIM, 1, NUM_TRIALS, NUM_SESSIONS) )\n",
    "cursor_end = np.zeros( (NUM_DIM, 1, NUM_TRIALS, NUM_SESSIONS) )\n",
    "target_trial = np.zeros( (NUM_DIM, 1, NUM_TRIALS, NUM_SESSIONS) )\n",
    "lambda_trial = np.zeros( (NUM_NEURONS, NUM_LAMBDA, NUM_TRIALS, NUM_SESSIONS) )\n",
    "fr_trial = np.zeros( (NUM_NEURONS, 1, NUM_TRIALS) )\n",
    "a_trial = np.zeros( (NUM_DIM, NUM_TRIALS, NUM_SESSIONS) )\n",
    "k_trial = np.zeros( (NUM_DIM, NUM_NEURONS, NUM_TRIALS, NUM_SESSIONS) )\n",
    "re_startT = np.zeros( (NUM_TRIALS, NUM_SESSIONS) )\n",
    "re_endT = np.zeros( (NUM_TRIALS, NUM_SESSIONS) )\n",
    "\n",
    "\n",
    "for lambda_rate in rate_list:\n",
    "    for iS in range(NUM_SESSIONS):\n",
    "        print(\"\")\n",
    "        print(\"+++++++++++++++++++++++++++++++++++\")\n",
    "        print(\"Session #\" + str(iS))\n",
    "        ## BRAIN SIDE\n",
    "        FR_DIST = (FR_SIGMA, FR_DELTA, FR_DIST_SIZE)\n",
    "    #     fr_init[:, 0] = np.array(brainFiringRate(lambda_init, TARGET_VECTOR_ERR))\n",
    "\n",
    "        ## DECODER SIDE\n",
    "        A_DIST = (A_SIGMA, A_DELTA, A_DIST_SIZE)\n",
    "        K_DIST = (K_SIGMA, K_DELTA, K_DIST_SIZE)\n",
    "\n",
    "        # target position -- new target represents a new trial\n",
    "        target_trial[:, :, 0, iS] = TARGET_VECTOR\n",
    "        print(\"target at trial 0 = \" + str(target_trial[:, :, 0, iS]))\n",
    "\n",
    "        print(\"K MATX INIT= \" + str(K_MATX))\n",
    "        print(\"A VECT INIT = \" + str(A_VECT))\n",
    "\n",
    "        ## VECTORS FOR TRIALS    \n",
    "        lambda_trial[:, :, 0, iS] = lambda_init\n",
    "        print(\"lambda\")\n",
    "        print(lambda_trial[:, :, 0, iS])\n",
    "\n",
    "        a_trial[:, 0, iS] = np.array(A_VECT)\n",
    "        print(\"a\")\n",
    "        print(a_trial[:, 0, iS])\n",
    "\n",
    "        k_trial[:,:, 0, iS] = K_MATX\n",
    "        print(\"K\")\n",
    "        print(k_trial[:,:, 0, iS] )\n",
    "        decoder_params = (a_trial[:, 0, iS], A_RATE, A_DIST, k_trial[:,:,  0, iS], K_RATE, K_DIST)\n",
    "        decoder_vals = (A_VECT, K_MATX)\n",
    "        \n",
    "\n",
    "        for iT in range(NUM_TRIALS-1):\n",
    "            print(\"\")\n",
    "            print(\"=========================================\")\n",
    "            print(\"Trial #\" + str(iT) + \" | lambda learn rate = \" + str(lambda_rate))\n",
    "            print(\"Target = \" + str(target_trial[:, :, iT, iS]))\n",
    "\n",
    "            # calculate firing rate given lambda and decoder parameters with current target position \n",
    "            fr_start = np.array(brainFiringRate(lambda_trial[:, :, iT, iS], target_trial[:, :, iT, iS]))\n",
    "            fr_trial[:, :, iT] = fr_start\n",
    "#             print(\"fr start of trial\")\n",
    "#             print(fr_start)\n",
    "#             print(\"lambda start of trial\")\n",
    "#             print(lambda_trial[:, :, iT, iS])\n",
    "\n",
    "            # calculate reach error of firing rate at the beginning of the trial\n",
    "            # this becomes the error of the new target position being presented and where the cursor is\n",
    "            brain_vars = ( fr_trial[:, :, iT],  target_trial[:, :, iT, iS] )\n",
    "            cost_func_params = (decoder_vals, brain_vars) \n",
    "            \n",
    "#             print(\"cost func params = \"+ str(cost_func_params))\n",
    "            re_startT[iT, iS] = error_costFunc(cost_func_params)\n",
    "#             print(\"re start = \" + str(re_startT[iT, iS]))\n",
    "\n",
    "    #         (a_vect_in, k_matx_in) = decoder_params\n",
    "            cursor_start[ :, :, iT, iS] =  (decoder_findY(decoder_vals, brain_vars))\n",
    "#             print(\"cursor start = \" + str(cursor_start[:, :, iT, iS]) )\n",
    "\n",
    "            # Run through trial and see the reach at the end        \n",
    "            # current brain and decoder params\n",
    "            brain_params = (fr_trial[:, :, iT], FR_DIST, lambda_trial[:, :, iT, iS], lambda_rate)\n",
    "            decoder_params = (a_trial[:, iT, iS], A_RATE, A_DIST, k_trial[:, :,  iT, iS], K_RATE, K_DIST)\n",
    "\n",
    "            # adapt brain and decoder (together here)\n",
    "            a_run, k_run = calcNextDecoder(decoder_params, brain_vars)\n",
    "            if (KW_only):\n",
    "                a_run = np.zeros((2, 1))\n",
    "            fr_run, lambda_run = calcNextBrain(brain_params, decoder_params, target_trial[:, :, iT, iS], NUM_RUNS)\n",
    "            \n",
    "    #         print(\"fr_run = \" + str(fr_run))\n",
    "#             re_run, fr_run, lambda_run = brain_adapt_sgd(brain_params, decoder_params, target_trial[:, :, iT], NUM_RUNS)\n",
    "            # update cost function arguments\n",
    "            decoder_vals = (a_run, k_run)\n",
    "            brain_vars = (fr_run, target_trial[:, :, iT, iS])\n",
    "            # see how the updated decoder and brain paramters have done with the current\n",
    "            # target position (so target at trial = iT)\n",
    "            cost_func_params = (decoder_vals, brain_vars) \n",
    "            re_run = np.array(error_costFunc(cost_func_params))\n",
    "\n",
    "            # So what are the end trial metrics?\n",
    "            if (KW_only):\n",
    "                lambda_run[:, 0] = 0\n",
    "            cursor_end[:, :, iT, iS] =  (decoder_findY(decoder_vals, brain_vars))\n",
    "#             print(\"fr end of trial = \" + str(fr_run))\n",
    "            print(\"lambda end of trial = \" + str(lambda_run))\n",
    "#             print(\"cursor end = \" + str(cursor_end[:, :, iT, iS]) )\n",
    "\n",
    "            re_endT[iT, iS] = re_run\n",
    "#             print(\"re end = \" + str(re_endT[iT, iS]))\n",
    "#             print(\"re diff = \" + str(re_endT[iT, iS] - re_startT[iT, iS]))\n",
    "\n",
    "            # update the parameters\n",
    "            lambda_trial[:, :, iT + 1, iS] = np.squeeze(lambda_run)\n",
    "            a_trial[:, iT + 1, iS] = np.squeeze(a_run)\n",
    "            k_trial[:, :, iT + 1, iS] = np.squeeze(k_run)\n",
    "            print(\"a = \" + str(a_trial[:, iT + 1, iS]))\n",
    "            print(\"k = \" + str(k_trial[:, :, iT + 1, iS]))\n",
    "\n",
    "            # change to new target\n",
    "            target_trial[:, 0, iT + 1, iS] = findNextTarget( cursor_end[:, :, iT, iS], target_trial[:, :, iT, iS] )\n",
    "    \n",
    "        # display stuff\n",
    "#         print(\"target position:\")\n",
    "#         print(target_trial)\n",
    "#         print(\"cursor end: \")\n",
    "#         print(cursor_end)\n",
    "#         print(\"cursor start: \")\n",
    "#         print(cursor_start)\n",
    "\n",
    "        \n",
    "        pidx = rate_list.index(lambda_rate)\n",
    "        plt.figure(2*pidx + 1, figsize=(fig_x, fig_y))\n",
    "        plt.plot(np.arange(0, NUM_TRIALS-1, 1), re_startT[0:len(re_startT)-1, iS], label = '' + str(iS))\n",
    "        plt.legend()\n",
    "        plt.xlabel('Trials')\n",
    "        plt.ylabel('Reach Error at the Start of Trial')\n",
    "        plt.title('Initial RE across trials, learn rate = ' + str(lambda_rate))\n",
    "        #     plt.show()\n",
    "        \n",
    "#         plt.figure(2*pidx + 2, figsize=(fig_x, fig_y))\n",
    "#         plt.plot(np.arange(NUM_TRIALS-20-1, NUM_TRIALS-1, 1), re_startT[NUM_TRIALS-1-20:NUM_TRIALS-1, iS])\n",
    "#         plt.xlabel('Trials' )#, color='white')\n",
    "#         plt.ylabel('Reach Error at Last 20 Trials')#, color='white')\n",
    "#         plt.title('Ending RE across trials | learn rate = ' + str(lambda_rate) + '| Decoder Adapt = ' + str(ADAPT_DEC)) #, color = 'white')\n",
    "#         #     plt.show()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = 0\n",
    "y = 1\n",
    "\n",
    "plt.figure(figsize = (12, 8))\n",
    "start_x_mean = np.mean(cursor_start, axis=3)[x, 0, 0:NUM_TRIALS-1]\n",
    "end_x_mean = np.mean(cursor_end, axis=3)[x, 0, 0:NUM_TRIALS-1]\n",
    "start_y_mean = np.mean(cursor_start, axis=3)[y, 0, 0:NUM_TRIALS-1]\n",
    "end_y_mean = np.mean(cursor_end, axis=3)[y, 0, 0:NUM_TRIALS-1]\n",
    "targ_x_mean = np.mean(target_trial, axis=3)[x, 0, 0:NUM_TRIALS-1]\n",
    "targ_y_mean = np.mean(target_trial, axis=3)[y, 0, 0:NUM_TRIALS-1]\n",
    "\n",
    "plt.plot(start_x_mean, linestyle = '-', marker = '.', label = 'cursor (start of trial)')\n",
    "plt.plot(targ_x_mean, linestyle = '-', marker = '.', label = 'target' )\n",
    "plt.legend()\n",
    "plt.xlabel('Trials')\n",
    "plt.ylabel('Starting Cursor and Target Position (X)')\n",
    "plt.title('Cursor Position Across Trials')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# plt.figure(figsize = (12, 8))\n",
    "# plt.plot(np.arange(0, NUM_TRIALS, 1), end_x_mean, linestyle = '-', marker = '.', label = 'cursor (end of trial)')\n",
    "# plt.plot(np.arange(0, NUM_TRIALS, 1), targ_x_mean, linestyle = '-', marker = '.', label = 'target' )\n",
    "# plt.legend()\n",
    "# plt.xlabel('Trials')\n",
    "# plt.ylabel('Ending Cursor and Target Position (X)')\n",
    "# plt.title('Cursor Position Across Trials')\n",
    "# plt.show()\n",
    "\n",
    "plt.figure(figsize = (12, 8))\n",
    "plt.plot(start_y_mean, linestyle = '-', marker = '.', label = 'cursor (start of trial)')\n",
    "plt.plot(targ_y_mean, linestyle = '-', marker = '.', label = 'target' )\n",
    "plt.legend()\n",
    "plt.xlabel('Trials')\n",
    "plt.ylabel('Starting Cursor and Target Position (Y)')\n",
    "plt.title('Cursor Position Across Trials')\n",
    "plt.show()\n",
    "\n",
    "# plt.figure(figsize = (12, 8))\n",
    "# plt.plot(np.arange(0, NUM_TRIALS, 1), end_y_mean, linestyle = '-', marker = '.', label = 'cursor (end of trial)')\n",
    "# plt.plot(np.arange(0, NUM_TRIALS, 1), targ_y_mean, linestyle = '-', marker = '.', label = 'target' )\n",
    "# plt.legend()\n",
    "# plt.xlabel('Trials')\n",
    "# plt.ylabel('Ending Cursor and Target Position (Y)')\n",
    "# plt.title('Cursor Position Across Trials')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (12, 8))\n",
    "plt.plot(start_x_mean - targ_x_mean, linestyle = '-', marker = '.', label = 'X error')\n",
    "plt.plot(start_y_mean - targ_y_mean, linestyle = '-', marker = '.', label = 'Y error' )\n",
    "plt.legend()\n",
    "plt.xlabel('Trials')\n",
    "plt.ylabel('Difference in Starting Cursor and Target Position')\n",
    "plt.title('Cursor Error Across Trials')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Mean KW Matrix (1,1)')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# print(np.shape(lambda_trial))\n",
    "# print(np.shape(k_trial))\n",
    "# print(np.shape((k_trial[:, :,1])))\n",
    "# print(np.shape((lambda_trial[:, 1:3, 1])))\n",
    "\n",
    "lk_mtx = np.zeros((NUM_DIM, NUM_DIM, NUM_TRIALS))\n",
    "lk_mtx_temp = np.zeros((NUM_DIM, NUM_DIM, NUM_TRIALS, NUM_SESSIONS))\n",
    "# print(np.shape((k_trial[:,:, :, 1])))\n",
    "# print((lambda_trial[:, 1:3, 1, 1]))\n",
    "for iT in range(NUM_TRIALS):\n",
    "    for iS in range(NUM_SESSIONS):\n",
    "        lk_mtx_temp[:,:, iT, iS] = np.matmul(k_trial[:,:, iT, iS], lambda_trial[:, 1:3, iT, iS])\n",
    "    lk_mtx = np.mean(lk_mtx_temp[:,:, :, :], axis=3)\n",
    "\n",
    " \n",
    "plt.figure(figsize = (12, 8))\n",
    "plt.subplot(221)\n",
    "plt.plot(lk_mtx[0, 0, :])\n",
    "plt.title(\"Mean KW Matrix (0,0)\")\n",
    "\n",
    "plt.subplot(222)\n",
    "plt.plot(lk_mtx[0, 1, :])\n",
    "plt.title(\"Mean KW Matrix (0,1)\")\n",
    "\n",
    "plt.subplot(223)\n",
    "plt.plot(lk_mtx[1, 0, :])\n",
    "plt.title(\"Mean KW Matrix (1,0)\")\n",
    "\n",
    "plt.subplot(224)\n",
    "plt.plot(lk_mtx[1, 1, :])\n",
    "plt.title(\"Mean KW Matrix (1,1)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Mean KW Matrix (1,1) | Last 100 Trials ')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.figure(figsize = (12, 8))\n",
    "plt.subplot(221)\n",
    "plt.plot(lk_mtx[0, 0, NUM_TRIALS-1-100:NUM_TRIALS-1])\n",
    "plt.title(\"Mean KW Matrix (0,0) | Last 100 Trials \")\n",
    "\n",
    "plt.subplot(222)\n",
    "plt.plot(lk_mtx[0, 1,  NUM_TRIALS-1-100:NUM_TRIALS-1])\n",
    "plt.title(\"Mean KW Matrix (0,1) | Last 100 Trials \")\n",
    "\n",
    "plt.subplot(223)\n",
    "plt.plot(lk_mtx[1, 0,  NUM_TRIALS-1-100:NUM_TRIALS-1])\n",
    "plt.title(\"Mean KW Matrix (1,0) | Last 100 Trials \")\n",
    "\n",
    "plt.subplot(224)\n",
    "plt.plot(lk_mtx[1, 1,  NUM_TRIALS-1-100:NUM_TRIALS-1])\n",
    "plt.title(\"Mean KW Matrix (1,1) | Last 100 Trials \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Reach Error Per Session:\n",
      "Session # 0| RE = 2.5652846538401026\n",
      "Session # 1| RE = 2.5184366696942253\n",
      "Session # 2| RE = 2.708795639912477\n",
      "Session # 3| RE = 2.5568172373353883\n",
      "Session # 4| RE = 2.4877354694882587\n",
      "Session # 5| RE = 2.447678942318\n",
      "Session # 6| RE = 2.6642595739017945\n",
      "Session # 7| RE = 2.5020776041772685\n",
      "Session # 8| RE = 2.568020329794595\n",
      "Session # 9| RE = 2.684876687918232\n"
     ]
    }
   ],
   "source": [
    "print(\"Average Reach Error Per Session:\")\n",
    "\n",
    "for iS in range(NUM_SESSIONS):\n",
    "    print(\"Session # \" + str(iS) + \"| RE = \" + str(np.mean(re_startT[:, iS])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
