{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Introduction:**\n",
    "\n",
    "Using simple random search. In our case, the cost function is just the reach error -- calculated by the reach error between the previous lamdba values and the current one. \n",
    "\n",
    "Error is defined as reach error: $ error = ||t-y||^2 $ and the perturbation term $ p_{2k+1} $ can be thought of a normal distribution.\n",
    "\n",
    "$$ FR+ = FR - \\frac{\\nu}{N\\delta} \\sum_{n = 1}^N ( error(FR + \\delta p) - error(FR) ) \\cdot  p, p \\sim \\mathcal{N}(0,\\sigma^2) $$\n",
    "\n",
    "Note: p is a perturbation taken from a distribution with mean = 0\n",
    "\n",
    "References:\n",
    "\n",
    "[1] G. Cauwenberghs, “A Fast Stochastic Error-Descent Algorithm for Supervised Learning and Optimization,” in Advances in Neural Information Processing Systems 5, S. J. Hanson, J. D. Cowan, and C. L. Giles, Eds. Morgan-Kaufmann, 1993, pp. 244–251.\n",
    "\n",
    "[2] R. Héliot, K. Ganguly, J. Jimenez, and J. M. Carmena, “Learning in Closed-Loop Brain–Machine Interfaces: Modeling and Experimental Validation,” IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics), vol. 40, no. 5, pp. 1387–1397, Oct. 2010, doi: 10.1109/TSMCB.2009.2036931.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import linalg\n",
    "import numpy.matlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "\n",
    "seaborn.set()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Brain Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Brain Model \n",
    "###################\n",
    "# Function that calculates firing rate from b, W, t\n",
    "# B(t) = b + [Wx Wy][tx ty]' = firing rate\n",
    "# This is Equation (2.a, 2.b) in Heliot et al, 2010\n",
    "\n",
    "## INPUT\n",
    "# N = number of neurons\n",
    "# lambda_vect = [b, W_x, W_y] for each neuron; N x 3\n",
    "# targ_vect = 2 x 1\n",
    "## OUTPUT\n",
    "# newFR = N x 1\n",
    "def brainFiringRate(lambda_vect, targ_vect):\n",
    "    targ_vect_mult = np.insert(targ_vect.copy(), 0, 1)\n",
    "    newFR = np.zeros( (np.size(lambda_vect, 0), 1) )\n",
    "    newFR[:, 0] = np.matmul(lambda_vect, targ_vect_mult)\n",
    "    return newFR\n",
    "\n",
    "###################\n",
    "# Function that alters the lambda paramters (b, W) for the brain\n",
    "# B(t) = b + [Wx Wy][tx ty]' = firing rate\n",
    "# This is Equation (6) in Heliot et al, 2010\n",
    "\n",
    "## INPUT\n",
    "# N = number of neurons\n",
    "# lambda_vect = [b, W_x, W_y] for each neuron; N x 3\n",
    "# delta_perturb = N x 1\n",
    "# targ_vect = 2 x 1\n",
    "## MIDDLE\n",
    "# targ_vect_mult = 3 x 1 [1 t_x t_y]'\n",
    "# targ_matx = N x 3\n",
    "# delta_matx = N x 3\n",
    "# next_term = delta_matx*delta_matx (element-wise mult) = N x 3\n",
    "## OUTPUT\n",
    "# lambda_vect_new = N x 3\n",
    "\n",
    "def calcNextLambda(lambda_vect, gamma, delta_perturb, targ_vect):\n",
    "    # This is the vector to multiply the lambda update term with = [1 t_x t_y]'\n",
    "    num_neurons = np.size(lambda_vect.copy(), 0)\n",
    "    targ_vect_mult = np.insert(targ_vect.copy(), 0, 1) # 3 x 1  \n",
    "    targ_matx = (np.matlib.repmat(targ_vect_mult, num_neurons, 1)) # N x 3\n",
    "\n",
    "    # next gradient term: \\gamma*delta_perturb\n",
    "    delta_matx = np.matlib.repmat(delta_perturb, 1, 3) # N x 3\n",
    "    next_term = (delta_matx*targ_matx) # 3 x N\n",
    "\n",
    "    lambda_vect_new = lambda_vect.copy() - (gamma*next_term)\n",
    "    return lambda_vect_new\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################\n",
    "# Decoder Model \n",
    "# Affine Function that calculates target postion from firing rate\n",
    "# Y = D(f) = a + Kf --> Weiner Filter\n",
    "# This is Equation (1) in Heliot et al, 2010\n",
    "\n",
    "## INPUT\n",
    "# N = number of neurons, d = dimension of target\n",
    "# decoder params = current a vector and K matrix (a = d x 1, K = d x N)\n",
    "# fr_curr = current firing rate as a vector\n",
    "# targ_vect = target position (T_x, Y_y)\n",
    "## OUTPUT\n",
    "# Cursor position = Y_x, Y_y\n",
    "def decoder_findY(decoder_params, brain_params):\n",
    "    # check firing rate \n",
    "    # Start with affine decoder\n",
    "    (a_vect_in, k_matx_in) = decoder_params\n",
    "    (fr_curr, targ) = brain_params\n",
    "    a_vect = a_vect_in.copy()\n",
    "    k_matx = k_matx_in.copy()\n",
    "    cursor_pos = np.zeros( (NUM_DIM, 1))\n",
    "    cursor_pos = a_vect.reshape(NUM_DIM, 1) +  (np.matmul(k_matx, fr_curr))\n",
    "#     print(\"in decoder_findY\")\n",
    "#     print(cursor_pos)\n",
    "#     print(np.shape(cursor_pos))\n",
    "    return (cursor_pos)\n",
    "\n",
    "# Function uses stochastic gradient descent to adjust decoder parameters\n",
    "## INPUT\n",
    "# decoder params = current a vector and K matrix (a = d x 1, K = d x N)\n",
    "# fr_curr = current firing rate as a vector\n",
    "## OUTPUT\n",
    "# next decoder parameters = a_next, k_next\n",
    "def calcNextDecoder(decoder_params, brain_vars):\n",
    "    (a_vect, a_rate, a_dist, k_matx, k_rate, k_dist) = decoder_params\n",
    "    cost_func_args = ( (a_vect, k_matx), brain_vars)\n",
    "    # a vector\n",
    "    if (ADAPT_DEC == True):\n",
    "        a_grad = findErrorGrad(a_vect.copy(), A_VAR, a_dist,error_costFunc, cost_func_args)\n",
    "        k_grad = findErrorGrad(k_matx.copy(), K_VAR, k_dist, error_costFunc, cost_func_args)\n",
    "        a_next = a_vect.copy().reshape(np.shape(a_grad)) - a_rate*a_grad\n",
    "        k_next = k_matx.copy() - k_rate*k_grad\n",
    "    else:\n",
    "        a_next = a_vect\n",
    "        k_next = k_matx\n",
    "\n",
    "    return (a_next, k_next)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reach Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################\n",
    "# Reach error\n",
    "# This is Equation (3) in Heliot et al, 2010\n",
    "\n",
    "## INPUT\n",
    "# y_x, y_y = predicted cursor position\n",
    "# t_x, t_y = target position\n",
    "## OUTPUT\n",
    "# norm squared of (target position - cursor position)\n",
    "# where reach error is the target position - cursor position\n",
    "def calcReachError(y_vect, t_vect):\n",
    "    norm_vect = np.array(y_vect) - np.array(t_vect)\n",
    "    return (np.linalg.norm(norm_vect, 2)**2)\n",
    "\n",
    "## INPUT\n",
    "# cost_func_params = decoder params (a vect, k matx) and current firing rate\n",
    "## OUTPUT\n",
    "# reach error = scalar; norm squared of (target position - cursor position)\n",
    "# where reach error is the target position - cursor position\n",
    "def error_costFunc(cost_func_params):\n",
    "    (decoder_params, brain_vars) = cost_func_params\n",
    "    (fr_curr, targ_vect) = brain_vars\n",
    "    y_vect = decoder_findY(decoder_params, brain_vars)\n",
    "    t_vect = targ_vect\n",
    "    return calcReachError(y_vect, t_vect)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stochastic Error Descent: Update Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "\n",
    "\n",
    "## Stochastic Error Descent\n",
    "# This is Equation (4) and Equation (5) in Heliot, 2010\n",
    "# Derivation is found in Cauwenberghs, 1993 \n",
    "\n",
    "# This function is one iteration of the error descent calcuation\n",
    "## INPUT\n",
    "# input_vect = vector to stochastically perturb\n",
    "# input_var = FR_VAR, A_VAR OR K_VAR \n",
    "# param_dist = distribution from which perturbations to the input are selected\n",
    "# cost_func = cost function (always reach error)\n",
    "# cost_func_args = arguments to the cost function (depends on error cost function)\n",
    "## OUTPUT\n",
    "# errorGrad = gradient for updating parameter (input vect)\n",
    "def findErrorGrad(input_vect, input_var, param_dist, cost_func, cost_func_args):\n",
    "    # Un-nest everything\n",
    "    (sigma, delta, num_dist) = param_dist\n",
    "    (decoder_params, (curr_fr, targ_vect) ) = cost_func_args\n",
    "    (a_vect, k_matx) = decoder_params\n",
    "    \n",
    "    # Get size of input vector\n",
    "    num_neurons = np.size(k_matx, 1)\n",
    "    num_input_row = np.size(input_vect, 0) \n",
    "    num_input_column = 1\n",
    "    if (input_vect.ndim > 1): \n",
    "        num_input_column = np.size(input_vect, 1)\n",
    "    \n",
    "    # What to perturb and input firing rate for error cost function\n",
    "    input_vect = input_vect.copy().reshape(num_input_row, num_input_column)\n",
    "    input_fr = curr_fr.copy().reshape(num_neurons, 1)\n",
    "       \n",
    "    error_sum = np.zeros((num_input_row, 1)) \n",
    "    error_grad = np.zeros((num_input_row, 1))\n",
    "    perturb_rand = np.zeros((num_input_row, num_input_column, num_dist))\n",
    "    \n",
    "    \n",
    "    for iC in range(num_input_column):\n",
    "        for iN in range(num_input_row):\n",
    "            random.seed(time.time())\n",
    "            perturb_rand[iN, iC, :] = np.random.uniform(0, sigma, num_dist) \n",
    "            # perturb_rand = N_input x N_dist\n",
    "            # for each iteration, np.random.normal returns a N_dist x 1 array\n",
    "    \n",
    "    for iD in range(num_dist):\n",
    "        # perturb_vect = stochastic pertrbation (amount of stochastic descent perturbation)\n",
    "        perturb_vect = np.squeeze(perturb_rand[:, :, [iD]])\n",
    "        perturb_vect = perturb_vect.copy().reshape(num_input_row, num_input_column)\n",
    "        \n",
    "        # find the delta error caused by the perturbation (direction to descend gradient in) \n",
    "        input_perturb = np.add(input_vect, delta*perturb_vect) \n",
    "        \n",
    "        # Case 1: firing rate\n",
    "        # error = reachError(a + K*fr')\n",
    "        if (input_var == FR_VAR):        \n",
    "            # Calculate error \n",
    "            perturb_cost_args = (decoder_params, (input_perturb, targ_vect) ) \n",
    "            \n",
    "        # case 2: a\n",
    "        # error = reachError(a' + K*fr)\n",
    "        elif (input_var == A_VAR):\n",
    "            decoder_params_perturb = (input_perturb, k_matx)\n",
    "            perturb_cost_args = (decoder_params_perturb, (input_fr, targ_vect))\n",
    "\n",
    "        # case 3: k\n",
    "        # error = reachError(a + K'*fr)\n",
    "        elif (input_var == K_VAR):\n",
    "            decoder_params_perturb = (a_vect, input_perturb)\n",
    "            perturb_cost_args = (decoder_params_perturb, (input_fr, targ_vect))   \n",
    "        \n",
    "        # default: do nothing\n",
    "        else:\n",
    "            perturb_cost_args = cost_func_args\n",
    "        \n",
    "        error_perturb = cost_func(perturb_cost_args)   \n",
    "        error_input = cost_func(cost_func_args)\n",
    "        error_sum = np.add(error_sum, (error_perturb - error_input)*perturb_vect)\n",
    "\n",
    "    error_grad = np.array(error_sum/(num_dist*delta))\n",
    "    return error_grad\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stochastic Gradient Descent: Update Step and Recalculate Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function goes through and updates brain paramters over the num_iter times\n",
    "def brain_adapt_sgd(brain_params, decoder_params, targ_vect, num_iter):\n",
    "    (fr_init, fr_dist, lambda_init, lambda_rate) = brain_params\n",
    "    (fr_init, targ_vect)= brain_vars\n",
    "    (fr_sigma, fr_delta, fr_dist_size) = fr_dist\n",
    "    (a_init, a_rate, a_dist, k_init, k_rate, k_dist) = decoder_params\n",
    "    decoder_init = (a_init, k_init)\n",
    "    grad_args_init = (decoder_init, brain_vars)\n",
    "    \n",
    "\n",
    "    num_neurons = np.size(fr_init, 0)\n",
    "    runs_num = 1\n",
    "\n",
    "    # for sigma in sigma_list:\n",
    "    for iR in range(runs_num):\n",
    "        # Set the u vectors\n",
    "        fr_vect = np.zeros( (num_neurons, 1, num_iter) )\n",
    "        fr_vect[:, :, 0] = fr_init #fr init = num_neurons x 1\n",
    "#         fr_vect[:, 0] = fr_init\n",
    "        fr_final = np.zeros((num_neurons, 1, runs_num))\n",
    "        re_final = np.zeros(runs_num)\n",
    "        lambda_final = np.zeros((num_neurons, np.size(lambda_init, 1), runs_num))\n",
    "\n",
    "        print(\"starting fr vect = \" + str( fr_vect[:, :, 0] ))\n",
    "        # lambda init = N x 3\n",
    "        # lambda_vect = N x 3 X ITER\n",
    "        lambda_vect = np.zeros( (num_neurons, np.size(lambda_init, 1), num_iter))\n",
    "        lambda_vect[:,:,0] = lambda_init \n",
    "\n",
    "        # set the cost vector\n",
    "        err_vect = np.zeros(num_iter)\n",
    "        err_vect[0] = error_costFunc(grad_args_init)\n",
    "        print('initial error = ' + str(err_vect[0]))\n",
    "\n",
    "        # calculate the initial delta e\n",
    "        grad_new = np.zeros(num_iter)\n",
    "        grad_new = findErrorGrad(fr_init, FR_VAR, fr_dist, error_costFunc, grad_args_init)\n",
    "\n",
    "        for iT in range(num_iter-1):\n",
    "            ## calculate the new u \n",
    "            # (1) lambda+ = lambda - learn_rate*grad_error; B(lambda) = f\n",
    "            lambda_next = calcNextLambda(lambda_vect[:, :, iT], lambda_rate, grad_new, targ_vect)\n",
    "            lambda_vect[:,:, iT + 1] = lambda_next\n",
    "            \n",
    "            # (2) fr+ = B(lambda+)\n",
    "            fr_next = brainFiringRate(lambda_next, targ_vect)\n",
    "            fr_vect[:, :, iT+1] = fr_next\n",
    "\n",
    "            # Update parameters for calculating error and calculate the new cost\n",
    "            # (3) Calculate the new reach error \n",
    "            brain_vars_next = fr_next, targ_vect\n",
    "            grad_args_next = (decoder_init, brain_vars_next)\n",
    "            err_next = np.array(error_costFunc(grad_args_next))\n",
    "            err_vect[iT+1] = err_next\n",
    "\n",
    "            # (4) calculate the next error descent term to update FR again\n",
    "            grad_new = findErrorGrad(fr_next, FR_VAR, fr_dist, error_costFunc, grad_args_next)\n",
    "        \n",
    "        fr_final[:, :, iR] = fr_next\n",
    "        re_final[iR] = err_next\n",
    "        lambda_final[:, :, iR] = lambda_next        \n",
    "\n",
    "    return (re_final, fr_final, lambda_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function goes through and updates brain paramters over the num_iter times\n",
    "def calcNextBrain(brain_params, decoder_params, targ_vect, num_iter):\n",
    "    # Unpack arguments that are being passed in\n",
    "    (fr_init, fr_dist, lambda_init, lambda_rate) = brain_params\n",
    "#     (fr_sigma, fr_delta, fr_dist_size) = fr_dist\n",
    "    (a_vect, a_rate, a_dist, k_matx, k_rate, k_dist) = decoder_params\n",
    "    decoder_vals = (a_vect, k_matx)\n",
    "#     grad_args_init = (decoder_vals, fr_init)\n",
    "    \n",
    "    num_neurons = np.size(fr_init, 0)\n",
    "    fr_vect = np.zeros( (num_neurons, 1, num_iter) )\n",
    "    fr_final = np.zeros( np.size(fr_init) )\n",
    "    fr_vect[:, :, 0] = fr_init #fr init = num_neurons x 1\n",
    "    \n",
    "    # lambda init = N x 3\n",
    "    # lambda_vect = N x 3 X ITER\n",
    "    lambda_vect = np.zeros( (num_neurons, np.size(lambda_init, 1), num_iter))\n",
    "    lambda_vect[:, :, 0] = lambda_init \n",
    "    lambda_final = np.zeros(np.size(lambda_init))\n",
    "    \n",
    "    for iT in range(num_iter-1):\n",
    "        # (1) calculate the perturbation\n",
    "        brain_vars = (fr_vect[:, :, iT], targ_vect)\n",
    "        grad_args = (decoder_vals, brain_vars)\n",
    "        grad_new = findErrorGrad(fr_vect[:, :, iT], FR_VAR, fr_dist, error_costFunc, grad_args)\n",
    "       \n",
    "        # (2) lambda+ = lambda - learn_rate*grad_error; B(lambda) = f\n",
    "        lambda_next = calcNextLambda(lambda_vect[:, :, iT], lambda_rate, grad_new, targ_vect)\n",
    "        lambda_vect[:,:, iT + 1] = lambda_next\n",
    "       \n",
    "        # (2) fr+ = B(lambda+)\n",
    "        fr_next = brainFiringRate(lambda_next, targ_vect)\n",
    "        fr_vect[:, :, iT + 1] = fr_next\n",
    "       \n",
    "    lambda_final = lambda_next\n",
    "    fr_final = fr_next\n",
    "\n",
    "    return  (fr_final, lambda_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate New Trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findNextTarget(curr_cursor, prev_targ):\n",
    "    ## random\n",
    "    x_pos = int(np.random.random_sample()*10)\n",
    "    y_pos = int(np.random.random_sample()*10)\n",
    "\n",
    "#     x_pos = prev_targ[0][0]\n",
    "#     y_pos = prev_targ[1][0]\n",
    "\n",
    "    return np.array( [x_pos, y_pos] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set initial conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INITIAL CONDITIONS\n",
      "NUM NEURONS = 10\n",
      "(2, 1)\n",
      "initial target = [[1]\n",
      " [1]]\n",
      "baseline shape = (10,)\n",
      "b =[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "K MATX = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "A = [-0. -0.]\n",
      "lambda init = \n",
      "[[ 0.          0.17569819 -0.1168215 ]\n",
      " [ 0.          0.17094785  0.05671689]\n",
      " [ 0.         -0.13660684  0.34736166]\n",
      " [ 0.          0.39038693 -0.30734903]\n",
      " [ 0.          0.07484879  0.16279938]\n",
      " [ 0.          0.06604893  0.12726184]\n",
      " [ 0.         -0.35233706  0.44135871]\n",
      " [ 0.         -0.15102956  0.35740288]\n",
      " [ 0.          0.23767146 -0.14068682]\n",
      " [ 0.          0.63275023 -0.52240076]]\n"
     ]
    }
   ],
   "source": [
    "########\n",
    "## Set some initial conditions here\n",
    "\n",
    "# Helper info:\n",
    "# fr_init = N x 1\n",
    "# lambda init = N x 3\n",
    "# baseline = 1 x N\n",
    "# target_vector = 2 x 1\n",
    "# K_matx = 2 x N\n",
    "# A = 2 x 1\n",
    "\n",
    "NUM_NEURONS = 10\n",
    "NUM_DIM = 2\n",
    "NUM_LAMBDA = NUM_DIM + 1\n",
    "\n",
    "print(\"INITIAL CONDITIONS\")\n",
    "print(\"NUM NEURONS = \" + str(NUM_NEURONS))\n",
    "# target position\n",
    "TARGET_VECTOR = np.array([[1] , [1]])\n",
    "print(np.shape(TARGET_VECTOR))\n",
    "print(\"initial target = \" + str(TARGET_VECTOR))\n",
    "\n",
    "# firing rate \n",
    "fr_init = np.zeros( (NUM_NEURONS, 1) ) \n",
    "\n",
    "# BASELINE (b)\n",
    "BASELINE = (0*np.random.random_sample(NUM_NEURONS))  # random float [0, 10)\n",
    "print(\"baseline shape = \" + str(np.shape(BASELINE)))\n",
    "print(\"b =\" + str(BASELINE))\n",
    "\n",
    "# decoder initial paramters\n",
    "# IDEAL: y = a + Kf = a + K(b + Wt) = a + Kb + KWt\n",
    "# in order for y = t, want: a + Kb --> 0 and KW --> Identity matx\n",
    "K_MATX = np.random.random_sample( (NUM_DIM, NUM_NEURONS) ) # random float [0, 1)\n",
    "A_VECT = (-np.matmul(K_MATX, BASELINE))*0\n",
    "print(\"K MATX = \" + str(K_MATX))\n",
    "print(\"A = \" + str(A_VECT))\n",
    "\n",
    "# lambda\n",
    "lambda_init = np.zeros((NUM_NEURONS, NUM_LAMBDA))\n",
    "W_init = np.linalg.pinv(K_MATX) \n",
    "W_rand = 0*np.random.random_sample( (NUM_NEURONS, NUM_DIM) )\n",
    "W_init = W_init + W_rand\n",
    "lambda_init[:, 0] = np.array([BASELINE])        # lambda[0] = baseline\n",
    "lambda_init[:, 1:3] = W_init\n",
    "print(\"lambda init = \")\n",
    "print(lambda_init)\n",
    "\n",
    "# lambda_init[:, 1] = np.random.random_sample(np.shape(lambda_init[:, 0]))    # lambda[2] = w_y\n",
    "# lambda_init[:, 2] = np.random.random_sample(np.shape(lambda_init[:, 0]))*10 \n",
    "# # lambda_init[:, 1] = np.array([0.4, 0.6, 1, 2])  # lambda[1] = w_x\n",
    "# # lambda_init[:, 2] = np.array([3, 5, 4, 2])      # lambda[2] = w_\n",
    "\n",
    "# SGD initial parameters\n",
    "# Mapping for variables\n",
    "FR_VAR = 1\n",
    "A_VAR = 2\n",
    "K_VAR = 3\n",
    "\n",
    "# Brain\n",
    "FR_SIGMA = 1\n",
    "FR_DELTA = 1\n",
    "FR_DIST_SIZE = 100\n",
    "\n",
    "# Decoder\n",
    "# A_RATE = 1e-4\n",
    "A_SIGMA = 1\n",
    "A_DELTA = 1\n",
    "A_DIST_SIZE = 100\n",
    "# --\n",
    "# K_RATE = 5e-4\n",
    "K_SIGMA = 1\n",
    "K_DELTA = 1\n",
    "K_DIST_SIZE = 100\n",
    "\n",
    "# display parameters\n",
    "fig_x = 10\n",
    "fig_y = 5\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adaptive Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "+++++++++++++++++++++++++++++++++++\n",
      "Session #0\n",
      "target at trial 0 = [[1.]\n",
      " [1.]]\n",
      "K MATX INIT= [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "A VECT INIT = [-0. -0.]\n",
      "lambda\n",
      "[[ 0.          0.17569819 -0.1168215 ]\n",
      " [ 0.          0.17094785  0.05671689]\n",
      " [ 0.         -0.13660684  0.34736166]\n",
      " [ 0.          0.39038693 -0.30734903]\n",
      " [ 0.          0.07484879  0.16279938]\n",
      " [ 0.          0.06604893  0.12726184]\n",
      " [ 0.         -0.35233706  0.44135871]\n",
      " [ 0.         -0.15102956  0.35740288]\n",
      " [ 0.          0.23767146 -0.14068682]\n",
      " [ 0.          0.63275023 -0.52240076]]\n",
      "a\n",
      "[-0. -0.]\n",
      "K\n",
      "[[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #0 | lambda learn rate = 0.001\n",
      "Target = [[1.]\n",
      " [1.]]\n",
      "lambda end of trial = [[ 0.          0.1668984  -0.1256213 ]\n",
      " [ 0.          0.16245318  0.04822222]\n",
      " [ 0.         -0.1453731   0.33859541]\n",
      " [ 0.          0.38203199 -0.31570397]\n",
      " [ 0.          0.06575852  0.15370911]\n",
      " [ 0.          0.05658763  0.11780054]\n",
      " [ 0.         -0.36052537  0.43317041]\n",
      " [ 0.         -0.16036684  0.3480656 ]\n",
      " [ 0.          0.22948143 -0.14887685]\n",
      " [ 0.          0.62451529 -0.5306357 ]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #1 | lambda learn rate = 0.001\n",
      "Target = [[6.]\n",
      " [9.]]\n",
      "lambda end of trial = [[ 0.          0.14163879 -0.1635107 ]\n",
      " [ 0.          0.13733983  0.01055219]\n",
      " [ 0.         -0.17325382  0.29677433]\n",
      " [ 0.          0.35543285 -0.35560269]\n",
      " [ 0.          0.03625602  0.10945535]\n",
      " [ 0.          0.02828898  0.07535256]\n",
      " [ 0.         -0.38622036  0.39462792]\n",
      " [ 0.         -0.18816038  0.30637529]\n",
      " [ 0.          0.20349707 -0.18785338]\n",
      " [ 0.          0.59908485 -0.56878136]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #2 | lambda learn rate = 0.001\n",
      "Target = [[2.]\n",
      " [8.]]\n",
      "lambda end of trial = [[ 0.          0.15551817 -0.10799319]\n",
      " [ 0.          0.15018645  0.06193868]\n",
      " [ 0.         -0.16010709  0.34936124]\n",
      " [ 0.          0.36824467 -0.3043554 ]\n",
      " [ 0.          0.04770784  0.15526264]\n",
      " [ 0.          0.04090415  0.12581323]\n",
      " [ 0.         -0.37259866  0.44911471]\n",
      " [ 0.         -0.17534121  0.35765196]\n",
      " [ 0.          0.21750192 -0.13183401]\n",
      " [ 0.          0.61326148 -0.51207484]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #3 | lambda learn rate = 0.001\n",
      "Target = [[3.]\n",
      " [0.]]\n",
      "lambda end of trial = [[ 0.          0.13858472 -0.10799319]\n",
      " [ 0.          0.13373668  0.06193868]\n",
      " [ 0.         -0.17860561  0.34936124]\n",
      " [ 0.          0.35313681 -0.3043554 ]\n",
      " [ 0.          0.03061815  0.15526264]\n",
      " [ 0.          0.02488779  0.12581323]\n",
      " [ 0.         -0.390682    0.44911471]\n",
      " [ 0.         -0.19238034  0.35765196]\n",
      " [ 0.          0.19975772 -0.13183401]\n",
      " [ 0.          0.59770109 -0.51207484]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #4 | lambda learn rate = 0.001\n",
      "Target = [[8.]\n",
      " [5.]]\n",
      "lambda end of trial = [[ 0.          0.15065186 -0.10045123]\n",
      " [ 0.          0.14391828  0.06830218]\n",
      " [ 0.         -0.16676158  0.35676375]\n",
      " [ 0.          0.36522623 -0.29679951]\n",
      " [ 0.          0.03958374  0.16086614]\n",
      " [ 0.          0.03654037  0.13309609]\n",
      " [ 0.         -0.37633359  0.45808247]\n",
      " [ 0.         -0.18205132  0.3641076 ]\n",
      " [ 0.          0.21137111 -0.12457564]\n",
      " [ 0.          0.60871131 -0.50519345]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #5 | lambda learn rate = 0.001\n",
      "Target = [[5.]\n",
      " [0.]]\n",
      "lambda end of trial = [[ 0.          0.13168426 -0.10045123]\n",
      " [ 0.          0.1223807   0.06830218]\n",
      " [ 0.         -0.18768845  0.35676375]\n",
      " [ 0.          0.34400684 -0.29679951]\n",
      " [ 0.          0.0180103   0.16086614]\n",
      " [ 0.          0.01601071  0.13309609]\n",
      " [ 0.         -0.39774704  0.45808247]\n",
      " [ 0.         -0.2035884   0.3641076 ]\n",
      " [ 0.          0.19345343 -0.12457564]\n",
      " [ 0.          0.58927856 -0.50519345]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #6 | lambda learn rate = 0.001\n",
      "Target = [[6.]\n",
      " [2.]]\n",
      "lambda end of trial = [[ 0.          0.13557101 -0.09915564]\n",
      " [ 0.          0.12393299  0.06881961]\n",
      " [ 0.         -0.18553288  0.35748227]\n",
      " [ 0.          0.34735158 -0.2956846 ]\n",
      " [ 0.          0.02050193  0.16169668]\n",
      " [ 0.          0.01872956  0.13400237]\n",
      " [ 0.         -0.39328185  0.45957086]\n",
      " [ 0.         -0.20042935  0.36516062]\n",
      " [ 0.          0.19674714 -0.12347773]\n",
      " [ 0.          0.59183436 -0.50434152]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #7 | lambda learn rate = 0.001\n",
      "Target = [[5.]\n",
      " [9.]]\n",
      "lambda end of trial = [[ 0.00000000e+00  1.19986632e-01 -1.27207517e-01]\n",
      " [ 0.00000000e+00  1.07727535e-01  3.96497956e-02]\n",
      " [ 0.00000000e+00 -2.01798657e-01  3.28203878e-01]\n",
      " [ 0.00000000e+00  3.30770049e-01 -3.25531350e-01]\n",
      " [ 0.00000000e+00  1.11444062e-03  1.26799198e-01]\n",
      " [ 0.00000000e+00  3.42362721e-04  1.00905419e-01]\n",
      " [ 0.00000000e+00 -4.09234439e-01  4.30856197e-01]\n",
      " [ 0.00000000e+00 -2.19693138e-01  3.30485798e-01]\n",
      " [ 0.00000000e+00  1.77433483e-01 -1.58242321e-01]\n",
      " [ 0.00000000e+00  5.73375735e-01 -5.37567034e-01]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #8 | lambda learn rate = 0.001\n",
      "Target = [[9.]\n",
      " [5.]]\n",
      "lambda end of trial = [[ 0.          0.25447075 -0.05249412]\n",
      " [ 0.          0.22910892  0.1070839 ]\n",
      " [ 0.         -0.06967253  0.40160728]\n",
      " [ 0.          0.44412492 -0.26255642]\n",
      " [ 0.          0.12896747  0.19782866]\n",
      " [ 0.          0.12449476  0.16987897]\n",
      " [ 0.         -0.28983878  0.49718712]\n",
      " [ 0.         -0.08691277  0.40425267]\n",
      " [ 0.          0.29870465 -0.09086945]\n",
      " [ 0.          0.68878933 -0.47344837]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #9 | lambda learn rate = 0.001\n",
      "Target = [[0.]\n",
      " [6.]]\n",
      "lambda end of trial = [[ 0.          0.25447075 -0.16117568]\n",
      " [ 0.          0.22910892 -0.01689224]\n",
      " [ 0.         -0.06967253  0.28393405]\n",
      " [ 0.          0.44412492 -0.37118626]\n",
      " [ 0.          0.12896747  0.0868479 ]\n",
      " [ 0.          0.12449476  0.06207967]\n",
      " [ 0.         -0.28983878  0.38634181]\n",
      " [ 0.         -0.08691277  0.28430556]\n",
      " [ 0.          0.29870465 -0.19929118]\n",
      " [ 0.          0.68878933 -0.5867028 ]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #10 | lambda learn rate = 0.001\n",
      "Target = [[2.]\n",
      " [5.]]\n",
      "lambda end of trial = [[ 0.          0.25156298 -0.16844511]\n",
      " [ 0.          0.22576291 -0.02525725]\n",
      " [ 0.         -0.07371483  0.27382829]\n",
      " [ 0.          0.44073763 -0.37965448]\n",
      " [ 0.          0.1252902   0.07765474]\n",
      " [ 0.          0.12113235  0.05367365]\n",
      " [ 0.         -0.29336366  0.37752962]\n",
      " [ 0.         -0.09056883  0.2751654 ]\n",
      " [ 0.          0.2955655  -0.20713907]\n",
      " [ 0.          0.68585601 -0.59403611]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #11 | lambda learn rate = 0.001\n",
      "Target = [[5.]\n",
      " [5.]]\n",
      "lambda end of trial = [[ 0.          0.22374018 -0.19626791]\n",
      " [ 0.          0.19285873 -0.05816143]\n",
      " [ 0.         -0.10261951  0.24492361]\n",
      " [ 0.          0.4124317  -0.40796041]\n",
      " [ 0.          0.09688386  0.0492484 ]\n",
      " [ 0.          0.09285642  0.02539772]\n",
      " [ 0.         -0.32203716  0.34885612]\n",
      " [ 0.         -0.12256386  0.24317038]\n",
      " [ 0.          0.26596537 -0.2367392 ]\n",
      " [ 0.          0.65788085 -0.62201126]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #12 | lambda learn rate = 0.001\n",
      "Target = [[3.]\n",
      " [8.]]\n",
      "lambda end of trial = [[ 0.          0.27107266 -0.07004796]\n",
      " [ 0.          0.2415822   0.07176781]\n",
      " [ 0.         -0.05075941  0.38321723]\n",
      " [ 0.          0.46011856 -0.28079546]\n",
      " [ 0.          0.14567837  0.17936709]\n",
      " [ 0.          0.14373603  0.16107667]\n",
      " [ 0.         -0.27443096  0.47580598]\n",
      " [ 0.         -0.06919263  0.38549366]\n",
      " [ 0.          0.3184702  -0.09672631]\n",
      " [ 0.          0.69988802 -0.50999215]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #13 | lambda learn rate = 0.001\n",
      "Target = [[1.]\n",
      " [2.]]\n",
      "lambda end of trial = [[ 0.          0.25862902 -0.09493525]\n",
      " [ 0.          0.22881846  0.04624033]\n",
      " [ 0.         -0.06439008  0.35595589]\n",
      " [ 0.          0.44789614 -0.30524029]\n",
      " [ 0.          0.13419038  0.1563911 ]\n",
      " [ 0.          0.13177383  0.13715227]\n",
      " [ 0.         -0.28672257  0.45122276]\n",
      " [ 0.         -0.08274343  0.35839205]\n",
      " [ 0.          0.30555838 -0.12254996]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [ 0.          0.68679086 -0.53618647]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #14 | lambda learn rate = 0.001\n",
      "Target = [[2.]\n",
      " [5.]]\n",
      "lambda end of trial = [[ 0.          0.23225329 -0.16087458]\n",
      " [ 0.          0.20336872 -0.01738401]\n",
      " [ 0.         -0.0907921   0.28995085]\n",
      " [ 0.          0.42059965 -0.37348153]\n",
      " [ 0.          0.10518868  0.08388685]\n",
      " [ 0.          0.10692807  0.07503787]\n",
      " [ 0.         -0.31100084  0.39052709]\n",
      " [ 0.         -0.10858342  0.29379208]\n",
      " [ 0.          0.27841857 -0.19039949]\n",
      " [ 0.          0.66000434 -0.60315277]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #15 | lambda learn rate = 0.001\n",
      "Target = [[6.]\n",
      " [2.]]\n",
      "lambda end of trial = [[ 0.          0.16318531 -0.18389724]\n",
      " [ 0.          0.13585278 -0.03988932]\n",
      " [ 0.         -0.16500914  0.26521183]\n",
      " [ 0.          0.34936078 -0.39722782]\n",
      " [ 0.          0.0353708   0.06061422]\n",
      " [ 0.          0.02491775  0.0477011 ]\n",
      " [ 0.         -0.38402234  0.36618659]\n",
      " [ 0.         -0.18070132  0.26975278]\n",
      " [ 0.          0.20860656 -0.21367016]\n",
      " [ 0.          0.58690576 -0.62751896]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #16 | lambda learn rate = 0.001\n",
      "Target = [[4.]\n",
      " [8.]]\n",
      "lambda end of trial = [[ 0.          0.23473567 -0.04079652]\n",
      " [ 0.          0.21073017  0.10986545]\n",
      " [ 0.         -0.0892651   0.41669992]\n",
      " [ 0.          0.42564347 -0.24466244]\n",
      " [ 0.          0.10695503  0.20378268]\n",
      " [ 0.          0.10063615  0.1991379 ]\n",
      " [ 0.         -0.31436817  0.50549492]\n",
      " [ 0.         -0.11324843  0.40465854]\n",
      " [ 0.          0.28209679 -0.06668971]\n",
      " [ 0.          0.65499426 -0.49134195]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #17 | lambda learn rate = 0.001\n",
      "Target = [[1.]\n",
      " [1.]]\n",
      "lambda end of trial = [[ 0.          0.22327707 -0.05225511]\n",
      " [ 0.          0.19915037  0.09828565]\n",
      " [ 0.         -0.10054743  0.40541759]\n",
      " [ 0.          0.41433482 -0.25597109]\n",
      " [ 0.          0.09585534  0.19268299]\n",
      " [ 0.          0.08906135  0.1875631 ]\n",
      " [ 0.         -0.32588746  0.49397563]\n",
      " [ 0.         -0.12519588  0.39271109]\n",
      " [ 0.          0.2714148  -0.0773717 ]\n",
      " [ 0.          0.64361128 -0.50272494]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #18 | lambda learn rate = 0.001\n",
      "Target = [[5.]\n",
      " [3.]]\n",
      "lambda end of trial = [[ 0.          0.13782251 -0.10352785]\n",
      " [ 0.          0.10445955  0.04147116]\n",
      " [ 0.         -0.19489945  0.34880638]\n",
      " [ 0.          0.32294941 -0.31080234]\n",
      " [ 0.         -0.00595856  0.13159465]\n",
      " [ 0.         -0.00287739  0.13239986]\n",
      " [ 0.         -0.41253266  0.44198852]\n",
      " [ 0.         -0.21526136  0.33867181]\n",
      " [ 0.          0.18573336 -0.12878056]\n",
      " [ 0.          0.56434881 -0.55028242]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #19 | lambda learn rate = 0.001\n",
      "Target = [[4.]\n",
      " [6.]]\n",
      "lambda end of trial = [[ 0.          0.1445574  -0.09342552]\n",
      " [ 0.          0.11103871  0.05133991]\n",
      " [ 0.         -0.18720835  0.36034302]\n",
      " [ 0.          0.32988182 -0.30040372]\n",
      " [ 0.          0.00091208  0.14190062]\n",
      " [ 0.          0.00411092  0.14288231]\n",
      " [ 0.         -0.40504465  0.45322053]\n",
      " [ 0.         -0.20831629  0.34908941]\n",
      " [ 0.          0.1931166  -0.11770571]\n",
      " [ 0.          0.57108597 -0.54017668]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #20 | lambda learn rate = 0.001\n",
      "Target = [[0.]\n",
      " [8.]]\n",
      "lambda end of trial = [[ 0.          0.1445574  -0.16618558]\n",
      " [ 0.          0.11103871 -0.02224093]\n",
      " [ 0.         -0.18720835  0.28100584]\n",
      " [ 0.          0.32988182 -0.37552967]\n",
      " [ 0.          0.00091208  0.06286054]\n",
      " [ 0.          0.00411092  0.06771358]\n",
      " [ 0.         -0.40504465  0.3761474 ]\n",
      " [ 0.         -0.20831629  0.27948827]\n",
      " [ 0.          0.1931166  -0.1903288 ]\n",
      " [ 0.          0.57108597 -0.61115065]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #21 | lambda learn rate = 0.001\n",
      "Target = [[9.]\n",
      " [3.]]\n",
      "lambda end of trial = [[ 0.          0.29139979 -0.11723811]\n",
      " [ 0.          0.2578252   0.02668789]\n",
      " [ 0.         -0.04676318  0.3278209 ]\n",
      " [ 0.          0.47075219 -0.32857288]\n",
      " [ 0.          0.14260753  0.11009235]\n",
      " [ 0.          0.14780059  0.11561013]\n",
      " [ 0.         -0.25877094  0.4249053 ]\n",
      " [ 0.         -0.06732838  0.32648424]\n",
      " [ 0.          0.33194259 -0.14405347]\n",
      " [ 0.          0.71784129 -0.56223221]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #22 | lambda learn rate = 0.001\n",
      "Target = [[4.]\n",
      " [6.]]\n",
      "lambda end of trial = [[ 0.          0.23282128 -0.20510588]\n",
      " [ 0.          0.20067978 -0.05903023]\n",
      " [ 0.         -0.09753126  0.25166877]\n",
      " [ 0.          0.4180573  -0.40761521]\n",
      " [ 0.          0.08701592  0.02670494]\n",
      " [ 0.          0.08881535  0.02713228]\n",
      " [ 0.         -0.31289515  0.34371898]\n",
      " [ 0.         -0.11974414  0.2478606 ]\n",
      " [ 0.          0.27278111 -0.2327957 ]\n",
      " [ 0.          0.66375539 -0.64336106]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #23 | lambda learn rate = 0.001\n",
      "Target = [[1.]\n",
      " [8.]]\n",
      "lambda end of trial = [[ 0.          0.25349173 -0.03974227]\n",
      " [ 0.          0.22296749  0.11927142]\n",
      " [ 0.         -0.08062576  0.38691278]\n",
      " [ 0.          0.43760771 -0.25121197]\n",
      " [ 0.          0.10684175  0.18531155]\n",
      " [ 0.          0.10806953  0.18116569]\n",
      " [ 0.         -0.2933239   0.50028898]\n",
      " [ 0.         -0.09805131  0.42140319]\n",
      " [ 0.          0.29175399 -0.08101268]\n",
      " [ 0.          0.68488565 -0.47431903]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #24 | lambda learn rate = 0.001\n",
      "Target = [[0.]\n",
      " [9.]]\n",
      "lambda end of trial = [[ 0.          0.25349173 -0.23533665]\n",
      " [ 0.          0.22296749 -0.08782933]\n",
      " [ 0.         -0.08062576  0.18111965]\n",
      " [ 0.          0.43760771 -0.45958972]\n",
      " [ 0.          0.10684175 -0.04528701]\n",
      " [ 0.          0.10806953 -0.00903683]\n",
      " [ 0.         -0.2933239   0.29142903]\n",
      " [ 0.         -0.09805131  0.20330117]\n",
      " [ 0.          0.29175399 -0.29554673]\n",
      " [ 0.          0.68488565 -0.67739649]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #25 | lambda learn rate = 0.001\n",
      "Target = [[9.]\n",
      " [7.]]\n",
      "lambda end of trial = [[ 0.          0.36390339 -0.14946091]\n",
      " [ 0.          0.32999233 -0.00458779]\n",
      " [ 0.          0.04898951  0.28193153]\n",
      " [ 0.          0.54121832 -0.37900369]\n",
      " [ 0.          0.22682965  0.04803691]\n",
      " [ 0.          0.22046668  0.07838318]\n",
      " [ 0.         -0.17192278  0.38585213]\n",
      " [ 0.          0.00831937  0.28603392]\n",
      " [ 0.          0.40414286 -0.20813316]\n",
      " [ 0.          0.80507531 -0.58391564]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #26 | lambda learn rate = 0.001\n",
      "Target = [[1.]\n",
      " [4.]]\n",
      "lambda end of trial = [[ 0.          0.35820916 -0.17223786]\n",
      " [ 0.          0.32324116 -0.03159247]\n",
      " [ 0.          0.04221226  0.25482256]\n",
      " [ 0.          0.53557665 -0.40157038]\n",
      " [ 0.          0.22038694  0.02226609]\n",
      " [ 0.          0.2143446   0.05389485]\n",
      " [ 0.         -0.17777661  0.36243678]\n",
      " [ 0.          0.00187809  0.2602688 ]\n",
      " [ 0.          0.39797194 -0.23281685]\n",
      " [ 0.          0.79921127 -0.60737182]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #27 | lambda learn rate = 0.001\n",
      "Target = [[5.]\n",
      " [9.]]\n",
      "lambda end of trial = [[ 0.          0.32681227 -0.22875225]\n",
      " [ 0.          0.28831969 -0.09445111]\n",
      " [ 0.          0.00770617  0.1927116 ]\n",
      " [ 0.          0.50243453 -0.46122619]\n",
      " [ 0.          0.1848614  -0.04167989]\n",
      " [ 0.          0.18270997 -0.0030475 ]\n",
      " [ 0.         -0.21239843  0.30011751]\n",
      " [ 0.         -0.03490476  0.19405966]\n",
      " [ 0.          0.36428086 -0.2934608 ]\n",
      " [ 0.          0.7646337  -0.66961144]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #28 | lambda learn rate = 0.001\n",
      "Target = [[2.]\n",
      " [6.]]\n",
      "lambda end of trial = [[ 0.          0.35424233 -0.14646206]\n",
      " [ 0.          0.31676281 -0.00912176]\n",
      " [ 0.          0.03661127  0.27942688]\n",
      " [ 0.          0.53148144 -0.37408546]\n",
      " [ 0.          0.21097429  0.03665878]\n",
      " [ 0.          0.20994986  0.0786722 ]\n",
      " [ 0.         -0.1856037   0.3805017 ]\n",
      " [ 0.         -0.00894145  0.2719496 ]\n",
      " [ 0.          0.39059322 -0.21452372]\n",
      " [ 0.          0.79180521 -0.5880969 ]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #29 | lambda learn rate = 0.001\n",
      "Target = [[0.]\n",
      " [6.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda end of trial = [[ 0.          0.35424233 -0.1126174 ]\n",
      " [ 0.          0.31676281  0.02511086]\n",
      " [ 0.          0.03661127  0.31561135]\n",
      " [ 0.          0.53148144 -0.33810356]\n",
      " [ 0.          0.21097429  0.07217574]\n",
      " [ 0.          0.20994986  0.1122008 ]\n",
      " [ 0.         -0.1856037   0.41420428]\n",
      " [ 0.         -0.00894145  0.31038562]\n",
      " [ 0.          0.39059322 -0.17932392]\n",
      " [ 0.          0.79180521 -0.55218682]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #30 | lambda learn rate = 0.001\n",
      "Target = [[7.]\n",
      " [6.]]\n",
      "lambda end of trial = [[ 0.          0.13048173 -0.3044122 ]\n",
      " [ 0.          0.08262358 -0.17557991]\n",
      " [ 0.         -0.21080694  0.10353861]\n",
      " [ 0.          0.27733026 -0.55594744]\n",
      " [ 0.         -0.00757149 -0.11514922]\n",
      " [ 0.         -0.03876663 -0.10098477]\n",
      " [ 0.         -0.39966834  0.23072031]\n",
      " [ 0.         -0.25801822  0.09689125]\n",
      " [ 0.          0.13906262 -0.39492158]\n",
      " [ 0.          0.55857939 -0.75209468]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #31 | lambda learn rate = 0.001\n",
      "Target = [[9.]\n",
      " [4.]]\n",
      "lambda end of trial = [[ 0.00000000e+00  5.59211446e-01 -1.13865664e-01]\n",
      " [ 0.00000000e+00  4.79490289e-01  8.05296128e-04]\n",
      " [ 0.00000000e+00  2.32923768e-01  3.00752253e-01]\n",
      " [ 0.00000000e+00  6.93901232e-01 -3.70804781e-01]\n",
      " [ 0.00000000e+00  4.70993366e-01  9.75462727e-02]\n",
      " [ 0.00000000e+00  4.03965253e-01  9.57849593e-02]\n",
      " [ 0.00000000e+00 -2.62874962e-03  4.07182345e-01]\n",
      " [ 0.00000000e+00  1.73521982e-01  2.88686893e-01]\n",
      " [ 0.00000000e+00  5.95426408e-01 -1.92093229e-01]\n",
      " [ 0.00000000e+00  1.01687837e+00 -5.48406241e-01]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #32 | lambda learn rate = 0.001\n",
      "Target = [[7.]\n",
      " [2.]]\n",
      "lambda end of trial = [[ 0.         -0.04354642 -0.2860822 ]\n",
      " [ 0.         -0.137457   -0.17546536]\n",
      " [ 0.         -0.42355052  0.11318817]\n",
      " [ 0.          0.10962167 -0.5377418 ]\n",
      " [ 0.         -0.13983437 -0.07697594]\n",
      " [ 0.         -0.24078868 -0.08843045]\n",
      " [ 0.         -0.5958519   0.23769002]\n",
      " [ 0.         -0.44160622  0.11293598]\n",
      " [ 0.          0.03623574 -0.35186199]\n",
      " [ 0.          0.40110779 -0.72434069]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #33 | lambda learn rate = 0.001\n",
      "Target = [[5.]\n",
      " [4.]]\n",
      "lambda end of trial = [[ 0.          0.23894754 -0.06008703]\n",
      " [ 0.          0.1698744   0.07039976]\n",
      " [ 0.         -0.13923275  0.34064239]\n",
      " [ 0.          0.41148886 -0.29624804]\n",
      " [ 0.          0.16650379  0.16809459]\n",
      " [ 0.          0.06141469  0.15333225]\n",
      " [ 0.         -0.29032272  0.48211336]\n",
      " [ 0.         -0.1332008   0.35966031]\n",
      " [ 0.          0.34906351 -0.10159978]\n",
      " [ 0.          0.68569333 -0.49667226]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #34 | lambda learn rate = 0.001\n",
      "Target = [[9.]\n",
      " [9.]]\n",
      "lambda end of trial = [[ 0.          0.0500435  -0.24899107]\n",
      " [ 0.         -0.03810977 -0.13758441]\n",
      " [ 0.         -0.35008678  0.12978835]\n",
      " [ 0.          0.21756396 -0.49017294]\n",
      " [ 0.         -0.04510877 -0.04351797]\n",
      " [ 0.         -0.14883055 -0.056913  ]\n",
      " [ 0.         -0.48922     0.28321608]\n",
      " [ 0.         -0.34589758  0.14696353]\n",
      " [ 0.          0.14125151 -0.30941177]\n",
      " [ 0.          0.48836784 -0.69399775]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #35 | lambda learn rate = 0.001\n",
      "Target = [[4.]\n",
      " [8.]]\n",
      "lambda end of trial = [[ 0.          0.30367573  0.25827339]\n",
      " [ 0.          0.2202624   0.37915994]\n",
      " [ 0.         -0.06208684  0.70578823]\n",
      " [ 0.          0.47919322  0.03308557]\n",
      " [ 0.          0.20527052  0.4572406 ]\n",
      " [ 0.          0.14917433  0.53909676]\n",
      " [ 0.         -0.23517619  0.7913037 ]\n",
      " [ 0.         -0.08752549  0.66370773]\n",
      " [ 0.          0.38792026  0.18392572]\n",
      " [ 0.          0.74875373 -0.17322596]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #36 | lambda learn rate = 0.001\n",
      "Target = [[4.]\n",
      " [1.]]\n",
      "lambda end of trial = [[ 0.          0.18022005  0.22740947]\n",
      " [ 0.          0.08943616  0.34645338]\n",
      " [ 0.         -0.19822872  0.67175276]\n",
      " [ 0.          0.34141334 -0.0013594 ]\n",
      " [ 0.          0.06288187  0.42164344]\n",
      " [ 0.          0.00635214  0.50339121]\n",
      " [ 0.         -0.38127701  0.7547785 ]\n",
      " [ 0.         -0.21453173  0.63195617]\n",
      " [ 0.          0.26963126  0.15435347]\n",
      " [ 0.          0.61598966 -0.20641698]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #37 | lambda learn rate = 0.001\n",
      "Target = [[9.]\n",
      " [0.]]\n",
      "lambda end of trial = [[ 0.          0.21297515  0.22740947]\n",
      " [ 0.          0.12147583  0.34645338]\n",
      " [ 0.         -0.1672301   0.67175276]\n",
      " [ 0.          0.37085724 -0.0013594 ]\n",
      " [ 0.          0.09395839  0.42164344]\n",
      " [ 0.          0.03832236  0.50339121]\n",
      " [ 0.         -0.34777844  0.7547785 ]\n",
      " [ 0.         -0.18216181  0.63195617]\n",
      " [ 0.          0.29859843  0.15435347]\n",
      " [ 0.          0.64373768 -0.20641698]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #38 | lambda learn rate = 0.001\n",
      "Target = [[7.]\n",
      " [4.]]\n",
      "lambda end of trial = [[ 0.         -0.08081236  0.0595309 ]\n",
      " [ 0.         -0.21392835  0.15479384]\n",
      " [ 0.         -0.49931993  0.48198714]\n",
      " [ 0.          0.06661583 -0.17521163]\n",
      " [ 0.         -0.22771342  0.23783098]\n",
      " [ 0.         -0.31821972  0.29965288]\n",
      " [ 0.         -0.65267702  0.58055074]\n",
      " [ 0.         -0.51136885  0.44383785]\n",
      " [ 0.         -0.00943237 -0.02166413]\n",
      " [ 0.          0.32577278 -0.38811121]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #39 | lambda learn rate = 0.001\n",
      "Target = [[7.]\n",
      " [1.]]\n",
      "lambda end of trial = [[ 0.          0.33992962  0.11963689]\n",
      " [ 0.          0.20372171  0.21445814]\n",
      " [ 0.         -0.01673193  0.55092829]\n",
      " [ 0.          0.51937909 -0.11053117]\n",
      " [ 0.          0.23049291  0.30328902]\n",
      " [ 0.          0.10810672  0.36055666]\n",
      " [ 0.         -0.19593822  0.64579914]\n",
      " [ 0.         -0.03317302  0.51215154]\n",
      " [ 0.          0.45708677  0.04498146]\n",
      " [ 0.          0.81911804 -0.31763331]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #40 | lambda learn rate = 0.001\n",
      "Target = [[3.]\n",
      " [3.]]\n",
      "lambda end of trial = [[ 0.          0.23342428  0.01313155]\n",
      " [ 0.          0.1048365   0.11557293]\n",
      " [ 0.         -0.12286826  0.44479196]\n",
      " [ 0.          0.41462456 -0.2152857 ]\n",
      " [ 0.          0.12069753  0.19349365]\n",
      " [ 0.          0.00878306  0.26123299]\n",
      " [ 0.         -0.30292092  0.53881644]\n",
      " [ 0.         -0.14667833  0.39864624]\n",
      " [ 0.          0.33647464 -0.07563067]\n",
      " [ 0.          0.70781723 -0.42893412]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #41 | lambda learn rate = 0.001\n",
      "Target = [[0.]\n",
      " [0.]]\n",
      "lambda end of trial = [[ 0.          0.23342428  0.01313155]\n",
      " [ 0.          0.1048365   0.11557293]\n",
      " [ 0.         -0.12286826  0.44479196]\n",
      " [ 0.          0.41462456 -0.2152857 ]\n",
      " [ 0.          0.12069753  0.19349365]\n",
      " [ 0.          0.00878306  0.26123299]\n",
      " [ 0.         -0.30292092  0.53881644]\n",
      " [ 0.         -0.14667833  0.39864624]\n",
      " [ 0.          0.33647464 -0.07563067]\n",
      " [ 0.          0.70781723 -0.42893412]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #42 | lambda learn rate = 0.001\n",
      "Target = [[3.]\n",
      " [6.]]\n",
      "lambda end of trial = [[ 0.          0.16768129 -0.11835444]\n",
      " [ 0.          0.02243471 -0.04923065]\n",
      " [ 0.         -0.19493906  0.30065036]\n",
      " [ 0.          0.34228588 -0.35996304]\n",
      " [ 0.          0.04900631  0.05011121]\n",
      " [ 0.         -0.08163204  0.08040281]\n",
      " [ 0.         -0.38194108  0.38077612]\n",
      " [ 0.         -0.22570638  0.24059013]\n",
      " [ 0.          0.26021491 -0.22815012]\n",
      " [ 0.          0.6399137  -0.56474119]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #43 | lambda learn rate = 0.001\n",
      "Target = [[2.]\n",
      " [9.]]\n",
      "lambda end of trial = [[ 0.          0.20535876  0.0511942 ]\n",
      " [ 0.          0.05319865  0.08920707]\n",
      " [ 0.         -0.16230312  0.44751208]\n",
      " [ 0.          0.37943895 -0.19277423]\n",
      " [ 0.          0.08254653  0.20104222]\n",
      " [ 0.         -0.04690276  0.23668456]\n",
      " [ 0.         -0.34725761  0.53685171]\n",
      " [ 0.         -0.18858551  0.40763406]\n",
      " [ 0.          0.29305951 -0.08034944]\n",
      " [ 0.          0.6767356  -0.39904262]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #44 | lambda learn rate = 0.001\n",
      "Target = [[5.]\n",
      " [5.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda end of trial = [[ 0.          0.11795341 -0.03621115]\n",
      " [ 0.         -0.03918336 -0.00317494]\n",
      " [ 0.         -0.24360615  0.36620905]\n",
      " [ 0.          0.29760888 -0.27460431]\n",
      " [ 0.         -0.00101036  0.11748532]\n",
      " [ 0.         -0.13171228  0.15187505]\n",
      " [ 0.         -0.43435584  0.44975349]\n",
      " [ 0.         -0.27183008  0.32438949]\n",
      " [ 0.          0.22100541 -0.15240355]\n",
      " [ 0.          0.58530546 -0.49047276]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #45 | lambda learn rate = 0.001\n",
      "Target = [[2.]\n",
      " [9.]]\n",
      "lambda end of trial = [[ 0.00000000e+00  1.20124298e-01 -2.64421619e-02]\n",
      " [ 0.00000000e+00 -3.78633925e-02  2.76492099e-03]\n",
      " [ 0.00000000e+00 -2.42167427e-01  3.72683293e-01]\n",
      " [ 0.00000000e+00  2.99811487e-01 -2.64692562e-01]\n",
      " [ 0.00000000e+00  4.19332142e-04  1.23918952e-01]\n",
      " [ 0.00000000e+00 -1.29985735e-01  1.59644480e-01]\n",
      " [ 0.00000000e+00 -4.32383156e-01  4.58630549e-01]\n",
      " [ 0.00000000e+00 -2.69665644e-01  3.34129450e-01]\n",
      " [ 0.00000000e+00  2.22701563e-01 -1.44770837e-01]\n",
      " [ 0.00000000e+00  5.87146564e-01 -4.82187792e-01]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #46 | lambda learn rate = 0.001\n",
      "Target = [[7.]\n",
      " [6.]]\n",
      "lambda end of trial = [[ 0.          0.24126258  0.07739065]\n",
      " [ 0.          0.07940667  0.10328212]\n",
      " [ 0.         -0.11739071  0.47963477]\n",
      " [ 0.          0.41583595 -0.16524302]\n",
      " [ 0.          0.12265608  0.22869331]\n",
      " [ 0.         -0.01147031  0.26122913]\n",
      " [ 0.         -0.31452999  0.55964755]\n",
      " [ 0.         -0.14412881  0.44173245]\n",
      " [ 0.          0.34029876 -0.04397324]\n",
      " [ 0.          0.70777502 -0.37879197]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #47 | lambda learn rate = 0.001\n",
      "Target = [[7.]\n",
      " [9.]]\n",
      "lambda end of trial = [[ 0.         -0.03989086 -0.28409234]\n",
      " [ 0.         -0.24945303 -0.3195375 ]\n",
      " [ 0.         -0.41294026  0.09964248]\n",
      " [ 0.          0.13408064 -0.52749985]\n",
      " [ 0.         -0.19198776 -0.17584878]\n",
      " [ 0.         -0.33820067 -0.15885276]\n",
      " [ 0.         -0.60102626  0.1912952 ]\n",
      " [ 0.         -0.42719577  0.07778921]\n",
      " [ 0.          0.05954264 -0.4049454 ]\n",
      " [ 0.          0.40949807 -0.7622909 ]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #48 | lambda learn rate = 0.001\n",
      "Target = [[3.]\n",
      " [1.]]\n",
      "lambda end of trial = [[ 0.          0.05117301 -0.25373772]\n",
      " [ 0.         -0.15678124 -0.2886469 ]\n",
      " [ 0.         -0.32766492  0.1280676 ]\n",
      " [ 0.          0.21956826 -0.49900398]\n",
      " [ 0.         -0.095517   -0.14369186]\n",
      " [ 0.         -0.23849988 -0.12561917]\n",
      " [ 0.         -0.51620356  0.21956943]\n",
      " [ 0.         -0.33641729  0.1080487 ]\n",
      " [ 0.          0.14856827 -0.37527019]\n",
      " [ 0.          0.50043522 -0.73197852]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #49 | lambda learn rate = 0.001\n",
      "Target = [[4.]\n",
      " [4.]]\n",
      "lambda end of trial = [[ 0.          0.26924049 -0.03567025]\n",
      " [ 0.          0.06022858 -0.07163708]\n",
      " [ 0.         -0.12248107  0.33325145]\n",
      " [ 0.          0.41998216 -0.29859008]\n",
      " [ 0.          0.10821875  0.06004389]\n",
      " [ 0.         -0.03815489  0.07472583]\n",
      " [ 0.         -0.32375689  0.4120161 ]\n",
      " [ 0.         -0.13295681  0.31150918]\n",
      " [ 0.          0.34823374 -0.17560472]\n",
      " [ 0.          0.70324937 -0.52916437]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #50 | lambda learn rate = 0.001\n",
      "Target = [[8.]\n",
      " [7.]]\n",
      "lambda end of trial = [[ 0.          0.29032096 -0.01722483]\n",
      " [ 0.          0.08084308 -0.0535994 ]\n",
      " [ 0.         -0.10416881  0.34927467]\n",
      " [ 0.          0.43990968 -0.2811535 ]\n",
      " [ 0.          0.12529501  0.07498562]\n",
      " [ 0.         -0.01725303  0.09301495]\n",
      " [ 0.         -0.30454373  0.42882761]\n",
      " [ 0.         -0.11385369  0.32822441]\n",
      " [ 0.          0.3695287  -0.15697162]\n",
      " [ 0.          0.72196905 -0.51278465]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #51 | lambda learn rate = 0.001\n",
      "Target = [[0.]\n",
      " [0.]]\n",
      "lambda end of trial = [[ 0.          0.29032096 -0.01722483]\n",
      " [ 0.          0.08084308 -0.0535994 ]\n",
      " [ 0.         -0.10416881  0.34927467]\n",
      " [ 0.          0.43990968 -0.2811535 ]\n",
      " [ 0.          0.12529501  0.07498562]\n",
      " [ 0.         -0.01725303  0.09301495]\n",
      " [ 0.         -0.30454373  0.42882761]\n",
      " [ 0.         -0.11385369  0.32822441]\n",
      " [ 0.          0.3695287  -0.15697162]\n",
      " [ 0.          0.72196905 -0.51278465]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #52 | lambda learn rate = 0.001\n",
      "Target = [[0.]\n",
      " [3.]]\n",
      "lambda end of trial = [[ 0.          0.29032096 -0.03195861]\n",
      " [ 0.          0.08084308 -0.06959579]\n",
      " [ 0.         -0.10416881  0.33308105]\n",
      " [ 0.          0.43990968 -0.2940594 ]\n",
      " [ 0.          0.12529501  0.05942237]\n",
      " [ 0.         -0.01725303  0.07604469]\n",
      " [ 0.         -0.30454373  0.41398421]\n",
      " [ 0.         -0.11385369  0.31220063]\n",
      " [ 0.          0.3695287  -0.17197849]\n",
      " [ 0.          0.72196905 -0.52859002]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #53 | lambda learn rate = 0.001\n",
      "Target = [[6.]\n",
      " [2.]]\n",
      "lambda end of trial = [[ 0.          0.22967921 -0.05217253]\n",
      " [ 0.          0.01731072 -0.09077325]\n",
      " [ 0.         -0.16112963  0.31409411]\n",
      " [ 0.          0.38067165 -0.31380541]\n",
      " [ 0.          0.0631731   0.03871506]\n",
      " [ 0.         -0.08143577  0.05465044]\n",
      " [ 0.         -0.36024838  0.39541599]\n",
      " [ 0.         -0.17274321  0.29257079]\n",
      " [ 0.          0.30719119 -0.19275766]\n",
      " [ 0.          0.65993434 -0.54926825]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #54 | lambda learn rate = 0.001\n",
      "Target = [[3.]\n",
      " [5.]]\n",
      "lambda end of trial = [[ 0.          0.24877009 -0.0203544 ]\n",
      " [ 0.          0.03693537 -0.05806549]\n",
      " [ 0.         -0.14273515  0.34475157]\n",
      " [ 0.          0.40017726 -0.28129606]\n",
      " [ 0.          0.08383887  0.07315802]\n",
      " [ 0.         -0.06325953  0.08494417]\n",
      " [ 0.         -0.34173045  0.42627921]\n",
      " [ 0.         -0.15191522  0.32728411]\n",
      " [ 0.          0.3269274  -0.15986398]\n",
      " [ 0.          0.67974515 -0.51625023]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #55 | lambda learn rate = 0.001\n",
      "Target = [[2.]\n",
      " [4.]]\n",
      "lambda end of trial = [[ 0.          0.2450204  -0.02785377]\n",
      " [ 0.          0.03199837 -0.06793949]\n",
      " [ 0.         -0.14734572  0.33553043]\n",
      " [ 0.          0.39553925 -0.29057209]\n",
      " [ 0.          0.07920206  0.0638844 ]\n",
      " [ 0.         -0.06789926  0.07566472]\n",
      " [ 0.         -0.34593895  0.41786222]\n",
      " [ 0.         -0.15641316  0.31828823]\n",
      " [ 0.          0.3222945  -0.16912978]\n",
      " [ 0.          0.67505009 -0.52564037]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #56 | lambda learn rate = 0.001\n",
      "Target = [[4.]\n",
      " [5.]]\n",
      "lambda end of trial = [[ 0.          0.25367488 -0.01703568]\n",
      " [ 0.          0.04125511 -0.05636857]\n",
      " [ 0.         -0.13822802  0.34692756]\n",
      " [ 0.          0.40568185 -0.27789384]\n",
      " [ 0.          0.08683617  0.07342704]\n",
      " [ 0.         -0.05904391  0.08673391]\n",
      " [ 0.         -0.33720528  0.42877931]\n",
      " [ 0.         -0.14845627  0.32823435]\n",
      " [ 0.          0.33242509 -0.15646654]\n",
      " [ 0.          0.68412419 -0.51429774]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #57 | lambda learn rate = 0.001\n",
      "Target = [[1.]\n",
      " [4.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda end of trial = [[ 0.          0.25067109 -0.02905083]\n",
      " [ 0.          0.0375914  -0.07102339]\n",
      " [ 0.         -0.14164452  0.33326157]\n",
      " [ 0.          0.40167824 -0.29390826]\n",
      " [ 0.          0.08324716  0.05907097]\n",
      " [ 0.         -0.06270652  0.07208344]\n",
      " [ 0.         -0.34047561  0.41569797]\n",
      " [ 0.         -0.15169352  0.31528536]\n",
      " [ 0.          0.32909031 -0.16980565]\n",
      " [ 0.          0.68074333 -0.52782117]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #58 | lambda learn rate = 0.001\n",
      "Target = [[3.]\n",
      " [2.]]\n",
      "lambda end of trial = [[ 0.          0.2413563  -0.0352607 ]\n",
      " [ 0.          0.02566764 -0.07897257]\n",
      " [ 0.         -0.15242216  0.32607647]\n",
      " [ 0.          0.39116542 -0.30091681]\n",
      " [ 0.          0.07192516  0.05152297]\n",
      " [ 0.         -0.07356696  0.06484315]\n",
      " [ 0.         -0.35106819  0.40863625]\n",
      " [ 0.         -0.16278751  0.30788937]\n",
      " [ 0.          0.31922709 -0.17638114]\n",
      " [ 0.          0.66930209 -0.53544867]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #59 | lambda learn rate = 0.001\n",
      "Target = [[5.]\n",
      " [0.]]\n",
      "lambda end of trial = [[ 0.          0.22710335 -0.0352607 ]\n",
      " [ 0.          0.00855572 -0.07897257]\n",
      " [ 0.         -0.16829407  0.32607647]\n",
      " [ 0.          0.37435839 -0.30091681]\n",
      " [ 0.          0.05500886  0.05152297]\n",
      " [ 0.         -0.09142826  0.06484315]\n",
      " [ 0.         -0.36753481  0.40863625]\n",
      " [ 0.         -0.17928738  0.30788937]\n",
      " [ 0.          0.30385885 -0.17638114]\n",
      " [ 0.          0.65170833 -0.53544867]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #60 | lambda learn rate = 0.001\n",
      "Target = [[7.]\n",
      " [0.]]\n",
      "lambda end of trial = [[ 0.          0.24054478 -0.0352607 ]\n",
      " [ 0.          0.02402595 -0.07897257]\n",
      " [ 0.         -0.15348099  0.32607647]\n",
      " [ 0.          0.38953339 -0.30091681]\n",
      " [ 0.          0.07032032  0.05152297]\n",
      " [ 0.         -0.07406552  0.06484315]\n",
      " [ 0.         -0.35329904  0.40863625]\n",
      " [ 0.         -0.16426998  0.30788937]\n",
      " [ 0.          0.31767242 -0.17638114]\n",
      " [ 0.          0.66891559 -0.53544867]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #61 | lambda learn rate = 0.001\n",
      "Target = [[3.]\n",
      " [5.]]\n",
      "lambda end of trial = [[ 0.          0.2515786  -0.016871  ]\n",
      " [ 0.          0.03499849 -0.060685  ]\n",
      " [ 0.         -0.14300933  0.34352923]\n",
      " [ 0.          0.39957584 -0.2841794 ]\n",
      " [ 0.          0.08046983  0.06843882]\n",
      " [ 0.         -0.06378078  0.08198439]\n",
      " [ 0.         -0.34210245  0.42729725]\n",
      " [ 0.         -0.1536773   0.32554383]\n",
      " [ 0.          0.32937799 -0.15687184]\n",
      " [ 0.          0.68042609 -0.51626449]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #62 | lambda learn rate = 0.001\n",
      "Target = [[0.]\n",
      " [5.]]\n",
      "lambda end of trial = [[ 0.          0.2515786  -0.03175821]\n",
      " [ 0.          0.03499849 -0.07768683]\n",
      " [ 0.         -0.14300933  0.32752707]\n",
      " [ 0.          0.39957584 -0.29743311]\n",
      " [ 0.          0.08046983  0.05099258]\n",
      " [ 0.         -0.06378078  0.065398  ]\n",
      " [ 0.         -0.34210245  0.41326626]\n",
      " [ 0.         -0.1536773   0.31049593]\n",
      " [ 0.          0.32937799 -0.17054963]\n",
      " [ 0.          0.68042609 -0.53094919]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #63 | lambda learn rate = 0.001\n",
      "Target = [[9.]\n",
      " [9.]]\n",
      "lambda end of trial = [[ 0.          0.36788662  0.08454981]\n",
      " [ 0.          0.16769639  0.05501106]\n",
      " [ 0.         -0.01722713  0.45330927]\n",
      " [ 0.          0.5129423  -0.18406664]\n",
      " [ 0.          0.20602685  0.17654959]\n",
      " [ 0.          0.05372366  0.18290244]\n",
      " [ 0.         -0.23622165  0.51914705]\n",
      " [ 0.         -0.0301749   0.43399833]\n",
      " [ 0.          0.45756123 -0.0423664 ]\n",
      " [ 0.          0.80350232 -0.40787297]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #64 | lambda learn rate = 0.001\n",
      "Target = [[7.]\n",
      " [6.]]\n",
      "lambda end of trial = [[ 0.          0.0373287  -0.19878555]\n",
      " [ 0.         -0.1857148  -0.24791281]\n",
      " [ 0.         -0.3466814   0.1709199 ]\n",
      " [ 0.          0.19843764 -0.45364207]\n",
      " [ 0.         -0.12738148 -0.10922897]\n",
      " [ 0.         -0.31466988 -0.13286346]\n",
      " [ 0.         -0.54228054  0.25681086]\n",
      " [ 0.         -0.36712147  0.14518698]\n",
      " [ 0.          0.14298841 -0.31200024]\n",
      " [ 0.          0.50663413 -0.66233142]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #65 | lambda learn rate = 0.001\n",
      "Target = [[1.]\n",
      " [2.]]\n",
      "lambda end of trial = [[ 0.          0.05167759 -0.17008776]\n",
      " [ 0.         -0.17325673 -0.22299667]\n",
      " [ 0.         -0.33260279  0.19907712]\n",
      " [ 0.          0.21088691 -0.42874353]\n",
      " [ 0.         -0.11534034 -0.0851467 ]\n",
      " [ 0.         -0.30178899 -0.10710167]\n",
      " [ 0.         -0.52816985  0.28503225]\n",
      " [ 0.         -0.35588264  0.16766465]\n",
      " [ 0.          0.15584875 -0.28627956]\n",
      " [ 0.          0.52007729 -0.63544509]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #66 | lambda learn rate = 0.001\n",
      "Target = [[4.]\n",
      " [0.]]\n",
      "lambda end of trial = [[ 0.          0.13070587 -0.17008776]\n",
      " [ 0.         -0.09812824 -0.22299667]\n",
      " [ 0.         -0.25403104  0.19907712]\n",
      " [ 0.          0.28589358 -0.42874353]\n",
      " [ 0.         -0.03286703 -0.0851467 ]\n",
      " [ 0.         -0.22259947 -0.10710167]\n",
      " [ 0.         -0.45677066  0.28503225]\n",
      " [ 0.         -0.27101704  0.16766465]\n",
      " [ 0.          0.23076556 -0.28627956]\n",
      " [ 0.          0.5927139  -0.63544509]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #67 | lambda learn rate = 0.001\n",
      "Target = [[3.]\n",
      " [5.]]\n",
      "lambda end of trial = [[ 0.          0.23195161 -0.00134486]\n",
      " [ 0.          0.01563819 -0.03338596]\n",
      " [ 0.         -0.14205177  0.38570924]\n",
      " [ 0.          0.39954849 -0.23931869]\n",
      " [ 0.          0.06493011  0.07784853]\n",
      " [ 0.         -0.10784175  0.0841612 ]\n",
      " [ 0.         -0.34952837  0.4637694 ]\n",
      " [ 0.         -0.16000268  0.35268859]\n",
      " [ 0.          0.33264895 -0.1164739 ]\n",
      " [ 0.          0.70386937 -0.45018597]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #68 | lambda learn rate = 0.001\n",
      "Target = [[6.]\n",
      " [3.]]\n",
      "lambda end of trial = [[ 0.          0.22335002 -0.00564566]\n",
      " [ 0.          0.00659584 -0.03790714]\n",
      " [ 0.         -0.15222301  0.38062362]\n",
      " [ 0.          0.39154771 -0.24331908]\n",
      " [ 0.          0.05475203  0.07275949]\n",
      " [ 0.         -0.1172559   0.07945412]\n",
      " [ 0.         -0.35775686  0.45965515]\n",
      " [ 0.         -0.16777829  0.34880078]\n",
      " [ 0.          0.32440914 -0.12059381]\n",
      " [ 0.          0.69555875 -0.45434128]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #69 | lambda learn rate = 0.001\n",
      "Target = [[9.]\n",
      " [9.]]\n",
      "lambda end of trial = [[ 0.          0.29176498  0.06276931]\n",
      " [ 0.          0.07894823  0.03444525]\n",
      " [ 0.         -0.08327157  0.44957506]\n",
      " [ 0.          0.45631112 -0.17855567]\n",
      " [ 0.          0.11730567  0.13531313]\n",
      " [ 0.         -0.05376355  0.14294648]\n",
      " [ 0.         -0.29301967  0.52439234]\n",
      " [ 0.         -0.09925002  0.41732905]\n",
      " [ 0.          0.39216635 -0.05283659]\n",
      " [ 0.          0.76224682 -0.38765322]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #70 | lambda learn rate = 0.001\n",
      "Target = [[8.]\n",
      " [6.]]\n",
      "lambda end of trial = [[ 0.          0.11589076 -0.06913636]\n",
      " [ 0.         -0.14204389 -0.13129884]\n",
      " [ 0.         -0.25796368  0.31855598]\n",
      " [ 0.          0.26733946 -0.32028441]\n",
      " [ 0.         -0.08080995 -0.01327358]\n",
      " [ 0.         -0.24305765  0.0009759 ]\n",
      " [ 0.         -0.48669695  0.37913438]\n",
      " [ 0.         -0.25591692  0.29982887]\n",
      " [ 0.          0.19528155 -0.2005002 ]\n",
      " [ 0.          0.5443799  -0.5510534 ]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #71 | lambda learn rate = 0.001\n",
      "Target = [[8.]\n",
      " [5.]]\n",
      "lambda end of trial = [[ 0.          0.52665493  0.18759125]\n",
      " [ 0.          0.27929804  0.13203987]\n",
      " [ 0.          0.09002676  0.53605   ]\n",
      " [ 0.          0.60967598 -0.10632409]\n",
      " [ 0.          0.30173498  0.225817  ]\n",
      " [ 0.          0.17267987  0.26081185]\n",
      " [ 0.         -0.10026349  0.6206553 ]\n",
      " [ 0.          0.14870338  0.55271656]\n",
      " [ 0.          0.59690529  0.05051464]\n",
      " [ 0.          0.94493415 -0.300707  ]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #72 | lambda learn rate = 0.001\n",
      "Target = [[2.]\n",
      " [6.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda end of trial = [[ 0.          0.41538437 -0.14622045]\n",
      " [ 0.          0.16499588 -0.2108666 ]\n",
      " [ 0.         -0.02252066  0.19840774]\n",
      " [ 0.          0.49894972 -0.43850287]\n",
      " [ 0.          0.18421522 -0.1267423 ]\n",
      " [ 0.          0.05975756 -0.07795507]\n",
      " [ 0.         -0.2162309   0.27275305]\n",
      " [ 0.          0.04115231  0.23006337]\n",
      " [ 0.          0.49417571 -0.2576741 ]\n",
      " [ 0.          0.83742512 -0.62323408]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #73 | lambda learn rate = 0.001\n",
      "Target = [[8.]\n",
      " [9.]]\n",
      "lambda end of trial = [[ 0.          0.5241458  -0.02386383]\n",
      " [ 0.          0.27425648 -0.08794844]\n",
      " [ 0.          0.10834428  0.3456308 ]\n",
      " [ 0.          0.60275158 -0.32172578]\n",
      " [ 0.          0.29877634  0.00213896]\n",
      " [ 0.          0.17112639  0.04733486]\n",
      " [ 0.         -0.11713033  0.38424119]\n",
      " [ 0.          0.15426104  0.35731069]\n",
      " [ 0.          0.61200555 -0.12511554]\n",
      " [ 0.          0.94761755 -0.4992676 ]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #74 | lambda learn rate = 0.001\n",
      "Target = [[0.]\n",
      " [6.]]\n",
      "lambda end of trial = [[ 0.          0.5241458  -0.01062092]\n",
      " [ 0.          0.27425648 -0.07804999]\n",
      " [ 0.          0.10834428  0.35644813]\n",
      " [ 0.          0.60275158 -0.30978856]\n",
      " [ 0.          0.29877634  0.01257757]\n",
      " [ 0.          0.17112639  0.057561  ]\n",
      " [ 0.         -0.11713033  0.39633475]\n",
      " [ 0.          0.15426104  0.36774826]\n",
      " [ 0.          0.61200555 -0.11406609]\n",
      " [ 0.          0.94761755 -0.48909126]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #75 | lambda learn rate = 0.001\n",
      "Target = [[3.]\n",
      " [9.]]\n",
      "lambda end of trial = [[ 0.          0.46483222 -0.18856168]\n",
      " [ 0.          0.21315849 -0.26134396]\n",
      " [ 0.          0.05136955  0.18552394]\n",
      " [ 0.          0.54865882 -0.47206684]\n",
      " [ 0.          0.23584853 -0.17620585]\n",
      " [ 0.          0.11647185 -0.10640265]\n",
      " [ 0.         -0.17347614  0.22729733]\n",
      " [ 0.          0.10023402  0.2056672 ]\n",
      " [ 0.          0.55323472 -0.29037858]\n",
      " [ 0.          0.89187377 -0.6563226 ]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #76 | lambda learn rate = 0.001\n",
      "Target = [[1.]\n",
      " [6.]]\n",
      "lambda end of trial = [[ 0.          0.49218478 -0.02444633]\n",
      " [ 0.          0.2423951  -0.08592427]\n",
      " [ 0.          0.08135217  0.36541968]\n",
      " [ 0.          0.57725902 -0.30046564]\n",
      " [ 0.          0.26635664  0.00684283]\n",
      " [ 0.          0.1460345   0.07097329]\n",
      " [ 0.         -0.14634728  0.39007049]\n",
      " [ 0.          0.13197106  0.39608943]\n",
      " [ 0.          0.58031177 -0.12791626]\n",
      " [ 0.          0.92286917 -0.47035019]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #77 | lambda learn rate = 0.001\n",
      "Target = [[8.]\n",
      " [1.]]\n",
      "lambda end of trial = [[ 0.          0.007807   -0.08499355]\n",
      " [ 0.         -0.26201021 -0.14897493]\n",
      " [ 0.         -0.41048432  0.30394012]\n",
      " [ 0.          0.11298105 -0.35850038]\n",
      " [ 0.         -0.24039442 -0.05650105]\n",
      " [ 0.         -0.33915331  0.01032481]\n",
      " [ 0.         -0.62876748  0.32976796]\n",
      " [ 0.         -0.36363489  0.33413869]\n",
      " [ 0.          0.0582424  -0.19317493]\n",
      " [ 0.          0.4598182  -0.52823157]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #78 | lambda learn rate = 0.001\n",
      "Target = [[8.]\n",
      " [0.]]\n",
      "lambda end of trial = [[ 0.          0.61327842 -0.08499355]\n",
      " [ 0.          0.2743229  -0.14897493]\n",
      " [ 0.          0.15834866  0.30394012]\n",
      " [ 0.          0.67953004 -0.35850038]\n",
      " [ 0.          0.28569822 -0.05650105]\n",
      " [ 0.          0.20142965  0.01032481]\n",
      " [ 0.         -0.12122799  0.32976796]\n",
      " [ 0.          0.16311486  0.33413869]\n",
      " [ 0.          0.54976216 -0.19317493]\n",
      " [ 0.          1.0057545  -0.52823157]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #79 | lambda learn rate = 0.001\n",
      "Target = [[7.]\n",
      " [8.]]\n",
      "lambda end of trial = [[ 0.00000000e+00  3.83789193e-01 -3.47266949e-01]\n",
      " [ 0.00000000e+00 -3.71641503e-02 -5.04960139e-01]\n",
      " [ 0.00000000e+00 -1.48213835e-01 -4.64170230e-02]\n",
      " [ 0.00000000e+00  4.12511447e-01 -6.63664490e-01]\n",
      " [ 0.00000000e+00  7.46746436e-04 -3.82159878e-01]\n",
      " [ 0.00000000e+00 -6.75814568e-02 -2.97116457e-01]\n",
      " [ 0.00000000e+00 -3.88228956e-01  2.46239973e-02]\n",
      " [ 0.00000000e+00 -1.00425146e-01  3.29501152e-02]\n",
      " [ 0.00000000e+00  2.92316890e-01 -4.87398098e-01]\n",
      " [ 0.00000000e+00  7.53639063e-01 -8.16363489e-01]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #80 | lambda learn rate = 0.001\n",
      "Target = [[3.]\n",
      " [8.]]\n",
      "lambda end of trial = [[ 0.          0.67738737  0.43566153]\n",
      " [ 0.          0.28425854  0.35216704]\n",
      " [ 0.          0.15424746  0.76014644]\n",
      " [ 0.          0.6954876   0.09093859]\n",
      " [ 0.          0.30771283  0.43641633]\n",
      " [ 0.          0.23778528  0.51719483]\n",
      " [ 0.         -0.09917303  0.7954398 ]\n",
      " [ 0.          0.20279977  0.8415499 ]\n",
      " [ 0.          0.61117393  0.36288736]\n",
      " [ 0.          1.06039716  0.0016581 ]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #81 | lambda learn rate = 0.001\n",
      "Target = [[0.]\n",
      " [8.]]\n",
      "lambda end of trial = [[ 0.          0.67738737 -0.47127721]\n",
      " [ 0.          0.28425854 -0.56357667]\n",
      " [ 0.          0.15424746 -0.16292733]\n",
      " [ 0.          0.6954876  -0.80993954]\n",
      " [ 0.          0.30771283 -0.3933839 ]\n",
      " [ 0.          0.23778528 -0.45813993]\n",
      " [ 0.         -0.09917303 -0.19740428]\n",
      " [ 0.          0.20279977 -0.12172486]\n",
      " [ 0.          0.61117393 -0.51199705]\n",
      " [ 0.          1.06039716 -0.90928093]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #82 | lambda learn rate = 0.001\n",
      "Target = [[0.]\n",
      " [8.]]\n",
      "lambda end of trial = [[ 0.          0.67738737  0.47153972]\n",
      " [ 0.          0.28425854  0.50398407]\n",
      " [ 0.          0.15424746  0.91106251]\n",
      " [ 0.          0.6954876   0.26114253]\n",
      " [ 0.          0.30771283  0.61071451]\n",
      " [ 0.          0.23778528  0.51272204]\n",
      " [ 0.         -0.09917303  0.74048682]\n",
      " [ 0.          0.20279977  1.01698116]\n",
      " [ 0.          0.61117393  0.60508696]\n",
      " [ 0.          1.06039716  0.09041893]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #83 | lambda learn rate = 0.001\n",
      "Target = [[2.]\n",
      " [1.]]\n",
      "lambda end of trial = [[ 0.          0.59092794  0.42831001]\n",
      " [ 0.          0.20707653  0.46539306]\n",
      " [ 0.          0.06997513  0.86892635]\n",
      " [ 0.          0.61368198  0.22023972]\n",
      " [ 0.          0.21823026  0.56597323]\n",
      " [ 0.          0.15430651  0.47098265]\n",
      " [ 0.         -0.18559044  0.69727812]\n",
      " [ 0.          0.11849789  0.97483022]\n",
      " [ 0.          0.53423211  0.56661605]\n",
      " [ 0.          0.98107341  0.05075705]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #84 | lambda learn rate = 0.001\n",
      "Target = [[6.]\n",
      " [4.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda end of trial = [[ 0.          0.04988898  0.06761737]\n",
      " [ 0.         -0.48148171  0.00635423]\n",
      " [ 0.         -0.59867199  0.4231616 ]\n",
      " [ 0.         -0.02701595 -0.20689223]\n",
      " [ 0.         -0.41865931  0.14138019]\n",
      " [ 0.         -0.51985271  0.02154317]\n",
      " [ 0.         -0.8996089   0.22126581]\n",
      " [ 0.         -0.59506616  0.49912085]\n",
      " [ 0.         -0.16043906  0.10350194]\n",
      " [ 0.          0.34831055 -0.37108486]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #85 | lambda learn rate = 0.001\n",
      "Target = [[5.]\n",
      " [3.]]\n",
      "lambda end of trial = [[ 0.          0.35359884  0.24984328]\n",
      " [ 0.         -0.15516089  0.20214673]\n",
      " [ 0.         -0.28679738  0.61028636]\n",
      " [ 0.          0.29734309 -0.01227681]\n",
      " [ 0.         -0.08128796  0.34380299]\n",
      " [ 0.         -0.19152669  0.21853879]\n",
      " [ 0.         -0.58818626  0.40811939]\n",
      " [ 0.         -0.27906484  0.68872164]\n",
      " [ 0.          0.14536496  0.28698435]\n",
      " [ 0.          0.6593009  -0.18449065]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #86 | lambda learn rate = 0.001\n",
      "Target = [[1.]\n",
      " [0.]]\n",
      "lambda end of trial = [[ 0.          0.35024421  0.24984328]\n",
      " [ 0.         -0.15883798  0.20214673]\n",
      " [ 0.         -0.29038513  0.61028636]\n",
      " [ 0.          0.29395487 -0.01227681]\n",
      " [ 0.         -0.08473813  0.34380299]\n",
      " [ 0.         -0.19510119  0.21853879]\n",
      " [ 0.         -0.59148937  0.40811939]\n",
      " [ 0.         -0.282596    0.68872164]\n",
      " [ 0.          0.14200645  0.28698435]\n",
      " [ 0.          0.65605395 -0.18449065]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #87 | lambda learn rate = 0.001\n",
      "Target = [[3.]\n",
      " [1.]]\n",
      "lambda end of trial = [[ 0.          0.34920512  0.24949692]\n",
      " [ 0.         -0.1605893   0.20156295]\n",
      " [ 0.         -0.29182275  0.60980715]\n",
      " [ 0.          0.29252474 -0.01275351]\n",
      " [ 0.         -0.08649589  0.34321707]\n",
      " [ 0.         -0.19665534  0.21802074]\n",
      " [ 0.         -0.59208996  0.4079192 ]\n",
      " [ 0.         -0.28355586  0.68840169]\n",
      " [ 0.          0.14122516  0.28672392]\n",
      " [ 0.          0.65416656 -0.18511978]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #88 | lambda learn rate = 0.001\n",
      "Target = [[8.]\n",
      " [0.]]\n",
      "lambda end of trial = [[ 0.          0.58478368  0.24949692]\n",
      " [ 0.          0.13503198  0.20156295]\n",
      " [ 0.         -0.0283393   0.60980715]\n",
      " [ 0.          0.54789446 -0.01275351]\n",
      " [ 0.          0.16574083  0.34321707]\n",
      " [ 0.          0.09605437  0.21802074]\n",
      " [ 0.         -0.33075196  0.4079192 ]\n",
      " [ 0.         -0.03039028  0.68840169]\n",
      " [ 0.          0.40475593  0.28672392]\n",
      " [ 0.          0.91529675 -0.18511978]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #89 | lambda learn rate = 0.001\n",
      "Target = [[6.]\n",
      " [6.]]\n",
      "lambda end of trial = [[ 0.          0.16324753 -0.17203923]\n",
      " [ 0.         -0.36381912 -0.29728814]\n",
      " [ 0.         -0.48344521  0.15470125]\n",
      " [ 0.          0.11644005 -0.44420792]\n",
      " [ 0.         -0.28371851 -0.10624227]\n",
      " [ 0.         -0.32789779 -0.20593142]\n",
      " [ 0.         -0.7873038  -0.04863264]\n",
      " [ 0.         -0.50373747  0.2150545 ]\n",
      " [ 0.         -0.04821963 -0.16625164]\n",
      " [ 0.          0.47262504 -0.62779149]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #90 | lambda learn rate = 0.001\n",
      "Target = [[5.]\n",
      " [0.]]\n",
      "lambda end of trial = [[ 0.          0.40703952 -0.17203923]\n",
      " [ 0.         -0.12082075 -0.29728814]\n",
      " [ 0.         -0.23982309  0.15470125]\n",
      " [ 0.          0.36459303 -0.44420792]\n",
      " [ 0.         -0.05666904 -0.10624227]\n",
      " [ 0.         -0.07576701 -0.20593142]\n",
      " [ 0.         -0.53251633 -0.04863264]\n",
      " [ 0.         -0.24206417  0.2150545 ]\n",
      " [ 0.          0.17761881 -0.16625164]\n",
      " [ 0.          0.70768784 -0.62779149]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #91 | lambda learn rate = 0.001\n",
      "Target = [[2.]\n",
      " [8.]]\n",
      "lambda end of trial = [[ 0.          0.52026478  0.28086182]\n",
      " [ 0.         -0.02045318  0.10418216]\n",
      " [ 0.         -0.12777456  0.60289535]\n",
      " [ 0.          0.46861536 -0.02811859]\n",
      " [ 0.          0.0517169   0.32730148]\n",
      " [ 0.          0.03498419  0.23707335]\n",
      " [ 0.         -0.41258686  0.43108524]\n",
      " [ 0.         -0.13802224  0.63122222]\n",
      " [ 0.          0.29090788  0.28690464]\n",
      " [ 0.          0.83098944 -0.13458506]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #92 | lambda learn rate = 0.001\n",
      "Target = [[1.]\n",
      " [5.]]\n",
      "lambda end of trial = [[ 0.          0.48318287  0.09545226]\n",
      " [ 0.         -0.06566601 -0.121882  ]\n",
      " [ 0.         -0.17231935  0.38017144]\n",
      " [ 0.          0.42774546 -0.23246807]\n",
      " [ 0.          0.01154582  0.12644609]\n",
      " [ 0.         -0.0068375   0.02796493]\n",
      " [ 0.         -0.45110194  0.23850981]\n",
      " [ 0.         -0.18089765  0.41684519]\n",
      " [ 0.          0.25135239  0.08912717]\n",
      " [ 0.          0.78900143 -0.34452511]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #93 | lambda learn rate = 0.001\n",
      "Target = [[9.]\n",
      " [3.]]\n",
      "lambda end of trial = [[ 0.          0.50592817  0.10303402]\n",
      " [ 0.         -0.0436053  -0.11452843]\n",
      " [ 0.         -0.15129353  0.38718005]\n",
      " [ 0.          0.44787792 -0.22575725]\n",
      " [ 0.          0.03258067  0.1334577 ]\n",
      " [ 0.          0.01181513  0.03418247]\n",
      " [ 0.         -0.42667382  0.24665252]\n",
      " [ 0.         -0.15965568  0.42392585]\n",
      " [ 0.          0.27004317  0.09535743]\n",
      " [ 0.          0.80741432 -0.33838749]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #94 | lambda learn rate = 0.001\n",
      "Target = [[9.]\n",
      " [2.]]\n",
      "lambda end of trial = [[ 0.          0.47107265  0.09528835]\n",
      " [ 0.         -0.08556144 -0.12385201]\n",
      " [ 0.         -0.18737088  0.37916286]\n",
      " [ 0.          0.41116925 -0.23391473]\n",
      " [ 0.         -0.0072452   0.12460751]\n",
      " [ 0.         -0.02742151  0.02546322]\n",
      " [ 0.         -0.46298197  0.23858404]\n",
      " [ 0.         -0.19881367  0.41522407]\n",
      " [ 0.          0.23407252  0.08736395]\n",
      " [ 0.          0.76477362 -0.3478632 ]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #95 | lambda learn rate = 0.001\n",
      "Target = [[5.]\n",
      " [7.]]\n",
      "lambda end of trial = [[ 0.          0.47484887  0.10057506]\n",
      " [ 0.         -0.08351011 -0.12098014]\n",
      " [ 0.         -0.18350532  0.38457464]\n",
      " [ 0.          0.41434069 -0.22947472]\n",
      " [ 0.         -0.00484231  0.12797156]\n",
      " [ 0.         -0.02364603  0.03074888]\n",
      " [ 0.         -0.45872268  0.24454704]\n",
      " [ 0.         -0.19651652  0.41844009]\n",
      " [ 0.          0.2380246   0.09289687]\n",
      " [ 0.          0.76767022 -0.34380795]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #96 | lambda learn rate = 0.001\n",
      "Target = [[9.]\n",
      " [3.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda end of trial = [[ 0.          0.53370291  0.12019307]\n",
      " [ 0.         -0.02509965 -0.10150999]\n",
      " [ 0.         -0.12339843  0.40461027]\n",
      " [ 0.          0.47276703 -0.20999927]\n",
      " [ 0.          0.0548365   0.14786449]\n",
      " [ 0.          0.03621044  0.05070104]\n",
      " [ 0.         -0.39325251  0.26637043]\n",
      " [ 0.         -0.13533001  0.43883559]\n",
      " [ 0.          0.2952353   0.11196711]\n",
      " [ 0.          0.82524903 -0.32461502]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #97 | lambda learn rate = 0.001\n",
      "Target = [[5.]\n",
      " [7.]]\n",
      "lambda end of trial = [[ 0.          0.45177641  0.00549598]\n",
      " [ 0.         -0.10583826 -0.21454404]\n",
      " [ 0.         -0.2099594   0.2834249 ]\n",
      " [ 0.          0.38866951 -0.3277358 ]\n",
      " [ 0.         -0.02659689  0.03385775]\n",
      " [ 0.         -0.04261916 -0.05966041]\n",
      " [ 0.         -0.46852345  0.16099112]\n",
      " [ 0.         -0.22260329  0.31665299]\n",
      " [ 0.          0.22041379  0.00721699]\n",
      " [ 0.          0.74364483 -0.43886089]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #98 | lambda learn rate = 0.001\n",
      "Target = [[6.]\n",
      " [5.]]\n",
      "lambda end of trial = [[ 0.          0.58897481  0.11982798]\n",
      " [ 0.          0.0439014  -0.08976099]\n",
      " [ 0.         -0.07373275  0.39694711]\n",
      " [ 0.          0.51709856 -0.22071159]\n",
      " [ 0.          0.1102308   0.14788082]\n",
      " [ 0.          0.08078881  0.04317957]\n",
      " [ 0.         -0.34796204  0.26145896]\n",
      " [ 0.         -0.08599614  0.43049229]\n",
      " [ 0.          0.36284751  0.12591176]\n",
      " [ 0.          0.8719298  -0.33195675]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "+++++++++++++++++++++++++++++++++++\n",
      "Session #1\n",
      "target at trial 0 = [[1.]\n",
      " [1.]]\n",
      "K MATX INIT= [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "A VECT INIT = [-0. -0.]\n",
      "lambda\n",
      "[[ 0.          0.17569819 -0.1168215 ]\n",
      " [ 0.          0.17094785  0.05671689]\n",
      " [ 0.         -0.13660684  0.34736166]\n",
      " [ 0.          0.39038693 -0.30734903]\n",
      " [ 0.          0.07484879  0.16279938]\n",
      " [ 0.          0.06604893  0.12726184]\n",
      " [ 0.         -0.35233706  0.44135871]\n",
      " [ 0.         -0.15102956  0.35740288]\n",
      " [ 0.          0.23767146 -0.14068682]\n",
      " [ 0.          0.63275023 -0.52240076]]\n",
      "a\n",
      "[-0. -0.]\n",
      "K\n",
      "[[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #0 | lambda learn rate = 0.001\n",
      "Target = [[1.]\n",
      " [1.]]\n",
      "lambda end of trial = [[ 0.          0.1674044  -0.12511529]\n",
      " [ 0.          0.16383687  0.04960591]\n",
      " [ 0.         -0.14490158  0.33906693]\n",
      " [ 0.          0.38257299 -0.31516298]\n",
      " [ 0.          0.06675136  0.15470195]\n",
      " [ 0.          0.05819919  0.11941209]\n",
      " [ 0.         -0.36017036  0.43352542]\n",
      " [ 0.         -0.15861259  0.34981986]\n",
      " [ 0.          0.22921413 -0.14914415]\n",
      " [ 0.          0.62475096 -0.53040003]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #1 | lambda learn rate = 0.001\n",
      "Target = [[8.]\n",
      " [1.]]\n",
      "lambda end of trial = [[ 0.          0.12114208 -0.13089808]\n",
      " [ 0.          0.11632698  0.04366717]\n",
      " [ 0.         -0.19220009  0.33315462]\n",
      " [ 0.          0.33366389 -0.32127661]\n",
      " [ 0.          0.02068892  0.14894415]\n",
      " [ 0.          0.01389036  0.11387349]\n",
      " [ 0.         -0.40724313  0.42764132]\n",
      " [ 0.         -0.20524134  0.34399126]\n",
      " [ 0.          0.18778935 -0.15432225]\n",
      " [ 0.          0.58003738 -0.53598923]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #2 | lambda learn rate = 0.001\n",
      "Target = [[1.]\n",
      " [7.]]\n",
      "lambda end of trial = [[ 0.          0.11775914 -0.15457862]\n",
      " [ 0.          0.11290961  0.0197456 ]\n",
      " [ 0.         -0.19595888  0.30684309]\n",
      " [ 0.          0.33006242 -0.34648692]\n",
      " [ 0.          0.01715947  0.12423796]\n",
      " [ 0.          0.01020006  0.08804135]\n",
      " [ 0.         -0.41011663  0.40752677]\n",
      " [ 0.         -0.20894869  0.31803981]\n",
      " [ 0.          0.18411111 -0.18006995]\n",
      " [ 0.          0.57661755 -0.55992803]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #3 | lambda learn rate = 0.001\n",
      "Target = [[6.]\n",
      " [5.]]\n",
      "lambda end of trial = [[ 0.          0.16811109 -0.11261867]\n",
      " [ 0.          0.16739598  0.0651509 ]\n",
      " [ 0.         -0.13996794  0.35350221]\n",
      " [ 0.          0.37897347 -0.30572771]\n",
      " [ 0.          0.0729977   0.17076982]\n",
      " [ 0.          0.06107274  0.13043526]\n",
      " [ 0.         -0.36093715  0.44850967]\n",
      " [ 0.         -0.15543437  0.36263508]\n",
      " [ 0.          0.23502823 -0.13763902]\n",
      " [ 0.          0.63480317 -0.51144001]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #4 | lambda learn rate = 0.001\n",
      "Target = [[1.]\n",
      " [0.]]\n",
      "lambda end of trial = [[ 0.          0.1585139  -0.11261867]\n",
      " [ 0.          0.15729717  0.0651509 ]\n",
      " [ 0.         -0.14973735  0.35350221]\n",
      " [ 0.          0.37080195 -0.30572771]\n",
      " [ 0.          0.0632081   0.17076982]\n",
      " [ 0.          0.05058145  0.13043526]\n",
      " [ 0.         -0.37013603  0.44850967]\n",
      " [ 0.         -0.16507533  0.36263508]\n",
      " [ 0.          0.22672537 -0.13763902]\n",
      " [ 0.          0.62508486 -0.51144001]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #5 | lambda learn rate = 0.001\n",
      "Target = [[6.]\n",
      " [2.]]\n",
      "lambda end of trial = [[ 0.          0.12090102 -0.12515629]\n",
      " [ 0.          0.11614359  0.05143304]\n",
      " [ 0.         -0.19283097  0.33913767]\n",
      " [ 0.          0.33250223 -0.31849428]\n",
      " [ 0.          0.02256738  0.15722291]\n",
      " [ 0.          0.01250276  0.11774236]\n",
      " [ 0.         -0.40585801  0.43660234]\n",
      " [ 0.         -0.2038843   0.34969876]\n",
      " [ 0.          0.19206942 -0.149191  ]\n",
      " [ 0.          0.58672682 -0.52422603]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #6 | lambda learn rate = 0.001\n",
      "Target = [[0.]\n",
      " [1.]]\n",
      "lambda end of trial = [[ 0.          0.12090102 -0.13283147]\n",
      " [ 0.          0.11614359  0.04219778]\n",
      " [ 0.         -0.19283097  0.3298409 ]\n",
      " [ 0.          0.33250223 -0.32712365]\n",
      " [ 0.          0.02256738  0.1480838 ]\n",
      " [ 0.          0.01250276  0.10912841]\n",
      " [ 0.         -0.40585801  0.42770081]\n",
      " [ 0.         -0.2038843   0.34129892]\n",
      " [ 0.          0.19206942 -0.15737773]\n",
      " [ 0.          0.58672682 -0.53314069]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #7 | lambda learn rate = 0.001\n",
      "Target = [[7.]\n",
      " [0.]]\n",
      "lambda end of trial = [[ 0.          0.14105132 -0.13283147]\n",
      " [ 0.          0.13820969  0.04219778]\n",
      " [ 0.         -0.1728483   0.3298409 ]\n",
      " [ 0.          0.35554135 -0.32712365]\n",
      " [ 0.          0.04638295  0.1480838 ]\n",
      " [ 0.          0.03364483  0.10912841]\n",
      " [ 0.         -0.38071041  0.42770081]\n",
      " [ 0.         -0.17864953  0.34129892]\n",
      " [ 0.          0.21830639 -0.15737773]\n",
      " [ 0.          0.60856804 -0.53314069]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #8 | lambda learn rate = 0.001\n",
      "Target = [[9.]\n",
      " [2.]]\n",
      "lambda end of trial = [[ 0.          0.15256019 -0.13027394]\n",
      " [ 0.          0.14746933  0.04425548]\n",
      " [ 0.         -0.16189331  0.33227534]\n",
      " [ 0.          0.36620358 -0.32475427]\n",
      " [ 0.          0.05749732  0.15055366]\n",
      " [ 0.          0.04479903  0.11160712]\n",
      " [ 0.         -0.36982309  0.43012022]\n",
      " [ 0.         -0.16726134  0.34382963]\n",
      " [ 0.          0.22996885 -0.15478607]\n",
      " [ 0.          0.61989449 -0.53062369]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #9 | lambda learn rate = 0.001\n",
      "Target = [[9.]\n",
      " [2.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda end of trial = [[ 0.          0.13593574 -0.13396826]\n",
      " [ 0.          0.12898356  0.04014753]\n",
      " [ 0.         -0.18022582  0.32820145]\n",
      " [ 0.          0.34920488 -0.32853176]\n",
      " [ 0.          0.03815097  0.14625447]\n",
      " [ 0.          0.02728359  0.1077148 ]\n",
      " [ 0.         -0.38526754  0.42668811]\n",
      " [ 0.         -0.18524868  0.33983244]\n",
      " [ 0.          0.21405353 -0.15832281]\n",
      " [ 0.          0.60368074 -0.53422675]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #10 | lambda learn rate = 0.001\n",
      "Target = [[6.]\n",
      " [9.]]\n",
      "lambda end of trial = [[ 0.          0.15805856 -0.10078404]\n",
      " [ 0.          0.1502878   0.07210389]\n",
      " [ 0.         -0.15946145  0.35934801]\n",
      " [ 0.          0.37016441 -0.29709246]\n",
      " [ 0.          0.05949384  0.17826879]\n",
      " [ 0.          0.04785632  0.1385739 ]\n",
      " [ 0.         -0.36204407  0.46152332]\n",
      " [ 0.         -0.16227607  0.37429135]\n",
      " [ 0.          0.23552978 -0.12610844]\n",
      " [ 0.          0.62634204 -0.50023481]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #11 | lambda learn rate = 0.001\n",
      "Target = [[9.]\n",
      " [9.]]\n",
      "lambda end of trial = [[ 0.          0.08243889 -0.1764037 ]\n",
      " [ 0.          0.0665343  -0.01164961]\n",
      " [ 0.         -0.2330786   0.28573085]\n",
      " [ 0.          0.29152896 -0.37572791]\n",
      " [ 0.         -0.01441962  0.10435533]\n",
      " [ 0.         -0.03675211  0.05396546]\n",
      " [ 0.         -0.44003839  0.38352901]\n",
      " [ 0.         -0.24617274  0.29039468]\n",
      " [ 0.          0.15025265 -0.21138557]\n",
      " [ 0.          0.55152144 -0.57505541]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #12 | lambda learn rate = 0.001\n",
      "Target = [[5.]\n",
      " [0.]]\n",
      "lambda end of trial = [[ 0.          0.11591848 -0.1764037 ]\n",
      " [ 0.          0.10099812 -0.01164961]\n",
      " [ 0.         -0.19656389  0.28573085]\n",
      " [ 0.          0.32454982 -0.37572791]\n",
      " [ 0.          0.01809795  0.10435533]\n",
      " [ 0.         -0.00431818  0.05396546]\n",
      " [ 0.         -0.4062081   0.38352901]\n",
      " [ 0.         -0.21273832  0.29039468]\n",
      " [ 0.          0.18549498 -0.21138557]\n",
      " [ 0.          0.58773444 -0.57505541]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #13 | lambda learn rate = 0.001\n",
      "Target = [[4.]\n",
      " [9.]]\n",
      "lambda end of trial = [[ 0.          0.18976063 -0.01025886]\n",
      " [ 0.          0.1722568   0.14868243]\n",
      " [ 0.         -0.13121956  0.43275561]\n",
      " [ 0.          0.39244335 -0.22296747]\n",
      " [ 0.          0.08587509  0.2568539 ]\n",
      " [ 0.          0.06690347  0.21421417]\n",
      " [ 0.         -0.33323017  0.54772935]\n",
      " [ 0.         -0.14147355  0.45074041]\n",
      " [ 0.          0.25877077 -0.04651504]\n",
      " [ 0.          0.66088507 -0.4104665 ]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #14 | lambda learn rate = 0.001\n",
      "Target = [[3.]\n",
      " [0.]]\n",
      "lambda end of trial = [[ 0.          0.1638083  -0.01025886]\n",
      " [ 0.          0.14388376  0.14868243]\n",
      " [ 0.         -0.16224428  0.43275561]\n",
      " [ 0.          0.3642795  -0.22296747]\n",
      " [ 0.          0.05754703  0.2568539 ]\n",
      " [ 0.          0.04038844  0.21421417]\n",
      " [ 0.         -0.3632159   0.54772935]\n",
      " [ 0.         -0.16862915  0.45074041]\n",
      " [ 0.          0.22873285 -0.04651504]\n",
      " [ 0.          0.63267859 -0.4104665 ]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #15 | lambda learn rate = 0.001\n",
      "Target = [[9.]\n",
      " [4.]]\n",
      "lambda end of trial = [[ 0.          0.03273178 -0.06851509]\n",
      " [ 0.          0.00762399  0.08812254]\n",
      " [ 0.         -0.30837772  0.36780741]\n",
      " [ 0.          0.23216452 -0.28168524]\n",
      " [ 0.         -0.08459263  0.19368072]\n",
      " [ 0.         -0.10903945  0.14780177]\n",
      " [ 0.         -0.51157437  0.48179226]\n",
      " [ 0.         -0.3080711   0.38876622]\n",
      " [ 0.          0.08185036 -0.11179615]\n",
      " [ 0.          0.50121514 -0.4688947 ]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #16 | lambda learn rate = 0.001\n",
      "Target = [[4.]\n",
      " [5.]]\n",
      "lambda end of trial = [[ 0.          0.0612854  -0.03282307]\n",
      " [ 0.          0.03681367  0.12460963]\n",
      " [ 0.         -0.28080593  0.40227215]\n",
      " [ 0.          0.2622252  -0.24410939]\n",
      " [ 0.         -0.05531373  0.23027934]\n",
      " [ 0.         -0.08149054  0.18223791]\n",
      " [ 0.         -0.48263843  0.51796218]\n",
      " [ 0.         -0.28205296  0.42128889]\n",
      " [ 0.          0.10964795 -0.07704916]\n",
      " [ 0.          0.52936086 -0.43371256]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #17 | lambda learn rate = 0.001\n",
      "Target = [[9.]\n",
      " [6.]]\n",
      "lambda end of trial = [[ 0.          0.20421094  0.06246062]\n",
      " [ 0.          0.18254055  0.22176088]\n",
      " [ 0.         -0.13892242  0.49686116]\n",
      " [ 0.          0.40251773 -0.15058104]\n",
      " [ 0.          0.11156811  0.3415339 ]\n",
      " [ 0.          0.07937773  0.28948342]\n",
      " [ 0.         -0.34060083  0.61265392]\n",
      " [ 0.         -0.12368241  0.52686925]\n",
      " [ 0.          0.26145247  0.02415385]\n",
      " [ 0.          0.68242501 -0.33166979]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #18 | lambda learn rate = 0.001\n",
      "Target = [[4.]\n",
      " [1.]]\n",
      "lambda end of trial = [[ 0.          0.14348831  0.04727996]\n",
      " [ 0.          0.10281837  0.20183034]\n",
      " [ 0.         -0.21138457  0.47874562]\n",
      " [ 0.          0.33124198 -0.16839997]\n",
      " [ 0.          0.03704997  0.32290437]\n",
      " [ 0.          0.00795162  0.2716269 ]\n",
      " [ 0.         -0.40868124  0.59563381]\n",
      " [ 0.         -0.19324656  0.50947822]\n",
      " [ 0.          0.19543474  0.00764942]\n",
      " [ 0.          0.61232529 -0.34919472]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #19 | lambda learn rate = 0.001\n",
      "Target = [[5.]\n",
      " [9.]]\n",
      "lambda end of trial = [[ 0.         -0.06473582 -0.32752348]\n",
      " [ 0.         -0.09993127 -0.16311902]\n",
      " [ 0.         -0.41529554  0.11170587]\n",
      " [ 0.          0.13066506 -0.52943843]\n",
      " [ 0.         -0.20887603 -0.11976243]\n",
      " [ 0.         -0.20919655 -0.11923981]\n",
      " [ 0.         -0.64996553  0.1613221 ]\n",
      " [ 0.         -0.43004094  0.08324833]\n",
      " [ 0.         -0.0418264  -0.41942064]\n",
      " [ 0.          0.36802464 -0.78893588]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #20 | lambda learn rate = 0.001\n",
      "Target = [[3.]\n",
      " [9.]]\n",
      "lambda end of trial = [[ 0.          0.24956291  0.61537271]\n",
      " [ 0.          0.16583283  0.6341733 ]\n",
      " [ 0.         -0.13469109  0.95351921]\n",
      " [ 0.          0.43771018  0.39169694]\n",
      " [ 0.          0.08239277  0.75404396]\n",
      " [ 0.          0.05918935  0.68591787]\n",
      " [ 0.         -0.38395307  0.95935948]\n",
      " [ 0.         -0.15229565  0.9164842 ]\n",
      " [ 0.          0.21150958  0.3405873 ]\n",
      " [ 0.          0.67264877  0.1249365 ]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #21 | lambda learn rate = 0.001\n",
      "Target = [[2.]\n",
      " [9.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda end of trial = [[ 0.         -0.12156998 -1.0547253 ]\n",
      " [ 0.         -0.21509824 -1.08001652]\n",
      " [ 0.         -0.4984631  -0.68345481]\n",
      " [ 0.          0.07940981 -1.22065473]\n",
      " [ 0.         -0.29465    -0.9426485 ]\n",
      " [ 0.         -0.30300275 -0.94394657]\n",
      " [ 0.         -0.73042537 -0.59976586]\n",
      " [ 0.         -0.48903245 -0.59883138]\n",
      " [ 0.         -0.11179273 -1.11427309]\n",
      " [ 0.          0.33631394 -1.38857024]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #22 | lambda learn rate = 0.001\n",
      "Target = [[5.]\n",
      " [6.]]\n",
      "lambda end of trial = [[0.         1.27073287 0.61603812]\n",
      " [0.         1.15032472 0.55849102]\n",
      " [0.         0.80524344 0.88099303]\n",
      " [0.         1.37573903 0.33494033]\n",
      " [0.         1.01801668 0.63255151]\n",
      " [0.         1.02287464 0.64710629]\n",
      " [0.         0.61334982 1.01276437]\n",
      " [0.         0.70195939 0.83035882]\n",
      " [0.         1.26332007 0.53586227]\n",
      " [0.         1.65795574 0.19739992]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #23 | lambda learn rate = 0.001\n",
      "Target = [[1.]\n",
      " [0.]]\n",
      "lambda end of trial = [[0.         1.22798178 0.61603812]\n",
      " [0.         1.1115316  0.55849102]\n",
      " [0.         0.76475187 0.88099303]\n",
      " [0.         1.33572757 0.33494033]\n",
      " [0.         0.97765244 0.63255151]\n",
      " [0.         0.9816362  0.64710629]\n",
      " [0.         0.57233394 1.01276437]\n",
      " [0.         0.66019998 0.83035882]\n",
      " [0.         1.2203678  0.53586227]\n",
      " [0.         1.61659966 0.19739992]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #24 | lambda learn rate = 0.001\n",
      "Target = [[5.]\n",
      " [0.]]\n",
      "lambda end of trial = [[ 0.          0.4183761   0.61603812]\n",
      " [ 0.          0.23426853  0.55849102]\n",
      " [ 0.          0.01755607  0.88099303]\n",
      " [ 0.          0.63506217  0.33494033]\n",
      " [ 0.          0.12169108  0.63255151]\n",
      " [ 0.          0.11999848  0.64710629]\n",
      " [ 0.         -0.22504693  1.01276437]\n",
      " [ 0.         -0.20045588  0.83035882]\n",
      " [ 0.          0.43544917  0.53586227]\n",
      " [ 0.          0.78298263  0.19739992]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #25 | lambda learn rate = 0.001\n",
      "Target = [[5.]\n",
      " [4.]]\n",
      "lambda end of trial = [[ 0.         -0.06357066  0.23048071]\n",
      " [ 0.         -0.26218633  0.16132713]\n",
      " [ 0.         -0.44344783  0.51218991]\n",
      " [ 0.          0.17122179 -0.03613197]\n",
      " [ 0.         -0.34800482  0.25679479]\n",
      " [ 0.         -0.36831753  0.25645348]\n",
      " [ 0.         -0.69332095  0.63814516]\n",
      " [ 0.         -0.66400141  0.4595224 ]\n",
      " [ 0.         -0.04530523  0.15125874]\n",
      " [ 0.          0.29211608 -0.19529333]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #26 | lambda learn rate = 0.001\n",
      "Target = [[7.]\n",
      " [8.]]\n",
      "lambda end of trial = [[ 0.00000000e+00  2.03368577e-01  5.35554122e-01]\n",
      " [ 0.00000000e+00 -5.69701784e-04  4.60317566e-01]\n",
      " [ 0.00000000e+00 -1.96895860e-01  7.93963587e-01]\n",
      " [ 0.00000000e+00  3.78877269e-01  2.01188579e-01]\n",
      " [ 0.00000000e+00 -1.08901456e-01  5.30055777e-01]\n",
      " [ 0.00000000e+00 -1.16782884e-01  5.43921651e-01]\n",
      " [ 0.00000000e+00 -4.72171156e-01  8.90887776e-01]\n",
      " [ 0.00000000e+00 -4.38330681e-01  7.17431799e-01]\n",
      " [ 0.00000000e+00  1.82129771e-01  4.11184462e-01]\n",
      " [ 0.00000000e+00  5.39791901e-01  8.77647567e-02]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #27 | lambda learn rate = 0.001\n",
      "Target = [[3.]\n",
      " [4.]]\n",
      "lambda end of trial = [[ 0.          0.04676851  0.32675404]\n",
      " [ 0.         -0.17955398  0.22167186]\n",
      " [ 0.         -0.36322385  0.57219293]\n",
      " [ 0.          0.20397078 -0.03202007]\n",
      " [ 0.         -0.26854886  0.31719257]\n",
      " [ 0.         -0.29386291  0.30781494]\n",
      " [ 0.         -0.64731408  0.65736388]\n",
      " [ 0.         -0.61077913  0.48750053]\n",
      " [ 0.          0.01145378  0.18361647]\n",
      " [ 0.          0.37316281 -0.13440736]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #28 | lambda learn rate = 0.001\n",
      "Target = [[4.]\n",
      " [8.]]\n",
      "lambda end of trial = [[ 0.         -0.05896409  0.11528884]\n",
      " [ 0.         -0.29418744 -0.00759506]\n",
      " [ 0.         -0.48426824  0.33010416]\n",
      " [ 0.          0.0965395  -0.24688264]\n",
      " [ 0.         -0.38213367  0.09002294]\n",
      " [ 0.         -0.39813066  0.09927945]\n",
      " [ 0.         -0.75519302  0.44160601]\n",
      " [ 0.         -0.72039731  0.26826417]\n",
      " [ 0.         -0.09386758 -0.02702624]\n",
      " [ 0.          0.27625229 -0.32822841]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #29 | lambda learn rate = 0.001\n",
      "Target = [[1.]\n",
      " [7.]]\n",
      "lambda end of trial = [[ 0.         -0.05392333  0.15057414]\n",
      " [ 0.         -0.28920452  0.02728537]\n",
      " [ 0.         -0.47984693  0.36105333]\n",
      " [ 0.          0.10135779 -0.21315458]\n",
      " [ 0.         -0.37700359  0.12593352]\n",
      " [ 0.         -0.39291655  0.13577824]\n",
      " [ 0.         -0.75004109  0.47766945]\n",
      " [ 0.         -0.7153962   0.30327193]\n",
      " [ 0.         -0.08924122  0.00535828]\n",
      " [ 0.          0.28136988 -0.29240524]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #30 | lambda learn rate = 0.001\n",
      "Target = [[2.]\n",
      " [3.]]\n",
      "lambda end of trial = [[ 0.         -0.02215702  0.1982236 ]\n",
      " [ 0.         -0.25818806  0.07381007]\n",
      " [ 0.         -0.45343624  0.40066936]\n",
      " [ 0.          0.13004568 -0.17012275]\n",
      " [ 0.         -0.351386    0.16435991]\n",
      " [ 0.         -0.36212521  0.18196525]\n",
      " [ 0.         -0.72256397  0.51888514]\n",
      " [ 0.         -0.68457705  0.34950066]\n",
      " [ 0.         -0.05920668  0.05041009]\n",
      " [ 0.          0.31214134 -0.24624805]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #31 | lambda learn rate = 0.001\n",
      "Target = [[4.]\n",
      " [3.]]\n",
      "lambda end of trial = [[ 0.          0.11065418  0.297832  ]\n",
      " [ 0.         -0.11246478  0.18310252]\n",
      " [ 0.         -0.30648303  0.51088426]\n",
      " [ 0.          0.2662659  -0.06795758]\n",
      " [ 0.         -0.21760672  0.26469437]\n",
      " [ 0.         -0.21552651  0.29191427]\n",
      " [ 0.         -0.59108621  0.61749346]\n",
      " [ 0.         -0.5363707   0.46065542]\n",
      " [ 0.          0.07949452  0.15443599]\n",
      " [ 0.          0.45109244 -0.14203472]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #32 | lambda learn rate = 0.001\n",
      "Target = [[1.]\n",
      " [1.]]\n",
      "lambda end of trial = [[ 0.          0.10396013  0.29113795]\n",
      " [ 0.         -0.11953451  0.1760328 ]\n",
      " [ 0.         -0.31265198  0.50471532]\n",
      " [ 0.          0.25948762 -0.07473586]\n",
      " [ 0.         -0.22461609  0.25768501]\n",
      " [ 0.         -0.22224931  0.28519147]\n",
      " [ 0.         -0.59729408  0.61128559]\n",
      " [ 0.         -0.54283993  0.45418619]\n",
      " [ 0.          0.07267637  0.14761784]\n",
      " [ 0.          0.44511724 -0.14800993]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #33 | lambda learn rate = 0.001\n",
      "Target = [[9.]\n",
      " [1.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda end of trial = [[ 0.          0.60815217  0.34715929]\n",
      " [ 0.          0.45595826  0.23997644]\n",
      " [ 0.          0.31326305  0.57426143]\n",
      " [ 0.          0.78314274 -0.01655196]\n",
      " [ 0.          0.34574407  0.32105836]\n",
      " [ 0.          0.33611802  0.34723228]\n",
      " [ 0.         -0.03361287  0.67391684]\n",
      " [ 0.         -0.00449215  0.51400261]\n",
      " [ 0.          0.63874859  0.21051475]\n",
      " [ 0.          0.93501895 -0.09357641]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #34 | lambda learn rate = 0.001\n",
      "Target = [[6.]\n",
      " [4.]]\n",
      "lambda end of trial = [[ 0.          0.07496173 -0.008301  ]\n",
      " [ 0.         -0.14237812 -0.15891448]\n",
      " [ 0.         -0.28747669  0.17376827]\n",
      " [ 0.          0.21061295 -0.39823849]\n",
      " [ 0.         -0.22959677 -0.0625022 ]\n",
      " [ 0.         -0.25916508 -0.04962311]\n",
      " [ 0.         -0.59828767  0.29746697]\n",
      " [ 0.         -0.59739256  0.11873567]\n",
      " [ 0.          0.01992266 -0.20203587]\n",
      " [ 0.          0.29112723 -0.52283756]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #35 | lambda learn rate = 0.001\n",
      "Target = [[1.]\n",
      " [7.]]\n",
      "lambda end of trial = [[ 0.          0.11366759  0.26264005]\n",
      " [ 0.         -0.10814481  0.08071869]\n",
      " [ 0.         -0.25149     0.42567509]\n",
      " [ 0.          0.24537017 -0.15493791]\n",
      " [ 0.         -0.19658201  0.16860112]\n",
      " [ 0.         -0.22230572  0.20839237]\n",
      " [ 0.         -0.55866659  0.57481451]\n",
      " [ 0.         -0.56002006  0.38034316]\n",
      " [ 0.          0.05322808  0.03110209]\n",
      " [ 0.          0.33222237 -0.23517152]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #36 | lambda learn rate = 0.001\n",
      "Target = [[2.]\n",
      " [7.]]\n",
      "lambda end of trial = [[ 0.          0.08673508  0.16837626]\n",
      " [ 0.         -0.14136814 -0.03556295]\n",
      " [ 0.         -0.28575794  0.3057373 ]\n",
      " [ 0.          0.21704606 -0.2540723 ]\n",
      " [ 0.         -0.22720152  0.06143283]\n",
      " [ 0.         -0.25273566  0.1018876 ]\n",
      " [ 0.         -0.58759761  0.47355595]\n",
      " [ 0.         -0.59101962  0.2718447 ]\n",
      " [ 0.          0.02140428 -0.08028121]\n",
      " [ 0.          0.30579985 -0.32765038]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #37 | lambda learn rate = 0.001\n",
      "Target = [[2.]\n",
      " [2.]]\n",
      "lambda end of trial = [[ 0.          0.10803216  0.18967334]\n",
      " [ 0.         -0.12117612 -0.01537092]\n",
      " [ 0.         -0.26390826  0.32758698]\n",
      " [ 0.          0.2356499  -0.23546846]\n",
      " [ 0.         -0.20768881  0.08094555]\n",
      " [ 0.         -0.23049125  0.12413201]\n",
      " [ 0.         -0.56536596  0.49578759]\n",
      " [ 0.         -0.57046391  0.29240041]\n",
      " [ 0.          0.0424737  -0.0592118 ]\n",
      " [ 0.          0.32683723 -0.30661299]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #38 | lambda learn rate = 0.001\n",
      "Target = [[1.]\n",
      " [3.]]\n",
      "lambda end of trial = [[ 0.          0.10699818  0.18657141]\n",
      " [ 0.         -0.12250371 -0.01935372]\n",
      " [ 0.         -0.26522108  0.32364852]\n",
      " [ 0.          0.23447248 -0.23900072]\n",
      " [ 0.         -0.20895163  0.07715707]\n",
      " [ 0.         -0.23171234  0.12046876]\n",
      " [ 0.         -0.56637668  0.49275545]\n",
      " [ 0.         -0.57161596  0.28894427]\n",
      " [ 0.          0.04129564 -0.06274598]\n",
      " [ 0.          0.32561817 -0.31027015]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #39 | lambda learn rate = 0.001\n",
      "Target = [[9.]\n",
      " [2.]]\n",
      "lambda end of trial = [[ 0.          0.7314558   0.32533977]\n",
      " [ 0.          0.48912225  0.11656316]\n",
      " [ 0.          0.36379984  0.46343094]\n",
      " [ 0.          0.81564362 -0.10985158]\n",
      " [ 0.          0.42354731  0.21771239]\n",
      " [ 0.          0.3696862   0.25411288]\n",
      " [ 0.          0.05262643  0.63031169]\n",
      " [ 0.          0.11453215  0.44142163]\n",
      " [ 0.          0.60703329  0.0629735 ]\n",
      " [ 0.          0.93933602 -0.1738884 ]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #40 | lambda learn rate = 0.001\n",
      "Target = [[8.]\n",
      " [4.]]\n",
      "lambda end of trial = [[ 0.         -0.31762881 -0.19920253]\n",
      " [ 0.         -0.54755576 -0.40177584]\n",
      " [ 0.         -0.63429114 -0.03561455]\n",
      " [ 0.         -0.1683271  -0.60183694]\n",
      " [ 0.         -0.67097557 -0.32954905]\n",
      " [ 0.         -0.7069953  -0.28422787]\n",
      " [ 0.         -0.94912552  0.12943572]\n",
      " [ 0.         -0.88557656 -0.05863272]\n",
      " [ 0.         -0.37853696 -0.42981162]\n",
      " [ 0.         -0.08458287 -0.68584785]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #41 | lambda learn rate = 0.001\n",
      "Target = [[4.]\n",
      " [6.]]\n",
      "lambda end of trial = [[ 0.          0.25408168  0.65836319]\n",
      " [ 0.          0.0188575   0.44784405]\n",
      " [ 0.         -0.00843849  0.90316443]\n",
      " [ 0.          0.43940083  0.30975495]\n",
      " [ 0.         -0.05987022  0.58710897]\n",
      " [ 0.         -0.11871499  0.59819259]\n",
      " [ 0.         -0.32460373  1.06621841]\n",
      " [ 0.         -0.31101611  0.80320794]\n",
      " [ 0.          0.14931563  0.36196725]\n",
      " [ 0.          0.47078969  0.14721098]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #42 | lambda learn rate = 0.001\n",
      "Target = [[8.]\n",
      " [4.]]\n",
      "lambda end of trial = [[ 0.         -0.16775927  0.44744272]\n",
      " [ 0.         -0.41280104  0.23201478]\n",
      " [ 0.         -0.446712    0.68402767]\n",
      " [ 0.         -0.02017107  0.079969  ]\n",
      " [ 0.         -0.47165362  0.38121728]\n",
      " [ 0.         -0.58286963  0.36611527]\n",
      " [ 0.         -0.70756211  0.87473921]\n",
      " [ 0.         -0.77358388  0.57192406]\n",
      " [ 0.         -0.2326963   0.17096129]\n",
      " [ 0.          0.04589376 -0.06523698]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #43 | lambda learn rate = 0.001\n",
      "Target = [[6.]\n",
      " [1.]]\n",
      "lambda end of trial = [[ 0.          0.31181151  0.52737118]\n",
      " [ 0.          0.1340732   0.32316049]\n",
      " [ 0.          0.04322215  0.76568336]\n",
      " [ 0.          0.47323435  0.16220324]\n",
      " [ 0.          0.08787564  0.47447215]\n",
      " [ 0.         -0.0771777   0.45039726]\n",
      " [ 0.         -0.16707013  0.96482121]\n",
      " [ 0.         -0.2693799   0.65595806]\n",
      " [ 0.          0.26880241  0.25454441]\n",
      " [ 0.          0.4995511   0.01037257]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #44 | lambda learn rate = 0.001\n",
      "Target = [[1.]\n",
      " [2.]]\n",
      "lambda end of trial = [[ 0.          0.27654849  0.45684512]\n",
      " [ 0.          0.10156482  0.25814373]\n",
      " [ 0.          0.00766711  0.69457328]\n",
      " [ 0.          0.43815742  0.09204938]\n",
      " [ 0.          0.05109916  0.4009192 ]\n",
      " [ 0.         -0.11660655  0.37153955]\n",
      " [ 0.         -0.19659827  0.90576493]\n",
      " [ 0.         -0.30492813  0.5848616 ]\n",
      " [ 0.          0.23397649  0.18489257]\n",
      " [ 0.          0.46923831 -0.05025301]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #45 | lambda learn rate = 0.001\n",
      "Target = [[8.]\n",
      " [3.]]\n",
      "lambda end of trial = [[ 0.          0.04827228  0.37124154]\n",
      " [ 0.         -0.14250378  0.166618  ]\n",
      " [ 0.         -0.22014327  0.60914439]\n",
      " [ 0.          0.21800886  0.00949367]\n",
      " [ 0.         -0.20385399  0.30531177]\n",
      " [ 0.         -0.35448453  0.28233531]\n",
      " [ 0.         -0.40798115  0.82649635]\n",
      " [ 0.         -0.53242149  0.49955159]\n",
      " [ 0.          0.01738389  0.10367035]\n",
      " [ 0.          0.22778333 -0.14079863]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #46 | lambda learn rate = 0.001\n",
      "Target = [[0.]\n",
      " [0.]]\n",
      "lambda end of trial = [[ 0.          0.04827228  0.37124154]\n",
      " [ 0.         -0.14250378  0.166618  ]\n",
      " [ 0.         -0.22014327  0.60914439]\n",
      " [ 0.          0.21800886  0.00949367]\n",
      " [ 0.         -0.20385399  0.30531177]\n",
      " [ 0.         -0.35448453  0.28233531]\n",
      " [ 0.         -0.40798115  0.82649635]\n",
      " [ 0.         -0.53242149  0.49955159]\n",
      " [ 0.          0.01738389  0.10367035]\n",
      " [ 0.          0.22778333 -0.14079863]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #47 | lambda learn rate = 0.001\n",
      "Target = [[4.]\n",
      " [0.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda end of trial = [[ 0.          0.14882403  0.37124154]\n",
      " [ 0.         -0.03148893  0.166618  ]\n",
      " [ 0.         -0.11451789  0.60914439]\n",
      " [ 0.          0.32341219  0.00949367]\n",
      " [ 0.         -0.10482137  0.30531177]\n",
      " [ 0.         -0.24479861  0.28233531]\n",
      " [ 0.         -0.30586445  0.82649635]\n",
      " [ 0.         -0.42404185  0.49955159]\n",
      " [ 0.          0.13102427  0.10367035]\n",
      " [ 0.          0.33252291 -0.14079863]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #48 | lambda learn rate = 0.001\n",
      "Target = [[5.]\n",
      " [9.]]\n",
      "lambda end of trial = [[ 0.         -0.10464799 -0.0850081 ]\n",
      " [ 0.         -0.29528323 -0.30821173]\n",
      " [ 0.         -0.39039234  0.11257036]\n",
      " [ 0.          0.06702356 -0.45200586]\n",
      " [ 0.         -0.37323973 -0.17784128]\n",
      " [ 0.         -0.50648186 -0.18869453]\n",
      " [ 0.         -0.54674157  0.39291755]\n",
      " [ 0.         -0.67584102  0.04631307]\n",
      " [ 0.         -0.12352437 -0.35451722]\n",
      " [ 0.          0.09003313 -0.57728024]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #49 | lambda learn rate = 0.001\n",
      "Target = [[3.]\n",
      " [8.]]\n",
      "lambda end of trial = [[ 0.          0.19083362  0.70294287]\n",
      " [ 0.          0.01375349  0.51588619]\n",
      " [ 0.         -0.07419569  0.95576144]\n",
      " [ 0.          0.3598916   0.32897556]\n",
      " [ 0.         -0.08423428  0.59283994]\n",
      " [ 0.         -0.24250769  0.51523658]\n",
      " [ 0.         -0.29341527  1.06845434]\n",
      " [ 0.         -0.37462909  0.84954489]\n",
      " [ 0.          0.18468654  0.46737856]\n",
      " [ 0.          0.39220494  0.22851125]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #50 | lambda learn rate = 0.001\n",
      "Target = [[6.]\n",
      " [5.]]\n",
      "lambda end of trial = [[ 0.         -0.24759192  0.33758825]\n",
      " [ 0.         -0.3923956   0.17742861]\n",
      " [ 0.         -0.49768068  0.60285729]\n",
      " [ 0.         -0.09694386 -0.05172065]\n",
      " [ 0.         -0.45957702  0.28005432]\n",
      " [ 0.         -0.67935277  0.15119902]\n",
      " [ 0.         -0.70128313  0.72856446]\n",
      " [ 0.         -0.80031581  0.49480596]\n",
      " [ 0.         -0.26292288  0.0943707 ]\n",
      " [ 0.         -0.03244369 -0.1253626 ]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #51 | lambda learn rate = 0.001\n",
      "Target = [[1.]\n",
      " [5.]]\n",
      "lambda end of trial = [[ 0.         -0.27069969  0.22204939]\n",
      " [ 0.         -0.41495885  0.06461238]\n",
      " [ 0.         -0.52058291  0.48834612]\n",
      " [ 0.         -0.11795134 -0.15675809]\n",
      " [ 0.         -0.4832218   0.16183037]\n",
      " [ 0.         -0.70095588  0.04318348]\n",
      " [ 0.         -0.72582728  0.60584372]\n",
      " [ 0.         -0.82332745  0.37974773]\n",
      " [ 0.         -0.28286015 -0.00531564]\n",
      " [ 0.         -0.05756361 -0.2509622 ]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #52 | lambda learn rate = 0.001\n",
      "Target = [[9.]\n",
      " [7.]]\n",
      "lambda end of trial = [[0.         0.98549807 1.19909209]\n",
      " [0.         0.8923231  1.08138723]\n",
      " [0.         0.78359982 1.50271047]\n",
      " [0.         1.1518313  0.83085063]\n",
      " [0.         0.89273655 1.23202021]\n",
      " [0.         0.61252301 1.06477818]\n",
      " [0.         0.59655454 1.63436291]\n",
      " [0.         0.58061044 1.47169942]\n",
      " [0.         0.96643553 0.96635878]\n",
      " [0.         1.15811368 0.69456458]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #53 | lambda learn rate = 0.001\n",
      "Target = [[9.]\n",
      " [9.]]\n",
      "lambda end of trial = [[ 0.         -3.92209396 -3.70849994]\n",
      " [ 0.         -4.22653918 -4.03747505]\n",
      " [ 0.         -4.66253769 -3.94342704]\n",
      " [ 0.         -3.87543176 -4.19641243]\n",
      " [ 0.         -4.46567433 -4.12639067]\n",
      " [ 0.         -3.71233555 -3.26008039]\n",
      " [ 0.         -4.58748878 -3.54968041]\n",
      " [ 0.         -4.40135529 -3.51026631]\n",
      " [ 0.         -4.15738097 -4.15745772]\n",
      " [ 0.         -3.54790455 -4.01145365]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #54 | lambda learn rate = 0.001\n",
      "Target = [[6.]\n",
      " [2.]]\n",
      "lambda end of trial = [[ 0.          2.60026924 -1.53437887]\n",
      " [ 0.          2.41491966 -1.82365544]\n",
      " [ 0.          1.54529227 -1.87415038]\n",
      " [ 0.          3.12375164 -1.86335129]\n",
      " [ 0.          2.40965511 -1.83461419]\n",
      " [ 0.          2.91468398 -1.05107388]\n",
      " [ 0.          1.77489609 -1.42888545]\n",
      " [ 0.          2.46749077 -1.22065096]\n",
      " [ 0.          2.87658028 -1.81280397]\n",
      " [ 0.          3.4386218  -1.68261154]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #55 | lambda learn rate = 0.001\n",
      "Target = [[1.]\n",
      " [3.]]\n",
      "lambda end of trial = [[ 0.          2.67747134 -1.30277255]\n",
      " [ 0.          2.50009683 -1.56812392]\n",
      " [ 0.          1.62581588 -1.63257956]\n",
      " [ 0.          3.20971623 -1.60545752]\n",
      " [ 0.          2.48861404 -1.59773741]\n",
      " [ 0.          2.99499381 -0.81014439]\n",
      " [ 0.          1.84873195 -1.20737788]\n",
      " [ 0.          2.55476317 -0.95883375]\n",
      " [ 0.          2.95259651 -1.58475529]\n",
      " [ 0.          3.5272694  -1.41666871]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #56 | lambda learn rate = 0.001\n",
      "Target = [[7.]\n",
      " [6.]]\n",
      "lambda end of trial = [[ 0.          0.36774129 -3.28254117]\n",
      " [ 0.          0.20311542 -3.53696513]\n",
      " [ 0.         -0.35214175 -3.32797182]\n",
      " [ 0.          1.1905177  -3.33619912]\n",
      " [ 0.          0.27782864 -3.49269632]\n",
      " [ 0.          0.94215982 -2.56971638]\n",
      " [ 0.         -0.03752081 -2.82416596]\n",
      " [ 0.          0.46956921 -2.74614286]\n",
      " [ 0.          0.88716202 -3.3551277 ]\n",
      " [ 0.          1.54523426 -3.11555597]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #57 | lambda learn rate = 0.001\n",
      "Target = [[1.]\n",
      " [7.]]\n",
      "lambda end of trial = [[0.         1.02937186 1.34887286]\n",
      " [0.         0.97642625 1.8762107 ]\n",
      " [0.         0.41720026 2.05742224]\n",
      " [0.         1.95772946 2.03428317]\n",
      " [0.         1.08119436 2.13086372]\n",
      " [0.         1.712106   2.81990691]\n",
      " [0.         0.65544034 2.0265621 ]\n",
      " [0.         1.2550393  2.75214781]\n",
      " [0.         1.64679899 1.96233109]\n",
      " [0.         2.32940559 2.37364328]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #58 | lambda learn rate = 0.001\n",
      "Target = [[8.]\n",
      " [1.]]\n",
      "lambda end of trial = [[ 0.         -1.95942963  0.97527267]\n",
      " [ 0.         -2.04564138  1.49845224]\n",
      " [ 0.         -2.57820626  1.68299643]\n",
      " [ 0.         -1.18432145  1.6415268 ]\n",
      " [ 0.         -2.07017075  1.73694308]\n",
      " [ 0.         -1.29766428  2.44368562]\n",
      " [ 0.         -2.2726924   1.66054551]\n",
      " [ 0.         -1.83675551  2.36567346]\n",
      " [ 0.         -1.55049422  1.56266944]\n",
      " [ 0.         -0.6918302   1.99598881]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #59 | lambda learn rate = 0.001\n",
      "Target = [[6.]\n",
      " [3.]]\n",
      "lambda end of trial = [[ 0.         -0.79206417  1.5589554 ]\n",
      " [ 0.         -0.92502085  2.05876251]\n",
      " [ 0.         -1.422268    2.26096556]\n",
      " [ 0.         -0.08722679  2.19007413]\n",
      " [ 0.         -0.92678007  2.30863842]\n",
      " [ 0.         -0.04881928  3.06810812]\n",
      " [ 0.         -1.17077813  2.21150264]\n",
      " [ 0.         -0.83571898  2.86619173]\n",
      " [ 0.         -0.33590596  2.16996357]\n",
      " [ 0.          0.55061802  2.61721292]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #60 | lambda learn rate = 0.001\n",
      "Target = [[2.]\n",
      " [8.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda end of trial = [[ 0.         -1.91175993 -2.91982765]\n",
      " [ 0.         -2.05930762 -2.47838457]\n",
      " [ 0.         -2.60757904 -2.48027861]\n",
      " [ 0.         -1.21855208 -2.335227  ]\n",
      " [ 0.         -2.15533554 -2.60558345]\n",
      " [ 0.         -1.21570529 -1.59943591]\n",
      " [ 0.         -2.29910987 -2.30182433]\n",
      " [ 0.         -1.92519953 -1.49173051]\n",
      " [ 0.         -1.29392089 -1.66209616]\n",
      " [ 0.         -0.51271011 -1.63609959]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #61 | lambda learn rate = 0.001\n",
      "Target = [[1.]\n",
      " [4.]]\n",
      "lambda end of trial = [[ 0.         -1.59738359 -1.66232226]\n",
      " [ 0.         -1.7363434  -1.18652768]\n",
      " [ 0.         -2.27918679 -1.1667096 ]\n",
      " [ 0.         -0.88876713 -1.01608721]\n",
      " [ 0.         -1.82941512 -1.30190176]\n",
      " [ 0.         -0.86381205 -0.19186296]\n",
      " [ 0.         -2.00144957 -1.1111831 ]\n",
      " [ 0.         -1.58748982 -0.14089165]\n",
      " [ 0.         -0.96878436 -0.36155003]\n",
      " [ 0.         -0.18534307 -0.32663145]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #62 | lambda learn rate = 0.001\n",
      "Target = [[6.]\n",
      " [3.]]\n",
      "lambda end of trial = [[ 0.          0.88338392 -0.42193851]\n",
      " [ 0.          0.69860621  0.03094712]\n",
      " [ 0.          0.33868521  0.1422264 ]\n",
      " [ 0.          1.5553333   0.205963  ]\n",
      " [ 0.          0.60016504 -0.08711168]\n",
      " [ 0.          1.46720735  0.97364675]\n",
      " [ 0.          0.46249356  0.12078846]\n",
      " [ 0.          0.77535372  1.04053012]\n",
      " [ 0.          1.30173555  0.77370992]\n",
      " [ 0.          2.29668325  0.91438171]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #63 | lambda learn rate = 0.001\n",
      "Target = [[2.]\n",
      " [1.]]\n",
      "lambda end of trial = [[ 0.          0.73964928 -0.49380583]\n",
      " [ 0.          0.54537572 -0.04566813]\n",
      " [ 0.          0.18403692  0.06490225]\n",
      " [ 0.          1.38824158  0.12241714]\n",
      " [ 0.          0.43742703 -0.16848069]\n",
      " [ 0.          1.33156968  0.90582791]\n",
      " [ 0.          0.31436479  0.04672408]\n",
      " [ 0.          0.64119221  0.97344937]\n",
      " [ 0.          1.15688952  0.70128691]\n",
      " [ 0.          2.15468383  0.843382  ]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #64 | lambda learn rate = 0.001\n",
      "Target = [[7.]\n",
      " [6.]]\n",
      "lambda end of trial = [[ 0.         -0.61672227 -1.65641002]\n",
      " [ 0.         -1.22831727 -1.5659764 ]\n",
      " [ 0.         -1.36314085 -1.26125012]\n",
      " [ 0.         -0.17952583 -1.2213835 ]\n",
      " [ 0.         -1.16409031 -1.54120984]\n",
      " [ 0.         -0.21109929 -0.41645977]\n",
      " [ 0.         -1.28900957 -1.32759681]\n",
      " [ 0.         -0.82001375 -0.27901288]\n",
      " [ 0.         -0.29547658 -0.54359832]\n",
      " [ 0.          0.53035969 -0.54889583]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #65 | lambda learn rate = 0.001\n",
      "Target = [[0.]\n",
      " [6.]]\n",
      "lambda end of trial = [[ 0.         -0.61672227 -0.4837242 ]\n",
      " [ 0.         -1.22831727 -0.26835274]\n",
      " [ 0.         -1.36314085  0.0307603 ]\n",
      " [ 0.         -0.17952583  0.06657005]\n",
      " [ 0.         -1.16409031 -0.27460184]\n",
      " [ 0.         -0.21109929  0.93756443]\n",
      " [ 0.         -1.28900957 -0.13860412]\n",
      " [ 0.         -0.82001375  0.98585994]\n",
      " [ 0.         -0.29547658  0.73725383]\n",
      " [ 0.          0.53035969  0.54840024]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #66 | lambda learn rate = 0.001\n",
      "Target = [[9.]\n",
      " [9.]]\n",
      "lambda end of trial = [[0.         1.09672927 1.22972735]\n",
      " [0.         0.569529   1.52949353]\n",
      " [0.         0.51885406 1.91275521]\n",
      " [0.         1.55405046 1.80014634]\n",
      " [0.         0.68873388 1.57822235]\n",
      " [0.         1.70782211 2.85648583]\n",
      " [0.         0.39374563 1.54415109]\n",
      " [0.         0.88487137 2.69074506]\n",
      " [0.         1.61281958 2.64554999]\n",
      " [0.         2.34440367 2.36244421]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #67 | lambda learn rate = 0.001\n",
      "Target = [[5.]\n",
      " [9.]]\n",
      "lambda end of trial = [[ 0.         -2.64465314 -5.50476101]\n",
      " [ 0.         -3.31105412 -5.4555561 ]\n",
      " [ 0.         -3.10040897 -4.60191824]\n",
      " [ 0.         -2.32847604 -5.18840135]\n",
      " [ 0.         -2.9142205  -4.90709554]\n",
      " [ 0.         -1.83361847 -3.51810721]\n",
      " [ 0.         -3.4460966  -5.36756494]\n",
      " [ 0.         -2.9118174  -4.14329472]\n",
      " [ 0.         -2.02736785 -3.90678738]\n",
      " [ 0.         -1.33989703 -4.26929704]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #68 | lambda learn rate = 0.001\n",
      "Target = [[0.]\n",
      " [6.]]\n",
      "lambda end of trial = [[ 0.         -2.64465314  0.25309512]\n",
      " [ 0.         -3.31105412 -0.14936771]\n",
      " [ 0.         -3.10040897  1.40947198]\n",
      " [ 0.         -2.32847604  0.49077896]\n",
      " [ 0.         -2.9142205   0.52378938]\n",
      " [ 0.         -1.83361847  2.23278932]\n",
      " [ 0.         -3.4460966   0.20928585]\n",
      " [ 0.         -2.9118174   1.37363068]\n",
      " [ 0.         -2.02736785  1.73754907]\n",
      " [ 0.         -1.33989703  0.82718734]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #69 | lambda learn rate = 0.001\n",
      "Target = [[5.]\n",
      " [1.]]\n",
      "lambda end of trial = [[ 0.         -0.63499239  0.65502727]\n",
      " [ 0.         -1.19721736  0.27339964]\n",
      " [ 0.         -0.95254133  1.83904551]\n",
      " [ 0.         -0.27441258  0.90159165]\n",
      " [ 0.         -0.91892572  0.92284834]\n",
      " [ 0.          0.42404354  2.68432173]\n",
      " [ 0.         -1.46002693  0.60649978]\n",
      " [ 0.         -0.82805884  1.79038239]\n",
      " [ 0.          0.02916655  2.14885595]\n",
      " [ 0.          0.80507248  1.25618125]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #70 | lambda learn rate = 0.001\n",
      "Target = [[3.]\n",
      " [8.]]\n",
      "lambda end of trial = [[ 0.         -1.42579071 -1.45376826]\n",
      " [ 0.         -2.0617232  -2.03194927]\n",
      " [ 0.         -1.81640021 -0.46457817]\n",
      " [ 0.         -1.07711404 -1.23894557]\n",
      " [ 0.         -1.7066587  -1.17777294]\n",
      " [ 0.         -0.30843594  0.7310431 ]\n",
      " [ 0.         -2.37329538 -1.82888277]\n",
      " [ 0.         -1.63989411 -0.37451168]\n",
      " [ 0.         -0.86263637 -0.22928517]\n",
      " [ 0.         -0.00452523 -0.90274597]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #71 | lambda learn rate = 0.001\n",
      "Target = [[6.]\n",
      " [7.]]\n",
      "lambda end of trial = [[0.         1.24011264 1.65645232]\n",
      " [0.         0.71604125 1.20877592]\n",
      " [0.         1.02018609 2.84477251]\n",
      " [0.         1.76020532 2.07126034]\n",
      " [0.         1.19349445 2.20573907]\n",
      " [0.         2.73898715 4.28637004]\n",
      " [0.         0.56266218 1.59640105]\n",
      " [0.         1.52969532 3.32334265]\n",
      " [0.         1.82831031 2.91015261]\n",
      " [0.         2.52245359 2.04539598]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #72 | lambda learn rate = 0.001\n",
      "Target = [[2.]\n",
      " [1.]]\n",
      "lambda end of trial = [[0.         0.89866829 1.48573014]\n",
      " [0.         0.40382682 1.05266871]\n",
      " [0.         0.67388794 2.67162343]\n",
      " [0.         1.41983131 1.90107334]\n",
      " [0.         0.87575506 2.04686937]\n",
      " [0.         2.44007019 4.13691156]\n",
      " [0.         0.26266662 1.44640328]\n",
      " [0.         1.19703897 3.15701448]\n",
      " [0.         1.50702078 2.74950784]\n",
      " [0.         2.1726615  1.87049994]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #73 | lambda learn rate = 0.001\n",
      "Target = [[6.]\n",
      " [3.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda end of trial = [[ 0.         -1.3191005   0.37684575]\n",
      " [ 0.         -2.48196696 -0.39022818]\n",
      " [ 0.         -1.97835012  1.3455044 ]\n",
      " [ 0.         -1.19610672  0.59310432]\n",
      " [ 0.         -1.79679981  0.71059194]\n",
      " [ 0.         -0.03829409  2.89772942]\n",
      " [ 0.         -2.21555116  0.20729439]\n",
      " [ 0.         -1.34088987  1.88805006]\n",
      " [ 0.         -0.96039779  1.51579856]\n",
      " [ 0.         -0.36287123  0.60273357]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #74 | lambda learn rate = 0.001\n",
      "Target = [[9.]\n",
      " [7.]]\n",
      "lambda end of trial = [[ 0.          0.67227139  1.92569055]\n",
      " [ 0.         -0.58768951  1.08309872]\n",
      " [ 0.          0.0968384   2.95953992]\n",
      " [ 0.          0.6269575   2.01104317]\n",
      " [ 0.          0.1921697   2.25756823]\n",
      " [ 0.          1.96386695  4.45496578]\n",
      " [ 0.         -0.46089353  1.5720281 ]\n",
      " [ 0.          0.52838548  3.34193089]\n",
      " [ 0.          0.93735517  2.99182864]\n",
      " [ 0.          1.4377098   2.00318549]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #75 | lambda learn rate = 0.001\n",
      "Target = [[1.]\n",
      " [5.]]\n",
      "lambda end of trial = [[ 0.          0.30431438  0.08590549]\n",
      " [ 0.         -1.02086598 -1.08278365]\n",
      " [ 0.         -0.3656806   0.64694493]\n",
      " [ 0.          0.15975914 -0.32494866]\n",
      " [ 0.         -0.25192044  0.0371175 ]\n",
      " [ 0.          1.51537294  2.21249574]\n",
      " [ 0.         -0.89088953 -0.57795193]\n",
      " [ 0.          0.08865165  1.14326176]\n",
      " [ 0.          0.46394701  0.62478786]\n",
      " [ 0.          0.99670444 -0.20184131]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #76 | lambda learn rate = 0.001\n",
      "Target = [[0.]\n",
      " [4.]]\n",
      "lambda end of trial = [[ 0.          0.30431438 -0.05438618]\n",
      " [ 0.         -1.02086598 -1.24157598]\n",
      " [ 0.         -0.3656806   0.48746815]\n",
      " [ 0.          0.15975914 -0.46606623]\n",
      " [ 0.         -0.25192044 -0.10926857]\n",
      " [ 0.          1.51537294  2.06721995]\n",
      " [ 0.         -0.89088953 -0.73929023]\n",
      " [ 0.          0.08865165  0.98761989]\n",
      " [ 0.          0.46394701  0.46413067]\n",
      " [ 0.          0.99670444 -0.3635949 ]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #77 | lambda learn rate = 0.001\n",
      "Target = [[2.]\n",
      " [4.]]\n",
      "lambda end of trial = [[ 0.          0.26594465 -0.13112563]\n",
      " [ 0.         -1.06012666 -1.32009733]\n",
      " [ 0.         -0.40566093  0.40750749]\n",
      " [ 0.          0.12089669 -0.54379112]\n",
      " [ 0.         -0.29573471 -0.1968971 ]\n",
      " [ 0.          1.47385747  1.98418902]\n",
      " [ 0.         -0.9290921  -0.81569536]\n",
      " [ 0.          0.04740031  0.90511722]\n",
      " [ 0.          0.42595996  0.38815656]\n",
      " [ 0.          0.95963964 -0.43772451]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #78 | lambda learn rate = 0.001\n",
      "Target = [[6.]\n",
      " [0.]]\n",
      "lambda end of trial = [[ 0.          0.30299752 -0.13112563]\n",
      " [ 0.         -1.02485911 -1.32009733]\n",
      " [ 0.         -0.37330672  0.40750749]\n",
      " [ 0.          0.15420549 -0.54379112]\n",
      " [ 0.         -0.25943671 -0.1968971 ]\n",
      " [ 0.          1.51020998  1.98418902]\n",
      " [ 0.         -0.89572962 -0.81569536]\n",
      " [ 0.          0.08535714  0.90511722]\n",
      " [ 0.          0.46622991  0.38815656]\n",
      " [ 0.          0.99250456 -0.43772451]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #79 | lambda learn rate = 0.001\n",
      "Target = [[1.]\n",
      " [7.]]\n",
      "lambda end of trial = [[ 0.          0.29104501 -0.21479326]\n",
      " [ 0.         -1.03627288 -1.39999368]\n",
      " [ 0.         -0.38375281  0.33438486]\n",
      " [ 0.          0.14355188 -0.61836643]\n",
      " [ 0.         -0.27137864 -0.28049059]\n",
      " [ 0.          1.4987193   1.90375425]\n",
      " [ 0.         -0.90605436 -0.88796855]\n",
      " [ 0.          0.07393112  0.82513507]\n",
      " [ 0.          0.45575633  0.31484147]\n",
      " [ 0.          0.98172876 -0.51315513]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #80 | lambda learn rate = 0.001\n",
      "Target = [[0.]\n",
      " [3.]]\n",
      "lambda end of trial = [[ 0.          0.29104501 -0.22273009]\n",
      " [ 0.         -1.03627288 -1.40785625]\n",
      " [ 0.         -0.38375281  0.32553635]\n",
      " [ 0.          0.14355188 -0.62722577]\n",
      " [ 0.         -0.27137864 -0.28985795]\n",
      " [ 0.          1.4987193   1.89529429]\n",
      " [ 0.         -0.90605436 -0.89547674]\n",
      " [ 0.          0.07393112  0.81640337]\n",
      " [ 0.          0.45575633  0.30753512]\n",
      " [ 0.          0.98172876 -0.52161901]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #81 | lambda learn rate = 0.001\n",
      "Target = [[2.]\n",
      " [4.]]\n",
      "lambda end of trial = [[ 0.          0.29800587 -0.20880837]\n",
      " [ 0.         -1.02902559 -1.39336167]\n",
      " [ 0.         -0.37698737  0.33906724]\n",
      " [ 0.          0.1513809  -0.61156771]\n",
      " [ 0.         -0.26338668 -0.27387403]\n",
      " [ 0.          1.5064402   1.91073608]\n",
      " [ 0.         -0.89853199 -0.88043199]\n",
      " [ 0.          0.0818498   0.83224073]\n",
      " [ 0.          0.46343663  0.32289573]\n",
      " [ 0.          0.98873106 -0.5076144 ]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #82 | lambda learn rate = 0.001\n",
      "Target = [[6.]\n",
      " [9.]]\n",
      "lambda end of trial = [[ 0.          0.38794214 -0.07390396]\n",
      " [ 0.         -0.93278953 -1.24900758]\n",
      " [ 0.         -0.28080094  0.48334688]\n",
      " [ 0.          0.2414365  -0.47648431]\n",
      " [ 0.         -0.16670225 -0.1288474 ]\n",
      " [ 0.          1.60344825  2.05624816]\n",
      " [ 0.         -0.81385843 -0.75342166]\n",
      " [ 0.          0.18434101  0.98597754]\n",
      " [ 0.          0.55833388  0.46524159]\n",
      " [ 0.          1.08603269 -0.36166196]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #83 | lambda learn rate = 0.001\n",
      "Target = [[8.]\n",
      " [0.]]\n",
      "lambda end of trial = [[ 0.          0.20770435 -0.07390396]\n",
      " [ 0.         -1.10926322 -1.24900758]\n",
      " [ 0.         -0.45319442  0.48334688]\n",
      " [ 0.          0.05978066 -0.47648431]\n",
      " [ 0.         -0.35318659 -0.1288474 ]\n",
      " [ 0.          1.41695427  2.05624816]\n",
      " [ 0.         -1.00154429 -0.75342166]\n",
      " [ 0.         -0.01171863  0.98597754]\n",
      " [ 0.          0.39164478  0.46524159]\n",
      " [ 0.          0.87940594 -0.36166196]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #84 | lambda learn rate = 0.001\n",
      "Target = [[5.]\n",
      " [0.]]\n",
      "lambda end of trial = [[ 0.          0.27230922 -0.07390396]\n",
      " [ 0.         -1.04637778 -1.24900758]\n",
      " [ 0.         -0.38404099  0.48334688]\n",
      " [ 0.          0.12079932 -0.47648431]\n",
      " [ 0.         -0.28481329 -0.1288474 ]\n",
      " [ 0.          1.48077507  2.05624816]\n",
      " [ 0.         -0.93982574 -0.75342166]\n",
      " [ 0.          0.0573942   0.98597754]\n",
      " [ 0.          0.45640285  0.46524159]\n",
      " [ 0.          0.94652329 -0.36166196]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #85 | lambda learn rate = 0.001\n",
      "Target = [[1.]\n",
      " [7.]]\n",
      "lambda end of trial = [[ 0.          0.24727432 -0.24914824]\n",
      " [ 0.         -1.07122712 -1.4229529 ]\n",
      " [ 0.         -0.40853428  0.31189389]\n",
      " [ 0.          0.09589522 -0.65081301]\n",
      " [ 0.         -0.30921528 -0.29966136]\n",
      " [ 0.          1.45696903  1.88960588]\n",
      " [ 0.         -0.96672047 -0.94168474]\n",
      " [ 0.          0.03052841  0.79791702]\n",
      " [ 0.          0.43121689  0.28893985]\n",
      " [ 0.          0.92245878 -0.53011358]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #86 | lambda learn rate = 0.001\n",
      "Target = [[8.]\n",
      " [7.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda end of trial = [[ 0.          0.5114556  -0.01798962]\n",
      " [ 0.         -0.78536645 -1.17282481]\n",
      " [ 0.         -0.12562083  0.55944315]\n",
      " [ 0.          0.33721899 -0.43965471]\n",
      " [ 0.         -0.0454571  -0.06887295]\n",
      " [ 0.          1.74923024  2.14533444]\n",
      " [ 0.         -0.68584294 -0.6959169 ]\n",
      " [ 0.          0.30188063  1.03535021]\n",
      " [ 0.          0.72378191  0.54493425]\n",
      " [ 0.          1.19327223 -0.29315181]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #87 | lambda learn rate = 0.001\n",
      "Target = [[5.]\n",
      " [4.]]\n",
      "lambda end of trial = [[ 0.          0.20515818 -0.26302756]\n",
      " [ 0.         -1.09564308 -1.42104612]\n",
      " [ 0.         -0.42567252  0.3194018 ]\n",
      " [ 0.          0.07037815 -0.65312738]\n",
      " [ 0.         -0.30845075 -0.27926787]\n",
      " [ 0.          1.437524    1.89596944]\n",
      " [ 0.         -0.96810382 -0.92172561]\n",
      " [ 0.          0.02163151  0.81115092]\n",
      " [ 0.          0.42338745  0.30461867]\n",
      " [ 0.          0.90712381 -0.52207054]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #88 | lambda learn rate = 0.001\n",
      "Target = [[8.]\n",
      " [9.]]\n",
      "lambda end of trial = [[ 0.          0.55987118  0.13602457]\n",
      " [ 0.         -0.717132   -0.99522115]\n",
      " [ 0.         -0.03584273  0.75796032]\n",
      " [ 0.          0.41206604 -0.26872851]\n",
      " [ 0.          0.05717836  0.13206488]\n",
      " [ 0.          1.81654279  2.32236559]\n",
      " [ 0.         -0.58316866 -0.48867355]\n",
      " [ 0.          0.35947951  1.19122992]\n",
      " [ 0.          0.75836946  0.68147344]\n",
      " [ 0.          1.24216496 -0.14514925]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #89 | lambda learn rate = 0.001\n",
      "Target = [[1.]\n",
      " [8.]]\n",
      "lambda end of trial = [[ 0.          0.45941312 -0.66763995]\n",
      " [ 0.         -0.81975116 -1.81617441]\n",
      " [ 0.         -0.13324736 -0.02127674]\n",
      " [ 0.          0.30496192 -1.12556142]\n",
      " [ 0.         -0.05416169 -0.75865549]\n",
      " [ 0.          1.70862645  1.45903482]\n",
      " [ 0.         -0.68355362 -1.29175324]\n",
      " [ 0.          0.24824982  0.30139243]\n",
      " [ 0.          0.66547379 -0.06169196]\n",
      " [ 0.          1.14891842 -0.89112157]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #90 | lambda learn rate = 0.001\n",
      "Target = [[0.]\n",
      " [8.]]\n",
      "lambda end of trial = [[ 0.          0.45941312  0.24392961]\n",
      " [ 0.         -0.81975116 -0.74855546]\n",
      " [ 0.         -0.13324736  1.03632716]\n",
      " [ 0.          0.30496192 -0.33413599]\n",
      " [ 0.         -0.05416169  0.23652801]\n",
      " [ 0.          1.70862645  2.3916382 ]\n",
      " [ 0.         -0.68355362 -0.32685691]\n",
      " [ 0.          0.24824982  1.30949017]\n",
      " [ 0.          0.66547379  0.96858116]\n",
      " [ 0.          1.14891842  0.11343692]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #91 | lambda learn rate = 0.001\n",
      "Target = [[8.]\n",
      " [0.]]\n",
      "lambda end of trial = [[ 0.          0.08654386  0.24392961]\n",
      " [ 0.         -1.19667238 -0.74855546]\n",
      " [ 0.         -0.49979546  1.03632716]\n",
      " [ 0.         -0.07218355 -0.33413599]\n",
      " [ 0.         -0.46038202  0.23652801]\n",
      " [ 0.          1.35849937  2.3916382 ]\n",
      " [ 0.         -1.07038001 -0.32685691]\n",
      " [ 0.         -0.11817317  1.30949017]\n",
      " [ 0.          0.27082671  0.96858116]\n",
      " [ 0.          0.76460262  0.11343692]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #92 | lambda learn rate = 0.001\n",
      "Target = [[2.]\n",
      " [8.]]\n",
      "lambda end of trial = [[ 0.         -0.15478555 -0.721388  ]\n",
      " [ 0.         -1.43807105 -1.71415011]\n",
      " [ 0.         -0.75560853  0.01307489]\n",
      " [ 0.         -0.32142375 -1.33109676]\n",
      " [ 0.         -0.7217747  -0.80904273]\n",
      " [ 0.          1.08001938  1.2777182 ]\n",
      " [ 0.         -1.32697337 -1.35323037]\n",
      " [ 0.         -0.39940945  0.18454503]\n",
      " [ 0.          0.0318559   0.01269792]\n",
      " [ 0.          0.52771518 -0.83411287]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #93 | lambda learn rate = 0.001\n",
      "Target = [[9.]\n",
      " [2.]]\n",
      "lambda end of trial = [[ 0.          1.34429079 -0.38825992]\n",
      " [ 0.          0.24343208 -1.34048275]\n",
      " [ 0.          0.63536215  0.32217949]\n",
      " [ 0.          1.15391315 -1.00324412]\n",
      " [ 0.          0.62792615 -0.50910921]\n",
      " [ 0.          2.44967746  1.58208667]\n",
      " [ 0.          0.01918442 -1.05408419]\n",
      " [ 0.          1.0909902   0.51574495]\n",
      " [ 0.          1.59178362  0.35934853]\n",
      " [ 0.          1.94303969 -0.51959632]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #94 | lambda learn rate = 0.001\n",
      "Target = [[6.]\n",
      " [7.]]\n",
      "lambda end of trial = [[ 0.          0.43124148 -1.45348412]\n",
      " [ 0.         -0.73150274 -2.4779067 ]\n",
      " [ 0.         -0.23477385 -0.69297917]\n",
      " [ 0.          0.15583208 -2.16767204]\n",
      " [ 0.         -0.30662916 -1.59942373]\n",
      " [ 0.          1.55930935  0.54332388]\n",
      " [ 0.         -0.88906535 -2.11370892]\n",
      " [ 0.          0.14677048 -0.58584472]\n",
      " [ 0.          0.66005474 -0.7276685 ]\n",
      " [ 0.          1.03744049 -1.57612871]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #95 | lambda learn rate = 0.001\n",
      "Target = [[0.]\n",
      " [3.]]\n",
      "lambda end of trial = [[ 0.          0.43124148 -1.14085643]\n",
      " [ 0.         -0.73150274 -2.16938093]\n",
      " [ 0.         -0.23477385 -0.36067442]\n",
      " [ 0.          0.15583208 -1.84561373]\n",
      " [ 0.         -0.30662916 -1.26676433]\n",
      " [ 0.          1.55930935  0.89505682]\n",
      " [ 0.         -0.88906535 -1.78640962]\n",
      " [ 0.          0.14677048 -0.19384847]\n",
      " [ 0.          0.66005474 -0.39023919]\n",
      " [ 0.          1.03744049 -1.22524622]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #96 | lambda learn rate = 0.001\n",
      "Target = [[0.]\n",
      " [7.]]\n",
      "lambda end of trial = [[ 0.          0.43124148  0.35837703]\n",
      " [ 0.         -0.73150274 -0.60182522]\n",
      " [ 0.         -0.23477385  1.28327835]\n",
      " [ 0.          0.15583208 -0.33760669]\n",
      " [ 0.         -0.30662916  0.32712737]\n",
      " [ 0.          1.55930935  2.35998717]\n",
      " [ 0.         -0.88906535 -0.4331853 ]\n",
      " [ 0.          0.14677048  1.34045095]\n",
      " [ 0.          0.66005474  1.21829244]\n",
      " [ 0.          1.03744049  0.30226463]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #97 | lambda learn rate = 0.001\n",
      "Target = [[9.]\n",
      " [8.]]\n",
      "lambda end of trial = [[ 0.         -1.14626601 -1.04385185]\n",
      " [ 0.         -2.49161572 -2.16637009]\n",
      " [ 0.         -1.85715524 -0.15883844]\n",
      " [ 0.         -1.25561314 -1.59222466]\n",
      " [ 0.         -1.99342627 -1.17224784]\n",
      " [ 0.         -0.0344961   0.94327121]\n",
      " [ 0.         -2.37770484 -1.75642041]\n",
      " [ 0.         -1.38638535 -0.02235423]\n",
      " [ 0.         -1.00669509 -0.26326297]\n",
      " [ 0.         -0.61517242 -1.16672463]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #98 | lambda learn rate = 0.001\n",
      "Target = [[3.]\n",
      " [7.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda end of trial = [[ 0.         -0.14886359  1.28342046]\n",
      " [ 0.         -1.50863953  0.12724102]\n",
      " [ 0.         -0.78776941  2.33639517]\n",
      " [ 0.         -0.22914341  0.80287137]\n",
      " [ 0.         -0.90612215  1.3647951 ]\n",
      " [ 0.          0.98187673  3.31480782]\n",
      " [ 0.         -1.32018524  0.71112532]\n",
      " [ 0.         -0.3521271   2.39091503]\n",
      " [ 0.          0.07446371  2.25944092]\n",
      " [ 0.          0.40306914  1.20917236]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "+++++++++++++++++++++++++++++++++++\n",
      "Session #2\n",
      "target at trial 0 = [[1.]\n",
      " [1.]]\n",
      "K MATX INIT= [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "A VECT INIT = [-0. -0.]\n",
      "lambda\n",
      "[[ 0.          0.17569819 -0.1168215 ]\n",
      " [ 0.          0.17094785  0.05671689]\n",
      " [ 0.         -0.13660684  0.34736166]\n",
      " [ 0.          0.39038693 -0.30734903]\n",
      " [ 0.          0.07484879  0.16279938]\n",
      " [ 0.          0.06604893  0.12726184]\n",
      " [ 0.         -0.35233706  0.44135871]\n",
      " [ 0.         -0.15102956  0.35740288]\n",
      " [ 0.          0.23767146 -0.14068682]\n",
      " [ 0.          0.63275023 -0.52240076]]\n",
      "a\n",
      "[-0. -0.]\n",
      "K\n",
      "[[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #0 | lambda learn rate = 0.001\n",
      "Target = [[1.]\n",
      " [1.]]\n",
      "lambda end of trial = [[ 0.          0.16781354 -0.12470615]\n",
      " [ 0.          0.16283253  0.04860157]\n",
      " [ 0.         -0.1443603   0.3396082 ]\n",
      " [ 0.          0.38373929 -0.31399667]\n",
      " [ 0.          0.06734919  0.15529977]\n",
      " [ 0.          0.05799099  0.11920389]\n",
      " [ 0.         -0.3602844   0.43341137]\n",
      " [ 0.         -0.1581057   0.35032674]\n",
      " [ 0.          0.23029427 -0.14806401]\n",
      " [ 0.          0.62529255 -0.52985844]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #1 | lambda learn rate = 0.001\n",
      "Target = [[2.]\n",
      " [1.]]\n",
      "lambda end of trial = [[ 0.          0.15502554 -0.13110015]\n",
      " [ 0.          0.14958762  0.04197911]\n",
      " [ 0.         -0.15809805  0.33273933]\n",
      " [ 0.          0.36894345 -0.32139459]\n",
      " [ 0.          0.0537462   0.14849828]\n",
      " [ 0.          0.04354107  0.11197894]\n",
      " [ 0.         -0.37364066  0.42673325]\n",
      " [ 0.         -0.17171601  0.34352159]\n",
      " [ 0.          0.21453633 -0.15594298]\n",
      " [ 0.          0.61010974 -0.53744984]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #2 | lambda learn rate = 0.001\n",
      "Target = [[4.]\n",
      " [5.]]\n",
      "lambda end of trial = [[ 0.          0.14074433 -0.14895166]\n",
      " [ 0.          0.13172524  0.01965114]\n",
      " [ 0.         -0.17584552  0.310555  ]\n",
      " [ 0.          0.35345919 -0.34074992]\n",
      " [ 0.          0.03676453  0.12727118]\n",
      " [ 0.          0.02536171  0.08925473]\n",
      " [ 0.         -0.38797677  0.40881311]\n",
      " [ 0.         -0.18727948  0.32406724]\n",
      " [ 0.          0.19855713 -0.17591697]\n",
      " [ 0.          0.59548989 -0.55572466]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #3 | lambda learn rate = 0.001\n",
      "Target = [[4.]\n",
      " [4.]]\n",
      "lambda end of trial = [[ 0.          0.14499057 -0.14470543]\n",
      " [ 0.          0.13504527  0.02297116]\n",
      " [ 0.         -0.17259951  0.31380101]\n",
      " [ 0.          0.35707794 -0.33713117]\n",
      " [ 0.          0.03977858  0.13028524]\n",
      " [ 0.          0.02900528  0.0928983 ]\n",
      " [ 0.         -0.38394234  0.41284753]\n",
      " [ 0.         -0.18345442  0.32789231]\n",
      " [ 0.          0.2023791  -0.172095  ]\n",
      " [ 0.          0.5989711  -0.55224345]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #4 | lambda learn rate = 0.001\n",
      "Target = [[6.]\n",
      " [4.]]\n",
      "lambda end of trial = [[ 0.          0.15973516 -0.1348757 ]\n",
      " [ 0.          0.14659827  0.03067316]\n",
      " [ 0.         -0.16132975  0.32131418]\n",
      " [ 0.          0.37148966 -0.32752335]\n",
      " [ 0.          0.0532606   0.13927325]\n",
      " [ 0.          0.04293279  0.10218331]\n",
      " [ 0.         -0.37054703  0.42177774]\n",
      " [ 0.         -0.16878533  0.3376717 ]\n",
      " [ 0.          0.21572724 -0.16319624]\n",
      " [ 0.          0.61277629 -0.54303999]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #5 | lambda learn rate = 0.001\n",
      "Target = [[7.]\n",
      " [2.]]\n",
      "lambda end of trial = [[ 0.          0.1455158  -0.13893837]\n",
      " [ 0.          0.13076994  0.02615079]\n",
      " [ 0.         -0.18147607  0.31555808]\n",
      " [ 0.          0.35433036 -0.33242601]\n",
      " [ 0.          0.03372277  0.13369101]\n",
      " [ 0.          0.02697736  0.09762462]\n",
      " [ 0.         -0.38157675  0.41862639]\n",
      " [ 0.         -0.18608547  0.3327288 ]\n",
      " [ 0.          0.20083478 -0.16745123]\n",
      " [ 0.          0.59712519 -0.54751173]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #6 | lambda learn rate = 0.001\n",
      "Target = [[5.]\n",
      " [6.]]\n",
      "lambda end of trial = [[ 0.          0.15892436 -0.12284811]\n",
      " [ 0.          0.1447024   0.04286973]\n",
      " [ 0.         -0.16614764  0.33395221]\n",
      " [ 0.          0.36922544 -0.31455191]\n",
      " [ 0.          0.04826278  0.15113903]\n",
      " [ 0.          0.0398391   0.1130587 ]\n",
      " [ 0.         -0.366199    0.43707969]\n",
      " [ 0.         -0.17094493  0.35089745]\n",
      " [ 0.          0.21719309 -0.14782127]\n",
      " [ 0.          0.6118004  -0.52990147]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #7 | lambda learn rate = 0.001\n",
      "Target = [[2.]\n",
      " [5.]]\n",
      "lambda end of trial = [[ 0.          0.1466767  -0.15346724]\n",
      " [ 0.          0.13147058  0.00979018]\n",
      " [ 0.         -0.17894552  0.30195751]\n",
      " [ 0.          0.35671624 -0.34582492]\n",
      " [ 0.          0.03500831  0.11800286]\n",
      " [ 0.          0.02628409  0.07917118]\n",
      " [ 0.         -0.37831125  0.40679907]\n",
      " [ 0.         -0.18435226  0.31737912]\n",
      " [ 0.          0.20408526 -0.18059082]\n",
      " [ 0.          0.60018592 -0.55893768]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #8 | lambda learn rate = 0.001\n",
      "Target = [[6.]\n",
      " [3.]]\n",
      "lambda end of trial = [[ 0.          0.16289226 -0.14535947]\n",
      " [ 0.          0.14760268  0.01785623]\n",
      " [ 0.         -0.16253123  0.31016466]\n",
      " [ 0.          0.37214146 -0.33811231]\n",
      " [ 0.          0.05048183  0.12573962]\n",
      " [ 0.          0.04115037  0.08660432]\n",
      " [ 0.         -0.36142598  0.4152417 ]\n",
      " [ 0.         -0.17130412  0.32390319]\n",
      " [ 0.          0.22031625 -0.17247533]\n",
      " [ 0.          0.61646922 -0.55079603]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #9 | lambda learn rate = 0.001\n",
      "Target = [[0.]\n",
      " [9.]]\n",
      "lambda end of trial = [[ 0.          0.16289226 -0.12983711]\n",
      " [ 0.          0.14760268  0.03054996]\n",
      " [ 0.         -0.16253123  0.3226025 ]\n",
      " [ 0.          0.37214146 -0.32241742]\n",
      " [ 0.          0.05048183  0.13831296]\n",
      " [ 0.          0.04115037  0.09971765]\n",
      " [ 0.         -0.36142598  0.42954955]\n",
      " [ 0.         -0.17130412  0.33566373]\n",
      " [ 0.          0.22031625 -0.16078691]\n",
      " [ 0.          0.61646922 -0.53803702]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #10 | lambda learn rate = 0.001\n",
      "Target = [[0.]\n",
      " [6.]]\n",
      "lambda end of trial = [[ 0.          0.16289226 -0.15239938]\n",
      " [ 0.          0.14760268  0.00294682]\n",
      " [ 0.         -0.16253123  0.29295681]\n",
      " [ 0.          0.37214146 -0.34556541]\n",
      " [ 0.          0.05048183  0.11315627]\n",
      " [ 0.          0.04115037  0.07328273]\n",
      " [ 0.         -0.36142598  0.4072495 ]\n",
      " [ 0.         -0.17130412  0.30884001]\n",
      " [ 0.          0.22031625 -0.18249894]\n",
      " [ 0.          0.61646922 -0.56274204]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #11 | lambda learn rate = 0.001\n",
      "Target = [[6.]\n",
      " [1.]]\n",
      "lambda end of trial = [[ 0.00000000e+00  1.47797549e-01 -1.54915168e-01]\n",
      " [ 0.00000000e+00  1.27817053e-01 -3.50783043e-04]\n",
      " [ 0.00000000e+00 -1.77731535e-01  2.90423423e-01]\n",
      " [ 0.00000000e+00  3.54687325e-01 -3.48474431e-01]\n",
      " [ 0.00000000e+00  3.28634954e-02  1.10219880e-01]\n",
      " [ 0.00000000e+00  2.45686092e-02  7.05191049e-02]\n",
      " [ 0.00000000e+00 -3.76887502e-01  4.04672579e-01]\n",
      " [ 0.00000000e+00 -1.90610647e-01  3.05622260e-01]\n",
      " [ 0.00000000e+00  2.05253381e-01 -1.85009419e-01]\n",
      " [ 0.00000000e+00  5.99618525e-01 -5.65550494e-01]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #12 | lambda learn rate = 0.001\n",
      "Target = [[2.]\n",
      " [5.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda end of trial = [[ 0.          0.15281425 -0.14237342]\n",
      " [ 0.          0.13156647  0.00902275]\n",
      " [ 0.         -0.17329497  0.30151484]\n",
      " [ 0.          0.35868873 -0.33847092]\n",
      " [ 0.          0.03688895  0.12028351]\n",
      " [ 0.          0.02841698  0.08014002]\n",
      " [ 0.         -0.37292872  0.41456954]\n",
      " [ 0.         -0.18664592  0.31553407]\n",
      " [ 0.          0.20998562 -0.17317883]\n",
      " [ 0.          0.60429298 -0.55386436]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #13 | lambda learn rate = 0.001\n",
      "Target = [[1.]\n",
      " [4.]]\n",
      "lambda end of trial = [[ 0.          0.15069829 -0.15083727]\n",
      " [ 0.          0.12912033 -0.0007618 ]\n",
      " [ 0.         -0.17559779  0.29230354]\n",
      " [ 0.          0.3566096  -0.34678743]\n",
      " [ 0.          0.03471858  0.11160204]\n",
      " [ 0.          0.02623219  0.07140086]\n",
      " [ 0.         -0.37475129  0.40727927]\n",
      " [ 0.         -0.18909526  0.30573672]\n",
      " [ 0.          0.20780395 -0.18190551]\n",
      " [ 0.          0.60223964 -0.56207773]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #14 | lambda learn rate = 0.001\n",
      "Target = [[6.]\n",
      " [5.]]\n",
      "lambda end of trial = [[ 0.          0.18956656 -0.11844704]\n",
      " [ 0.          0.16356908  0.02794549]\n",
      " [ 0.         -0.1339922   0.32697487]\n",
      " [ 0.          0.39443049 -0.31527002]\n",
      " [ 0.          0.0755382   0.14561838]\n",
      " [ 0.          0.06329243  0.1022844 ]\n",
      " [ 0.         -0.33725429  0.43852677]\n",
      " [ 0.         -0.15221262  0.33647226]\n",
      " [ 0.          0.24381697 -0.15189466]\n",
      " [ 0.          0.6459438  -0.5256576 ]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #15 | lambda learn rate = 0.001\n",
      "Target = [[9.]\n",
      " [9.]]\n",
      "lambda end of trial = [[ 0.          0.15648336 -0.15153024]\n",
      " [ 0.          0.12851627 -0.00710732]\n",
      " [ 0.         -0.17450723  0.28645983]\n",
      " [ 0.          0.35539468 -0.35430583]\n",
      " [ 0.          0.03432122  0.10440141]\n",
      " [ 0.          0.02155322  0.06054518]\n",
      " [ 0.         -0.37502277  0.40075829]\n",
      " [ 0.         -0.18644564  0.30223924]\n",
      " [ 0.          0.20611935 -0.18959227]\n",
      " [ 0.          0.61267518 -0.55892622]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #16 | lambda learn rate = 0.001\n",
      "Target = [[3.]\n",
      " [6.]]\n",
      "lambda end of trial = [[ 0.          0.17163827 -0.12122043]\n",
      " [ 0.          0.1440702   0.02400053]\n",
      " [ 0.         -0.15744444  0.32058542]\n",
      " [ 0.          0.37260504 -0.31988511]\n",
      " [ 0.          0.05070695  0.13717287]\n",
      " [ 0.          0.03798951  0.09341777]\n",
      " [ 0.         -0.3581989   0.43440602]\n",
      " [ 0.         -0.16999121  0.3351481 ]\n",
      " [ 0.          0.22220934 -0.1574123 ]\n",
      " [ 0.          0.63054744 -0.5231817 ]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #17 | lambda learn rate = 0.001\n",
      "Target = [[2.]\n",
      " [1.]]\n",
      "lambda end of trial = [[ 0.          0.15945788 -0.12731062]\n",
      " [ 0.          0.12732978  0.01563032]\n",
      " [ 0.         -0.17216706  0.31322411]\n",
      " [ 0.          0.35745502 -0.32746012]\n",
      " [ 0.          0.03510699  0.12937288]\n",
      " [ 0.          0.02341493  0.08613048]\n",
      " [ 0.         -0.3725156   0.42724767]\n",
      " [ 0.         -0.18517827  0.32755457]\n",
      " [ 0.          0.20586023 -0.16558685]\n",
      " [ 0.          0.61422943 -0.5313407 ]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #18 | lambda learn rate = 0.001\n",
      "Target = [[0.]\n",
      " [7.]]\n",
      "lambda end of trial = [[ 0.00000000e+00  1.59457885e-01 -1.40745107e-01]\n",
      " [ 0.00000000e+00  1.27329779e-01 -3.50840874e-04]\n",
      " [ 0.00000000e+00 -1.72167063e-01  2.98073248e-01]\n",
      " [ 0.00000000e+00  3.57455016e-01 -3.43176632e-01]\n",
      " [ 0.00000000e+00  3.51069854e-02  1.14222759e-01]\n",
      " [ 0.00000000e+00  2.34149330e-02  6.94659952e-02]\n",
      " [ 0.00000000e+00 -3.72515599e-01  4.13713061e-01]\n",
      " [ 0.00000000e+00 -1.85178274e-01  3.11330072e-01]\n",
      " [ 0.00000000e+00  2.05860231e-01 -1.79189109e-01]\n",
      " [ 0.00000000e+00  6.14229434e-01 -5.47105133e-01]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #19 | lambda learn rate = 0.001\n",
      "Target = [[7.]\n",
      " [9.]]\n",
      "lambda end of trial = [[ 0.          0.25683488 -0.01554611]\n",
      " [ 0.          0.21224312  0.10882346]\n",
      " [ 0.         -0.08428345  0.41106646]\n",
      " [ 0.          0.44390333 -0.2320288 ]\n",
      " [ 0.          0.12453942  0.22920732]\n",
      " [ 0.          0.10662867  0.17645509]\n",
      " [ 0.         -0.28412499  0.52735813]\n",
      " [ 0.         -0.09285028  0.43003749]\n",
      " [ 0.          0.28686936 -0.07503452]\n",
      " [ 0.          0.69894462 -0.43818561]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #20 | lambda learn rate = 0.001\n",
      "Target = [[5.]\n",
      " [0.]]\n",
      "lambda end of trial = [[ 0.          0.17387689 -0.01554611]\n",
      " [ 0.          0.12603358  0.10882346]\n",
      " [ 0.         -0.17742133  0.41106646]\n",
      " [ 0.          0.35831382 -0.2320288 ]\n",
      " [ 0.          0.04683248  0.22920732]\n",
      " [ 0.          0.02652063  0.17645509]\n",
      " [ 0.         -0.36192571  0.52735813]\n",
      " [ 0.         -0.17332045  0.43003749]\n",
      " [ 0.          0.20433237 -0.07503452]\n",
      " [ 0.          0.60663358 -0.43818561]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #21 | lambda learn rate = 0.001\n",
      "Target = [[7.]\n",
      " [3.]]\n",
      "lambda end of trial = [[ 0.          0.11438171 -0.04104405]\n",
      " [ 0.          0.06699883  0.08352285]\n",
      " [ 0.         -0.23732908  0.38539171]\n",
      " [ 0.          0.29646209 -0.25853669]\n",
      " [ 0.         -0.01816973  0.20134923]\n",
      " [ 0.         -0.03571999  0.14978053]\n",
      " [ 0.         -0.4210535   0.50201765]\n",
      " [ 0.         -0.22861792  0.40633858]\n",
      " [ 0.          0.1475691  -0.09936163]\n",
      " [ 0.          0.54077325 -0.46641147]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #22 | lambda learn rate = 0.001\n",
      "Target = [[5.]\n",
      " [1.]]\n",
      "lambda end of trial = [[ 0.          0.13954448 -0.03601149]\n",
      " [ 0.          0.08919281  0.08796165]\n",
      " [ 0.         -0.21220655  0.39041621]\n",
      " [ 0.          0.32117516 -0.25359407]\n",
      " [ 0.          0.00638796  0.20626076]\n",
      " [ 0.         -0.01255581  0.15441337]\n",
      " [ 0.         -0.39390888  0.50744657]\n",
      " [ 0.         -0.20596216  0.41086973]\n",
      " [ 0.          0.17129483 -0.09461649]\n",
      " [ 0.          0.56605125 -0.46135587]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #23 | lambda learn rate = 0.001\n",
      "Target = [[1.]\n",
      " [8.]]\n",
      "lambda end of trial = [[ 0.          0.12105108 -0.18395864]\n",
      " [ 0.          0.06915618 -0.07233141]\n",
      " [ 0.         -0.22915239  0.25484953]\n",
      " [ 0.          0.30343463 -0.39551829]\n",
      " [ 0.         -0.01032778  0.07253486]\n",
      " [ 0.         -0.03071944  0.00910431]\n",
      " [ 0.         -0.41331842  0.35217027]\n",
      " [ 0.         -0.22285722  0.27570929]\n",
      " [ 0.          0.15391899 -0.23362322]\n",
      " [ 0.          0.54766637 -0.60843494]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #24 | lambda learn rate = 0.001\n",
      "Target = [[5.]\n",
      " [6.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda end of trial = [[ 0.          0.23991284 -0.04132453]\n",
      " [ 0.          0.18763054  0.06983783]\n",
      " [ 0.         -0.11234352  0.39502018]\n",
      " [ 0.          0.41937323 -0.25639197]\n",
      " [ 0.          0.1005053   0.20553456]\n",
      " [ 0.          0.08908081  0.15286461]\n",
      " [ 0.         -0.29448515  0.49477019]\n",
      " [ 0.         -0.10063873  0.42237147]\n",
      " [ 0.          0.26503182 -0.10028782]\n",
      " [ 0.          0.67867703 -0.45122215]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #25 | lambda learn rate = 0.001\n",
      "Target = [[3.]\n",
      " [1.]]\n",
      "lambda end of trial = [[ 0.          0.20000734 -0.05462637]\n",
      " [ 0.          0.14481722  0.05556672]\n",
      " [ 0.         -0.15677545  0.38020953]\n",
      " [ 0.          0.37899167 -0.26985249]\n",
      " [ 0.          0.0574263   0.19117489]\n",
      " [ 0.          0.04583156  0.13844819]\n",
      " [ 0.         -0.33673395  0.48068726]\n",
      " [ 0.         -0.13909292  0.40955341]\n",
      " [ 0.          0.22659405 -0.11310041]\n",
      " [ 0.          0.63790776 -0.46481191]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #26 | lambda learn rate = 0.001\n",
      "Target = [[4.]\n",
      " [3.]]\n",
      "lambda end of trial = [[ 0.          0.15564699 -0.08789663]\n",
      " [ 0.          0.10485453  0.0255947 ]\n",
      " [ 0.         -0.20457044  0.34436329]\n",
      " [ 0.          0.34221638 -0.29743395]\n",
      " [ 0.          0.01018752  0.15574581]\n",
      " [ 0.          0.00202257  0.10559145]\n",
      " [ 0.         -0.3795887   0.44854619]\n",
      " [ 0.         -0.1832045   0.37646973]\n",
      " [ 0.          0.18633198 -0.14329696]\n",
      " [ 0.          0.59751191 -0.49510879]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #27 | lambda learn rate = 0.001\n",
      "Target = [[8.]\n",
      " [8.]]\n",
      "lambda end of trial = [[ 0.          0.20059469 -0.04294893]\n",
      " [ 0.          0.15050506  0.07124523]\n",
      " [ 0.         -0.15628521  0.39264852]\n",
      " [ 0.          0.38792145 -0.25172889]\n",
      " [ 0.          0.05233278  0.19789106]\n",
      " [ 0.          0.047462    0.15103088]\n",
      " [ 0.         -0.33168604  0.49644885]\n",
      " [ 0.         -0.1369226   0.42275163]\n",
      " [ 0.          0.23120657 -0.09842237]\n",
      " [ 0.          0.64407554 -0.44854517]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #28 | lambda learn rate = 0.001\n",
      "Target = [[0.]\n",
      " [8.]]\n",
      "lambda end of trial = [[ 0.          0.20059469 -0.19812844]\n",
      " [ 0.          0.15050506 -0.09190113]\n",
      " [ 0.         -0.15628521  0.21617494]\n",
      " [ 0.          0.38792145 -0.42118398]\n",
      " [ 0.          0.05233278  0.03555182]\n",
      " [ 0.          0.047462   -0.03264088]\n",
      " [ 0.         -0.33168604  0.34432279]\n",
      " [ 0.         -0.1369226   0.26266219]\n",
      " [ 0.          0.23120657 -0.26165235]\n",
      " [ 0.          0.64407554 -0.6112786 ]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #29 | lambda learn rate = 0.001\n",
      "Target = [[7.]\n",
      " [8.]]\n",
      "lambda end of trial = [[ 0.          0.37705542  0.00354098]\n",
      " [ 0.          0.31429393  0.09528615]\n",
      " [ 0.          0.01962693  0.41721738]\n",
      " [ 0.          0.55412099 -0.23124165]\n",
      " [ 0.          0.23070274  0.2394032 ]\n",
      " [ 0.          0.20944596  0.15248365]\n",
      " [ 0.         -0.15635134  0.54470531]\n",
      " [ 0.          0.04701009  0.47287098]\n",
      " [ 0.          0.39860257 -0.07034263]\n",
      " [ 0.          0.81232049 -0.41899865]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #30 | lambda learn rate = 0.001\n",
      "Target = [[0.]\n",
      " [6.]]\n",
      "lambda end of trial = [[ 0.          0.37705542 -0.14043663]\n",
      " [ 0.          0.31429393 -0.04686812]\n",
      " [ 0.          0.01962693  0.26512897]\n",
      " [ 0.          0.55412099 -0.3570115 ]\n",
      " [ 0.          0.23070274  0.07832478]\n",
      " [ 0.          0.20944596 -0.00205214]\n",
      " [ 0.         -0.15635134  0.40970091]\n",
      " [ 0.          0.04701009  0.33054383]\n",
      " [ 0.          0.39860257 -0.20656431]\n",
      " [ 0.          0.81232049 -0.56130978]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #31 | lambda learn rate = 0.001\n",
      "Target = [[3.]\n",
      " [3.]]\n",
      "lambda end of trial = [[ 0.          0.32558569 -0.19190637]\n",
      " [ 0.          0.25834026 -0.10282179]\n",
      " [ 0.         -0.0401335   0.20536853]\n",
      " [ 0.          0.50453258 -0.40659991]\n",
      " [ 0.          0.17394728  0.02156931]\n",
      " [ 0.          0.15649925 -0.05499885]\n",
      " [ 0.         -0.21738431  0.34866795]\n",
      " [ 0.         -0.009995    0.27353874]\n",
      " [ 0.          0.34557216 -0.25959472]\n",
      " [ 0.          0.75638344 -0.61724684]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #32 | lambda learn rate = 0.001\n",
      "Target = [[9.]\n",
      " [6.]]\n",
      "lambda end of trial = [[ 0.          0.19931648 -0.27608584]\n",
      " [ 0.          0.12839654 -0.18945094]\n",
      " [ 0.         -0.16425847  0.12261855]\n",
      " [ 0.          0.36413608 -0.50019758]\n",
      " [ 0.          0.04546632 -0.06408466]\n",
      " [ 0.          0.01874157 -0.1468373 ]\n",
      " [ 0.         -0.33286001  0.27168414]\n",
      " [ 0.         -0.13401806  0.19085669]\n",
      " [ 0.          0.21019561 -0.34984575]\n",
      " [ 0.          0.63761582 -0.69642525]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #33 | lambda learn rate = 0.001\n",
      "Target = [[1.]\n",
      " [6.]]\n",
      "lambda end of trial = [[ 0.          0.23479077 -0.06324007]\n",
      " [ 0.          0.16766327  0.04614944]\n",
      " [ 0.         -0.13155935  0.31881326]\n",
      " [ 0.          0.40077821 -0.28034476]\n",
      " [ 0.          0.07925268  0.13863348]\n",
      " [ 0.          0.05425418  0.06623835]\n",
      " [ 0.         -0.30107111  0.46241752]\n",
      " [ 0.         -0.09591131  0.41949723]\n",
      " [ 0.          0.2451281  -0.1402508 ]\n",
      " [ 0.          0.67268372 -0.48601787]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #34 | lambda learn rate = 0.001\n",
      "Target = [[4.]\n",
      " [4.]]\n",
      "lambda end of trial = [[ 0.          0.19580848 -0.10222236]\n",
      " [ 0.          0.12269549  0.00118165]\n",
      " [ 0.         -0.17963555  0.27073707]\n",
      " [ 0.          0.35569422 -0.32542875]\n",
      " [ 0.          0.02986762  0.08924842]\n",
      " [ 0.          0.00372014  0.01570431]\n",
      " [ 0.         -0.34449902  0.41898961]\n",
      " [ 0.         -0.13772098  0.37768756]\n",
      " [ 0.          0.20037105 -0.18500785]\n",
      " [ 0.          0.62881197 -0.52988961]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #35 | lambda learn rate = 0.001\n",
      "Target = [[5.]\n",
      " [1.]]\n",
      "lambda end of trial = [[ 0.          0.18505171 -0.10437372]\n",
      " [ 0.          0.10990223 -0.001377  ]\n",
      " [ 0.         -0.19114984  0.26843421]\n",
      " [ 0.          0.34393423 -0.32778074]\n",
      " [ 0.          0.01705367  0.08668563]\n",
      " [ 0.         -0.00830398  0.01329949]\n",
      " [ 0.         -0.35417288  0.41705484]\n",
      " [ 0.         -0.15001698  0.37522836]\n",
      " [ 0.          0.18989461 -0.18710314]\n",
      " [ 0.          0.61746294 -0.53215942]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #36 | lambda learn rate = 0.001\n",
      "Target = [[8.]\n",
      " [5.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda end of trial = [[ 0.          0.2691328  -0.05182304]\n",
      " [ 0.          0.18999399  0.04868035]\n",
      " [ 0.         -0.11172985  0.3180717 ]\n",
      " [ 0.          0.42589114 -0.27655768]\n",
      " [ 0.          0.10307573  0.14044942]\n",
      " [ 0.          0.07759439  0.06698597]\n",
      " [ 0.         -0.27277057  0.46793129]\n",
      " [ 0.         -0.07031331  0.42504315]\n",
      " [ 0.          0.28128631 -0.12998333]\n",
      " [ 0.          0.68724232 -0.48854731]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #37 | lambda learn rate = 0.001\n",
      "Target = [[4.]\n",
      " [8.]]\n",
      "lambda end of trial = [[ 0.          0.21019039 -0.16970785]\n",
      " [ 0.          0.12631964 -0.07866835]\n",
      " [ 0.         -0.16983537  0.20186066]\n",
      " [ 0.          0.36906031 -0.39021935]\n",
      " [ 0.          0.0438789   0.02205575]\n",
      " [ 0.          0.01729452 -0.05361377]\n",
      " [ 0.         -0.33316364  0.34714515]\n",
      " [ 0.         -0.12976909  0.30613161]\n",
      " [ 0.          0.2258219  -0.24091214]\n",
      " [ 0.          0.62762144 -0.60778907]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #38 | lambda learn rate = 0.001\n",
      "Target = [[7.]\n",
      " [2.]]\n",
      "lambda end of trial = [[ 0.          0.23308099 -0.16316768]\n",
      " [ 0.          0.14914889 -0.07214571]\n",
      " [ 0.         -0.14673053  0.20846204]\n",
      " [ 0.          0.39268156 -0.38347042]\n",
      " [ 0.          0.06842032  0.02906759]\n",
      " [ 0.          0.03935921 -0.04730958]\n",
      " [ 0.         -0.30879958  0.35410631]\n",
      " [ 0.         -0.10360043  0.31360836]\n",
      " [ 0.          0.25000984 -0.2340013 ]\n",
      " [ 0.          0.65350123 -0.60039484]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #39 | lambda learn rate = 0.001\n",
      "Target = [[3.]\n",
      " [5.]]\n",
      "lambda end of trial = [[ 0.          0.26013642 -0.1180753 ]\n",
      " [ 0.          0.17385536 -0.03096825]\n",
      " [ 0.         -0.12049089  0.25219477]\n",
      " [ 0.          0.42003297 -0.33788473]\n",
      " [ 0.          0.09355003  0.07095042]\n",
      " [ 0.          0.06542653 -0.00386404]\n",
      " [ 0.         -0.28345436  0.39634836]\n",
      " [ 0.         -0.07598449  0.35963493]\n",
      " [ 0.          0.27442942 -0.19330199]\n",
      " [ 0.          0.68115299 -0.55430859]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #40 | lambda learn rate = 0.001\n",
      "Target = [[0.]\n",
      " [7.]]\n",
      "lambda end of trial = [[ 0.          0.26013642 -0.07470215]\n",
      " [ 0.          0.17385536  0.01065536]\n",
      " [ 0.         -0.12049089  0.29700314]\n",
      " [ 0.          0.42003297 -0.29475378]\n",
      " [ 0.          0.09355003  0.11622842]\n",
      " [ 0.          0.06542653  0.04357298]\n",
      " [ 0.         -0.28345436  0.44022399]\n",
      " [ 0.         -0.07598449  0.40501436]\n",
      " [ 0.          0.27442942 -0.14768156]\n",
      " [ 0.          0.68115299 -0.50978269]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #41 | lambda learn rate = 0.001\n",
      "Target = [[3.]\n",
      " [4.]]\n",
      "lambda end of trial = [[ 0.          0.23143941 -0.11296484]\n",
      " [ 0.          0.14385718 -0.02934222]\n",
      " [ 0.         -0.15202362  0.2549595 ]\n",
      " [ 0.          0.38807049 -0.33737041]\n",
      " [ 0.          0.06316764  0.07571857]\n",
      " [ 0.          0.03581819  0.00409519]\n",
      " [ 0.         -0.31004825  0.40476547]\n",
      " [ 0.         -0.10581579  0.3652393 ]\n",
      " [ 0.          0.24502229 -0.18689107]\n",
      " [ 0.          0.65314981 -0.54712026]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #42 | lambda learn rate = 0.001\n",
      "Target = [[4.]\n",
      " [9.]]\n",
      "lambda end of trial = [[ 0.          0.27014337 -0.02588092]\n",
      " [ 0.          0.18014587  0.05230734]\n",
      " [ 0.         -0.1128843   0.34302296]\n",
      " [ 0.          0.43162214 -0.23937919]\n",
      " [ 0.          0.10082451  0.16044652]\n",
      " [ 0.          0.07410429  0.09023893]\n",
      " [ 0.         -0.27258243  0.48906356]\n",
      " [ 0.         -0.06669745  0.45325556]\n",
      " [ 0.          0.28285579 -0.10176571]\n",
      " [ 0.          0.68913654 -0.46615012]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #43 | lambda learn rate = 0.001\n",
      "Target = [[6.]\n",
      " [4.]]\n",
      "lambda end of trial = [[ 0.          0.16082453 -0.09876014]\n",
      " [ 0.          0.06192077 -0.0265094 ]\n",
      " [ 0.         -0.22909016  0.26555239]\n",
      " [ 0.          0.32670807 -0.30932191]\n",
      " [ 0.         -0.01012157  0.08648247]\n",
      " [ 0.         -0.03939003  0.01457604]\n",
      " [ 0.         -0.38703757  0.41276014]\n",
      " [ 0.         -0.19084693  0.37048924]\n",
      " [ 0.          0.16242496 -0.18205293]\n",
      " [ 0.          0.58194687 -0.5376099 ]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #44 | lambda learn rate = 0.001\n",
      "Target = [[0.]\n",
      " [9.]]\n",
      "lambda end of trial = [[ 0.          0.16082453 -0.0359123 ]\n",
      " [ 0.          0.06192077  0.02806815]\n",
      " [ 0.         -0.22909016  0.32623779]\n",
      " [ 0.          0.32670807 -0.24720995]\n",
      " [ 0.         -0.01012157  0.14949597]\n",
      " [ 0.         -0.03939003  0.07813101]\n",
      " [ 0.         -0.38703757  0.47032465]\n",
      " [ 0.         -0.19084693  0.43187203]\n",
      " [ 0.          0.16242496 -0.12132298]\n",
      " [ 0.          0.58194687 -0.47476622]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #45 | lambda learn rate = 0.001\n",
      "Target = [[8.]\n",
      " [0.]]\n",
      "lambda end of trial = [[ 0.          0.25044634 -0.0359123 ]\n",
      " [ 0.          0.1542483   0.02806815]\n",
      " [ 0.         -0.13606043  0.32623779]\n",
      " [ 0.          0.42005277 -0.24720995]\n",
      " [ 0.          0.0805948   0.14949597]\n",
      " [ 0.          0.06374881  0.07813101]\n",
      " [ 0.         -0.29493558  0.47032465]\n",
      " [ 0.         -0.10227153  0.43187203]\n",
      " [ 0.          0.25354931 -0.12132298]\n",
      " [ 0.          0.67209265 -0.47476622]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #46 | lambda learn rate = 0.001\n",
      "Target = [[5.]\n",
      " [7.]]\n",
      "lambda end of trial = [[ 0.          0.17441529 -0.14235577]\n",
      " [ 0.          0.07811165 -0.07852317]\n",
      " [ 0.         -0.21259078  0.21909529]\n",
      " [ 0.          0.34877526 -0.34699847]\n",
      " [ 0.          0.01084733  0.05184952]\n",
      " [ 0.         -0.00565659 -0.01903655]\n",
      " [ 0.         -0.36355221  0.37426135]\n",
      " [ 0.         -0.17418387  0.33119475]\n",
      " [ 0.          0.18142336 -0.22229932]\n",
      " [ 0.          0.60600244 -0.56729253]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #47 | lambda learn rate = 0.001\n",
      "Target = [[1.]\n",
      " [9.]]\n",
      "lambda end of trial = [[ 0.          0.19385867  0.03263465]\n",
      " [ 0.          0.09876295  0.10733855]\n",
      " [ 0.         -0.19196504  0.40472699]\n",
      " [ 0.          0.37016538 -0.1544874 ]\n",
      " [ 0.          0.03186788  0.24103447]\n",
      " [ 0.          0.01250311  0.14440071]\n",
      " [ 0.         -0.3427802   0.56120948]\n",
      " [ 0.         -0.1562162   0.49290381]\n",
      " [ 0.          0.20215201 -0.03574149]\n",
      " [ 0.          0.62618444 -0.3856545 ]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #48 | lambda learn rate = 0.001\n",
      "Target = [[3.]\n",
      " [7.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda end of trial = [[ 0.          0.10890598 -0.16558831]\n",
      " [ 0.          0.01673838 -0.0840521 ]\n",
      " [ 0.         -0.2792168   0.20113955]\n",
      " [ 0.          0.28650948 -0.3496845 ]\n",
      " [ 0.         -0.05070787  0.0483577 ]\n",
      " [ 0.         -0.07551363 -0.06097168]\n",
      " [ 0.         -0.42577729  0.36754959]\n",
      " [ 0.         -0.23662965  0.30527242]\n",
      " [ 0.          0.12222432 -0.22223942]\n",
      " [ 0.          0.53927434 -0.58844473]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #49 | lambda learn rate = 0.001\n",
      "Target = [[2.]\n",
      " [4.]]\n",
      "lambda end of trial = [[ 0.          0.1327358  -0.11792867]\n",
      " [ 0.          0.04240722 -0.03271443]\n",
      " [ 0.         -0.25152989  0.25651337]\n",
      " [ 0.          0.31381944 -0.29506456]\n",
      " [ 0.         -0.02575761  0.09825824]\n",
      " [ 0.         -0.04839887 -0.00674216]\n",
      " [ 0.         -0.40065191  0.41780036]\n",
      " [ 0.         -0.20910463  0.36032247]\n",
      " [ 0.          0.14846097 -0.16976612]\n",
      " [ 0.          0.56720243 -0.53258855]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #50 | lambda learn rate = 0.001\n",
      "Target = [[8.]\n",
      " [2.]]\n",
      "lambda end of trial = [[ 0.          0.29842002 -0.07650762]\n",
      " [ 0.          0.20006394  0.00669975]\n",
      " [ 0.         -0.08316288  0.29860512]\n",
      " [ 0.          0.47368362 -0.25509852]\n",
      " [ 0.          0.14122955  0.14000503]\n",
      " [ 0.          0.1087965   0.03255668]\n",
      " [ 0.         -0.23896364  0.45822242]\n",
      " [ 0.         -0.03215368  0.4045602 ]\n",
      " [ 0.          0.29751409 -0.13250284]\n",
      " [ 0.          0.72113216 -0.49410612]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #51 | lambda learn rate = 0.001\n",
      "Target = [[2.]\n",
      " [3.]]\n",
      "lambda end of trial = [[ 0.          0.2753521  -0.1111095 ]\n",
      " [ 0.          0.17592388 -0.02951034]\n",
      " [ 0.         -0.10829833  0.26090194]\n",
      " [ 0.          0.45068226 -0.28960056]\n",
      " [ 0.          0.11824406  0.10552679]\n",
      " [ 0.          0.08521674 -0.00281296]\n",
      " [ 0.         -0.26290348  0.42231266]\n",
      " [ 0.         -0.05706799  0.36718873]\n",
      " [ 0.          0.27273029 -0.16967854]\n",
      " [ 0.          0.70039674 -0.52520925]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #52 | lambda learn rate = 0.001\n",
      "Target = [[7.]\n",
      " [4.]]\n",
      "lambda end of trial = [[ 0.          0.18739747 -0.16136928]\n",
      " [ 0.          0.09196319 -0.07748788]\n",
      " [ 0.         -0.19679139  0.21033448]\n",
      " [ 0.          0.35864971 -0.34219059]\n",
      " [ 0.          0.03430426  0.0575612 ]\n",
      " [ 0.         -0.00417777 -0.05389553]\n",
      " [ 0.         -0.35209155  0.37134805]\n",
      " [ 0.         -0.14506123  0.31690688]\n",
      " [ 0.          0.19572205 -0.21368325]\n",
      " [ 0.          0.61213399 -0.57564511]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #53 | lambda learn rate = 0.001\n",
      "Target = [[9.]\n",
      " [6.]]\n",
      "lambda end of trial = [[ 0.          0.38320372 -0.03083178]\n",
      " [ 0.          0.31901285  0.07387856]\n",
      " [ 0.         -0.00310713  0.33945732]\n",
      " [ 0.          0.55821945 -0.2091441 ]\n",
      " [ 0.          0.2489595   0.20066469]\n",
      " [ 0.          0.20008336  0.08227856]\n",
      " [ 0.         -0.15126437  0.50523284]\n",
      " [ 0.          0.07415115  0.46304847]\n",
      " [ 0.          0.40553452 -0.07380826]\n",
      " [ 0.          0.80672416 -0.44591833]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #54 | lambda learn rate = 0.001\n",
      "Target = [[5.]\n",
      " [5.]]\n",
      "lambda end of trial = [[ 0.          0.16279089 -0.25124461]\n",
      " [ 0.          0.07411595 -0.17101833]\n",
      " [ 0.         -0.23476699  0.10779746]\n",
      " [ 0.          0.33645403 -0.43090951]\n",
      " [ 0.          0.0064434  -0.04185142]\n",
      " [ 0.         -0.01870796 -0.13651277]\n",
      " [ 0.         -0.37156294  0.28493427]\n",
      " [ 0.         -0.15340634  0.23549098]\n",
      " [ 0.          0.1731932  -0.30614959]\n",
      " [ 0.          0.5868714  -0.66577109]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #55 | lambda learn rate = 0.001\n",
      "Target = [[2.]\n",
      " [0.]]\n",
      "lambda end of trial = [[ 0.          0.15322995 -0.25124461]\n",
      " [ 0.          0.06487435 -0.17101833]\n",
      " [ 0.         -0.24490979  0.10779746]\n",
      " [ 0.          0.32687518 -0.43090951]\n",
      " [ 0.         -0.00428575 -0.04185142]\n",
      " [ 0.         -0.02862647 -0.13651277]\n",
      " [ 0.         -0.38135903  0.28493427]\n",
      " [ 0.         -0.16350128  0.23549098]\n",
      " [ 0.          0.16308502 -0.30614959]\n",
      " [ 0.          0.57736384 -0.66577109]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #56 | lambda learn rate = 0.001\n",
      "Target = [[1.]\n",
      " [1.]]\n",
      "lambda end of trial = [[ 0.          0.15332633 -0.25114824]\n",
      " [ 0.          0.06474145 -0.17115122]\n",
      " [ 0.         -0.24505041  0.10765684]\n",
      " [ 0.          0.32689202 -0.43089267]\n",
      " [ 0.         -0.00441261 -0.04197828]\n",
      " [ 0.         -0.02873767 -0.13662397]\n",
      " [ 0.         -0.38121534  0.28507795]\n",
      " [ 0.         -0.16365936  0.2353329 ]\n",
      " [ 0.          0.16320012 -0.30603448]\n",
      " [ 0.          0.57739459 -0.66574033]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #57 | lambda learn rate = 0.001\n",
      "Target = [[0.]\n",
      " [2.]]\n",
      "lambda end of trial = [[ 0.          0.15332633 -0.24319369]\n",
      " [ 0.          0.06474145 -0.16438402]\n",
      " [ 0.         -0.24505041  0.11522958]\n",
      " [ 0.          0.32689202 -0.42247254]\n",
      " [ 0.         -0.00441261 -0.03365482]\n",
      " [ 0.         -0.02873767 -0.1293569 ]\n",
      " [ 0.         -0.38121534  0.29318688]\n",
      " [ 0.         -0.16365936  0.24258593]\n",
      " [ 0.          0.16320012 -0.29775322]\n",
      " [ 0.          0.57739459 -0.65876711]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #58 | lambda learn rate = 0.001\n",
      "Target = [[6.]\n",
      " [1.]]\n",
      "lambda end of trial = [[ 0.          0.22540547 -0.2311805 ]\n",
      " [ 0.          0.13387807 -0.15286125]\n",
      " [ 0.         -0.17951541  0.12615208]\n",
      " [ 0.          0.39363545 -0.41134863]\n",
      " [ 0.          0.05355158 -0.02399412]\n",
      " [ 0.          0.03777764 -0.11827102]\n",
      " [ 0.         -0.31865227  0.30361406]\n",
      " [ 0.         -0.09418932  0.25416427]\n",
      " [ 0.          0.2337666  -0.28599214]\n",
      " [ 0.          0.64882901 -0.64686137]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #59 | lambda learn rate = 0.001\n",
      "Target = [[7.]\n",
      " [9.]]\n",
      "lambda end of trial = [[ 0.          0.53723973  0.16974926]\n",
      " [ 0.          0.47585816  0.28682743]\n",
      " [ 0.          0.13161052  0.52617114]\n",
      " [ 0.          0.73003974  0.02117117]\n",
      " [ 0.          0.4267745   0.45586392]\n",
      " [ 0.          0.3418712   0.27270641]\n",
      " [ 0.          0.0135069   0.73067585]\n",
      " [ 0.          0.20921896  0.64426063]\n",
      " [ 0.          0.54180951  0.11006303]\n",
      " [ 0.          0.94506311 -0.26598895]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #60 | lambda learn rate = 0.001\n",
      "Target = [[4.]\n",
      " [6.]]\n",
      "lambda end of trial = [[ 0.          0.1807751  -0.36494768]\n",
      " [ 0.          0.09668207 -0.28193669]\n",
      " [ 0.         -0.25679479 -0.05643682]\n",
      " [ 0.          0.29529473 -0.63094635]\n",
      " [ 0.          0.04718187 -0.11352503]\n",
      " [ 0.         -0.04168185 -0.30262315]\n",
      " [ 0.         -0.36421393  0.16409461]\n",
      " [ 0.         -0.17693444  0.06503053]\n",
      " [ 0.          0.16775286 -0.45102195]\n",
      " [ 0.          0.59367372 -0.79307303]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #61 | lambda learn rate = 0.001\n",
      "Target = [[1.]\n",
      " [1.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda end of trial = [[ 0.          0.18485813 -0.36086465]\n",
      " [ 0.          0.10052624 -0.27809252]\n",
      " [ 0.         -0.2530494  -0.05269143]\n",
      " [ 0.          0.29915433 -0.62708675]\n",
      " [ 0.          0.05108649 -0.10962041]\n",
      " [ 0.         -0.03768505 -0.29862635]\n",
      " [ 0.         -0.36019073  0.1681178 ]\n",
      " [ 0.         -0.17271264  0.06925233]\n",
      " [ 0.          0.17231552 -0.44645929]\n",
      " [ 0.          0.59751699 -0.78922977]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #62 | lambda learn rate = 0.001\n",
      "Target = [[3.]\n",
      " [5.]]\n",
      "lambda end of trial = [[ 0.          0.31902382 -0.13725517]\n",
      " [ 0.          0.27063269  0.00541823]\n",
      " [ 0.         -0.11540247  0.17672011]\n",
      " [ 0.          0.44634019 -0.38177699]\n",
      " [ 0.          0.1968934   0.13339111]\n",
      " [ 0.          0.11105046 -0.05073384]\n",
      " [ 0.         -0.22300843  0.39675497]\n",
      " [ 0.         -0.01063867  0.33937562]\n",
      " [ 0.          0.31985119 -0.2005665 ]\n",
      " [ 0.          0.73580458 -0.55875045]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #63 | lambda learn rate = 0.001\n",
      "Target = [[3.]\n",
      " [9.]]\n",
      "lambda end of trial = [[ 0.          0.33171392 -0.09918485]\n",
      " [ 0.          0.28309864  0.04281607]\n",
      " [ 0.         -0.10305714  0.2137561 ]\n",
      " [ 0.          0.45915851 -0.34332203]\n",
      " [ 0.          0.2094726   0.17112871]\n",
      " [ 0.          0.12329306 -0.01400603]\n",
      " [ 0.         -0.20912735  0.43839821]\n",
      " [ 0.          0.00163793  0.37620542]\n",
      " [ 0.          0.33187175 -0.16450483]\n",
      " [ 0.          0.74871889 -0.52000751]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #64 | lambda learn rate = 0.001\n",
      "Target = [[6.]\n",
      " [0.]]\n",
      "lambda end of trial = [[ 0.          0.17004219 -0.09918485]\n",
      " [ 0.          0.10572194  0.04281607]\n",
      " [ 0.         -0.27243843  0.2137561 ]\n",
      " [ 0.          0.29193252 -0.34332203]\n",
      " [ 0.          0.04257732  0.17112871]\n",
      " [ 0.         -0.0396572  -0.01400603]\n",
      " [ 0.         -0.37182434  0.43839821]\n",
      " [ 0.         -0.16535117  0.37620542]\n",
      " [ 0.          0.17662704 -0.16450483]\n",
      " [ 0.          0.58206242 -0.52000751]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #65 | lambda learn rate = 0.001\n",
      "Target = [[9.]\n",
      " [0.]]\n",
      "lambda end of trial = [[ 0.          0.26872031 -0.09918485]\n",
      " [ 0.          0.19834419  0.04281607]\n",
      " [ 0.         -0.18374754  0.2137561 ]\n",
      " [ 0.          0.38255879 -0.34332203]\n",
      " [ 0.          0.13773837  0.17112871]\n",
      " [ 0.          0.0448425  -0.01400603]\n",
      " [ 0.         -0.2777939   0.43839821]\n",
      " [ 0.         -0.06838396  0.37620542]\n",
      " [ 0.          0.26191509 -0.16450483]\n",
      " [ 0.          0.66869911 -0.52000751]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #66 | lambda learn rate = 0.001\n",
      "Target = [[7.]\n",
      " [8.]]\n",
      "lambda end of trial = [[ 0.          0.23719117 -0.13521816]\n",
      " [ 0.          0.15296922 -0.00904105]\n",
      " [ 0.         -0.22574343  0.1657608 ]\n",
      " [ 0.          0.34207428 -0.38959004]\n",
      " [ 0.          0.09963667  0.12758391]\n",
      " [ 0.          0.00189514 -0.06308872]\n",
      " [ 0.         -0.31288096  0.39829871]\n",
      " [ 0.         -0.11066011  0.32788982]\n",
      " [ 0.          0.22374287 -0.20813023]\n",
      " [ 0.          0.62766838 -0.56689976]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #67 | lambda learn rate = 0.001\n",
      "Target = [[4.]\n",
      " [0.]]\n",
      "lambda end of trial = [[ 0.          0.20819483 -0.13521816]\n",
      " [ 0.          0.1199755  -0.00904105]\n",
      " [ 0.         -0.25891533  0.1657608 ]\n",
      " [ 0.          0.31208404 -0.38959004]\n",
      " [ 0.          0.06808271  0.12758391]\n",
      " [ 0.         -0.02854484 -0.06308872]\n",
      " [ 0.         -0.34276623  0.39829871]\n",
      " [ 0.         -0.14091345  0.32788982]\n",
      " [ 0.          0.19376903 -0.20813023]\n",
      " [ 0.          0.59911678 -0.56689976]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #68 | lambda learn rate = 0.001\n",
      "Target = [[5.]\n",
      " [3.]]\n",
      "lambda end of trial = [[ 0.          0.24165701 -0.11514085]\n",
      " [ 0.          0.15432248  0.01156714]\n",
      " [ 0.         -0.22841277  0.18406233]\n",
      " [ 0.          0.3469642  -0.36866195]\n",
      " [ 0.          0.1033512   0.148745  ]\n",
      " [ 0.          0.00386688 -0.04364169]\n",
      " [ 0.         -0.31078409  0.417488  ]\n",
      " [ 0.         -0.10979101  0.34656328]\n",
      " [ 0.          0.22653866 -0.18846846]\n",
      " [ 0.          0.63226734 -0.54700943]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #69 | lambda learn rate = 0.001\n",
      "Target = [[7.]\n",
      " [3.]]\n",
      "lambda end of trial = [[ 0.          0.24530163 -0.11357887]\n",
      " [ 0.          0.1551344   0.01191511]\n",
      " [ 0.         -0.22775508  0.1843442 ]\n",
      " [ 0.          0.34921029 -0.36769934]\n",
      " [ 0.          0.10405555  0.14904687]\n",
      " [ 0.          0.00504111 -0.04313845]\n",
      " [ 0.         -0.30730041  0.418981  ]\n",
      " [ 0.         -0.1072629   0.34764676]\n",
      " [ 0.          0.22975828 -0.18708862]\n",
      " [ 0.          0.6342189  -0.54617304]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #70 | lambda learn rate = 0.001\n",
      "Target = [[8.]\n",
      " [3.]]\n",
      "lambda end of trial = [[ 0.          0.24754985 -0.11273579]\n",
      " [ 0.          0.15292992  0.01108843]\n",
      " [ 0.         -0.22863085  0.18401578]\n",
      " [ 0.          0.35027256 -0.36730099]\n",
      " [ 0.          0.10295463  0.14863402]\n",
      " [ 0.          0.00530647 -0.04303894]\n",
      " [ 0.         -0.30549676  0.41965737]\n",
      " [ 0.         -0.10711973  0.34770045]\n",
      " [ 0.          0.23085856 -0.18667602]\n",
      " [ 0.          0.63496674 -0.54589261]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #71 | lambda learn rate = 0.001\n",
      "Target = [[2.]\n",
      " [9.]]\n",
      "lambda end of trial = [[ 0.          0.26922246 -0.01520904]\n",
      " [ 0.          0.17130819  0.09379067]\n",
      " [ 0.         -0.20899054  0.27239719]\n",
      " [ 0.          0.37315349 -0.2643368 ]\n",
      " [ 0.          0.12313066  0.23942613]\n",
      " [ 0.          0.02845778  0.06114195]\n",
      " [ 0.         -0.28296119  0.52106745]\n",
      " [ 0.         -0.08790245  0.43417822]\n",
      " [ 0.          0.25242197 -0.08964064]\n",
      " [ 0.          0.6571072  -0.44626055]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #72 | lambda learn rate = 0.001\n",
      "Target = [[8.]\n",
      " [0.]]\n",
      "lambda end of trial = [[ 0.          0.18154547 -0.01520904]\n",
      " [ 0.          0.07185443  0.09379067]\n",
      " [ 0.         -0.29769971  0.27239719]\n",
      " [ 0.          0.28936053 -0.2643368 ]\n",
      " [ 0.          0.01959054  0.23942613]\n",
      " [ 0.         -0.06535489  0.06114195]\n",
      " [ 0.         -0.38008502  0.52106745]\n",
      " [ 0.         -0.17928579  0.43417822]\n",
      " [ 0.          0.16213502 -0.08964064]\n",
      " [ 0.          0.56567065 -0.44626055]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #73 | lambda learn rate = 0.001\n",
      "Target = [[6.]\n",
      " [6.]]\n",
      "lambda end of trial = [[ 0.          0.19155904 -0.00519546]\n",
      " [ 0.          0.08050757  0.10244382]\n",
      " [ 0.         -0.28689331  0.28320359]\n",
      " [ 0.          0.29922324 -0.25447409]\n",
      " [ 0.          0.02860263  0.24843822]\n",
      " [ 0.         -0.0552782   0.07121864]\n",
      " [ 0.         -0.36882918  0.53232329]\n",
      " [ 0.         -0.16985778  0.44360623]\n",
      " [ 0.          0.17279351 -0.07898216]\n",
      " [ 0.          0.57588867 -0.43604253]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #74 | lambda learn rate = 0.001\n",
      "Target = [[5.]\n",
      " [3.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda end of trial = [[ 0.          0.18895433 -0.00675829]\n",
      " [ 0.          0.07608865  0.09979246]\n",
      " [ 0.         -0.2908942   0.28080306]\n",
      " [ 0.          0.29599618 -0.25641033]\n",
      " [ 0.          0.02395953  0.24565236]\n",
      " [ 0.         -0.05894654  0.06901764]\n",
      " [ 0.         -0.37215285  0.53032909]\n",
      " [ 0.         -0.1731975   0.4416024 ]\n",
      " [ 0.          0.16987692 -0.08073211]\n",
      " [ 0.          0.57307071 -0.43773331]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #75 | lambda learn rate = 0.001\n",
      "Target = [[4.]\n",
      " [4.]]\n",
      "lambda end of trial = [[ 0.          0.17616475 -0.01954787]\n",
      " [ 0.          0.06340759  0.08711141]\n",
      " [ 0.         -0.30412409  0.26757316]\n",
      " [ 0.          0.28360702 -0.26879949]\n",
      " [ 0.          0.00995011  0.23164294]\n",
      " [ 0.         -0.07275656  0.05520762]\n",
      " [ 0.         -0.38312084  0.5193611 ]\n",
      " [ 0.         -0.18679312  0.42800678]\n",
      " [ 0.          0.15664905 -0.09395998]\n",
      " [ 0.          0.56174786 -0.44905616]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #76 | lambda learn rate = 0.001\n",
      "Target = [[7.]\n",
      " [6.]]\n",
      "lambda end of trial = [[ 0.          0.22437093  0.02177171]\n",
      " [ 0.          0.11535517  0.1316379 ]\n",
      " [ 0.         -0.25487784  0.30978424]\n",
      " [ 0.          0.33014358 -0.22891101]\n",
      " [ 0.          0.05636395  0.27142623]\n",
      " [ 0.         -0.0261583   0.09514898]\n",
      " [ 0.         -0.3338107   0.56162694]\n",
      " [ 0.         -0.13968665  0.46838375]\n",
      " [ 0.          0.20281133 -0.05439231]\n",
      " [ 0.          0.61379389 -0.40444527]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #77 | lambda learn rate = 0.001\n",
      "Target = [[9.]\n",
      " [8.]]\n",
      "lambda end of trial = [[ 0.          0.10652649 -0.0829789 ]\n",
      " [ 0.         -0.00587545  0.02387735]\n",
      " [ 0.         -0.36982691  0.20760729]\n",
      " [ 0.          0.21670126 -0.32974862]\n",
      " [ 0.         -0.0776122   0.15233633]\n",
      " [ 0.         -0.15407185 -0.01855195]\n",
      " [ 0.         -0.4386109   0.4684712 ]\n",
      " [ 0.         -0.27720897  0.34614169]\n",
      " [ 0.          0.08686883 -0.15745231]\n",
      " [ 0.          0.50764618 -0.49879879]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #78 | lambda learn rate = 0.001\n",
      "Target = [[8.]\n",
      " [9.]]\n",
      "lambda end of trial = [[ 0.          0.44718278  0.30025942]\n",
      " [ 0.          0.38188692  0.46011001]\n",
      " [ 0.          0.00421658  0.62840621]\n",
      " [ 0.          0.63454402  0.14032448]\n",
      " [ 0.          0.27988786  0.55452389]\n",
      " [ 0.          0.23964829  0.42438321]\n",
      " [ 0.         -0.01628939  0.94358289]\n",
      " [ 0.          0.08878392  0.7578837 ]\n",
      " [ 0.          0.497185    0.30415338]\n",
      " [ 0.          0.84319796 -0.12130305]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #79 | lambda learn rate = 0.001\n",
      "Target = [[4.]\n",
      " [2.]]\n",
      "lambda end of trial = [[ 0.          0.18646244  0.16989926]\n",
      " [ 0.          0.14012654  0.33922983]\n",
      " [ 0.         -0.24325084  0.5046725 ]\n",
      " [ 0.          0.37089066  0.0084978 ]\n",
      " [ 0.          0.01733553  0.42324773]\n",
      " [ 0.         -0.00559878  0.30175968]\n",
      " [ 0.         -0.28035002  0.81155258]\n",
      " [ 0.         -0.13484544  0.64606901]\n",
      " [ 0.          0.25585213  0.18348694]\n",
      " [ 0.          0.58937701 -0.24821352]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #80 | lambda learn rate = 0.001\n",
      "Target = [[2.]\n",
      " [0.]]\n",
      "lambda end of trial = [[ 0.          0.17419935  0.16989926]\n",
      " [ 0.          0.12603479  0.33922983]\n",
      " [ 0.         -0.25597081  0.5046725 ]\n",
      " [ 0.          0.35809459  0.0084978 ]\n",
      " [ 0.          0.00410177  0.42324773]\n",
      " [ 0.         -0.01874318  0.30175968]\n",
      " [ 0.         -0.2925418   0.81155258]\n",
      " [ 0.         -0.1479782   0.64606901]\n",
      " [ 0.          0.24452854  0.18348694]\n",
      " [ 0.          0.57643829 -0.24821352]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #81 | lambda learn rate = 0.001\n",
      "Target = [[7.]\n",
      " [0.]]\n",
      "lambda end of trial = [[ 0.          0.1899663   0.16989926]\n",
      " [ 0.          0.13872844  0.33922983]\n",
      " [ 0.         -0.24250357  0.5046725 ]\n",
      " [ 0.          0.37133058  0.0084978 ]\n",
      " [ 0.          0.01757685  0.42324773]\n",
      " [ 0.         -0.00635798  0.30175968]\n",
      " [ 0.         -0.27863572  0.81155258]\n",
      " [ 0.         -0.13324836  0.64606901]\n",
      " [ 0.          0.2583543   0.18348694]\n",
      " [ 0.          0.59054736 -0.24821352]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #82 | lambda learn rate = 0.001\n",
      "Target = [[3.]\n",
      " [4.]]\n",
      "lambda end of trial = [[ 0.          0.07058802  0.01072823]\n",
      " [ 0.          0.01803633  0.17830702]\n",
      " [ 0.         -0.35880723  0.34960096]\n",
      " [ 0.          0.25356986 -0.1485165 ]\n",
      " [ 0.         -0.10584288  0.25868808]\n",
      " [ 0.         -0.11315332  0.15936589]\n",
      " [ 0.         -0.38928917  0.66401465]\n",
      " [ 0.         -0.24230292  0.50066293]\n",
      " [ 0.          0.15326148  0.04336319]\n",
      " [ 0.          0.48586123 -0.38779502]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #83 | lambda learn rate = 0.001\n",
      "Target = [[2.]\n",
      " [6.]]\n",
      "lambda end of trial = [[ 0.          0.03037195 -0.10991999]\n",
      " [ 0.         -0.02215199  0.05774206]\n",
      " [ 0.         -0.39847535  0.23059658]\n",
      " [ 0.          0.21355304 -0.26856696]\n",
      " [ 0.         -0.15135782  0.12214328]\n",
      " [ 0.         -0.15537429  0.03270298]\n",
      " [ 0.         -0.4296626   0.54289436]\n",
      " [ 0.         -0.28492959  0.37278294]\n",
      " [ 0.          0.11319119 -0.07684768]\n",
      " [ 0.          0.44849385 -0.49989717]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #84 | lambda learn rate = 0.001\n",
      "Target = [[3.]\n",
      " [1.]]\n",
      "lambda end of trial = [[ 0.          0.06149351 -0.09954613]\n",
      " [ 0.          0.00715966  0.06751261]\n",
      " [ 0.         -0.36469958  0.24185517]\n",
      " [ 0.          0.24367746 -0.25852548]\n",
      " [ 0.         -0.1201871   0.13253352]\n",
      " [ 0.         -0.12600063  0.0424942 ]\n",
      " [ 0.         -0.39928943  0.55301875]\n",
      " [ 0.         -0.25206776  0.38373688]\n",
      " [ 0.          0.14536401 -0.06612341]\n",
      " [ 0.          0.48150049 -0.48889495]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #85 | lambda learn rate = 0.001\n",
      "Target = [[8.]\n",
      " [4.]]\n",
      "lambda end of trial = [[ 0.          0.32840419  0.03390921]\n",
      " [ 0.          0.30064245  0.214254  ]\n",
      " [ 0.         -0.12520091  0.36160451]\n",
      " [ 0.          0.52119385 -0.11976729]\n",
      " [ 0.          0.16295715  0.27410564]\n",
      " [ 0.          0.15911525  0.18505214]\n",
      " [ 0.         -0.11564231  0.69484231]\n",
      " [ 0.          0.01902305  0.51928229]\n",
      " [ 0.          0.41592249  0.06915583]\n",
      " [ 0.          0.76157969 -0.34885535]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #86 | lambda learn rate = 0.001\n",
      "Target = [[5.]\n",
      " [2.]]\n",
      "lambda end of trial = [[ 0.          0.16424309 -0.03175523]\n",
      " [ 0.          0.11964375  0.14185452]\n",
      " [ 0.         -0.30497758  0.28969384]\n",
      " [ 0.          0.34209477 -0.19140692]\n",
      " [ 0.         -0.01562281  0.20267366]\n",
      " [ 0.         -0.01856006  0.11398202]\n",
      " [ 0.         -0.27294518  0.63192116]\n",
      " [ 0.         -0.14390874  0.45410957]\n",
      " [ 0.          0.23596793 -0.00282599]\n",
      " [ 0.          0.59109223 -0.41705034]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #87 | lambda learn rate = 0.001\n",
      "Target = [[9.]\n",
      " [4.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda end of trial = [[ 0.          0.16569902 -0.03110815]\n",
      " [ 0.          0.11874641  0.14145571]\n",
      " [ 0.         -0.30603387  0.28922437]\n",
      " [ 0.          0.34356109 -0.19075522]\n",
      " [ 0.         -0.01665125  0.20221658]\n",
      " [ 0.         -0.01872494  0.11390873]\n",
      " [ 0.         -0.27160002  0.63251901]\n",
      " [ 0.         -0.14407593  0.45403526]\n",
      " [ 0.          0.23677462 -0.00246747]\n",
      " [ 0.          0.59137348 -0.41692534]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #88 | lambda learn rate = 0.001\n",
      "Target = [[1.]\n",
      " [5.]]\n",
      "lambda end of trial = [[ 0.          0.14888105 -0.11519802]\n",
      " [ 0.          0.10134832  0.05446526]\n",
      " [ 0.         -0.32347334  0.20202705]\n",
      " [ 0.          0.32730462 -0.27203758]\n",
      " [ 0.         -0.03416519  0.11464687]\n",
      " [ 0.         -0.03627149  0.02617599]\n",
      " [ 0.         -0.28947923  0.54312299]\n",
      " [ 0.         -0.16223145  0.36325765]\n",
      " [ 0.          0.21984505 -0.08711529]\n",
      " [ 0.          0.57334672 -0.50705914]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #89 | lambda learn rate = 0.001\n",
      "Target = [[9.]\n",
      " [4.]]\n",
      "lambda end of trial = [[ 0.          0.29593473 -0.04984083]\n",
      " [ 0.          0.27125329  0.12997858]\n",
      " [ 0.         -0.18100086  0.26534815]\n",
      " [ 0.          0.48254194 -0.20304322]\n",
      " [ 0.          0.13799138  0.1911609 ]\n",
      " [ 0.          0.13475546  0.10218797]\n",
      " [ 0.         -0.13903202  0.60998842]\n",
      " [ 0.          0.00312449  0.43674918]\n",
      " [ 0.          0.38542888 -0.01352248]\n",
      " [ 0.          0.72398472 -0.44010892]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #90 | lambda learn rate = 0.001\n",
      "Target = [[5.]\n",
      " [4.]]\n",
      "lambda end of trial = [[ 0.          0.14762865 -0.16848569]\n",
      " [ 0.          0.12430325  0.01241855]\n",
      " [ 0.         -0.3387404   0.13915652]\n",
      " [ 0.          0.33787478 -0.31877695]\n",
      " [ 0.         -0.00991871  0.07283282]\n",
      " [ 0.         -0.0175768  -0.01967784]\n",
      " [ 0.         -0.28538634  0.49290496]\n",
      " [ 0.         -0.1522551   0.31244551]\n",
      " [ 0.          0.24164451 -0.12854997]\n",
      " [ 0.          0.5841563  -0.55197166]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #91 | lambda learn rate = 0.001\n",
      "Target = [[9.]\n",
      " [3.]]\n",
      "lambda end of trial = [[ 0.          0.30763482 -0.1151503 ]\n",
      " [ 0.          0.26875101  0.0605678 ]\n",
      " [ 0.         -0.19427643  0.18731117]\n",
      " [ 0.          0.49825795 -0.26531589]\n",
      " [ 0.          0.1297306   0.1193826 ]\n",
      " [ 0.          0.14436336  0.03430221]\n",
      " [ 0.         -0.12539198  0.54623641]\n",
      " [ 0.          0.00495395  0.36484853]\n",
      " [ 0.          0.40628271 -0.07367057]\n",
      " [ 0.          0.73502689 -0.50168146]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #92 | lambda learn rate = 0.001\n",
      "Target = [[0.]\n",
      " [0.]]\n",
      "lambda end of trial = [[ 0.          0.30763482 -0.1151503 ]\n",
      " [ 0.          0.26875101  0.0605678 ]\n",
      " [ 0.         -0.19427643  0.18731117]\n",
      " [ 0.          0.49825795 -0.26531589]\n",
      " [ 0.          0.1297306   0.1193826 ]\n",
      " [ 0.          0.14436336  0.03430221]\n",
      " [ 0.         -0.12539198  0.54623641]\n",
      " [ 0.          0.00495395  0.36484853]\n",
      " [ 0.          0.40628271 -0.07367057]\n",
      " [ 0.          0.73502689 -0.50168146]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #93 | lambda learn rate = 0.001\n",
      "Target = [[2.]\n",
      " [8.]]\n",
      "lambda end of trial = [[ 0.          0.29321574 -0.17282663]\n",
      " [ 0.          0.2531484  -0.00184264]\n",
      " [ 0.         -0.20980196  0.12520906]\n",
      " [ 0.          0.48243508 -0.32860737]\n",
      " [ 0.          0.11383865  0.05581476]\n",
      " [ 0.          0.12747424 -0.03325426]\n",
      " [ 0.         -0.14312769  0.47529359]\n",
      " [ 0.         -0.00970068  0.30623001]\n",
      " [ 0.          0.39067362 -0.13610694]\n",
      " [ 0.          0.71881355 -0.56653482]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #94 | lambda learn rate = 0.001\n",
      "Target = [[9.]\n",
      " [1.]]\n",
      "lambda end of trial = [[ 0.          0.05087234 -0.19975367]\n",
      " [ 0.          0.0062084  -0.02928042]\n",
      " [ 0.         -0.47058452  0.09623322]\n",
      " [ 0.          0.23431958 -0.35617576]\n",
      " [ 0.         -0.13339033  0.02834487]\n",
      " [ 0.         -0.0953078  -0.05800782]\n",
      " [ 0.         -0.39208301  0.44763189]\n",
      " [ 0.         -0.27599832  0.27664139]\n",
      " [ 0.          0.1709311  -0.16052278]\n",
      " [ 0.          0.4635667  -0.59489559]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #95 | lambda learn rate = 0.001\n",
      "Target = [[4.]\n",
      " [8.]]\n",
      "lambda end of trial = [[ 0.          0.21125914  0.12101992]\n",
      " [ 0.          0.18224939  0.32280155]\n",
      " [ 0.         -0.31032963  0.41674299]\n",
      " [ 0.          0.40985713 -0.00510066]\n",
      " [ 0.          0.0408443   0.37681413]\n",
      " [ 0.          0.07535006  0.2833079 ]\n",
      " [ 0.         -0.20414987  0.82349816]\n",
      " [ 0.         -0.11081478  0.60700847]\n",
      " [ 0.          0.34316026  0.18393554]\n",
      " [ 0.          0.62969743 -0.26263412]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #96 | lambda learn rate = 0.001\n",
      "Target = [[6.]\n",
      " [3.]]\n",
      "lambda end of trial = [[ 0.          0.01230644  0.02154357]\n",
      " [ 0.         -0.01859261  0.22238055]\n",
      " [ 0.         -0.50321383  0.32030089]\n",
      " [ 0.          0.23362571 -0.09321637]\n",
      " [ 0.         -0.15440379  0.27919009]\n",
      " [ 0.         -0.11681084  0.18722745]\n",
      " [ 0.         -0.39671293  0.72721663]\n",
      " [ 0.         -0.3093369   0.50774741]\n",
      " [ 0.          0.15825069  0.09148076]\n",
      " [ 0.          0.43881753 -0.35807407]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #97 | lambda learn rate = 0.001\n",
      "Target = [[2.]\n",
      " [1.]]\n",
      "lambda end of trial = [[ 0.          0.01177862  0.02127966]\n",
      " [ 0.         -0.01961511  0.2218693 ]\n",
      " [ 0.         -0.50403995  0.31988784]\n",
      " [ 0.          0.23316643 -0.09344601]\n",
      " [ 0.         -0.15522432  0.27877982]\n",
      " [ 0.         -0.11742477  0.18692048]\n",
      " [ 0.         -0.39705823  0.72704398]\n",
      " [ 0.         -0.30990391  0.50746391]\n",
      " [ 0.          0.15777235  0.09124159]\n",
      " [ 0.          0.43805078 -0.35845744]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #98 | lambda learn rate = 0.001\n",
      "Target = [[0.]\n",
      " [5.]]\n",
      "lambda end of trial = [[ 0.          0.01177862 -0.12540857]\n",
      " [ 0.         -0.01961511  0.0909327 ]\n",
      " [ 0.         -0.50403995  0.17597552]\n",
      " [ 0.          0.23316643 -0.22745483]\n",
      " [ 0.         -0.15522432  0.12750301]\n",
      " [ 0.         -0.11742477  0.03585061]\n",
      " [ 0.         -0.39705823  0.59596593]\n",
      " [ 0.         -0.30990391  0.37169372]\n",
      " [ 0.          0.15777235 -0.06530022]\n",
      " [ 0.          0.43805078 -0.49463012]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "+++++++++++++++++++++++++++++++++++\n",
      "Session #3\n",
      "target at trial 0 = [[1.]\n",
      " [1.]]\n",
      "K MATX INIT= [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "A VECT INIT = [-0. -0.]\n",
      "lambda\n",
      "[[ 0.          0.17569819 -0.1168215 ]\n",
      " [ 0.          0.17094785  0.05671689]\n",
      " [ 0.         -0.13660684  0.34736166]\n",
      " [ 0.          0.39038693 -0.30734903]\n",
      " [ 0.          0.07484879  0.16279938]\n",
      " [ 0.          0.06604893  0.12726184]\n",
      " [ 0.         -0.35233706  0.44135871]\n",
      " [ 0.         -0.15102956  0.35740288]\n",
      " [ 0.          0.23767146 -0.14068682]\n",
      " [ 0.          0.63275023 -0.52240076]]\n",
      "a\n",
      "[-0. -0.]\n",
      "K\n",
      "[[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #0 | lambda learn rate = 0.001\n",
      "Target = [[1.]\n",
      " [1.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda end of trial = [[ 0.          0.16748549 -0.12503421]\n",
      " [ 0.          0.16245085  0.04821989]\n",
      " [ 0.         -0.14541577  0.33855274]\n",
      " [ 0.          0.38223637 -0.3154996 ]\n",
      " [ 0.          0.06596482  0.1539154 ]\n",
      " [ 0.          0.05766082  0.11887373]\n",
      " [ 0.         -0.36111927  0.43257651]\n",
      " [ 0.         -0.15961435  0.34881809]\n",
      " [ 0.          0.22917294 -0.14918534]\n",
      " [ 0.          0.62363702 -0.53151397]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #1 | lambda learn rate = 0.001\n",
      "Target = [[7.]\n",
      " [8.]]\n",
      "lambda end of trial = [[ 0.          0.13465744 -0.16255197]\n",
      " [ 0.          0.12560704  0.00611267]\n",
      " [ 0.         -0.18250441  0.29616572]\n",
      " [ 0.          0.35071371 -0.3515255 ]\n",
      " [ 0.          0.03120996  0.11419557]\n",
      " [ 0.          0.02586073  0.08253076]\n",
      " [ 0.         -0.39565682  0.39310501]\n",
      " [ 0.         -0.19454164  0.30890119]\n",
      " [ 0.          0.19816995 -0.18461733]\n",
      " [ 0.          0.58795854 -0.57228937]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #2 | lambda learn rate = 0.001\n",
      "Target = [[5.]\n",
      " [5.]]\n",
      "lambda end of trial = [[ 0.          0.16272932 -0.1344801 ]\n",
      " [ 0.          0.15498361  0.03548925]\n",
      " [ 0.         -0.15148892  0.32718121]\n",
      " [ 0.          0.37858396 -0.32365524]\n",
      " [ 0.          0.060924    0.14390961]\n",
      " [ 0.          0.05639937  0.1130694 ]\n",
      " [ 0.         -0.3626702   0.42609164]\n",
      " [ 0.         -0.16237579  0.34106704]\n",
      " [ 0.          0.22866933 -0.15411795]\n",
      " [ 0.          0.61629004 -0.54395788]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #3 | lambda learn rate = 0.001\n",
      "Target = [[9.]\n",
      " [1.]]\n",
      "lambda end of trial = [[ 0.          0.13084733 -0.13802254]\n",
      " [ 0.          0.1139938   0.03093483]\n",
      " [ 0.         -0.19179215  0.32270307]\n",
      " [ 0.          0.34156867 -0.32776805]\n",
      " [ 0.          0.01917823  0.13927119]\n",
      " [ 0.          0.01886491  0.10889891]\n",
      " [ 0.         -0.40336703  0.42156977]\n",
      " [ 0.         -0.20212495  0.33665046]\n",
      " [ 0.          0.19078858 -0.15832693]\n",
      " [ 0.          0.58063687 -0.54791934]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #4 | lambda learn rate = 0.001\n",
      "Target = [[6.]\n",
      " [0.]]\n",
      "lambda end of trial = [[ 0.          0.14200578 -0.13802254]\n",
      " [ 0.          0.12196703  0.03093483]\n",
      " [ 0.         -0.18293109  0.32270307]\n",
      " [ 0.          0.35044997 -0.32776805]\n",
      " [ 0.          0.02751912  0.13927119]\n",
      " [ 0.          0.02969268  0.10889891]\n",
      " [ 0.         -0.39309204  0.42156977]\n",
      " [ 0.         -0.19291619  0.33665046]\n",
      " [ 0.          0.20074643 -0.15832693]\n",
      " [ 0.          0.58989438 -0.54791934]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #5 | lambda learn rate = 0.001\n",
      "Target = [[4.]\n",
      " [4.]]\n",
      "lambda end of trial = [[ 0.          0.14236204 -0.13766629]\n",
      " [ 0.          0.12126557  0.03023337]\n",
      " [ 0.         -0.18348143  0.32215273]\n",
      " [ 0.          0.35047092 -0.3277471 ]\n",
      " [ 0.          0.02713412  0.13888618]\n",
      " [ 0.          0.02959459  0.10880082]\n",
      " [ 0.         -0.39296355  0.42169826]\n",
      " [ 0.         -0.19289542  0.33667123]\n",
      " [ 0.          0.20085578 -0.15821757]\n",
      " [ 0.          0.59018202 -0.5476317 ]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #6 | lambda learn rate = 0.001\n",
      "Target = [[3.]\n",
      " [7.]]\n",
      "lambda end of trial = [[ 0.          0.14374258 -0.13444502]\n",
      " [ 0.          0.12246228  0.0330257 ]\n",
      " [ 0.         -0.18271056  0.32395143]\n",
      " [ 0.          0.35187006 -0.32448244]\n",
      " [ 0.          0.02797353  0.14084482]\n",
      " [ 0.          0.03040375  0.11068885]\n",
      " [ 0.         -0.39127586  0.42563619]\n",
      " [ 0.         -0.19208978  0.33855106]\n",
      " [ 0.          0.20174155 -0.15615079]\n",
      " [ 0.          0.5913181  -0.54498086]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #7 | lambda learn rate = 0.001\n",
      "Target = [[4.]\n",
      " [9.]]\n",
      "lambda end of trial = [[ 0.          0.15521682 -0.10862797]\n",
      " [ 0.          0.13193377  0.05433654]\n",
      " [ 0.         -0.1721057   0.34781236]\n",
      " [ 0.          0.36458028 -0.29588445]\n",
      " [ 0.          0.03980383  0.16746298]\n",
      " [ 0.          0.0421092   0.13702612]\n",
      " [ 0.         -0.38161786  0.44736669]\n",
      " [ 0.         -0.18206772  0.36110069]\n",
      " [ 0.          0.21319426 -0.1303822 ]\n",
      " [ 0.          0.60257129 -0.51966118]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #8 | lambda learn rate = 0.001\n",
      "Target = [[5.]\n",
      " [3.]]\n",
      "lambda end of trial = [[ 0.          0.13671934 -0.11972646]\n",
      " [ 0.          0.11081569  0.04166569]\n",
      " [ 0.         -0.19202101  0.33586318]\n",
      " [ 0.          0.34580176 -0.30715156]\n",
      " [ 0.          0.01920029  0.15510086]\n",
      " [ 0.          0.02107262  0.12440417]\n",
      " [ 0.         -0.39765627  0.43774364]\n",
      " [ 0.         -0.20216867  0.34904012]\n",
      " [ 0.          0.19594752 -0.14073024]\n",
      " [ 0.          0.5830856  -0.5313526 ]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #9 | lambda learn rate = 0.001\n",
      "Target = [[9.]\n",
      " [8.]]\n",
      "lambda end of trial = [[ 0.          0.21493076 -0.0502052 ]\n",
      " [ 0.          0.18571805  0.10824557]\n",
      " [ 0.         -0.1144551   0.40481065]\n",
      " [ 0.          0.41737044 -0.24353495]\n",
      " [ 0.          0.0904233   0.2184102 ]\n",
      " [ 0.          0.0955564   0.19061198]\n",
      " [ 0.         -0.32581233  0.50160492]\n",
      " [ 0.         -0.12689974  0.41594584]\n",
      " [ 0.          0.26375537 -0.0804566 ]\n",
      " [ 0.          0.66436342 -0.45910564]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #10 | lambda learn rate = 0.001\n",
      "Target = [[5.]\n",
      " [5.]]\n",
      "lambda end of trial = [[ 0.          0.10015637 -0.16497959]\n",
      " [ 0.          0.05876823 -0.01870425]\n",
      " [ 0.         -0.23697779  0.28228796]\n",
      " [ 0.          0.31092583 -0.34997957]\n",
      " [ 0.         -0.03916537  0.08882153]\n",
      " [ 0.         -0.02096115  0.07409443]\n",
      " [ 0.         -0.44068969  0.38672757]\n",
      " [ 0.         -0.23528143  0.30756414]\n",
      " [ 0.          0.16077275 -0.18343922]\n",
      " [ 0.          0.54929604 -0.57417302]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #11 | lambda learn rate = 0.001\n",
      "Target = [[3.]\n",
      " [1.]]\n",
      "lambda end of trial = [[ 0.          0.10728902 -0.16260204]\n",
      " [ 0.          0.06470624 -0.01672491]\n",
      " [ 0.         -0.22911332  0.28490945]\n",
      " [ 0.          0.31821544 -0.34754969]\n",
      " [ 0.         -0.03250687  0.09104103]\n",
      " [ 0.         -0.01385749  0.07646231]\n",
      " [ 0.         -0.43300946  0.38928764]\n",
      " [ 0.         -0.22836932  0.30986818]\n",
      " [ 0.          0.16753309 -0.18118577]\n",
      " [ 0.          0.55653094 -0.57176139]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #12 | lambda learn rate = 0.001\n",
      "Target = [[7.]\n",
      " [6.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda end of trial = [[ 0.          0.25481505 -0.03615115]\n",
      " [ 0.          0.20902369  0.10697575]\n",
      " [ 0.         -0.05493748  0.43420303]\n",
      " [ 0.          0.46038594 -0.22568927]\n",
      " [ 0.          0.11613711  0.21845015]\n",
      " [ 0.          0.11772675  0.18924881]\n",
      " [ 0.         -0.2771658   0.52286793]\n",
      " [ 0.         -0.07570266  0.44072532]\n",
      " [ 0.          0.31376069 -0.05584782]\n",
      " [ 0.          0.71740388 -0.43387029]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #13 | lambda learn rate = 0.001\n",
      "Target = [[5.]\n",
      " [2.]]\n",
      "lambda end of trial = [[ 0.          0.13582525 -0.08374707]\n",
      " [ 0.          0.09957543  0.06319645]\n",
      " [ 0.         -0.17201331  0.3873727 ]\n",
      " [ 0.          0.35023267 -0.26975057]\n",
      " [ 0.         -0.00176745  0.17128833]\n",
      " [ 0.          0.01626574  0.1486644 ]\n",
      " [ 0.         -0.39291753  0.47656723]\n",
      " [ 0.         -0.19894588  0.39142803]\n",
      " [ 0.          0.19593389 -0.10297855]\n",
      " [ 0.          0.60902809 -0.47722061]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #14 | lambda learn rate = 0.001\n",
      "Target = [[9.]\n",
      " [6.]]\n",
      "lambda end of trial = [[ 0.          0.14544865 -0.07733147]\n",
      " [ 0.          0.10703981  0.0681727 ]\n",
      " [ 0.         -0.16442838  0.39242932]\n",
      " [ 0.          0.35953412 -0.26354961]\n",
      " [ 0.          0.00571074  0.17627379]\n",
      " [ 0.          0.02349068  0.15348103]\n",
      " [ 0.         -0.38496301  0.48187024]\n",
      " [ 0.         -0.19141498  0.39644863]\n",
      " [ 0.          0.20443436 -0.09731156]\n",
      " [ 0.          0.61859176 -0.47084483]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #15 | lambda learn rate = 0.001\n",
      "Target = [[0.]\n",
      " [5.]]\n",
      "lambda end of trial = [[ 0.          0.14544865 -0.14702969]\n",
      " [ 0.          0.10703981  0.00115802]\n",
      " [ 0.         -0.16442838  0.32067094]\n",
      " [ 0.          0.35953412 -0.3255145 ]\n",
      " [ 0.          0.00571074  0.1074212 ]\n",
      " [ 0.          0.02349068  0.08585934]\n",
      " [ 0.         -0.38496301  0.41165506]\n",
      " [ 0.         -0.19141498  0.32404851]\n",
      " [ 0.          0.20443436 -0.16558931]\n",
      " [ 0.          0.61859176 -0.5395517 ]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #16 | lambda learn rate = 0.001\n",
      "Target = [[4.]\n",
      " [9.]]\n",
      "lambda end of trial = [[ 0.          0.17574107 -0.07887175]\n",
      " [ 0.          0.13838525  0.07168525]\n",
      " [ 0.         -0.13578908  0.38510937]\n",
      " [ 0.          0.39210862 -0.25222187]\n",
      " [ 0.          0.03529084  0.17397641]\n",
      " [ 0.          0.05481893  0.1563479 ]\n",
      " [ 0.         -0.35154195  0.48685245]\n",
      " [ 0.         -0.15928986  0.39633004]\n",
      " [ 0.          0.23599879 -0.09456934]\n",
      " [ 0.          0.65104254 -0.46653745]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #17 | lambda learn rate = 0.001\n",
      "Target = [[7.]\n",
      " [3.]]\n",
      "lambda end of trial = [[ 0.          0.11278025 -0.10585496]\n",
      " [ 0.          0.07601784  0.04495636]\n",
      " [ 0.         -0.19975941  0.35769351]\n",
      " [ 0.          0.32939927 -0.27909731]\n",
      " [ 0.         -0.03152619  0.14534054]\n",
      " [ 0.         -0.01286456  0.12734069]\n",
      " [ 0.         -0.40735828  0.46293116]\n",
      " [ 0.         -0.22160796  0.36962228]\n",
      " [ 0.          0.17845106 -0.11923266]\n",
      " [ 0.          0.59230413 -0.49171105]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #18 | lambda learn rate = 0.001\n",
      "Target = [[1.]\n",
      " [7.]]\n",
      "lambda end of trial = [[ 0.          0.10577798 -0.15487089]\n",
      " [ 0.          0.06821699 -0.00964957]\n",
      " [ 0.         -0.20775025  0.30175767]\n",
      " [ 0.          0.32238837 -0.32817365]\n",
      " [ 0.         -0.0391903   0.0916918 ]\n",
      " [ 0.         -0.0211555   0.06930412]\n",
      " [ 0.         -0.41477434  0.41101876]\n",
      " [ 0.         -0.22881728  0.31915704]\n",
      " [ 0.          0.17133046 -0.16907684]\n",
      " [ 0.          0.58425048 -0.5480866 ]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #19 | lambda learn rate = 0.001\n",
      "Target = [[9.]\n",
      " [5.]]\n",
      "lambda end of trial = [[ 0.          0.33822864 -0.02573163]\n",
      " [ 0.          0.29995113  0.11909162]\n",
      " [ 0.         -0.01044123  0.41137379]\n",
      " [ 0.          0.53801048 -0.20838358]\n",
      " [ 0.          0.17887352  0.21283836]\n",
      " [ 0.          0.2118341   0.19874279]\n",
      " [ 0.         -0.20716433  0.52635766]\n",
      " [ 0.         -0.00721528  0.44226927]\n",
      " [ 0.          0.39631697 -0.04408433]\n",
      " [ 0.          0.79999343 -0.4282294 ]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #20 | lambda learn rate = 0.001\n",
      "Target = [[6.]\n",
      " [8.]]\n",
      "lambda end of trial = [[ 0.         -0.00391138 -0.48191832]\n",
      " [ 0.         -0.03860594 -0.33231781]\n",
      " [ 0.         -0.35977255 -0.0544013 ]\n",
      " [ 0.          0.22398385 -0.62708576]\n",
      " [ 0.         -0.16488225 -0.24550266]\n",
      " [ 0.         -0.12928657 -0.25608478]\n",
      " [ 0.         -0.53913777  0.0837264 ]\n",
      " [ 0.         -0.32653854  0.01650492]\n",
      " [ 0.          0.06930631 -0.48009855]\n",
      " [ 0.          0.48093363 -0.85364247]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #21 | lambda learn rate = 0.001\n",
      "Target = [[9.]\n",
      " [0.]]\n",
      "lambda end of trial = [[ 0.          0.43543963 -0.48191832]\n",
      " [ 0.          0.40044761 -0.33231781]\n",
      " [ 0.          0.10913831 -0.0544013 ]\n",
      " [ 0.          0.68833297 -0.62708576]\n",
      " [ 0.          0.26840511 -0.24550266]\n",
      " [ 0.          0.32200919 -0.25608478]\n",
      " [ 0.         -0.09744049  0.0837264 ]\n",
      " [ 0.          0.08283581  0.01650492]\n",
      " [ 0.          0.50706091 -0.48009855]\n",
      " [ 0.          0.89531668 -0.85364247]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #22 | lambda learn rate = 0.001\n",
      "Target = [[7.]\n",
      " [9.]]\n",
      "lambda end of trial = [[ 0.          0.75699045 -0.06849585]\n",
      " [ 0.          0.7274669   0.08813556]\n",
      " [ 0.          0.42738795  0.3547768 ]\n",
      " [ 0.          1.02232901 -0.19766227]\n",
      " [ 0.          0.60487938  0.18710712]\n",
      " [ 0.          0.63746992  0.14950758]\n",
      " [ 0.          0.22326389  0.4960606 ]\n",
      " [ 0.          0.40680377  0.43303516]\n",
      " [ 0.          0.83207547 -0.06222268]\n",
      " [ 0.          1.21954024 -0.43678362]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #23 | lambda learn rate = 0.001\n",
      "Target = [[3.]\n",
      " [2.]]\n",
      "lambda end of trial = [[ 0.          0.57279383 -0.19129359]\n",
      " [ 0.          0.50561017 -0.05976893]\n",
      " [ 0.          0.22705057  0.22121855]\n",
      " [ 0.          0.81733219 -0.33432682]\n",
      " [ 0.          0.39610917  0.04792699]\n",
      " [ 0.          0.42032386  0.00474354]\n",
      " [ 0.          0.03701118  0.37189213]\n",
      " [ 0.          0.22013536  0.30858955]\n",
      " [ 0.          0.63836644 -0.19136203]\n",
      " [ 0.          1.02029662 -0.56961269]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #24 | lambda learn rate = 0.001\n",
      "Target = [[6.]\n",
      " [9.]]\n",
      "lambda end of trial = [[ 0.          0.2918794  -0.61266524]\n",
      " [ 0.          0.18405245 -0.54210551]\n",
      " [ 0.         -0.10489297 -0.27669676]\n",
      " [ 0.          0.49282017 -0.82109485]\n",
      " [ 0.          0.07130691 -0.43927641]\n",
      " [ 0.          0.14497956 -0.4082729 ]\n",
      " [ 0.         -0.2758632  -0.09741943]\n",
      " [ 0.         -0.11750454 -0.1978703 ]\n",
      " [ 0.          0.32572286 -0.66032741]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [ 0.          0.7217355  -1.01745437]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #25 | lambda learn rate = 0.001\n",
      "Target = [[8.]\n",
      " [8.]]\n",
      "lambda end of trial = [[ 0.          1.32260798  0.41806334]\n",
      " [ 0.          1.22709344  0.50093548]\n",
      " [ 0.          0.77805773  0.60625395]\n",
      " [ 0.          1.49530887  0.18139385]\n",
      " [ 0.          1.05349074  0.54290742]\n",
      " [ 0.          1.18622716  0.63297469]\n",
      " [ 0.          0.69462664  0.8730704 ]\n",
      " [ 0.          0.93458462  0.85421886]\n",
      " [ 0.          1.23385357  0.2478033 ]\n",
      " [ 0.          1.71079082 -0.02839905]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #26 | lambda learn rate = 0.001\n",
      "Target = [[0.]\n",
      " [7.]]\n",
      "lambda end of trial = [[ 0.          1.32260798 -0.27118478]\n",
      " [ 0.          1.22709344 -0.23050728]\n",
      " [ 0.          0.77805773 -0.118338  ]\n",
      " [ 0.          1.49530887 -0.581538  ]\n",
      " [ 0.          1.05349074 -0.22385121]\n",
      " [ 0.          1.18622716 -0.12837022]\n",
      " [ 0.          0.69462664  0.1955176 ]\n",
      " [ 0.          0.93458462  0.15444355]\n",
      " [ 0.          1.23385357 -0.45807572]\n",
      " [ 0.          1.71079082 -0.68886388]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #27 | lambda learn rate = 0.001\n",
      "Target = [[9.]\n",
      " [8.]]\n",
      "lambda end of trial = [[ 0.         -0.75403109 -2.11708617]\n",
      " [ 0.         -1.18167887 -2.37163822]\n",
      " [ 0.         -1.32787724 -1.99028021]\n",
      " [ 0.         -0.63343788 -2.47375733]\n",
      " [ 0.         -1.17682432 -2.20635348]\n",
      " [ 0.         -1.17152212 -2.22414736]\n",
      " [ 0.         -1.50549108 -1.76014258]\n",
      " [ 0.         -1.26987273 -1.8050741 ]\n",
      " [ 0.         -0.80051784 -2.26640586]\n",
      " [ 0.         -0.25602899 -2.43714816]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #28 | lambda learn rate = 0.001\n",
      "Target = [[6.]\n",
      " [3.]]\n",
      "lambda end of trial = [[ 0.          1.85801577 -0.81106275]\n",
      " [ 0.          1.64278049 -0.95940855]\n",
      " [ 0.          1.38721729 -0.63273294]\n",
      " [ 0.          2.05720053 -1.12843812]\n",
      " [ 0.          1.84535164 -0.6952655 ]\n",
      " [ 0.          1.81525429 -0.73075916]\n",
      " [ 0.          1.34551598 -0.33463905]\n",
      " [ 0.          1.3005801  -0.51984768]\n",
      " [ 0.          1.81530842 -0.95849273]\n",
      " [ 0.          2.64158955 -0.98833889]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #29 | lambda learn rate = 0.001\n",
      "Target = [[3.]\n",
      " [8.]]\n",
      "lambda end of trial = [[ 0.          2.01027173 -0.40504684]\n",
      " [ 0.          1.81035196 -0.51255127]\n",
      " [ 0.          1.54576808 -0.20993085]\n",
      " [ 0.          2.21321425 -0.71240155]\n",
      " [ 0.          2.00659452 -0.2652845 ]\n",
      " [ 0.          1.96623632 -0.32814041]\n",
      " [ 0.          1.51089638  0.10637534]\n",
      " [ 0.          1.44558919 -0.13315677]\n",
      " [ 0.          1.97273035 -0.53870093]\n",
      " [ 0.          2.79186451 -0.58760566]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #30 | lambda learn rate = 0.001\n",
      "Target = [[4.]\n",
      " [7.]]\n",
      "lambda end of trial = [[ 0.          1.4431028  -1.39759247]\n",
      " [ 0.          1.23155087 -1.52545318]\n",
      " [ 0.          0.95975279 -1.2354576 ]\n",
      " [ 0.          1.65558947 -1.68824492]\n",
      " [ 0.          1.40190448 -1.32349206]\n",
      " [ 0.          1.40967748 -1.30211838]\n",
      " [ 0.          0.97821432 -0.82581826]\n",
      " [ 0.          0.90983597 -1.07072491]\n",
      " [ 0.          1.46407329 -1.42885078]\n",
      " [ 0.          2.22373313 -1.58183557]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #31 | lambda learn rate = 0.001\n",
      "Target = [[7.]\n",
      " [3.]]\n",
      "lambda end of trial = [[ 0.          0.3779728  -1.85407675]\n",
      " [ 0.          0.14587435 -1.99074312]\n",
      " [ 0.         -0.12791542 -1.70160112]\n",
      " [ 0.          0.60377621 -2.13902203]\n",
      " [ 0.          0.29296611 -1.79875136]\n",
      " [ 0.          0.34253226 -1.75946633]\n",
      " [ 0.         -0.10425623 -1.28973421]\n",
      " [ 0.         -0.12392977 -1.51376737]\n",
      " [ 0.          0.4306169  -1.87176066]\n",
      " [ 0.          1.2335387  -2.00620462]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #32 | lambda learn rate = 0.001\n",
      "Target = [[9.]\n",
      " [6.]]\n",
      "lambda end of trial = [[ 0.          2.79667352 -0.24160961]\n",
      " [ 0.          2.52809729 -0.40259449]\n",
      " [ 0.          2.55704328  0.08837134]\n",
      " [ 0.          3.27589708 -0.35760812]\n",
      " [ 0.          2.82780527 -0.10885859]\n",
      " [ 0.          2.69042866 -0.19420207]\n",
      " [ 0.          2.52579172  0.46363109]\n",
      " [ 0.          2.57403981  0.28487902]\n",
      " [ 0.          2.93158516 -0.20444848]\n",
      " [ 0.          3.94172259 -0.20074869]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #33 | lambda learn rate = 0.001\n",
      "Target = [[4.]\n",
      " [0.]]\n",
      "lambda end of trial = [[ 0.          1.35273557 -0.24160961]\n",
      " [ 0.          0.79268984 -0.40259449]\n",
      " [ 0.          1.18181406  0.08837134]\n",
      " [ 0.          1.86417649 -0.35760812]\n",
      " [ 0.          1.31115479 -0.10885859]\n",
      " [ 0.          1.09772804 -0.19420207]\n",
      " [ 0.          0.94945539  0.46363109]\n",
      " [ 0.          1.13524373  0.28487902]\n",
      " [ 0.          1.47037302 -0.20444848]\n",
      " [ 0.          2.45658235 -0.20074869]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #34 | lambda learn rate = 0.001\n",
      "Target = [[1.]\n",
      " [5.]]\n",
      "lambda end of trial = [[ 0.          1.33444907 -0.33304214]\n",
      " [ 0.          0.77344713 -0.49880803]\n",
      " [ 0.          1.16053379 -0.01803002]\n",
      " [ 0.          1.8453868  -0.45155656]\n",
      " [ 0.          1.2916062  -0.20660152]\n",
      " [ 0.          1.07888273 -0.28842861]\n",
      " [ 0.          0.92991475  0.36592792]\n",
      " [ 0.          1.11484608  0.18289078]\n",
      " [ 0.          1.45171377 -0.29774478]\n",
      " [ 0.          2.4378651  -0.29433496]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #35 | lambda learn rate = 0.001\n",
      "Target = [[0.]\n",
      " [8.]]\n",
      "lambda end of trial = [[0.         1.33444907 0.15751631]\n",
      " [0.         0.77344713 0.03967657]\n",
      " [0.         1.16053379 0.50043463]\n",
      " [0.         1.8453868  0.03390501]\n",
      " [0.         1.2916062  0.28833885]\n",
      " [0.         1.07888273 0.22484655]\n",
      " [0.         0.92991475 0.89187948]\n",
      " [0.         1.11484608 0.60459796]\n",
      " [0.         1.45171377 0.22608502]\n",
      " [0.         2.4378651  0.21967234]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #36 | lambda learn rate = 0.001\n",
      "Target = [[3.]\n",
      " [4.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda end of trial = [[ 0.          0.89285953 -0.43126974]\n",
      " [ 0.          0.27635022 -0.62311931]\n",
      " [ 0.          0.67182973 -0.15117078]\n",
      " [ 0.          1.36501857 -0.60658596]\n",
      " [ 0.          0.86813206 -0.27629333]\n",
      " [ 0.          0.61373107 -0.39535565]\n",
      " [ 0.          0.48388257  0.29716991]\n",
      " [ 0.          0.68193386  0.02738167]\n",
      " [ 0.          0.99942097 -0.37697203]\n",
      " [ 0.          1.97232988 -0.40104128]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #37 | lambda learn rate = 0.001\n",
      "Target = [[6.]\n",
      " [6.]]\n",
      "lambda end of trial = [[ 0.          0.44988976 -0.87423951]\n",
      " [ 0.         -0.17409579 -1.07356532]\n",
      " [ 0.          0.24872039 -0.57428012]\n",
      " [ 0.          0.90388236 -1.06772217]\n",
      " [ 0.          0.38596216 -0.75846324]\n",
      " [ 0.          0.19422582 -0.81486091]\n",
      " [ 0.          0.04640382 -0.14030884]\n",
      " [ 0.          0.22175343 -0.43279877]\n",
      " [ 0.          0.56162009 -0.81477292]\n",
      " [ 0.          1.53217399 -0.84119717]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #38 | lambda learn rate = 0.001\n",
      "Target = [[4.]\n",
      " [1.]]\n",
      "lambda end of trial = [[ 0.          0.38689949 -0.88998708]\n",
      " [ 0.         -0.24664634 -1.09170296]\n",
      " [ 0.          0.1824444  -0.59084912]\n",
      " [ 0.          0.8402936  -1.08361936]\n",
      " [ 0.          0.32170941 -0.77452643]\n",
      " [ 0.          0.11857834 -0.83377278]\n",
      " [ 0.         -0.01705009 -0.15617232]\n",
      " [ 0.          0.15617117 -0.44919433]\n",
      " [ 0.          0.49752016 -0.8307979 ]\n",
      " [ 0.          1.46712357 -0.85745978]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #39 | lambda learn rate = 0.001\n",
      "Target = [[2.]\n",
      " [6.]]\n",
      "lambda end of trial = [[ 0.          0.67292233 -0.03191856]\n",
      " [ 0.          0.04273947 -0.22354553]\n",
      " [ 0.          0.46123383  0.24551916]\n",
      " [ 0.          1.14022874 -0.18381393]\n",
      " [ 0.          0.60801595  0.0843932 ]\n",
      " [ 0.          0.42135099  0.07454517]\n",
      " [ 0.          0.29328709  0.77483922]\n",
      " [ 0.          0.4548283   0.44677705]\n",
      " [ 0.          0.77671955  0.00680025]\n",
      " [ 0.          1.75363696  0.0020804 ]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #40 | lambda learn rate = 0.001\n",
      "Target = [[7.]\n",
      " [5.]]\n",
      "lambda end of trial = [[ 0.         -0.20141674 -0.65644647]\n",
      " [ 0.         -0.83472243 -0.85030403]\n",
      " [ 0.         -0.52915371 -0.46190051]\n",
      " [ 0.          0.36805444 -0.735367  ]\n",
      " [ 0.         -0.34717784 -0.59788808]\n",
      " [ 0.         -0.53022539 -0.60515223]\n",
      " [ 0.         -0.57331392  0.15583849]\n",
      " [ 0.         -0.39234576 -0.15834727]\n",
      " [ 0.         -0.07133539 -0.59895328]\n",
      " [ 0.          0.7574715  -0.70946636]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #41 | lambda learn rate = 0.001\n",
      "Target = [[7.]\n",
      " [3.]]\n",
      "lambda end of trial = [[ 0.          0.82877405 -0.21493613]\n",
      " [ 0.          0.21572885 -0.40011062]\n",
      " [ 0.          0.5347284  -0.00595103]\n",
      " [ 0.          1.38893413 -0.29784713]\n",
      " [ 0.          0.59650638 -0.19345199]\n",
      " [ 0.          0.33582072 -0.23398962]\n",
      " [ 0.          0.46620628  0.60134715]\n",
      " [ 0.          0.64076051  0.28441256]\n",
      " [ 0.          0.95485956 -0.15915544]\n",
      " [ 0.          1.75589462 -0.28157074]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #42 | lambda learn rate = 0.001\n",
      "Target = [[9.]\n",
      " [0.]]\n",
      "lambda end of trial = [[ 0.         -0.70904025 -0.21493613]\n",
      " [ 0.         -1.51181954 -0.40011062]\n",
      " [ 0.         -1.04919392 -0.00595103]\n",
      " [ 0.         -0.30403314 -0.29784713]\n",
      " [ 0.         -0.98582119 -0.19345199]\n",
      " [ 0.         -1.31520794 -0.23398962]\n",
      " [ 0.         -1.12049502  0.60134715]\n",
      " [ 0.         -1.16674182  0.28441256]\n",
      " [ 0.         -0.72556579 -0.15915544]\n",
      " [ 0.          0.1890884  -0.28157074]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #43 | lambda learn rate = 0.001\n",
      "Target = [[5.]\n",
      " [4.]]\n",
      "lambda end of trial = [[ 0.          0.30733492  0.598164  ]\n",
      " [ 0.         -0.532658    0.38321861]\n",
      " [ 0.         -0.01255745  0.82335814]\n",
      " [ 0.          0.69317962  0.49992307]\n",
      " [ 0.          0.0253616   0.61549425]\n",
      " [ 0.         -0.33986767  0.54628261]\n",
      " [ 0.         -0.25567512  1.29320307]\n",
      " [ 0.         -0.16290593  1.08748127]\n",
      " [ 0.          0.21091269  0.59002734]\n",
      " [ 0.          1.22964613  0.55087545]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #44 | lambda learn rate = 0.001\n",
      "Target = [[4.]\n",
      " [4.]]\n",
      "lambda end of trial = [[ 0.          0.03706832  0.32789741]\n",
      " [ 0.         -0.83578226  0.08009435]\n",
      " [ 0.         -0.28911596  0.54679963]\n",
      " [ 0.          0.43044851  0.23719197]\n",
      " [ 0.         -0.27611788  0.31401476]\n",
      " [ 0.         -0.65537332  0.23077696]\n",
      " [ 0.         -0.55707549  0.99180269]\n",
      " [ 0.         -0.4398715   0.8105157 ]\n",
      " [ 0.         -0.11730051  0.26181414]\n",
      " [ 0.          0.93198352  0.25321283]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #45 | lambda learn rate = 0.001\n",
      "Target = [[7.]\n",
      " [5.]]\n",
      "lambda end of trial = [[ 0.          0.20768102  0.44976362]\n",
      " [ 0.         -0.6645271   0.20241946]\n",
      " [ 0.         -0.09324581  0.68670688]\n",
      " [ 0.          0.60188575  0.35964714]\n",
      " [ 0.         -0.08942897  0.44736398]\n",
      " [ 0.         -0.48722585  0.35088229]\n",
      " [ 0.         -0.371929    1.12405019]\n",
      " [ 0.         -0.25336615  0.94373381]\n",
      " [ 0.          0.06245357  0.39020991]\n",
      " [ 0.          1.12279704  0.38950821]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #46 | lambda learn rate = 0.001\n",
      "Target = [[3.]\n",
      " [4.]]\n",
      "lambda end of trial = [[ 0.          0.06395951  0.25813494]\n",
      " [ 0.         -0.80783053  0.01134822]\n",
      " [ 0.         -0.22978658  0.50465253]\n",
      " [ 0.          0.46143187  0.17237529]\n",
      " [ 0.         -0.2369607   0.25065501]\n",
      " [ 0.         -0.62370453  0.16891072]\n",
      " [ 0.         -0.4951793   0.95971645]\n",
      " [ 0.         -0.40608356  0.74011059]\n",
      " [ 0.         -0.06594941  0.21900594]\n",
      " [ 0.          0.99316696  0.2166681 ]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #47 | lambda learn rate = 0.001\n",
      "Target = [[0.]\n",
      " [4.]]\n",
      "lambda end of trial = [[ 0.          0.06395951  0.09057132]\n",
      " [ 0.         -0.80783053 -0.14594625]\n",
      " [ 0.         -0.22978658  0.35849489]\n",
      " [ 0.          0.46143187  0.01579086]\n",
      " [ 0.         -0.2369607   0.09076987]\n",
      " [ 0.         -0.62370453  0.01493509]\n",
      " [ 0.         -0.4951793   0.81960995]\n",
      " [ 0.         -0.40608356  0.58638281]\n",
      " [ 0.         -0.06594941  0.07776452]\n",
      " [ 0.          0.99316696  0.07035792]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #48 | lambda learn rate = 0.001\n",
      "Target = [[6.]\n",
      " [9.]]\n",
      "lambda end of trial = [[ 0.          0.23419672  0.34592714]\n",
      " [ 0.         -0.62327998  0.13087957]\n",
      " [ 0.         -0.05954341  0.61385965]\n",
      " [ 0.          0.62139068  0.25572907]\n",
      " [ 0.         -0.05587961  0.3623915 ]\n",
      " [ 0.         -0.44752791  0.27920001]\n",
      " [ 0.         -0.32841757  1.06975255]\n",
      " [ 0.         -0.21997895  0.86553974]\n",
      " [ 0.          0.10863224  0.339637  ]\n",
      " [ 0.          1.17316727  0.34035838]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #49 | lambda learn rate = 0.001\n",
      "Target = [[7.]\n",
      " [0.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda end of trial = [[ 0.          0.40465635  0.34592714]\n",
      " [ 0.         -0.45571265  0.13087957]\n",
      " [ 0.          0.10641004  0.61385965]\n",
      " [ 0.          0.79801078  0.25572907]\n",
      " [ 0.          0.1018355   0.3623915 ]\n",
      " [ 0.         -0.28628574  0.27920001]\n",
      " [ 0.         -0.15559449  1.06975255]\n",
      " [ 0.         -0.03092246  0.86553974]\n",
      " [ 0.          0.27625079  0.339637  ]\n",
      " [ 0.          1.34242999  0.34035838]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #50 | lambda learn rate = 0.001\n",
      "Target = [[6.]\n",
      " [2.]]\n",
      "lambda end of trial = [[ 0.          0.21827317  0.28379941]\n",
      " [ 0.         -0.67761763  0.05691124]\n",
      " [ 0.         -0.10502777  0.54338038]\n",
      " [ 0.          0.5983992   0.18919188]\n",
      " [ 0.         -0.09703829  0.29610024]\n",
      " [ 0.         -0.49339512  0.21016355]\n",
      " [ 0.         -0.35234457  1.00416919]\n",
      " [ 0.         -0.24378638  0.79458509]\n",
      " [ 0.          0.04488198  0.26251406]\n",
      " [ 0.          1.13116558  0.26993691]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #51 | lambda learn rate = 0.001\n",
      "Target = [[7.]\n",
      " [8.]]\n",
      "lambda end of trial = [[ 0.         -0.05979142 -0.03398868]\n",
      " [ 0.         -0.94999902 -0.25438177]\n",
      " [ 0.         -0.41244099  0.19205098]\n",
      " [ 0.          0.32136709 -0.12741626]\n",
      " [ 0.         -0.38992535 -0.03862783]\n",
      " [ 0.         -0.76493363 -0.10016618]\n",
      " [ 0.         -0.60931481  0.71048891]\n",
      " [ 0.         -0.55102577  0.44345437]\n",
      " [ 0.         -0.24641514 -0.07039693]\n",
      " [ 0.          0.82693511 -0.07775506]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #52 | lambda learn rate = 0.001\n",
      "Target = [[2.]\n",
      " [3.]]\n",
      "lambda end of trial = [[ 0.00000000e+00 -6.99243139e-03  4.52097970e-02]\n",
      " [ 0.00000000e+00 -8.94007223e-01 -1.70394080e-01]\n",
      " [ 0.00000000e+00 -3.57807956e-01  2.74000534e-01]\n",
      " [ 0.00000000e+00  3.71442378e-01 -5.23033155e-02]\n",
      " [ 0.00000000e+00 -3.41394282e-01  3.41687721e-02]\n",
      " [ 0.00000000e+00 -7.17191120e-01 -2.85524136e-02]\n",
      " [ 0.00000000e+00 -5.57130450e-01  7.88765452e-01]\n",
      " [ 0.00000000e+00 -4.99609588e-01  5.20578639e-01]\n",
      " [ 0.00000000e+00 -1.99589881e-01 -1.59042525e-04]\n",
      " [ 0.00000000e+00  8.81433782e-01  3.99295453e-03]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #53 | lambda learn rate = 0.001\n",
      "Target = [[5.]\n",
      " [5.]]\n",
      "lambda end of trial = [[ 0.          0.2623837   0.31458593]\n",
      " [ 0.         -0.61876558  0.10484756]\n",
      " [ 0.         -0.08601466  0.54579383]\n",
      " [ 0.          0.65566031  0.23191461]\n",
      " [ 0.         -0.05817224  0.31739081]\n",
      " [ 0.         -0.41252387  0.27611484]\n",
      " [ 0.         -0.29262794  1.05326796]\n",
      " [ 0.         -0.24869904  0.77148919]\n",
      " [ 0.          0.05274797  0.25217881]\n",
      " [ 0.          1.15363681  0.27619598]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #54 | lambda learn rate = 0.001\n",
      "Target = [[1.]\n",
      " [9.]]\n",
      "lambda end of trial = [[ 0.          0.17580462 -0.46462581]\n",
      " [ 0.         -0.71389561 -0.75132266]\n",
      " [ 0.         -0.18031243 -0.30288614]\n",
      " [ 0.          0.56362186 -0.5964314 ]\n",
      " [ 0.         -0.15102936 -0.51832324]\n",
      " [ 0.         -0.50364012 -0.54393144]\n",
      " [ 0.         -0.38080313  0.25969129]\n",
      " [ 0.         -0.33791254 -0.03143232]\n",
      " [ 0.         -0.04826445 -0.65693298]\n",
      " [ 0.          1.06434873 -0.5273967 ]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #55 | lambda learn rate = 0.001\n",
      "Target = [[0.]\n",
      " [2.]]\n",
      "lambda end of trial = [[ 0.          0.17580462 -0.41912413]\n",
      " [ 0.         -0.71389561 -0.70747166]\n",
      " [ 0.         -0.18031243 -0.25213564]\n",
      " [ 0.          0.56362186 -0.54430658]\n",
      " [ 0.         -0.15102936 -0.47233348]\n",
      " [ 0.         -0.50364012 -0.49788654]\n",
      " [ 0.         -0.38080313  0.30888725]\n",
      " [ 0.         -0.33791254  0.01604613]\n",
      " [ 0.         -0.04826445 -0.60631103]\n",
      " [ 0.          1.06434873 -0.47804042]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #56 | lambda learn rate = 0.001\n",
      "Target = [[9.]\n",
      " [8.]]\n",
      "lambda end of trial = [[0.         1.72189326 0.95517688]\n",
      " [0.         1.05239528 0.86256468]\n",
      " [0.         1.58288064 1.31514709]\n",
      " [0.         2.44902781 1.13160982]\n",
      " [0.         1.52544385 1.01786493]\n",
      " [0.         1.48195089 1.26708325]\n",
      " [0.         1.18037577 1.69660183]\n",
      " [0.         1.41293877 1.57235841]\n",
      " [0.         1.79602315 1.03305573]\n",
      " [0.         2.7437559  1.01476595]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #57 | lambda learn rate = 0.001\n",
      "Target = [[2.]\n",
      " [7.]]\n",
      "lambda end of trial = [[ 0.          0.96495284 -1.6941146 ]\n",
      " [ 0.          0.29474461 -1.78921266]\n",
      " [ 0.          0.83782271 -1.29255567]\n",
      " [ 0.          1.64870044 -1.66953598]\n",
      " [ 0.          0.72524143 -1.78284355]\n",
      " [ 0.          0.72424577 -1.38488465]\n",
      " [ 0.          0.49522409 -0.70142906]\n",
      " [ 0.          0.65908752 -1.06612098]\n",
      " [ 0.          0.98011227 -1.82263234]\n",
      " [ 0.          2.04671205 -1.42488752]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #58 | lambda learn rate = 0.001\n",
      "Target = [[1.]\n",
      " [6.]]\n",
      "lambda end of trial = [[ 0.          1.23314469 -0.08496347]\n",
      " [ 0.          0.5715358  -0.12846552]\n",
      " [ 0.          1.12244848  0.41519899]\n",
      " [ 0.          1.92544905 -0.00904428]\n",
      " [ 0.          1.02361376  0.00739049]\n",
      " [ 0.          1.01682761  0.37060636]\n",
      " [ 0.          0.76877317  0.93986546]\n",
      " [ 0.          0.95363122  0.70114121]\n",
      " [ 0.          1.23819667 -0.27412599]\n",
      " [ 0.          2.31532     0.18676019]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #59 | lambda learn rate = 0.001\n",
      "Target = [[8.]\n",
      " [0.]]\n",
      "lambda end of trial = [[ 0.         -0.92627044 -0.08496347]\n",
      " [ 0.         -1.75805874 -0.12846552]\n",
      " [ 0.         -0.89168857  0.41519899]\n",
      " [ 0.         -0.31947569 -0.00904428]\n",
      " [ 0.         -1.18877626  0.00739049]\n",
      " [ 0.         -1.40514769  0.37060636]\n",
      " [ 0.         -1.4130589   0.93986546]\n",
      " [ 0.         -0.98545955  0.70114121]\n",
      " [ 0.         -0.81536783 -0.27412599]\n",
      " [ 0.          0.1374579   0.18676019]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #60 | lambda learn rate = 0.001\n",
      "Target = [[3.]\n",
      " [8.]]\n",
      "lambda end of trial = [[ 0.         -0.72278427  0.45766632]\n",
      " [ 0.         -1.55777258  0.40563091]\n",
      " [ 0.         -0.7026125   0.91940184]\n",
      " [ 0.         -0.1245877   0.51065702]\n",
      " [ 0.         -0.98494581  0.55093835]\n",
      " [ 0.         -1.21536566  0.87669178]\n",
      " [ 0.         -1.19488938  1.52165085]\n",
      " [ 0.         -0.7918709   1.21737761]\n",
      " [ 0.         -0.63089476  0.21780219]\n",
      " [ 0.          0.3530581   0.76169404]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #61 | lambda learn rate = 0.001\n",
      "Target = [[9.]\n",
      " [8.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda end of trial = [[ 0.          0.06345094  1.15654206]\n",
      " [ 0.         -0.68421137  1.18212976]\n",
      " [ 0.          0.11142937  1.64299461]\n",
      " [ 0.          0.62592464  1.17777909]\n",
      " [ 0.         -0.1547934   1.28885161]\n",
      " [ 0.         -0.39642656  1.60463764]\n",
      " [ 0.         -0.35156077  2.27127628]\n",
      " [ 0.          0.00992197  1.93008238]\n",
      " [ 0.          0.17520464  0.93433498]\n",
      " [ 0.          1.13124435  1.45341515]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #62 | lambda learn rate = 0.001\n",
      "Target = [[6.]\n",
      " [3.]]\n",
      "lambda end of trial = [[ 0.         -0.65132971  0.79915173]\n",
      " [ 0.         -1.50742374  0.77052358]\n",
      " [ 0.         -0.61973693  1.27741146]\n",
      " [ 0.         -0.0913842   0.81912468]\n",
      " [ 0.         -0.91893427  0.90678118]\n",
      " [ 0.         -1.19763939  1.20403123]\n",
      " [ 0.         -1.01380835  1.94015249]\n",
      " [ 0.         -0.80596789  1.52213745]\n",
      " [ 0.         -0.57670934  0.55837799]\n",
      " [ 0.          0.39232738  1.08395667]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #63 | lambda learn rate = 0.001\n",
      "Target = [[3.]\n",
      " [6.]]\n",
      "lambda end of trial = [[ 0.         -1.00763788  0.08653539]\n",
      " [ 0.         -1.86422812  0.05691481]\n",
      " [ 0.         -0.99674768  0.52338997]\n",
      " [ 0.         -0.45793156  0.08602995]\n",
      " [ 0.         -1.28375081  0.17714809]\n",
      " [ 0.         -1.56458934  0.47013132]\n",
      " [ 0.         -1.33493082  1.29790756]\n",
      " [ 0.         -1.15771412  0.81864499]\n",
      " [ 0.         -0.98173746 -0.25167823]\n",
      " [ 0.          0.04085489  0.38101169]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #64 | lambda learn rate = 0.001\n",
      "Target = [[4.]\n",
      " [4.]]\n",
      "lambda end of trial = [[ 0.         -0.50336072  0.59081255]\n",
      " [ 0.         -1.36051665  0.56062628]\n",
      " [ 0.         -0.525237    0.99490064]\n",
      " [ 0.          0.01893682  0.56289833]\n",
      " [ 0.         -0.79383023  0.66706867]\n",
      " [ 0.         -1.0663987   0.96832196]\n",
      " [ 0.         -0.82634185  1.80649653]\n",
      " [ 0.         -0.66984523  1.30651388]\n",
      " [ 0.         -0.55423073  0.17582849]\n",
      " [ 0.          0.54791229  0.88806909]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #65 | lambda learn rate = 0.001\n",
      "Target = [[9.]\n",
      " [3.]]\n",
      "lambda end of trial = [[0.         0.68570111 0.98716649]\n",
      " [0.         0.00356198 1.01531915]\n",
      " [0.         0.80343594 1.43779163]\n",
      " [0.         1.28520302 0.98498707]\n",
      " [0.         0.39540991 1.06348205]\n",
      " [0.         0.1720811  1.38114856]\n",
      " [0.         0.45937638 2.23506927]\n",
      " [0.         0.58121719 1.72353469]\n",
      " [0.         0.69382447 0.59184689]\n",
      " [0.         1.86082868 1.32570789]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #66 | lambda learn rate = 0.001\n",
      "Target = [[8.]\n",
      " [2.]]\n",
      "lambda end of trial = [[ 0.         -0.91257503  0.58759746]\n",
      " [ 0.         -1.75459483  0.57577995]\n",
      " [ 0.         -1.12766876  0.95501545]\n",
      " [ 0.         -0.50796233  0.53669573]\n",
      " [ 0.         -1.34552745  0.62824771]\n",
      " [ 0.         -1.57951968  0.94324836]\n",
      " [ 0.         -1.41226174  1.76715974]\n",
      " [ 0.         -1.26692021  1.26150034]\n",
      " [ 0.         -1.28956135  0.09600044]\n",
      " [ 0.          0.14152896  0.89588296]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #67 | lambda learn rate = 0.001\n",
      "Target = [[1.]\n",
      " [3.]]\n",
      "lambda end of trial = [[ 0.         -0.94610041  0.4870213 ]\n",
      " [ 0.         -1.79217233  0.46304744]\n",
      " [ 0.         -1.1647931   0.84364243]\n",
      " [ 0.         -0.54408793  0.42831893]\n",
      " [ 0.         -1.37985323  0.52527037]\n",
      " [ 0.         -1.61810736  0.82748533]\n",
      " [ 0.         -1.44766092  1.66096219]\n",
      " [ 0.         -1.30354825  1.15161621]\n",
      " [ 0.         -1.32497953 -0.01025409]\n",
      " [ 0.          0.1063991   0.79049337]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #68 | lambda learn rate = 0.001\n",
      "Target = [[3.]\n",
      " [4.]]\n",
      "lambda end of trial = [[ 0.         -0.83174619  0.6394936 ]\n",
      " [ 0.         -1.66427586  0.63357606]\n",
      " [ 0.         -1.04999836  0.99670209]\n",
      " [ 0.         -0.4413664   0.56528097]\n",
      " [ 0.         -1.25439949  0.69254203]\n",
      " [ 0.         -1.49783237  0.98785198]\n",
      " [ 0.         -1.33136589  1.81602223]\n",
      " [ 0.         -1.19380387  1.29794205]\n",
      " [ 0.         -1.20729062  0.14666446]\n",
      " [ 0.          0.21902061  0.94065538]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #69 | lambda learn rate = 0.001\n",
      "Target = [[8.]\n",
      " [5.]]\n",
      "lambda end of trial = [[ 0.          0.61702103  1.54497311]\n",
      " [ 0.         -0.2650697   1.50807991]\n",
      " [ 0.          0.29492258  1.83727768]\n",
      " [ 0.          1.03892423  1.49046262]\n",
      " [ 0.          0.27080169  1.64579276]\n",
      " [ 0.         -0.07112015  1.87954712]\n",
      " [ 0.          0.0756576   2.69541192]\n",
      " [ 0.          0.28661356  2.22320294]\n",
      " [ 0.          0.37878364  1.13796087]\n",
      " [ 0.          1.62139228  1.81713768]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #70 | lambda learn rate = 0.001\n",
      "Target = [[2.]\n",
      " [6.]]\n",
      "lambda end of trial = [[ 0.         -0.0764324  -0.5353872 ]\n",
      " [ 0.         -0.91859377 -0.4524923 ]\n",
      " [ 0.         -0.38389358 -0.19917082]\n",
      " [ 0.          0.39155652 -0.45164051]\n",
      " [ 0.         -0.41746616 -0.4190108 ]\n",
      " [ 0.         -0.7661235  -0.20546294]\n",
      " [ 0.         -0.56318253  0.77889152]\n",
      " [ 0.         -0.44972925  0.01417452]\n",
      " [ 0.         -0.2617258  -0.78356747]\n",
      " [ 0.          0.95676744 -0.17673686]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #71 | lambda learn rate = 0.001\n",
      "Target = [[9.]\n",
      " [3.]]\n",
      "lambda end of trial = [[ 0.          1.44973832 -0.02666362]\n",
      " [ 0.          0.5881265   0.04974779]\n",
      " [ 0.          1.24423047  0.34353719]\n",
      " [ 0.          1.83125404  0.02825867]\n",
      " [ 0.          0.97273857  0.04439078]\n",
      " [ 0.          0.57848182  0.24273883]\n",
      " [ 0.          0.83227819  1.24404509]\n",
      " [ 0.          0.97034664  0.48753315]\n",
      " [ 0.          1.14648207 -0.31416485]\n",
      " [ 0.          2.47520626  0.32940942]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #72 | lambda learn rate = 0.001\n",
      "Target = [[9.]\n",
      " [4.]]\n",
      "lambda end of trial = [[ 0.         -1.46572731 -1.32242612]\n",
      " [ 0.         -2.40344939 -1.27984149]\n",
      " [ 0.         -1.60086765 -0.92095086]\n",
      " [ 0.         -0.97094502 -1.21716314]\n",
      " [ 0.         -1.84317404 -1.20712594]\n",
      " [ 0.         -2.26797871 -1.02235474]\n",
      " [ 0.         -1.74308082  0.09944108]\n",
      " [ 0.         -2.05016392 -0.85491599]\n",
      " [ 0.         -1.43400705 -1.4610489 ]\n",
      " [ 0.         -0.0215201  -0.78024674]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #73 | lambda learn rate = 0.001\n",
      "Target = [[8.]\n",
      " [4.]]\n",
      "lambda end of trial = [[0.         2.57309692 0.696986  ]\n",
      " [0.         2.36175637 1.10276139]\n",
      " [0.         3.34032982 1.54964787]\n",
      " [0.         3.53797015 1.03729445]\n",
      " [0.         3.55908633 1.49400425]\n",
      " [0.         2.01840886 1.12083905]\n",
      " [0.         3.29705969 2.61951134]\n",
      " [0.         3.07691259 1.70862227]\n",
      " [0.         3.02771956 0.76981441]\n",
      " [0.         4.5650512  1.51303891]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #74 | lambda learn rate = 0.001\n",
      "Target = [[2.]\n",
      " [9.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda end of trial = [[ 0.          1.41157351 -4.52986939]\n",
      " [ 0.          1.08915277 -4.62395479]\n",
      " [ 0.          2.07000812 -4.16679977]\n",
      " [ 0.          2.34907464 -4.31273534]\n",
      " [ 0.          2.3066389  -4.1420092 ]\n",
      " [ 0.          0.76843234 -4.50405529]\n",
      " [ 0.          2.19626543 -2.33406284]\n",
      " [ 0.          1.97254757 -3.26102033]\n",
      " [ 0.          1.95210894 -4.07043339]\n",
      " [ 0.          3.3484721  -3.961567  ]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #75 | lambda learn rate = 0.001\n",
      "Target = [[6.]\n",
      " [8.]]\n",
      "lambda end of trial = [[0.         5.10971589 0.40098712]\n",
      " [0.         5.27628731 0.95889127]\n",
      " [0.         6.46532798 1.69362672]\n",
      " [0.         6.82175206 1.65083455]\n",
      " [0.         5.99419912 0.77473777]\n",
      " [0.         4.87569296 0.9722922 ]\n",
      " [0.         6.45033784 3.3380337 ]\n",
      " [0.         6.17933383 2.34802801]\n",
      " [0.         6.21942806 1.61932543]\n",
      " [0.         7.5128474  1.59093339]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #76 | lambda learn rate = 0.001\n",
      "Target = [[3.]\n",
      " [0.]]\n",
      "lambda end of trial = [[0.         3.49367167 0.40098712]\n",
      " [0.         3.62396579 0.95889127]\n",
      " [0.         4.70553368 1.69362672]\n",
      " [0.         4.94100609 1.65083455]\n",
      " [0.         3.99705492 0.77473777]\n",
      " [0.         2.9386663  0.9722922 ]\n",
      " [0.         4.7863391  3.3380337 ]\n",
      " [0.         4.45150351 2.34802801]\n",
      " [0.         4.48929045 1.61932543]\n",
      " [0.         5.7586276  1.59093339]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #77 | lambda learn rate = 0.001\n",
      "Target = [[3.]\n",
      " [2.]]\n",
      "lambda end of trial = [[ 0.00000000e+00  2.19640017e+00 -4.63860538e-01]\n",
      " [ 0.00000000e+00  2.20806748e+00  1.49590623e-02]\n",
      " [ 0.00000000e+00  3.27427991e+00  7.39457542e-01]\n",
      " [ 0.00000000e+00  3.43977980e+00  6.50017023e-01]\n",
      " [ 0.00000000e+00  2.35545150e+00 -3.19664509e-01]\n",
      " [ 0.00000000e+00  1.48456110e+00  2.88872961e-03]\n",
      " [ 0.00000000e+00  3.43665597e+00  2.43824495e+00]\n",
      " [ 0.00000000e+00  2.97560958e+00  1.36409873e+00]\n",
      " [ 0.00000000e+00  3.02259782e+00  6.41530345e-01]\n",
      " [ 0.00000000e+00  4.30529503e+00  6.22045012e-01]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #78 | lambda learn rate = 0.001\n",
      "Target = [[9.]\n",
      " [0.]]\n",
      "lambda end of trial = [[ 0.00000000e+00 -5.37378776e+00 -4.63860538e-01]\n",
      " [ 0.00000000e+00 -4.93522406e+00  1.49590623e-02]\n",
      " [ 0.00000000e+00 -4.10394271e+00  7.39457542e-01]\n",
      " [ 0.00000000e+00 -3.60394789e+00  6.50017023e-01]\n",
      " [ 0.00000000e+00 -5.49868436e+00 -3.19664509e-01]\n",
      " [ 0.00000000e+00 -6.32260854e+00  2.88872961e-03]\n",
      " [ 0.00000000e+00 -3.63515381e+00  2.43824495e+00]\n",
      " [ 0.00000000e+00 -3.89193205e+00  1.36409873e+00]\n",
      " [ 0.00000000e+00 -4.64405401e+00  6.41530345e-01]\n",
      " [ 0.00000000e+00 -3.10620860e+00  6.22045012e-01]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #79 | lambda learn rate = 0.001\n",
      "Target = [[0.]\n",
      " [5.]]\n",
      "lambda end of trial = [[ 0.         -5.37378776 -0.79075893]\n",
      " [ 0.         -4.93522406 -0.35529921]\n",
      " [ 0.         -4.10394271  0.4068723 ]\n",
      " [ 0.         -3.60394789  0.35749094]\n",
      " [ 0.         -5.49868436 -0.69021896]\n",
      " [ 0.         -6.32260854 -0.35250594]\n",
      " [ 0.         -3.63515381  2.07920559]\n",
      " [ 0.         -3.89193205  1.01469839]\n",
      " [ 0.         -4.64405401  0.29740482]\n",
      " [ 0.         -3.1062086   0.25310288]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #80 | lambda learn rate = 0.001\n",
      "Target = [[2.]\n",
      " [1.]]\n",
      "lambda end of trial = [[ 0.         -4.66175514 -0.43474262]\n",
      " [ 0.         -4.29026902 -0.0328217 ]\n",
      " [ 0.         -3.46624377  0.72572177]\n",
      " [ 0.         -3.03841836  0.6402557 ]\n",
      " [ 0.         -4.87479376 -0.37827366]\n",
      " [ 0.         -5.76732657 -0.07486495]\n",
      " [ 0.         -3.02947982  2.38204259]\n",
      " [ 0.         -3.25123933  1.33504475]\n",
      " [ 0.         -3.99958442  0.61963961]\n",
      " [ 0.         -2.53589414  0.53826011]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #81 | lambda learn rate = 0.001\n",
      "Target = [[4.]\n",
      " [4.]]\n",
      "lambda end of trial = [[ 0.         -2.87211994  1.35489258]\n",
      " [ 0.         -2.44206367  1.81538365]\n",
      " [ 0.         -1.52405948  2.66790606]\n",
      " [ 0.         -1.12273472  2.55593935]\n",
      " [ 0.         -3.00512793  1.49139217]\n",
      " [ 0.         -3.87198919  1.82047243]\n",
      " [ 0.         -1.12274233  4.28878009]\n",
      " [ 0.         -1.31388453  3.27239955]\n",
      " [ 0.         -2.18516486  2.43405917]\n",
      " [ 0.         -0.57082432  2.50332994]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #82 | lambda learn rate = 0.001\n",
      "Target = [[3.]\n",
      " [1.]]\n",
      "lambda end of trial = [[ 0.         -2.43672477  1.50002431]\n",
      " [ 0.         -2.03356175  1.95155096]\n",
      " [ 0.         -1.13297055  2.79826904]\n",
      " [ 0.         -0.68059406  2.70331957]\n",
      " [ 0.         -2.5730753   1.63540971]\n",
      " [ 0.         -3.46757114  1.95527845]\n",
      " [ 0.         -0.73952494  4.41651921]\n",
      " [ 0.         -0.88176677  3.4164388 ]\n",
      " [ 0.         -1.7439729   2.58112316]\n",
      " [ 0.         -0.14203091  2.64626107]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #83 | lambda learn rate = 0.001\n",
      "Target = [[1.]\n",
      " [6.]]\n",
      "lambda end of trial = [[ 0.         -2.85884906 -1.03272142]\n",
      " [ 0.         -2.47143292 -0.67567603]\n",
      " [ 0.         -1.56620141  0.19888386]\n",
      " [ 0.         -1.11266991  0.11086448]\n",
      " [ 0.         -2.98483364 -0.83514033]\n",
      " [ 0.         -3.88271925 -0.5356102 ]\n",
      " [ 0.         -1.18972319  1.71532969]\n",
      " [ 0.         -1.2421937   1.2538772 ]\n",
      " [ 0.         -2.16393418  0.06135549]\n",
      " [ 0.         -0.55528321  0.1667473 ]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #84 | lambda learn rate = 0.001\n",
      "Target = [[0.]\n",
      " [2.]]\n",
      "lambda end of trial = [[ 0.         -2.85884906 -1.0323381 ]\n",
      " [ 0.         -2.47143292 -0.67618765]\n",
      " [ 0.         -1.56620141  0.19858079]\n",
      " [ 0.         -1.11266991  0.11116315]\n",
      " [ 0.         -2.98483364 -0.83520928]\n",
      " [ 0.         -3.88271925 -0.53588778]\n",
      " [ 0.         -1.18972319  1.7155725 ]\n",
      " [ 0.         -1.2421937   1.25345111]\n",
      " [ 0.         -2.16393418  0.06145367]\n",
      " [ 0.         -0.55528321  0.16686667]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #85 | lambda learn rate = 0.001\n",
      "Target = [[2.]\n",
      " [2.]]\n",
      "lambda end of trial = [[ 0.         -2.57487334 -0.74836238]\n",
      " [ 0.         -2.15655968 -0.36131441]\n",
      " [ 0.         -1.26469973  0.50008247]\n",
      " [ 0.         -0.8154296   0.40840347]\n",
      " [ 0.         -2.68532733 -0.53570297]\n",
      " [ 0.         -3.59816629 -0.25133482]\n",
      " [ 0.         -0.89171242  2.01358327]\n",
      " [ 0.         -0.93279997  1.56284484]\n",
      " [ 0.         -1.85558561  0.36980224]\n",
      " [ 0.         -0.27066669  0.45148319]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #86 | lambda learn rate = 0.001\n",
      "Target = [[3.]\n",
      " [9.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda end of trial = [[ 0.         -2.22618377  0.29770633]\n",
      " [ 0.         -1.77464456  0.78443094]\n",
      " [ 0.         -0.90757992  1.57144191]\n",
      " [ 0.         -0.41684893  1.60414548]\n",
      " [ 0.         -2.29400933  0.63825103]\n",
      " [ 0.         -3.21645593  0.89379628]\n",
      " [ 0.         -0.52024946  3.12797215]\n",
      " [ 0.         -0.54395834  2.72936974]\n",
      " [ 0.         -1.48367771  1.48552593]\n",
      " [ 0.          0.12712395  1.64485511]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #87 | lambda learn rate = 0.001\n",
      "Target = [[3.]\n",
      " [6.]]\n",
      "lambda end of trial = [[ 0.         -2.56885696 -0.38764004]\n",
      " [ 0.         -2.13450536  0.06470934]\n",
      " [ 0.         -1.24207472  0.90245231]\n",
      " [ 0.         -0.7835391   0.87076514]\n",
      " [ 0.         -2.6829249  -0.13958013]\n",
      " [ 0.         -3.56427706  0.19815401]\n",
      " [ 0.         -0.84439935  2.47967236]\n",
      " [ 0.         -0.86745633  2.08237376]\n",
      " [ 0.         -1.82648168  0.799918  ]\n",
      " [ 0.         -0.2042003   0.98220662]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #88 | lambda learn rate = 0.001\n",
      "Target = [[3.]\n",
      " [2.]]\n",
      "lambda end of trial = [[ 0.         -2.11934857 -0.08796778]\n",
      " [ 0.         -1.69391423  0.35843676]\n",
      " [ 0.         -0.79632157  1.19962108]\n",
      " [ 0.         -0.34781242  1.16124959]\n",
      " [ 0.         -2.27683051  0.13114947]\n",
      " [ 0.         -3.12729441  0.48947578]\n",
      " [ 0.         -0.42097854  2.7619529 ]\n",
      " [ 0.         -0.43567753  2.37022629]\n",
      " [ 0.         -1.38613355  1.09348342]\n",
      " [ 0.          0.18951917  1.24468626]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #89 | lambda learn rate = 0.001\n",
      "Target = [[1.]\n",
      " [4.]]\n",
      "lambda end of trial = [[ 0.         -2.1864378  -0.35632471]\n",
      " [ 0.         -1.76868941  0.05933606]\n",
      " [ 0.         -0.87248632  0.89496209]\n",
      " [ 0.         -0.42884176  0.83713225]\n",
      " [ 0.         -2.35091938 -0.165206  ]\n",
      " [ 0.         -3.2096946   0.15987502]\n",
      " [ 0.         -0.49701531  2.45780583]\n",
      " [ 0.         -0.50703647  2.08479054]\n",
      " [ 0.         -1.46260483  0.78759828]\n",
      " [ 0.          0.11330091  0.93981324]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #90 | lambda learn rate = 0.001\n",
      "Target = [[0.]\n",
      " [6.]]\n",
      "lambda end of trial = [[ 0.         -2.1864378  -1.14922175]\n",
      " [ 0.         -1.76868941 -0.65318007]\n",
      " [ 0.         -0.87248632  0.08936505]\n",
      " [ 0.         -0.42884176  0.06365827]\n",
      " [ 0.         -2.35091938 -0.91074167]\n",
      " [ 0.         -3.2096946  -0.61807417]\n",
      " [ 0.         -0.49701531  1.72069663]\n",
      " [ 0.         -0.50703647  1.32951545]\n",
      " [ 0.         -1.46260483  0.10553091]\n",
      " [ 0.          0.11330091  0.21308576]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #91 | lambda learn rate = 0.001\n",
      "Target = [[6.]\n",
      " [6.]]\n",
      "lambda end of trial = [[ 0.         -0.40185185  0.6353642 ]\n",
      " [ 0.          0.24438743  1.35989676]\n",
      " [ 0.          1.11055991  2.07241128]\n",
      " [ 0.          1.44716601  1.93966604]\n",
      " [ 0.         -0.18623644  1.25394127]\n",
      " [ 0.         -1.2639536   1.32766683]\n",
      " [ 0.          1.44256143  3.66027337]\n",
      " [ 0.          1.57141119  3.40796311]\n",
      " [ 0.          0.33236363  1.90049937]\n",
      " [ 0.          2.15878     2.25856486]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #92 | lambda learn rate = 0.001\n",
      "Target = [[3.]\n",
      " [5.]]\n",
      "lambda end of trial = [[ 0.         -1.43889663 -1.09304377]\n",
      " [ 0.         -0.74926367 -0.2961884 ]\n",
      " [ 0.          0.1189889   0.41979293]\n",
      " [ 0.          0.45107551  0.27951519]\n",
      " [ 0.         -1.24306833 -0.50744521]\n",
      " [ 0.         -2.31143645 -0.41813792]\n",
      " [ 0.          0.44146504  1.99177938]\n",
      " [ 0.          0.67953213  1.92149802]\n",
      " [ 0.         -0.66786275  0.23345541]\n",
      " [ 0.          1.10641363  0.50462091]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #93 | lambda learn rate = 0.001\n",
      "Target = [[7.]\n",
      " [3.]]\n",
      "lambda end of trial = [[ 0.         -0.6744953  -0.7654432 ]\n",
      " [ 0.         -0.0191792   0.01670494]\n",
      " [ 0.          0.8545392   0.73502877]\n",
      " [ 0.          1.17101219  0.58805949]\n",
      " [ 0.         -0.52767994 -0.20085019]\n",
      " [ 0.         -1.52367353 -0.08052524]\n",
      " [ 0.          1.15408799  2.29718922]\n",
      " [ 0.          1.38935952  2.22570975]\n",
      " [ 0.          0.0889575   0.55780694]\n",
      " [ 0.          1.80423578  0.80368754]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #94 | lambda learn rate = 0.001\n",
      "Target = [[9.]\n",
      " [4.]]\n",
      "lambda end of trial = [[ 0.         -1.72436181 -1.23205054]\n",
      " [ 0.         -1.19202417 -0.50455949]\n",
      " [ 0.         -0.27706747  0.23209247]\n",
      " [ 0.          0.00675383  0.07061132]\n",
      " [ 0.         -1.75604904 -0.74679201]\n",
      " [ 0.         -2.62497003 -0.56999036]\n",
      " [ 0.          0.10792712  1.83222883]\n",
      " [ 0.          0.19960025  1.69692785]\n",
      " [ 0.         -1.14996668  0.00717397]\n",
      " [ 0.          0.66466668  0.29721239]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #95 | lambda learn rate = 0.001\n",
      "Target = [[5.]\n",
      " [1.]]\n",
      "lambda end of trial = [[ 0.         -1.03082661 -1.0933435 ]\n",
      " [ 0.         -0.44246069 -0.35464679]\n",
      " [ 0.          0.49587489  0.38668095]\n",
      " [ 0.          0.69390069  0.2080407 ]\n",
      " [ 0.         -1.06888875 -0.60935995]\n",
      " [ 0.         -1.84837316 -0.41467098]\n",
      " [ 0.          0.87915396  1.9864742 ]\n",
      " [ 0.          0.94651113  1.84631003]\n",
      " [ 0.         -0.39777265  0.15761278]\n",
      " [ 0.          1.48896256  0.46207156]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #96 | lambda learn rate = 0.001\n",
      "Target = [[7.]\n",
      " [8.]]\n",
      "lambda end of trial = [[ 0.         -0.94253877 -0.99244311]\n",
      " [ 0.         -0.35958251 -0.25992887]\n",
      " [ 0.          0.5722259   0.47393925]\n",
      " [ 0.          0.78297957  0.30984513]\n",
      " [ 0.         -0.98345725 -0.51172395]\n",
      " [ 0.         -1.75873548 -0.31222791]\n",
      " [ 0.          0.96398801  2.0834274 ]\n",
      " [ 0.          1.0329656   1.94511514]\n",
      " [ 0.         -0.3122233   0.25538346]\n",
      " [ 0.          1.57389546  0.55913773]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #97 | lambda learn rate = 0.001\n",
      "Target = [[9.]\n",
      " [6.]]\n",
      "lambda end of trial = [[ 0.         -1.0227006  -1.04588433]\n",
      " [ 0.         -0.44131703 -0.31441856]\n",
      " [ 0.          0.48268969  0.41424844]\n",
      " [ 0.          0.71040597  0.26146273]\n",
      " [ 0.         -1.07150305 -0.57042115]\n",
      " [ 0.         -1.843728   -0.36888959]\n",
      " [ 0.          0.88732438  2.03231831]\n",
      " [ 0.          0.94458707  1.88619612]\n",
      " [ 0.         -0.38856759  0.20448727]\n",
      " [ 0.          1.49355051  0.50557444]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #98 | lambda learn rate = 0.001\n",
      "Target = [[2.]\n",
      " [2.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda end of trial = [[ 0.         -1.03102635 -1.05421008]\n",
      " [ 0.         -0.45065924 -0.32376076]\n",
      " [ 0.          0.4734101   0.40496884]\n",
      " [ 0.          0.70171383  0.25277059]\n",
      " [ 0.         -1.0803788  -0.5792969 ]\n",
      " [ 0.         -1.85333142 -0.37849301]\n",
      " [ 0.          0.87854466  2.02353859]\n",
      " [ 0.          0.93522853  1.87683758]\n",
      " [ 0.         -0.39735719  0.19569767]\n",
      " [ 0.          1.48463007  0.49665399]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "+++++++++++++++++++++++++++++++++++\n",
      "Session #4\n",
      "target at trial 0 = [[1.]\n",
      " [1.]]\n",
      "K MATX INIT= [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "A VECT INIT = [-0. -0.]\n",
      "lambda\n",
      "[[ 0.          0.17569819 -0.1168215 ]\n",
      " [ 0.          0.17094785  0.05671689]\n",
      " [ 0.         -0.13660684  0.34736166]\n",
      " [ 0.          0.39038693 -0.30734903]\n",
      " [ 0.          0.07484879  0.16279938]\n",
      " [ 0.          0.06604893  0.12726184]\n",
      " [ 0.         -0.35233706  0.44135871]\n",
      " [ 0.         -0.15102956  0.35740288]\n",
      " [ 0.          0.23767146 -0.14068682]\n",
      " [ 0.          0.63275023 -0.52240076]]\n",
      "a\n",
      "[-0. -0.]\n",
      "K\n",
      "[[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #0 | lambda learn rate = 0.001\n",
      "Target = [[1.]\n",
      " [1.]]\n",
      "lambda end of trial = [[ 0.          0.16837028 -0.12414941]\n",
      " [ 0.          0.16373885  0.04950789]\n",
      " [ 0.         -0.14439743  0.33957108]\n",
      " [ 0.          0.38329176 -0.3144442 ]\n",
      " [ 0.          0.06756191  0.1555125 ]\n",
      " [ 0.          0.05885659  0.1200695 ]\n",
      " [ 0.         -0.35975364  0.43394214]\n",
      " [ 0.         -0.15791721  0.35051524]\n",
      " [ 0.          0.23069422 -0.14766406]\n",
      " [ 0.          0.6252356  -0.52991538]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #1 | lambda learn rate = 0.001\n",
      "Target = [[2.]\n",
      " [9.]]\n",
      "lambda end of trial = [[ 0.          0.15694334 -0.17557064]\n",
      " [ 0.          0.15135338 -0.00622672]\n",
      " [ 0.         -0.15526226  0.29067932]\n",
      " [ 0.          0.37084948 -0.37043449]\n",
      " [ 0.          0.0548885   0.09848216]\n",
      " [ 0.          0.04722428  0.06772409]\n",
      " [ 0.         -0.37179545  0.37975399]\n",
      " [ 0.         -0.16946017  0.29857191]\n",
      " [ 0.          0.21986243 -0.1964071 ]\n",
      " [ 0.          0.61395337 -0.58068542]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #2 | lambda learn rate = 0.001\n",
      "Target = [[7.]\n",
      " [3.]]\n",
      "lambda end of trial = [[ 0.          0.16792451 -0.17086443]\n",
      " [ 0.          0.16108701 -0.00205517]\n",
      " [ 0.         -0.14598856  0.29465377]\n",
      " [ 0.          0.3819536  -0.36567558]\n",
      " [ 0.          0.06329527  0.10208506]\n",
      " [ 0.          0.05739848  0.07208446]\n",
      " [ 0.         -0.3608661   0.384438  ]\n",
      " [ 0.         -0.16024398  0.3025217 ]\n",
      " [ 0.          0.23025772 -0.19195198]\n",
      " [ 0.          0.62536217 -0.57579593]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #3 | lambda learn rate = 0.001\n",
      "Target = [[1.]\n",
      " [3.]]\n",
      "lambda end of trial = [[ 0.          0.16515947 -0.17915954]\n",
      " [ 0.          0.15812199 -0.01095024]\n",
      " [ 0.         -0.14947865  0.28418349]\n",
      " [ 0.          0.37921242 -0.3738991 ]\n",
      " [ 0.          0.06028489  0.09305392]\n",
      " [ 0.          0.05438321  0.06303864]\n",
      " [ 0.         -0.36392591  0.37525855]\n",
      " [ 0.         -0.16322957  0.29356492]\n",
      " [ 0.          0.22758528 -0.1999693 ]\n",
      " [ 0.          0.62249723 -0.58439076]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #4 | lambda learn rate = 0.001\n",
      "Target = [[0.]\n",
      " [5.]]\n",
      "lambda end of trial = [[ 0.          0.16515947 -0.16947342]\n",
      " [ 0.          0.15812199 -0.00109715]\n",
      " [ 0.         -0.14947865  0.29422045]\n",
      " [ 0.          0.37921242 -0.36351518]\n",
      " [ 0.          0.06028489  0.10009729]\n",
      " [ 0.          0.05438321  0.07242108]\n",
      " [ 0.         -0.36392591  0.38373134]\n",
      " [ 0.         -0.16322957  0.30253534]\n",
      " [ 0.          0.22758528 -0.19022623]\n",
      " [ 0.          0.62249723 -0.57438209]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #5 | lambda learn rate = 0.001\n",
      "Target = [[7.]\n",
      " [6.]]\n",
      "lambda end of trial = [[ 0.          0.19811166 -0.14122868]\n",
      " [ 0.          0.19232938  0.02822347]\n",
      " [ 0.         -0.11450998  0.3241936 ]\n",
      " [ 0.          0.41393794 -0.33375045]\n",
      " [ 0.          0.09575817  0.13050295]\n",
      " [ 0.          0.08742482  0.10074246]\n",
      " [ 0.         -0.32510414  0.41700714]\n",
      " [ 0.         -0.12858152  0.33223367]\n",
      " [ 0.          0.2647328  -0.1583855 ]\n",
      " [ 0.          0.65608858 -0.5455895 ]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #6 | lambda learn rate = 0.001\n",
      "Target = [[2.]\n",
      " [8.]]\n",
      "lambda end of trial = [[ 0.          0.19152763 -0.16756483]\n",
      " [ 0.          0.18622181  0.00379321]\n",
      " [ 0.         -0.12107347  0.29793962]\n",
      " [ 0.          0.40762217 -0.35901352]\n",
      " [ 0.          0.08927816  0.10458293]\n",
      " [ 0.          0.08096843  0.07491689]\n",
      " [ 0.         -0.33109493  0.39304398]\n",
      " [ 0.         -0.13526206  0.30551151]\n",
      " [ 0.          0.25830355 -0.18410248]\n",
      " [ 0.          0.64978931 -0.57078659]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #7 | lambda learn rate = 0.001\n",
      "Target = [[9.]\n",
      " [9.]]\n",
      "lambda end of trial = [[ 0.          0.20548755 -0.1536049 ]\n",
      " [ 0.          0.20095811  0.01852951]\n",
      " [ 0.         -0.10596191  0.31305118]\n",
      " [ 0.          0.422253   -0.3443827 ]\n",
      " [ 0.          0.10325608  0.11856085]\n",
      " [ 0.          0.09821882  0.09216728]\n",
      " [ 0.         -0.31830261  0.40583631]\n",
      " [ 0.         -0.12087042  0.31990316]\n",
      " [ 0.          0.27322551 -0.16918052]\n",
      " [ 0.          0.66564873 -0.55492717]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #8 | lambda learn rate = 0.001\n",
      "Target = [[7.]\n",
      " [2.]]\n",
      "lambda end of trial = [[ 0.00000000e+00  1.04949676e-01 -1.82330013e-01]\n",
      " [ 0.00000000e+00  9.78565314e-02 -1.09280819e-02]\n",
      " [ 0.00000000e+00 -2.13723792e-01  2.82262071e-01]\n",
      " [ 0.00000000e+00  3.22846884e-01 -3.72784447e-01]\n",
      " [ 0.00000000e+00  8.85131868e-05  8.90844010e-02]\n",
      " [ 0.00000000e+00 -1.02907395e-03  6.38107395e-02]\n",
      " [ 0.00000000e+00 -4.19247110e-01  3.76995021e-01]\n",
      " [ 0.00000000e+00 -2.23541999e-01  2.90568420e-01]\n",
      " [ 0.00000000e+00  1.81921481e-01 -1.95267385e-01]\n",
      " [ 0.00000000e+00  5.60511496e-01 -5.84966378e-01]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #9 | lambda learn rate = 0.001\n",
      "Target = [[0.]\n",
      " [3.]]\n",
      "lambda end of trial = [[ 0.00000000e+00  1.04949676e-01 -1.88577145e-01]\n",
      " [ 0.00000000e+00  9.78565314e-02 -1.86448527e-02]\n",
      " [ 0.00000000e+00 -2.13723792e-01  2.73951262e-01]\n",
      " [ 0.00000000e+00  3.22846884e-01 -3.79099553e-01]\n",
      " [ 0.00000000e+00  8.85131868e-05  8.16954283e-02]\n",
      " [ 0.00000000e+00 -1.02907395e-03  5.60934087e-02]\n",
      " [ 0.00000000e+00 -4.19247110e-01  3.70401831e-01]\n",
      " [ 0.00000000e+00 -2.23541999e-01  2.82984082e-01]\n",
      " [ 0.00000000e+00  1.81921481e-01 -2.02718597e-01]\n",
      " [ 0.00000000e+00  5.60511496e-01 -5.92433298e-01]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #10 | lambda learn rate = 0.001\n",
      "Target = [[7.]\n",
      " [2.]]\n",
      "lambda end of trial = [[ 0.          0.18843861 -0.16472316]\n",
      " [ 0.          0.18522359  0.00631716]\n",
      " [ 0.         -0.12384827  0.29962998]\n",
      " [ 0.          0.40789231 -0.35480086]\n",
      " [ 0.          0.09158098  0.10783613]\n",
      " [ 0.          0.08567476  0.08086593]\n",
      " [ 0.         -0.3297867   0.39596195]\n",
      " [ 0.         -0.14046327  0.30672086]\n",
      " [ 0.          0.27509773 -0.17609681]\n",
      " [ 0.          0.64683557 -0.56776928]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #11 | lambda learn rate = 0.001\n",
      "Target = [[8.]\n",
      " [2.]]\n",
      "lambda end of trial = [[ 0.          0.11701495 -0.18257908]\n",
      " [ 0.          0.11137421 -0.01214518]\n",
      " [ 0.         -0.20233738  0.28000771]\n",
      " [ 0.          0.32953741 -0.37438959]\n",
      " [ 0.          0.01493713  0.08867517]\n",
      " [ 0.          0.0088659   0.06166372]\n",
      " [ 0.         -0.40380737  0.37745678]\n",
      " [ 0.         -0.21720769  0.28753476]\n",
      " [ 0.          0.20497551 -0.19362737]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [ 0.          0.57381065 -0.58602551]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #12 | lambda learn rate = 0.001\n",
      "Target = [[5.]\n",
      " [9.]]\n",
      "lambda end of trial = [[ 0.          0.21532464 -0.00562163]\n",
      " [ 0.          0.2139703   0.17252779]\n",
      " [ 0.         -0.09941592  0.46526633]\n",
      " [ 0.          0.42757415 -0.19792345]\n",
      " [ 0.          0.11663294  0.27172761]\n",
      " [ 0.          0.1005139   0.22663012]\n",
      " [ 0.         -0.30438974  0.55640852]\n",
      " [ 0.         -0.10940722  0.48157561]\n",
      " [ 0.          0.3028973  -0.01736816]\n",
      " [ 0.          0.67300895 -0.40746858]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #13 | lambda learn rate = 0.001\n",
      "Target = [[7.]\n",
      " [6.]]\n",
      "lambda end of trial = [[ 0.         -0.05488532 -0.23723017]\n",
      " [ 0.         -0.04815223 -0.05214867]\n",
      " [ 0.         -0.37294247  0.230815  ]\n",
      " [ 0.          0.15266897 -0.43355647]\n",
      " [ 0.         -0.15636651  0.03772809]\n",
      " [ 0.         -0.15906029  0.00413796]\n",
      " [ 0.         -0.56560143  0.33251278]\n",
      " [ 0.         -0.35990627  0.26686214]\n",
      " [ 0.          0.01248575 -0.26629234]\n",
      " [ 0.          0.40768702 -0.63488737]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #14 | lambda learn rate = 0.001\n",
      "Target = [[9.]\n",
      " [1.]]\n",
      "lambda end of trial = [[ 0.          0.43883182 -0.18237271]\n",
      " [ 0.          0.35531056 -0.00731947]\n",
      " [ 0.          0.15650428  0.28964241]\n",
      " [ 0.          0.6185537  -0.3817915 ]\n",
      " [ 0.          0.40280524  0.09985828]\n",
      " [ 0.          0.38259082  0.06432142]\n",
      " [ 0.         -0.02358507  0.39273682]\n",
      " [ 0.          0.17986172  0.32683636]\n",
      " [ 0.          0.58229639 -0.20298005]\n",
      " [ 0.          0.95165433 -0.57444656]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #15 | lambda learn rate = 0.001\n",
      "Target = [[0.]\n",
      " [7.]]\n",
      "lambda end of trial = [[ 0.          0.43883182 -0.15335279]\n",
      " [ 0.          0.35531056  0.0258682 ]\n",
      " [ 0.          0.15650428  0.31990216]\n",
      " [ 0.          0.6185537  -0.35331317]\n",
      " [ 0.          0.40280524  0.13101957]\n",
      " [ 0.          0.38259082  0.09344829]\n",
      " [ 0.         -0.02358507  0.42244923]\n",
      " [ 0.          0.17986172  0.35712515]\n",
      " [ 0.          0.58229639 -0.17232341]\n",
      " [ 0.          0.95165433 -0.54318905]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #16 | lambda learn rate = 0.001\n",
      "Target = [[5.]\n",
      " [5.]]\n",
      "lambda end of trial = [[ 0.          0.16887916 -0.42330545]\n",
      " [ 0.          0.09208699 -0.23735537]\n",
      " [ 0.         -0.10382108  0.0595768 ]\n",
      " [ 0.          0.34847715 -0.62338971]\n",
      " [ 0.          0.09260781 -0.17917786]\n",
      " [ 0.          0.10976206 -0.17938048]\n",
      " [ 0.         -0.27765181  0.16838249]\n",
      " [ 0.         -0.09235676  0.08490667]\n",
      " [ 0.          0.33211354 -0.42250625]\n",
      " [ 0.          0.68572814 -0.80911524]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #17 | lambda learn rate = 0.001\n",
      "Target = [[9.]\n",
      " [7.]]\n",
      "lambda end of trial = [[ 0.          0.63085012 -0.0639947 ]\n",
      " [ 0.          0.54495308  0.11487381]\n",
      " [ 0.          0.38374179  0.43879237]\n",
      " [ 0.          0.85592326 -0.22870941]\n",
      " [ 0.          0.60102405  0.21625699]\n",
      " [ 0.          0.62229402  0.21925549]\n",
      " [ 0.          0.1934279   0.53477783]\n",
      " [ 0.          0.37735586  0.4502387 ]\n",
      " [ 0.          0.84699191 -0.0220453 ]\n",
      " [ 0.          1.17254423 -0.4304805 ]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #18 | lambda learn rate = 0.001\n",
      "Target = [[2.]\n",
      " [9.]]\n",
      "lambda end of trial = [[ 0.          0.49513615 -0.67470755]\n",
      " [ 0.          0.42404857 -0.42919648]\n",
      " [ 0.          0.25967121 -0.11952525]\n",
      " [ 0.          0.73925228 -0.7537288 ]\n",
      " [ 0.          0.46753883 -0.38442651]\n",
      " [ 0.          0.49539652 -0.35178323]\n",
      " [ 0.          0.07029866 -0.01930376]\n",
      " [ 0.          0.24688397 -0.13688479]\n",
      " [ 0.          0.71761326 -0.60424924]\n",
      " [ 0.          1.04150946 -1.02013698]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #19 | lambda learn rate = 0.001\n",
      "Target = [[0.]\n",
      " [6.]]\n",
      "lambda end of trial = [[ 0.          0.49513615 -0.18351134]\n",
      " [ 0.          0.42404857  0.11119951]\n",
      " [ 0.          0.25967121  0.33003151]\n",
      " [ 0.          0.73925228 -0.28099714]\n",
      " [ 0.          0.46753883  0.15111635]\n",
      " [ 0.          0.49539652  0.13008989]\n",
      " [ 0.          0.07029866  0.4891323 ]\n",
      " [ 0.          0.24688397  0.3106304 ]\n",
      " [ 0.          0.71761326 -0.12575607]\n",
      " [ 0.          1.04150946 -0.54496351]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #20 | lambda learn rate = 0.001\n",
      "Target = [[8.]\n",
      " [6.]]\n",
      "lambda end of trial = [[ 0.         -0.38027926 -0.8400729 ]\n",
      " [ 0.         -0.40230099 -0.50856266]\n",
      " [ 0.         -0.62082097 -0.33033763]\n",
      " [ 0.         -0.03492163 -0.86162757]\n",
      " [ 0.         -0.394593   -0.49548252]\n",
      " [ 0.         -0.373094   -0.521278  ]\n",
      " [ 0.         -0.83903998 -0.19287168]\n",
      " [ 0.         -0.55716756 -0.29240824]\n",
      " [ 0.         -0.16330605 -0.78644555]\n",
      " [ 0.          0.20772737 -1.17030007]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #21 | lambda learn rate = 0.001\n",
      "Target = [[9.]\n",
      " [9.]]\n",
      "lambda end of trial = [[0.         2.49454254 2.0347489 ]\n",
      " [0.         2.63538468 2.52912301]\n",
      " [0.         2.23808178 2.52856513]\n",
      " [0.         2.89194128 2.06523534]\n",
      " [0.         2.72715819 2.62626867]\n",
      " [0.         2.67876038 2.53057637]\n",
      " [0.         2.12218383 2.76835213]\n",
      " [0.         2.19069669 2.45545601]\n",
      " [0.         2.89227546 2.26913596]\n",
      " [0.         3.32548823 1.94746079]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #22 | lambda learn rate = 0.001\n",
      "Target = [[1.]\n",
      " [7.]]\n",
      "lambda end of trial = [[ 0.          1.90824821 -2.06931143]\n",
      " [ 0.          2.05640573 -1.52372964]\n",
      " [ 0.          1.61478472 -1.83451427]\n",
      " [ 0.          2.34892077 -1.73590826]\n",
      " [ 0.          2.12567792 -1.58409317]\n",
      " [ 0.          2.08953411 -1.59400752]\n",
      " [ 0.          1.55355893 -1.21202221]\n",
      " [ 0.          1.54928673 -2.03441376]\n",
      " [ 0.          2.33420619 -1.63734898]\n",
      " [ 0.          2.71454959 -2.32910972]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #23 | lambda learn rate = 0.001\n",
      "Target = [[6.]\n",
      " [2.]]\n",
      "lambda end of trial = [[ 0.00000000e+00  3.01831094e-01 -2.60478380e+00]\n",
      " [ 0.00000000e+00  5.24215366e-01 -2.03445976e+00]\n",
      " [ 0.00000000e+00 -3.69806422e-02 -2.38510272e+00]\n",
      " [ 0.00000000e+00  8.74896429e-01 -2.22724970e+00]\n",
      " [ 0.00000000e+00  3.79274742e-01 -2.16622757e+00]\n",
      " [ 0.00000000e+00  4.15985290e-01 -2.15185713e+00]\n",
      " [ 0.00000000e+00 -1.30183929e-03 -1.73030914e+00]\n",
      " [ 0.00000000e+00 -8.82293775e-02 -2.58025246e+00]\n",
      " [ 0.00000000e+00  8.40497953e-01 -2.13525172e+00]\n",
      " [ 0.00000000e+00  1.02652461e+00 -2.89178471e+00]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #24 | lambda learn rate = 0.001\n",
      "Target = [[7.]\n",
      " [3.]]\n",
      "lambda end of trial = [[ 0.          1.44876429 -2.11324101]\n",
      " [ 0.          1.58557886 -1.57958969]\n",
      " [ 0.          1.18231753 -1.86254636]\n",
      " [ 0.          1.94000117 -1.77077624]\n",
      " [ 0.          1.49249228 -1.68913434]\n",
      " [ 0.          1.59577009 -1.64623507]\n",
      " [ 0.          1.16757002 -1.22936406]\n",
      " [ 0.          1.00083872 -2.11350899]\n",
      " [ 0.          1.86156248 -1.69765264]\n",
      " [ 0.          2.06611612 -2.4462455 ]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #25 | lambda learn rate = 0.001\n",
      "Target = [[5.]\n",
      " [2.]]\n",
      "lambda end of trial = [[ 0.          0.86742551 -2.34577652]\n",
      " [ 0.          1.01616946 -1.80735345]\n",
      " [ 0.          0.57533147 -2.10534078]\n",
      " [ 0.          1.41554435 -1.98055897]\n",
      " [ 0.          0.86292236 -1.94096231]\n",
      " [ 0.          1.05996761 -1.86055606]\n",
      " [ 0.          0.56401762 -1.47078501]\n",
      " [ 0.          0.45938036 -2.33009233]\n",
      " [ 0.          1.3077878  -1.91916251]\n",
      " [ 0.          1.44972915 -2.69280028]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #26 | lambda learn rate = 0.001\n",
      "Target = [[2.]\n",
      " [6.]]\n",
      "lambda end of trial = [[ 0.          1.61240604 -0.11083493]\n",
      " [ 0.          1.73583417  0.35164068]\n",
      " [ 0.          1.28583664  0.02617471]\n",
      " [ 0.          2.16711139  0.27414213]\n",
      " [ 0.          1.51423578  0.01297797]\n",
      " [ 0.          1.68748872  0.02200726]\n",
      " [ 0.          1.33933557  0.85516885]\n",
      " [ 0.          1.16242336 -0.22096335]\n",
      " [ 0.          2.03726182  0.26925955]\n",
      " [ 0.          2.1482223  -0.59732084]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #27 | lambda learn rate = 0.001\n",
      "Target = [[8.]\n",
      " [0.]]\n",
      "lambda end of trial = [[ 0.         -1.52930238 -0.11083493]\n",
      " [ 0.         -1.62678645  0.35164068]\n",
      " [ 0.         -2.02172542  0.02617471]\n",
      " [ 0.         -1.18318686  0.27414213]\n",
      " [ 0.         -1.76753727  0.01297797]\n",
      " [ 0.         -1.41651141  0.02200726]\n",
      " [ 0.         -2.13275569  0.85516885]\n",
      " [ 0.         -2.14369802 -0.22096335]\n",
      " [ 0.         -1.09213526  0.26925955]\n",
      " [ 0.         -1.24922908 -0.59732084]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #28 | lambda learn rate = 0.001\n",
      "Target = [[6.]\n",
      " [8.]]\n",
      "lambda end of trial = [[0.         0.55834784 2.67269869]\n",
      " [0.         0.48994038 3.17394312]\n",
      " [0.         0.20861924 2.99996759]\n",
      " [0.         0.91024429 3.06538366]\n",
      " [0.         0.4370596  2.95244046]\n",
      " [0.         0.69154928 2.83275485]\n",
      " [0.         0.05147991 3.76748298]\n",
      " [0.         0.12762775 2.80747101]\n",
      " [0.         0.9478855  2.98928723]\n",
      " [0.         1.00643498 2.41023124]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #29 | lambda learn rate = 0.001\n",
      "Target = [[7.]\n",
      " [5.]]\n",
      "lambda end of trial = [[ 0.         -3.34694165 -0.1167938 ]\n",
      " [ 0.         -3.71843164  0.16796311]\n",
      " [ 0.         -3.60006182  0.27948112]\n",
      " [ 0.         -3.3167861   0.04607623]\n",
      " [ 0.         -4.03848326 -0.24437587]\n",
      " [ 0.         -3.82587716 -0.39397832]\n",
      " [ 0.         -3.6859654   1.09787919]\n",
      " [ 0.         -4.21616798 -0.29524022]\n",
      " [ 0.         -2.92581609  0.22235753]\n",
      " [ 0.         -2.88668981 -0.37057218]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #30 | lambda learn rate = 0.001\n",
      "Target = [[9.]\n",
      " [3.]]\n",
      "lambda end of trial = [[0.         8.25111742 3.74922589]\n",
      " [0.         7.22248288 3.81493461]\n",
      " [0.         6.05917892 3.49922803]\n",
      " [0.         6.94543083 3.46681521]\n",
      " [0.         6.7980721  3.36780925]\n",
      " [0.         4.84641796 2.49678672]\n",
      " [0.         5.84980798 4.27647032]\n",
      " [0.         5.59977139 2.97673957]\n",
      " [0.         6.67721967 3.42336944]\n",
      " [0.         7.02649109 2.93382145]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #31 | lambda learn rate = 0.001\n",
      "Target = [[3.]\n",
      " [0.]]\n",
      "lambda end of trial = [[0.         6.59094397 3.74922589]\n",
      " [0.         5.48868775 3.81493461]\n",
      " [0.         4.19258068 3.49922803]\n",
      " [0.         5.15413062 3.46681521]\n",
      " [0.         4.94501069 3.36780925]\n",
      " [0.         3.30170959 2.49678672]\n",
      " [0.         4.1174383  4.27647032]\n",
      " [0.         3.86530869 2.97673957]\n",
      " [0.         4.91838869 3.42336944]\n",
      " [0.         5.25433376 2.93382145]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #32 | lambda learn rate = 0.001\n",
      "Target = [[6.]\n",
      " [8.]]\n",
      "lambda end of trial = [[  0.          -4.31537896 -10.79253803]\n",
      " [  0.          -6.03493953 -11.54990176]\n",
      " [  0.          -6.78214789 -11.13374339]\n",
      " [  0.          -5.80907489 -11.15079214]\n",
      " [  0.          -7.93049495 -13.79953161]\n",
      " [  0.          -6.9233349  -11.13660594]\n",
      " [  0.          -6.87721914 -10.38307294]\n",
      " [  0.          -8.43095443 -13.41827793]\n",
      " [  0.          -5.52830847 -10.5055601 ]\n",
      " [  0.          -5.93717241 -11.98818678]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #33 | lambda learn rate = 0.001\n",
      "Target = [[8.]\n",
      " [0.]]\n",
      "lambda end of trial = [[  0.          10.07096645 -10.79253803]\n",
      " [  0.           7.24622676 -11.54990176]\n",
      " [  0.           6.46983025 -11.13374339]\n",
      " [  0.           7.84962767 -11.15079214]\n",
      " [  0.           6.61681998 -13.79953161]\n",
      " [  0.           6.76131875 -11.13660594]\n",
      " [  0.           6.13018874 -10.38307294]\n",
      " [  0.           5.78978188 -13.41827793]\n",
      " [  0.           8.2141897  -10.5055601 ]\n",
      " [  0.           7.66293565 -11.98818678]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #34 | lambda learn rate = 0.001\n",
      "Target = [[2.]\n",
      " [3.]]\n",
      "lambda end of trial = [[  0.          11.43798078  -8.74201652]\n",
      " [  0.           8.61856404  -9.49139584]\n",
      " [  0.           7.85999748  -9.04849254]\n",
      " [  0.           9.25566953  -9.04172934]\n",
      " [  0.           7.85829365 -11.9373211 ]\n",
      " [  0.           8.14093653  -9.06717927]\n",
      " [  0.           7.37320687  -8.51854574]\n",
      " [  0.           7.00159205 -11.60056267]\n",
      " [  0.           9.54754854  -8.50552186]\n",
      " [  0.           8.97767706 -10.01607466]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #35 | lambda learn rate = 0.001\n",
      "Target = [[6.]\n",
      " [1.]]\n",
      "lambda end of trial = [[  0.           3.60527422 -10.04746762]\n",
      " [  0.           1.68300684 -10.64732204]\n",
      " [  0.           0.49861735 -10.27538923]\n",
      " [  0.           1.70341711 -10.30043808]\n",
      " [  0.          -0.06199603 -13.25736938]\n",
      " [  0.           0.37251679 -10.36191589]\n",
      " [  0.          -0.80815335  -9.88210577]\n",
      " [  0.          -0.97262268 -12.92959846]\n",
      " [  0.           1.96654518  -9.76902241]\n",
      " [  0.           1.90391052 -11.19503575]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #36 | lambda learn rate = 0.001\n",
      "Target = [[3.]\n",
      " [5.]]\n",
      "lambda end of trial = [[ 0.          8.46254742 -1.95201228]\n",
      " [ 0.          6.7737254  -2.16279111]\n",
      " [ 0.          5.53142181 -1.8873818 ]\n",
      " [ 0.          6.41827537 -2.44234098]\n",
      " [ 0.          4.72631686 -5.27684789]\n",
      " [ 0.          5.55565587 -1.72335077]\n",
      " [ 0.          4.23342883 -1.4794688 ]\n",
      " [ 0.          3.93320761 -4.75321464]\n",
      " [ 0.          6.66286863 -1.94181666]\n",
      " [ 0.          6.54422785 -3.46117355]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #37 | lambda learn rate = 0.001\n",
      "Target = [[4.]\n",
      " [5.]]\n",
      "lambda end of trial = [[ 0.          7.51972048 -3.13054595]\n",
      " [ 0.          5.77458951 -3.41171098]\n",
      " [ 0.          4.56075345 -3.10071725]\n",
      " [ 0.          5.46831882 -3.62978667]\n",
      " [ 0.          3.87003239 -6.34720349]\n",
      " [ 0.          4.63420456 -2.8751649 ]\n",
      " [ 0.          3.3354864  -2.60189684]\n",
      " [ 0.          3.03049661 -5.8816034 ]\n",
      " [ 0.          5.74012553 -3.09524554]\n",
      " [ 0.          5.59803397 -4.64391589]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #38 | lambda learn rate = 0.001\n",
      "Target = [[4.]\n",
      " [9.]]\n",
      "lambda end of trial = [[ 0.          9.79644773  1.99209035]\n",
      " [ 0.          8.30467078  2.28097188]\n",
      " [ 0.          7.06033087  2.52333193]\n",
      " [ 0.          7.82989711  1.68376449]\n",
      " [ 0.          6.39047411 -0.67620961]\n",
      " [ 0.          7.2322531   2.97044432]\n",
      " [ 0.          5.47129611  2.203675  ]\n",
      " [ 0.          5.59975322 -0.10077602]\n",
      " [ 0.          8.00689588  2.00498775]\n",
      " [ 0.          7.99410206  0.74723731]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #39 | lambda learn rate = 0.001\n",
      "Target = [[3.]\n",
      " [5.]]\n",
      "lambda end of trial = [[ 0.          7.10929905 -2.48649077]\n",
      " [ 0.          5.53290619 -2.33863577]\n",
      " [ 0.          4.21862681 -2.21284149]\n",
      " [ 0.          5.16067616 -2.76493709]\n",
      " [ 0.          3.67122942 -5.2082841 ]\n",
      " [ 0.          4.53350829 -1.52746369]\n",
      " [ 0.          2.77201791 -2.29512201]\n",
      " [ 0.          2.80614096 -4.75679646]\n",
      " [ 0.          5.57340574 -2.05082915]\n",
      " [ 0.          5.3562729  -3.64914463]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #40 | lambda learn rate = 0.001\n",
      "Target = [[2.]\n",
      " [2.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda end of trial = [[ 0.          6.92961168 -2.66617815]\n",
      " [ 0.          5.38218329 -2.48935867]\n",
      " [ 0.          4.05604023 -2.37542808]\n",
      " [ 0.          4.99602296 -2.9295903 ]\n",
      " [ 0.          3.51474682 -5.3647667 ]\n",
      " [ 0.          4.37832906 -1.68264293]\n",
      " [ 0.          2.62146516 -2.44567475]\n",
      " [ 0.          2.62497749 -4.93795993]\n",
      " [ 0.          5.42251513 -2.20171976]\n",
      " [ 0.          5.20564562 -3.7997719 ]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #41 | lambda learn rate = 0.001\n",
      "Target = [[9.]\n",
      " [2.]]\n",
      "lambda end of trial = [[ 0.         -2.01045669 -4.65286001]\n",
      " [ 0.         -4.25035443 -4.62992261]\n",
      " [ 0.         -5.30470508 -4.4555937 ]\n",
      " [ 0.         -4.0439917  -4.93848244]\n",
      " [ 0.         -5.97456658 -7.47350301]\n",
      " [ 0.         -5.16888259 -3.80424552]\n",
      " [ 0.         -6.34909313 -4.43913215]\n",
      " [ 0.         -6.38787529 -6.9408161 ]\n",
      " [ 0.         -4.40744371 -4.38615506]\n",
      " [ 0.         -3.90952208 -5.82536473]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #42 | lambda learn rate = 0.001\n",
      "Target = [[0.]\n",
      " [6.]]\n",
      "lambda end of trial = [[ 0.         -2.01045669  1.3404187 ]\n",
      " [ 0.         -4.25035443  0.94541446]\n",
      " [ 0.         -5.30470508  1.76891683]\n",
      " [ 0.         -4.0439917   1.14183897]\n",
      " [ 0.         -5.97456658 -1.21350022]\n",
      " [ 0.         -5.16888259  2.00618841]\n",
      " [ 0.         -6.34909313  1.54080232]\n",
      " [ 0.         -6.38787529 -0.85347325]\n",
      " [ 0.         -4.40744371  1.96399496]\n",
      " [ 0.         -3.90952208 -0.11961698]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #43 | lambda learn rate = 0.001\n",
      "Target = [[2.]\n",
      " [9.]]\n",
      "lambda end of trial = [[ 0.         -1.70808252  2.70110245]\n",
      " [ 0.         -3.91873987  2.43767996]\n",
      " [ 0.         -4.94992164  3.36544234]\n",
      " [ 0.         -3.73209082  2.5453929 ]\n",
      " [ 0.         -5.64711351  0.26003859]\n",
      " [ 0.         -4.85604994  3.41393535]\n",
      " [ 0.         -6.02154339  3.01477614]\n",
      " [ 0.         -6.07127616  0.57122281]\n",
      " [ 0.         -4.09917665  3.35119673]\n",
      " [ 0.         -3.59040138  1.31642619]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #44 | lambda learn rate = 0.001\n",
      "Target = [[0.]\n",
      " [9.]]\n",
      "lambda end of trial = [[ 0.         -1.70808252 -2.5005329 ]\n",
      " [ 0.         -3.91873987 -2.99483826]\n",
      " [ 0.         -4.94992164 -1.89874163]\n",
      " [ 0.         -3.73209082 -3.04275867]\n",
      " [ 0.         -5.64711351 -5.29417893]\n",
      " [ 0.         -4.85604994 -2.67865179]\n",
      " [ 0.         -6.02154339 -2.41207155]\n",
      " [ 0.         -6.07127616 -4.91594126]\n",
      " [ 0.         -4.09917665 -2.32922686]\n",
      " [ 0.         -3.59040138 -4.4307551 ]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #45 | lambda learn rate = 0.001\n",
      "Target = [[1.]\n",
      " [8.]]\n",
      "lambda end of trial = [[ 0.         -0.61940054  6.20892298]\n",
      " [ 0.         -2.858153    5.48985673]\n",
      " [ 0.         -3.84483309  6.94196676]\n",
      " [ 0.         -2.65604498  5.56560809]\n",
      " [ 0.         -4.64546447  2.71901335]\n",
      " [ 0.         -3.73611758  6.28080706]\n",
      " [ 0.         -4.9784956   5.93231076]\n",
      " [ 0.         -5.17085854  2.28739976]\n",
      " [ 0.         -3.02627802  6.25396224]\n",
      " [ 0.         -2.59602632  3.52424538]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #46 | lambda learn rate = 0.001\n",
      "Target = [[6.]\n",
      " [1.]]\n",
      "lambda end of trial = [[ 0.          2.63034258  6.75054684]\n",
      " [ 0.          0.31494679  6.01870669]\n",
      " [ 0.         -0.46403319  7.50543341]\n",
      " [ 0.          0.37785628  6.0712583 ]\n",
      " [ 0.         -1.32865579  3.2718148 ]\n",
      " [ 0.         -0.44949286  6.82857785]\n",
      " [ 0.         -2.0274054   6.42415913]\n",
      " [ 0.         -1.8838983   2.83522647]\n",
      " [ 0.          0.51856427  6.84476929]\n",
      " [ 0.          0.65185317  4.06555863]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #47 | lambda learn rate = 0.001\n",
      "Target = [[0.]\n",
      " [4.]]\n",
      "lambda end of trial = [[ 0.          2.63034258  4.18525945]\n",
      " [ 0.          0.31494679  3.23544358]\n",
      " [ 0.         -0.46403319  4.85491015]\n",
      " [ 0.          0.37785628  3.37901395]\n",
      " [ 0.         -1.32865579  0.51338272]\n",
      " [ 0.         -0.44949286  4.06045379]\n",
      " [ 0.         -2.0274054   3.66367648]\n",
      " [ 0.         -1.8838983  -0.05265217]\n",
      " [ 0.          0.51856427  3.99501905]\n",
      " [ 0.          0.65185317  1.48208884]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #48 | lambda learn rate = 0.001\n",
      "Target = [[3.]\n",
      " [6.]]\n",
      "lambda end of trial = [[ 0.          1.33260696  1.58978822]\n",
      " [ 0.         -1.16206978  0.28141044]\n",
      " [ 0.         -1.83618649  2.11060354]\n",
      " [ 0.         -0.97750681  0.66828777]\n",
      " [ 0.         -2.79211026 -2.41352623]\n",
      " [ 0.         -1.76655271  1.42633408]\n",
      " [ 0.         -3.36253125  0.99342477]\n",
      " [ 0.         -3.31833276 -2.92152109]\n",
      " [ 0.         -0.79353508  1.37082036]\n",
      " [ 0.         -0.66610919 -1.15383587]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #49 | lambda learn rate = 0.001\n",
      "Target = [[0.]\n",
      " [6.]]\n",
      "lambda end of trial = [[ 0.          1.33260696  1.73228233]\n",
      " [ 0.         -1.16206978  0.4453399 ]\n",
      " [ 0.         -1.83618649  2.27128588]\n",
      " [ 0.         -0.97750681  0.83940839]\n",
      " [ 0.         -2.79211026 -2.23819464]\n",
      " [ 0.         -1.76655271  1.59667328]\n",
      " [ 0.         -3.36253125  1.16232825]\n",
      " [ 0.         -3.31833276 -2.74958736]\n",
      " [ 0.         -0.79353508  1.52363213]\n",
      " [ 0.         -0.66610919 -0.99133085]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #50 | lambda learn rate = 0.001\n",
      "Target = [[9.]\n",
      " [6.]]\n",
      "lambda end of trial = [[0.         6.14890144 4.94314531]\n",
      " [0.         3.38263957 3.47514613]\n",
      " [0.         3.0458152  5.52595367]\n",
      " [0.         3.92542118 4.10802705]\n",
      " [0.         2.28188362 1.14446795]\n",
      " [0.         2.75337029 4.60995528]\n",
      " [0.         1.52555619 4.42105321]\n",
      " [0.         1.7402297  0.62278761]\n",
      " [0.         4.18413431 4.84207838]\n",
      " [0.         4.25551108 2.28974933]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #51 | lambda learn rate = 0.001\n",
      "Target = [[9.]\n",
      " [8.]]\n",
      "lambda end of trial = [[  0.          -8.74883046  -8.29928304]\n",
      " [  0.         -14.08588758 -12.05243356]\n",
      " [  0.         -13.4565968   -9.14285699]\n",
      " [  0.         -12.95414904 -10.89603537]\n",
      " [  0.         -12.55429479 -12.0432462 ]\n",
      " [  0.         -13.83762381 -10.13759503]\n",
      " [  0.         -13.69352243  -9.10701667]\n",
      " [  0.         -14.013175   -13.38023878]\n",
      " [  0.         -11.24585714  -8.87346957]\n",
      " [  0.         -11.37556281 -11.60453857]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #52 | lambda learn rate = 0.001\n",
      "Target = [[8.]\n",
      " [2.]]\n",
      "lambda end of trial = [[ 0.         27.54511486  0.77420329]\n",
      " [ 0.         19.07664582 -3.7618002 ]\n",
      " [ 0.         22.45581918 -0.164753  ]\n",
      " [ 0.         24.34144365 -1.57213719]\n",
      " [ 0.         20.70407866 -3.72865283]\n",
      " [ 0.         19.17081104 -1.88548632]\n",
      " [ 0.         20.18314093 -0.63785083]\n",
      " [ 0.         20.24365822 -4.81603048]\n",
      " [ 0.         25.09190997  0.21097221]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [ 0.         24.29390034 -2.68717278]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #53 | lambda learn rate = 0.001\n",
      "Target = [[3.]\n",
      " [8.]]\n",
      "lambda end of trial = [[  0.          22.98222484 -11.39350342]\n",
      " [  0.          14.275925   -16.56372238]\n",
      " [  0.          18.17430964 -11.58211178]\n",
      " [  0.          19.73325331 -13.86064478]\n",
      " [  0.          15.72364673 -17.00980465]\n",
      " [  0.          14.59187098 -14.09599316]\n",
      " [  0.          15.64930633 -12.72807643]\n",
      " [  0.          15.73094814 -16.84992402]\n",
      " [  0.          20.94149635 -10.85679745]\n",
      " [  0.          19.48416669 -15.51312919]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #54 | lambda learn rate = 0.001\n",
      "Target = [[0.]\n",
      " [7.]]\n",
      "lambda end of trial = [[ 0.         22.98222484 11.22082282]\n",
      " [ 0.         14.275925    6.38229759]\n",
      " [ 0.         18.17430964 12.12674514]\n",
      " [ 0.         19.73325331  6.86141538]\n",
      " [ 0.         15.72364673  8.43855616]\n",
      " [ 0.         14.59187098 10.634053  ]\n",
      " [ 0.         15.64930633 10.03239868]\n",
      " [ 0.         15.73094814  6.35353797]\n",
      " [ 0.         20.94149635 12.2607099 ]\n",
      " [ 0.         19.48416669  8.77569039]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #55 | lambda learn rate = 0.001\n",
      "Target = [[9.]\n",
      " [0.]]\n",
      "lambda end of trial = [[  0.         -21.86589393  11.22082282]\n",
      " [  0.         -35.91395515   6.38229759]\n",
      " [  0.         -29.34155589  12.12674514]\n",
      " [  0.         -25.67849778   6.86141538]\n",
      " [  0.         -31.15071959   8.43855616]\n",
      " [  0.         -30.6577215   10.634053  ]\n",
      " [  0.         -31.64206929  10.03239868]\n",
      " [  0.         -31.04964838   6.35353797]\n",
      " [  0.         -22.25284805  12.2607099 ]\n",
      " [  0.         -27.1542981    8.77569039]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #56 | lambda learn rate = 0.001\n",
      "Target = [[6.]\n",
      " [0.]]\n",
      "lambda end of trial = [[ 0.         13.14148031 11.22082282]\n",
      " [ 0.         -0.21134726  6.38229759]\n",
      " [ 0.          6.50266431 12.12674514]\n",
      " [ 0.          5.1143599   6.86141538]\n",
      " [ 0.          5.57195048  8.43855616]\n",
      " [ 0.          3.5909038  10.634053  ]\n",
      " [ 0.          4.05654876 10.03239868]\n",
      " [ 0.          3.8815984   6.35353797]\n",
      " [ 0.         15.22686043 12.2607099 ]\n",
      " [ 0.          8.78869359  8.77569039]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #57 | lambda learn rate = 0.001\n",
      "Target = [[6.]\n",
      " [3.]]\n",
      "lambda end of trial = [[  0.           1.62482719   5.46249626]\n",
      " [  0.         -10.31946095   1.32824074]\n",
      " [  0.          -4.68533869   6.53274364]\n",
      " [  0.          -6.37182559   1.11832263]\n",
      " [  0.          -5.48077127   2.91219529]\n",
      " [  0.          -8.10852017   4.78434102]\n",
      " [  0.          -7.70179765   4.15322548]\n",
      " [  0.          -8.32704795   0.24921479]\n",
      " [  0.           2.81976888   6.05716413]\n",
      " [  0.          -3.71773503   2.52247608]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #58 | lambda learn rate = 0.001\n",
      "Target = [[5.]\n",
      " [6.]]\n",
      "lambda end of trial = [[ 0.          3.21553729  7.37134838]\n",
      " [ 0.         -8.61325657  3.37568601]\n",
      " [ 0.         -3.01716567  8.53455127]\n",
      " [ 0.         -4.5097104   3.35286087]\n",
      " [ 0.         -3.74331347  4.99714464]\n",
      " [ 0.         -6.45483116  6.76876782]\n",
      " [ 0.         -5.90163516  6.31342047]\n",
      " [ 0.         -6.38870265  2.57522915]\n",
      " [ 0.          4.5252293   8.10371663]\n",
      " [ 0.         -2.06640724  4.50406944]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #59 | lambda learn rate = 0.001\n",
      "Target = [[7.]\n",
      " [6.]]\n",
      "lambda end of trial = [[ 0.          2.8123935   7.02579655]\n",
      " [ 0.         -9.02562504  3.02222732]\n",
      " [ 0.         -3.38793922  8.21674537]\n",
      " [ 0.         -4.91224864  3.00782808]\n",
      " [ 0.         -4.14020052  4.65695574]\n",
      " [ 0.         -6.823852    6.45246425]\n",
      " [ 0.         -6.29646619  5.97499387]\n",
      " [ 0.         -6.76173427  2.25548776]\n",
      " [ 0.          4.13559212  7.7697419 ]\n",
      " [ 0.         -2.52798148  4.10843438]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #60 | lambda learn rate = 0.001\n",
      "Target = [[8.]\n",
      " [6.]]\n",
      "lambda end of trial = [[ 0.          4.80652629  8.52139615]\n",
      " [ 0.         -6.85198183  4.65245972]\n",
      " [ 0.         -1.13811543  9.90411321]\n",
      " [ 0.         -3.01338759  4.43197388]\n",
      " [ 0.         -1.96085163  6.29146741]\n",
      " [ 0.         -4.86264848  7.92336689]\n",
      " [ 0.         -4.20794607  7.54138396]\n",
      " [ 0.         -4.70138843  3.80074714]\n",
      " [ 0.          6.04203238  9.19957209]\n",
      " [ 0.         -0.76446057  5.43107506]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #61 | lambda learn rate = 0.001\n",
      "Target = [[2.]\n",
      " [2.]]\n",
      "lambda end of trial = [[ 0.          4.25926705  7.97413691]\n",
      " [ 0.         -7.35111324  4.15332832]\n",
      " [ 0.         -1.68728478  9.35494386]\n",
      " [ 0.         -3.51151467  3.93384679]\n",
      " [ 0.         -2.50852432  5.74379472]\n",
      " [ 0.         -5.37698257  7.4090328 ]\n",
      " [ 0.         -4.66752795  7.08180208]\n",
      " [ 0.         -5.23201681  3.27011876]\n",
      " [ 0.          5.51182619  8.66936591]\n",
      " [ 0.         -1.29462868  4.90090694]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #62 | lambda learn rate = 0.001\n",
      "Target = [[6.]\n",
      " [7.]]\n",
      "lambda end of trial = [[  0.          -0.39992941   2.5384077 ]\n",
      " [  0.         -11.7397545   -0.96675316]\n",
      " [  0.          -7.05791614   3.08920728]\n",
      " [  0.          -8.14866365  -1.47616035]\n",
      " [  0.          -7.2774476    0.18005089]\n",
      " [  0.          -9.93680643   2.0892383 ]\n",
      " [  0.          -9.43571665   1.51891526]\n",
      " [  0.         -10.00331596  -2.29639691]\n",
      " [  0.           1.3017824    3.75764814]\n",
      " [  0.          -5.52118728  -0.03007808]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #63 | lambda learn rate = 0.001\n",
      "Target = [[1.]\n",
      " [6.]]\n",
      "lambda end of trial = [[  0.          -0.24842624   3.44742675]\n",
      " [  0.         -11.60692557  -0.16977958]\n",
      " [  0.          -6.91269142   3.96055557]\n",
      " [  0.          -8.01660984  -0.68383753]\n",
      " [  0.          -7.1451278    0.97396971]\n",
      " [  0.          -9.79324215   2.95062395]\n",
      " [  0.          -9.30220005   2.32001486]\n",
      " [  0.          -9.87908237  -1.55099539]\n",
      " [  0.           1.42513654   4.49777303]\n",
      " [  0.          -5.38725207   0.77353313]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #64 | lambda learn rate = 0.001\n",
      "Target = [[0.]\n",
      " [0.]]\n",
      "lambda end of trial = [[  0.          -0.24842624   3.44742675]\n",
      " [  0.         -11.60692557  -0.16977958]\n",
      " [  0.          -6.91269142   3.96055557]\n",
      " [  0.          -8.01660984  -0.68383753]\n",
      " [  0.          -7.1451278    0.97396971]\n",
      " [  0.          -9.79324215   2.95062395]\n",
      " [  0.          -9.30220005   2.32001486]\n",
      " [  0.          -9.87908237  -1.55099539]\n",
      " [  0.           1.42513654   4.49777303]\n",
      " [  0.          -5.38725207   0.77353313]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #65 | lambda learn rate = 0.001\n",
      "Target = [[7.]\n",
      " [0.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda end of trial = [[ 0.         12.03665273  3.44742675]\n",
      " [ 0.          0.79301604 -0.16977958]\n",
      " [ 0.          4.32684044  3.96055557]\n",
      " [ 0.          4.54912279 -0.68383753]\n",
      " [ 0.          5.34727662  0.97396971]\n",
      " [ 0.          2.81972807  2.95062395]\n",
      " [ 0.          3.24160843  2.32001486]\n",
      " [ 0.          1.48622273 -1.55099539]\n",
      " [ 0.         13.1038462   4.49777303]\n",
      " [ 0.          6.89902835  0.77353313]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #66 | lambda learn rate = 0.001\n",
      "Target = [[0.]\n",
      " [5.]]\n",
      "lambda end of trial = [[ 0.         12.03665273  2.41179415]\n",
      " [ 0.          0.79301604 -1.38419681]\n",
      " [ 0.          4.32684044  2.78498601]\n",
      " [ 0.          4.54912279 -1.80349252]\n",
      " [ 0.          5.34727662 -0.17497093]\n",
      " [ 0.          2.81972807  1.82313229]\n",
      " [ 0.          3.24160843  1.2574039 ]\n",
      " [ 0.          1.48622273 -2.63483875]\n",
      " [ 0.         13.1038462   3.3760652 ]\n",
      " [ 0.          6.89902835 -0.32401432]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #67 | lambda learn rate = 0.001\n",
      "Target = [[0.]\n",
      " [8.]]\n",
      "lambda end of trial = [[ 0.         12.03665273  1.93976501]\n",
      " [ 0.          0.79301604 -1.78911313]\n",
      " [ 0.          4.32684044  2.31409538]\n",
      " [ 0.          4.54912279 -2.22571651]\n",
      " [ 0.          5.34727662 -0.62154177]\n",
      " [ 0.          2.81972807  1.41306064]\n",
      " [ 0.          3.24160843  0.81870124]\n",
      " [ 0.          1.48622273 -3.07844071]\n",
      " [ 0.         13.1038462   2.95097472]\n",
      " [ 0.          6.89902835 -0.75463741]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #68 | lambda learn rate = 0.001\n",
      "Target = [[8.]\n",
      " [6.]]\n",
      "lambda end of trial = [[ 0.          3.44482693 -4.50410434]\n",
      " [ 0.         -7.81608627 -8.24593987]\n",
      " [ 0.         -5.27052833 -4.8839312 ]\n",
      " [ 0.         -4.5013555  -9.01357522]\n",
      " [ 0.         -4.09733495 -7.70500045]\n",
      " [ 0.         -6.74829474 -5.76295647]\n",
      " [ 0.         -4.67985319 -5.12239498]\n",
      " [ 0.         -7.64389887 -9.92603191]\n",
      " [ 0.          3.83433445 -4.00115909]\n",
      " [ 0.         -1.64261375 -7.16086898]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #69 | lambda learn rate = 0.001\n",
      "Target = [[3.]\n",
      " [7.]]\n",
      "lambda end of trial = [[ 0.          9.82962684 10.39376213]\n",
      " [ 0.         -0.99855674  7.66162904]\n",
      " [ 0.          1.69403104 11.36670734]\n",
      " [ 0.          1.86236441  5.83510457]\n",
      " [ 0.          2.09247871  6.73789809]\n",
      " [ 0.         -0.27711636  9.33645975]\n",
      " [ 0.          1.75730997  9.8976524 ]\n",
      " [ 0.         -2.15841606  2.87342799]\n",
      " [ 0.          9.86322979 10.06626336]\n",
      " [ 0.          4.8680113   8.03058946]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #70 | lambda learn rate = 0.001\n",
      "Target = [[8.]\n",
      " [0.]]\n",
      "lambda end of trial = [[ 0.          6.21226304 10.39376213]\n",
      " [ 0.         -4.4735556   7.66162904]\n",
      " [ 0.         -1.97581474 11.36670734]\n",
      " [ 0.         -1.88277919  5.83510457]\n",
      " [ 0.         -1.48276079  6.73789809]\n",
      " [ 0.         -4.04581551  9.33645975]\n",
      " [ 0.         -1.90477827  9.8976524 ]\n",
      " [ 0.         -6.15887647  2.87342799]\n",
      " [ 0.          6.37218292 10.06626336]\n",
      " [ 0.          1.12906555  8.03058946]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #71 | lambda learn rate = 0.001\n",
      "Target = [[4.]\n",
      " [5.]]\n",
      "lambda end of trial = [[  0.           2.40482885   5.63446938]\n",
      " [  0.          -8.59464451   2.51026791]\n",
      " [  0.          -6.22487712   6.05537936]\n",
      " [  0.          -5.95879328   0.74008695]\n",
      " [  0.          -5.70631745   1.45845227]\n",
      " [  0.          -8.12057994   4.2430042 ]\n",
      " [  0.          -6.41175783   4.26392796]\n",
      " [  0.         -10.31197852  -2.31794958]\n",
      " [  0.           2.6384827    5.39913807]\n",
      " [  0.          -3.14523642   2.687712  ]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #72 | lambda learn rate = 0.001\n",
      "Target = [[1.]\n",
      " [8.]]\n",
      "lambda end of trial = [[  0.           1.89502668   1.55605201]\n",
      " [  0.          -9.11948734  -1.68847479]\n",
      " [  0.          -6.6942322    2.30053873]\n",
      " [  0.          -6.45344095  -3.21709439]\n",
      " [  0.          -6.21032572  -2.57361387]\n",
      " [  0.          -8.64834409   0.02089098]\n",
      " [  0.          -6.86916094   0.60470307]\n",
      " [  0.         -10.84437142  -6.57709272]\n",
      " [  0.           2.17794596   1.71484421]\n",
      " [  0.          -3.64488294  -1.30946017]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #73 | lambda learn rate = 0.001\n",
      "Target = [[9.]\n",
      " [6.]]\n",
      "lambda end of trial = [[ 0.         18.68816621 12.75147837]\n",
      " [ 0.         11.14638745 11.82210841]\n",
      " [ 0.         13.00624304 15.43418889]\n",
      " [ 0.         11.72808724  8.9039244 ]\n",
      " [ 0.         13.38161747 10.48768158]\n",
      " [ 0.         11.79214416 13.64788315]\n",
      " [ 0.         12.68652406 13.6418264 ]\n",
      " [ 0.          9.86372607  7.2283056 ]\n",
      " [ 0.         21.53385925 14.6187864 ]\n",
      " [ 0.         15.55462798 11.49021378]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #74 | lambda learn rate = 0.001\n",
      "Target = [[7.]\n",
      " [8.]]\n",
      "lambda end of trial = [[  0.         -23.04166317 -34.9397552 ]\n",
      " [  0.         -33.3099553  -38.98514045]\n",
      " [  0.         -24.67866724 -27.63428   ]\n",
      " [  0.         -28.89649777 -37.52417275]\n",
      " [  0.         -33.4106797  -42.98922947]\n",
      " [  0.         -35.41175465 -40.29942978]\n",
      " [  0.         -30.61458678 -35.84515742]\n",
      " [  0.         -30.13686008 -38.48665   ]\n",
      " [  0.         -20.75349216 -33.70961521]\n",
      " [  0.         -28.25140501 -38.57382393]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #75 | lambda learn rate = 0.001\n",
      "Target = [[8.]\n",
      " [1.]]\n",
      "lambda end of trial = [[  0.          45.42813805 -26.38103005]\n",
      " [  0.          37.09174007 -30.18492853]\n",
      " [  0.          44.38643044 -19.00114279]\n",
      " [  0.          44.92985598 -28.29587853]\n",
      " [  0.          35.57678468 -34.36579642]\n",
      " [  0.          34.21978403 -31.59548744]\n",
      " [  0.          39.74024398 -27.05080357]\n",
      " [  0.          45.90592507 -28.98130185]\n",
      " [  0.          46.89945332 -25.25299703]\n",
      " [  0.          45.04844289 -29.41134294]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #76 | lambda learn rate = 0.001\n",
      "Target = [[0.]\n",
      " [0.]]\n",
      "lambda end of trial = [[  0.          45.42813805 -26.38103005]\n",
      " [  0.          37.09174007 -30.18492853]\n",
      " [  0.          44.38643044 -19.00114279]\n",
      " [  0.          44.92985598 -28.29587853]\n",
      " [  0.          35.57678468 -34.36579642]\n",
      " [  0.          34.21978403 -31.59548744]\n",
      " [  0.          39.74024398 -27.05080357]\n",
      " [  0.          45.90592507 -28.98130185]\n",
      " [  0.          46.89945332 -25.25299703]\n",
      " [  0.          45.04844289 -29.41134294]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #77 | lambda learn rate = 0.001\n",
      "Target = [[7.]\n",
      " [7.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda end of trial = [[  0.          25.95025011 -45.858918  ]\n",
      " [  0.          18.34091207 -48.93575653]\n",
      " [  0.          24.9979648  -38.38960842]\n",
      " [  0.          25.07291893 -48.15281558]\n",
      " [  0.          16.4721023  -53.4704788 ]\n",
      " [  0.          15.43733295 -50.37793852]\n",
      " [  0.          20.78278055 -46.00826699]\n",
      " [  0.          25.7722784  -49.11494853]\n",
      " [  0.          28.21627526 -43.93617509]\n",
      " [  0.          27.18174038 -47.27804545]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #78 | lambda learn rate = 0.001\n",
      "Target = [[5.]\n",
      " [8.]]\n",
      "lambda end of trial = [[ 0.         71.62478762 27.22034203]\n",
      " [ 0.         61.42998963 20.00676757]\n",
      " [ 0.         71.91742881 36.68153399]\n",
      " [ 0.         63.76801399 13.75933653]\n",
      " [ 0.         59.87393704 15.97245679]\n",
      " [ 0.         59.61739619 20.31016265]\n",
      " [ 0.         62.91473885 21.40286628]\n",
      " [ 0.         68.96936042 20.00038271]\n",
      " [ 0.         72.05132468 26.19990399]\n",
      " [ 0.         73.30676213 26.52198935]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #79 | lambda learn rate = 0.001\n",
      "Target = [[3.]\n",
      " [1.]]\n",
      "lambda end of trial = [[ 0.         49.01654746 19.68426197]\n",
      " [ 0.         40.48469761 13.02500356]\n",
      " [ 0.         49.47264708 29.19994008]\n",
      " [ 0.         43.62696018  7.04565192]\n",
      " [ 0.         37.26513956  8.43619096]\n",
      " [ 0.         38.0340322  13.11570799]\n",
      " [ 0.         42.57661019 14.62349006]\n",
      " [ 0.         45.16272473 12.06483748]\n",
      " [ 0.         48.71370469 18.42069732]\n",
      " [ 0.         50.80913182 19.02277925]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #80 | lambda learn rate = 0.001\n",
      "Target = [[2.]\n",
      " [2.]]\n",
      "lambda end of trial = [[ 0.         41.65039861 12.31811313]\n",
      " [ 0.         31.98890618  4.52921213]\n",
      " [ 0.         40.92450287 20.65179587]\n",
      " [ 0.         36.19068961 -0.39061865]\n",
      " [ 0.         29.51152014  0.68257154]\n",
      " [ 0.         31.08301707  6.16469286]\n",
      " [ 0.         35.32494933  7.3718292 ]\n",
      " [ 0.         36.73167365  3.6337864 ]\n",
      " [ 0.         41.04281513 10.74980776]\n",
      " [ 0.         43.11528152 11.32892895]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #81 | lambda learn rate = 0.001\n",
      "Target = [[5.]\n",
      " [4.]]\n",
      "lambda end of trial = [[  0.           6.07552239 -16.14178785]\n",
      " [  0.          -0.5190684  -21.47716753]\n",
      " [  0.           8.92126033  -4.95079816]\n",
      " [  0.           2.4932394  -27.34857881]\n",
      " [  0.          -1.48881477 -24.11769639]\n",
      " [  0.          -1.41367018 -19.83265695]\n",
      " [  0.           0.48511937 -20.50003477]\n",
      " [  0.           6.08559195 -20.88307896]\n",
      " [  0.           6.58841795 -16.81370998]\n",
      " [  0.          11.680842   -13.81862266]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #82 | lambda learn rate = 0.001\n",
      "Target = [[8.]\n",
      " [3.]]\n",
      "lambda end of trial = [[  0.          13.18830788 -13.47449329]\n",
      " [  0.           6.50080167 -18.84471626]\n",
      " [  0.          16.17377658  -2.23110457]\n",
      " [  0.           9.47503099 -24.73040697]\n",
      " [  0.           5.64795462 -21.44140787]\n",
      " [  0.           5.67010063 -17.17624289]\n",
      " [  0.           7.74083044 -17.77914311]\n",
      " [  0.          13.56305451 -18.0790305 ]\n",
      " [  0.          14.04242862 -14.01845598]\n",
      " [  0.          18.63332413 -11.21144186]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #83 | lambda learn rate = 0.001\n",
      "Target = [[7.]\n",
      " [6.]]\n",
      "lambda end of trial = [[  0.          18.62884445  -8.81117624]\n",
      " [  0.          11.93496497 -14.186862  ]\n",
      " [  0.          20.98766148   1.89508249]\n",
      " [  0.          14.62076669 -20.31977637]\n",
      " [  0.          10.64098714 -17.16166571]\n",
      " [  0.          10.24290282 -13.25669816]\n",
      " [  0.          12.6571756  -13.56513298]\n",
      " [  0.          18.25735699 -14.05534266]\n",
      " [  0.          19.02745519  -9.74557606]\n",
      " [  0.          23.05018281  -7.425563  ]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #84 | lambda learn rate = 0.001\n",
      "Target = [[2.]\n",
      " [1.]]\n",
      "lambda end of trial = [[  0.          17.37143358  -9.43988167]\n",
      " [  0.          10.7895819  -14.75955354]\n",
      " [  0.          19.68463421   1.24356885]\n",
      " [  0.          13.4273451  -20.91648717]\n",
      " [  0.           9.42334166 -17.77048845]\n",
      " [  0.           8.90250542 -13.92689686]\n",
      " [  0.          11.43388969 -14.17677593]\n",
      " [  0.          17.03392311 -14.6670596 ]\n",
      " [  0.          17.84158294 -10.33851219]\n",
      " [  0.          21.88073275  -8.01028803]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #85 | lambda learn rate = 0.001\n",
      "Target = [[4.]\n",
      " [1.]]\n",
      "lambda end of trial = [[  0.          11.74597517 -10.84624627]\n",
      " [  0.           4.89394671 -16.23346233]\n",
      " [  0.          13.32447866  -0.34647003]\n",
      " [  0.           7.22949608 -22.46594942]\n",
      " [  0.           3.4735627  -19.25793319]\n",
      " [  0.           2.72055063 -15.47238555]\n",
      " [  0.           5.94526987 -15.54893089]\n",
      " [  0.          11.50609608 -16.04901636]\n",
      " [  0.          12.0698368  -11.78144872]\n",
      " [  0.          15.73506854  -9.54670408]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #86 | lambda learn rate = 0.001\n",
      "Target = [[7.]\n",
      " [0.]]\n",
      "lambda end of trial = [[  0.          -0.58939123 -10.84624627]\n",
      " [  0.          -8.62362996 -16.23346233]\n",
      " [  0.          -0.09575295  -0.34647003]\n",
      " [  0.          -5.80525443 -22.46594942]\n",
      " [  0.          -9.4656137  -19.25793319]\n",
      " [  0.         -10.82666824 -15.47238555]\n",
      " [  0.          -7.03415997 -15.54893089]\n",
      " [  0.          -2.92361955 -16.04901636]\n",
      " [  0.          -1.24178468 -11.78144872]\n",
      " [  0.           3.90479596  -9.54670408]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #87 | lambda learn rate = 0.001\n",
      "Target = [[4.]\n",
      " [0.]]\n",
      "lambda end of trial = [[  0.           1.95703559 -10.84624627]\n",
      " [  0.          -5.86010105 -16.23346233]\n",
      " [  0.           2.68613903  -0.34647003]\n",
      " [  0.          -3.07236641 -22.46594942]\n",
      " [  0.          -6.70006362 -19.25793319]\n",
      " [  0.          -8.23881447 -15.47238555]\n",
      " [  0.          -4.31221578 -15.54893089]\n",
      " [  0.           0.0225042  -16.04901636]\n",
      " [  0.           1.43730921 -11.78144872]\n",
      " [  0.           6.63012474  -9.54670408]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #88 | lambda learn rate = 0.001\n",
      "Target = [[2.]\n",
      " [2.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda end of trial = [[  0.           4.00499972  -8.79828215]\n",
      " [  0.          -3.71434862 -14.08770991]\n",
      " [  0.           4.90978925   1.87718019]\n",
      " [  0.          -1.11211978 -20.5057028 ]\n",
      " [  0.          -4.61645755 -17.17432712]\n",
      " [  0.          -6.04499732 -13.27856841]\n",
      " [  0.          -2.19967845 -13.43639356]\n",
      " [  0.           2.1871398  -13.88438076]\n",
      " [  0.           3.56625541  -9.65250252]\n",
      " [  0.           8.79717897  -7.37964985]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #89 | lambda learn rate = 0.001\n",
      "Target = [[6.]\n",
      " [7.]]\n",
      "lambda end of trial = [[ 0.         20.54647529 10.50010602]\n",
      " [ 0.         12.93190447  5.3329187 ]\n",
      " [ 0.         21.25396397 20.94538403]\n",
      " [ 0.         15.04391054 -1.65700075]\n",
      " [ 0.         11.10678206  1.16945243]\n",
      " [ 0.         10.26575868  5.75064692]\n",
      " [ 0.         13.31109095  4.65950407]\n",
      " [ 0.         18.99915128  5.72963263]\n",
      " [ 0.         17.20696143  6.2616545 ]\n",
      " [ 0.         24.92755328 11.43912018]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #90 | lambda learn rate = 0.001\n",
      "Target = [[3.]\n",
      " [9.]]\n",
      "lambda end of trial = [[  0.           9.92105567 -21.37615284]\n",
      " [  0.           1.78216848 -28.11628928]\n",
      " [  0.           9.78053963 -13.47488901]\n",
      " [  0.           3.54131965 -36.16477343]\n",
      " [  0.          -0.6388658  -34.06749114]\n",
      " [  0.          -0.86432666 -27.63960908]\n",
      " [  0.           2.28010104 -28.43346565]\n",
      " [  0.           7.93001404 -27.47777909]\n",
      " [  0.           6.22028212 -26.69838345]\n",
      " [  0.          14.72343955 -19.17322102]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #91 | lambda learn rate = 0.001\n",
      "Target = [[4.]\n",
      " [1.]]\n",
      "lambda end of trial = [[  0.          10.85464992 -21.14275427]\n",
      " [  0.           2.63033204 -27.90424839]\n",
      " [  0.          10.66479219 -13.25382587]\n",
      " [  0.           4.51525678 -35.92128915]\n",
      " [  0.           0.30653356 -33.83114131]\n",
      " [  0.           0.06210957 -27.40800002]\n",
      " [  0.           3.1099012  -28.22601561]\n",
      " [  0.           8.86754675 -27.24339591]\n",
      " [  0.           7.23325026 -26.44514141]\n",
      " [  0.          15.74296402 -18.9183399 ]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #92 | lambda learn rate = 0.001\n",
      "Target = [[6.]\n",
      " [9.]]\n",
      "lambda end of trial = [[ 0.         49.15505331 36.30785082]\n",
      " [ 0.         44.61103215 35.06680178]\n",
      " [ 0.         49.2193377  44.5779924 ]\n",
      " [ 0.         44.10508832 23.46345818]\n",
      " [ 0.         42.796932   29.90445636]\n",
      " [ 0.         40.19371874 32.78941373]\n",
      " [ 0.         46.82001052 37.33914837]\n",
      " [ 0.         49.3369379  33.46069081]\n",
      " [ 0.         46.66782528 32.70672111]\n",
      " [ 0.         55.73318302 41.0669886 ]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #93 | lambda learn rate = 0.001\n",
      "Target = [[6.]\n",
      " [7.]]\n",
      "lambda end of trial = [[  0.         -46.72085876 -75.54737993]\n",
      " [  0.         -60.57613341 -87.65155803]\n",
      " [  0.         -46.81693372 -67.46432426]\n",
      " [  0.         -54.33542562 -91.38380809]\n",
      " [  0.         -51.56314479 -80.1822999 ]\n",
      " [  0.         -52.87612651 -75.79207239]\n",
      " [  0.         -48.14048284 -73.44809388]\n",
      " [  0.         -44.15750364 -75.61615765]\n",
      " [  0.         -50.47094625 -80.62184567]\n",
      " [  0.         -42.75645508 -73.83758919]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #94 | lambda learn rate = 0.001\n",
      "Target = [[3.]\n",
      " [8.]]\n",
      "lambda end of trial = [[  0.          28.45686562 124.92655176]\n",
      " [  0.          17.96083084 121.78034661]\n",
      " [  0.          33.38553643 146.40892949]\n",
      " [  0.          25.05387655 120.3209977 ]\n",
      " [  0.          31.25637229 140.66974565]\n",
      " [  0.          21.19338484 121.72662454]\n",
      " [  0.          33.68236597 144.7461696 ]\n",
      " [  0.          37.05489787 140.95024636]\n",
      " [  0.          27.49966591 127.29978674]\n",
      " [  0.          30.50344854 121.52215381]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #95 | lambda learn rate = 0.001\n",
      "Target = [[7.]\n",
      " [2.]]\n",
      "lambda end of trial = [[  0.         -78.47210479  94.37541736]\n",
      " [  0.         -86.46178164  91.94531448]\n",
      " [  0.         -72.30871011 116.21057333]\n",
      " [  0.         -78.59444275  90.70719219]\n",
      " [  0.         -82.71673534 108.10600061]\n",
      " [  0.         -82.66666354  92.052325  ]\n",
      " [  0.         -70.67665788 114.92930565]\n",
      " [  0.         -75.66850462 108.74355994]\n",
      " [  0.         -87.94501632  94.31559182]\n",
      " [  0.         -74.82154838  91.42929754]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #96 | lambda learn rate = 0.001\n",
      "Target = [[6.]\n",
      " [3.]]\n",
      "lambda end of trial = [[  0.         -42.81137767 112.20578092]\n",
      " [  0.         -52.56529415 108.89355822]\n",
      " [  0.         -38.77040757 132.9797246 ]\n",
      " [  0.         -47.53610363 106.23636175]\n",
      " [  0.         -46.7080979  126.11031933]\n",
      " [  0.         -48.30697759 109.23216797]\n",
      " [  0.         -39.71246808 130.41140055]\n",
      " [  0.         -40.04930824 126.55315813]\n",
      " [  0.         -54.4799907  111.04810463]\n",
      " [  0.         -42.73202317 107.47406015]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #97 | lambda learn rate = 0.001\n",
      "Target = [[5.]\n",
      " [0.]]\n",
      "lambda end of trial = [[  0.          -6.86799609 112.20578092]\n",
      " [  0.         -17.0586339  108.89355822]\n",
      " [  0.          -3.99573621 132.9797246 ]\n",
      " [  0.         -11.65907587 106.23636175]\n",
      " [  0.         -13.42651381 126.11031933]\n",
      " [  0.         -14.49644385 109.23216797]\n",
      " [  0.          -3.33087613 130.41140055]\n",
      " [  0.          -3.9632548  126.55315813]\n",
      " [  0.         -20.33959101 111.04810463]\n",
      " [  0.          -7.38556409 107.47406015]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n",
      "\n",
      "=========================================\n",
      "Trial #98 | lambda learn rate = 0.001\n",
      "Target = [[8.]\n",
      " [8.]]\n",
      "lambda end of trial = [[   0.         -222.4355318  -103.3617548 ]\n",
      " [   0.         -258.06130645 -132.10911433]\n",
      " [   0.         -251.69093401 -114.7154732 ]\n",
      " [   0.         -227.15619958 -109.26076196]\n",
      " [   0.         -234.63819813  -95.10136498]\n",
      " [   0.         -214.89545604  -91.16684422]\n",
      " [   0.         -228.6101515   -94.86787482]\n",
      " [   0.         -232.14901568 -101.63260275]\n",
      " [   0.         -240.67634092 -109.28864527]\n",
      " [   0.         -242.07071301 -127.21108877]]\n",
      "a = [0. 0.]\n",
      "k = [[0.32641021 0.89074796 0.60919415 0.56451913 0.85413226 0.69855168\n",
      "  0.04208954 0.58391888 0.49987788 0.83344216]\n",
      " [0.13690339 0.79556369 0.8908393  0.11843568 0.88468554 0.7169283\n",
      "  0.5305356  0.88135669 0.25260546 0.0977267 ]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "NUM_TRIALS = 100\n",
    "NUM_RUNS = 2 # Has to be >1 # 2 = goes through the trail for target once\n",
    "NUM_SESSIONS = 5\n",
    "# rate_list = [5e-3, 1e-3, 5e-4, 1e-4]\n",
    "rate_list = [1e-3]\n",
    "A_RATE = 5e-5\n",
    "K_RATE = 5e-5\n",
    "ADAPT_TRIALS = NUM_TRIALS\n",
    "ADAPT_DEC = False\n",
    "KW_only = True\n",
    "\n",
    "# initialization\n",
    "cursor_start = np.zeros( (NUM_DIM, 1, NUM_TRIALS, NUM_SESSIONS) )\n",
    "cursor_end = np.zeros( (NUM_DIM, 1, NUM_TRIALS, NUM_SESSIONS) )\n",
    "target_trial = np.zeros( (NUM_DIM, 1, NUM_TRIALS, NUM_SESSIONS) )\n",
    "lambda_trial = np.zeros( (NUM_NEURONS, NUM_LAMBDA, NUM_TRIALS, NUM_SESSIONS) )\n",
    "fr_trial = np.zeros( (NUM_NEURONS, 1, NUM_TRIALS) )\n",
    "a_trial = np.zeros( (NUM_DIM, NUM_TRIALS, NUM_SESSIONS) )\n",
    "k_trial = np.zeros( (NUM_DIM, NUM_NEURONS, NUM_TRIALS, NUM_SESSIONS) )\n",
    "re_startT = np.zeros( (NUM_TRIALS, NUM_SESSIONS) )\n",
    "re_endT = np.zeros( (NUM_TRIALS, NUM_SESSIONS) )\n",
    "\n",
    "\n",
    "for lambda_rate in rate_list:\n",
    "    for iS in range(NUM_SESSIONS):\n",
    "        print(\"\")\n",
    "        print(\"+++++++++++++++++++++++++++++++++++\")\n",
    "        print(\"Session #\" + str(iS))\n",
    "        ## BRAIN SIDE\n",
    "        FR_DIST = (FR_SIGMA, FR_DELTA, FR_DIST_SIZE)\n",
    "    #     fr_init[:, 0] = np.array(brainFiringRate(lambda_init, TARGET_VECTOR_ERR))\n",
    "\n",
    "        ## DECODER SIDE\n",
    "        A_DIST = (A_SIGMA, A_DELTA, A_DIST_SIZE)\n",
    "        K_DIST = (K_SIGMA, K_DELTA, K_DIST_SIZE)\n",
    "\n",
    "        # target position -- new target represents a new trial\n",
    "        target_trial[:, :, 0, iS] = TARGET_VECTOR\n",
    "        print(\"target at trial 0 = \" + str(target_trial[:, :, 0, iS]))\n",
    "\n",
    "        print(\"K MATX INIT= \" + str(K_MATX))\n",
    "        print(\"A VECT INIT = \" + str(A_VECT))\n",
    "\n",
    "        ## VECTORS FOR TRIALS    \n",
    "        lambda_trial[:, :, 0, iS] = lambda_init\n",
    "        print(\"lambda\")\n",
    "        print(lambda_trial[:, :, 0, iS])\n",
    "\n",
    "        a_trial[:, 0, iS] = np.array(A_VECT)\n",
    "        print(\"a\")\n",
    "        print(a_trial[:, 0, iS])\n",
    "\n",
    "        k_trial[:,:, 0, iS] = K_MATX\n",
    "        print(\"K\")\n",
    "        print(k_trial[:,:, 0, iS] )\n",
    "        decoder_params = (a_trial[:, 0, iS], A_RATE, A_DIST, k_trial[:,:,  0, iS], K_RATE, K_DIST)\n",
    "        decoder_vals = (A_VECT, K_MATX)\n",
    "        \n",
    "\n",
    "        for iT in range(NUM_TRIALS-1):\n",
    "            print(\"\")\n",
    "            print(\"=========================================\")\n",
    "            print(\"Trial #\" + str(iT) + \" | lambda learn rate = \" + str(lambda_rate))\n",
    "            print(\"Target = \" + str(target_trial[:, :, iT, iS]))\n",
    "\n",
    "            # calculate firing rate given lambda and decoder parameters with current target position \n",
    "            fr_start = np.array(brainFiringRate(lambda_trial[:, :, iT, iS], target_trial[:, :, iT, iS]))\n",
    "            fr_trial[:, :, iT] = fr_start\n",
    "#             print(\"fr start of trial\")\n",
    "#             print(fr_start)\n",
    "#             print(\"lambda start of trial\")\n",
    "#             print(lambda_trial[:, :, iT, iS])\n",
    "\n",
    "            # calculate reach error of firing rate at the beginning of the trial\n",
    "            # this becomes the error of the new target position being presented and where the cursor is\n",
    "            brain_vars = ( fr_trial[:, :, iT],  target_trial[:, :, iT, iS] )\n",
    "            cost_func_params = (decoder_vals, brain_vars) \n",
    "            \n",
    "#             print(\"cost func params = \"+ str(cost_func_params))\n",
    "            re_startT[iT, iS] = error_costFunc(cost_func_params)\n",
    "#             print(\"re start = \" + str(re_startT[iT, iS]))\n",
    "\n",
    "    #         (a_vect_in, k_matx_in) = decoder_params\n",
    "            cursor_start[ :, :, iT, iS] =  (decoder_findY(decoder_vals, brain_vars))\n",
    "#             print(\"cursor start = \" + str(cursor_start[:, :, iT, iS]) )\n",
    "\n",
    "            # Run through trial and see the reach at the end        \n",
    "            # current brain and decoder params\n",
    "            brain_params = (fr_trial[:, :, iT], FR_DIST, lambda_trial[:, :, iT, iS], lambda_rate)\n",
    "            decoder_params = (a_trial[:, iT, iS], A_RATE, A_DIST, k_trial[:, :,  iT, iS], K_RATE, K_DIST)\n",
    "\n",
    "            # adapt brain and decoder (together here)\n",
    "            a_run, k_run = calcNextDecoder(decoder_params, brain_vars)\n",
    "            if (KW_only):\n",
    "                a_run = np.zeros((2, 1))\n",
    "            fr_run, lambda_run = calcNextBrain(brain_params, decoder_params, target_trial[:, :, iT, iS], NUM_RUNS)\n",
    "            \n",
    "    #         print(\"fr_run = \" + str(fr_run))\n",
    "#             re_run, fr_run, lambda_run = brain_adapt_sgd(brain_params, decoder_params, target_trial[:, :, iT], NUM_RUNS)\n",
    "            # update cost function arguments\n",
    "            decoder_vals = (a_run, k_run)\n",
    "            brain_vars = (fr_run, target_trial[:, :, iT, iS])\n",
    "            # see how the updated decoder and brain paramters have done with the current\n",
    "            # target position (so target at trial = iT)\n",
    "            cost_func_params = (decoder_vals, brain_vars) \n",
    "            re_run = np.array(error_costFunc(cost_func_params))\n",
    "\n",
    "            # So what are the end trial metrics?\n",
    "            if (KW_only):\n",
    "                lambda_run[:, 0] = 0\n",
    "            cursor_end[:, :, iT, iS] =  (decoder_findY(decoder_vals, brain_vars))\n",
    "#             print(\"fr end of trial = \" + str(fr_run))\n",
    "            print(\"lambda end of trial = \" + str(lambda_run))\n",
    "#             print(\"cursor end = \" + str(cursor_end[:, :, iT, iS]) )\n",
    "\n",
    "            re_endT[iT, iS] = re_run\n",
    "#             print(\"re end = \" + str(re_endT[iT, iS]))\n",
    "#             print(\"re diff = \" + str(re_endT[iT, iS] - re_startT[iT, iS]))\n",
    "\n",
    "            # update the parameters\n",
    "            lambda_trial[:, :, iT + 1, iS] = np.squeeze(lambda_run)\n",
    "            a_trial[:, iT + 1, iS] = np.squeeze(a_run)\n",
    "            k_trial[:, :, iT + 1, iS] = np.squeeze(k_run)\n",
    "            print(\"a = \" + str(a_trial[:, iT + 1, iS]))\n",
    "            print(\"k = \" + str(k_trial[:, :, iT + 1, iS]))\n",
    "\n",
    "            # change to new target\n",
    "            target_trial[:, 0, iT + 1, iS] = findNextTarget( cursor_end[:, :, iT, iS], target_trial[:, :, iT, iS] )\n",
    "    \n",
    "        # display stuff\n",
    "#         print(\"target position:\")\n",
    "#         print(target_trial)\n",
    "#         print(\"cursor end: \")\n",
    "#         print(cursor_end)\n",
    "#         print(\"cursor start: \")\n",
    "#         print(cursor_start)\n",
    "\n",
    "        \n",
    "        pidx = rate_list.index(lambda_rate)\n",
    "        plt.figure(2*pidx + 1, figsize=(fig_x, fig_y))\n",
    "        plt.plot(np.arange(0, NUM_TRIALS-1, 1), re_startT[0:len(re_startT)-1, iS], label = '' + str(iS))\n",
    "        plt.legend()\n",
    "        plt.xlabel('Trials')\n",
    "        plt.ylabel('Reach Error at the Start of Trial')\n",
    "        plt.title('Initial RE across trials, learn rate = ' + str(lambda_rate))\n",
    "        #     plt.show()\n",
    "        \n",
    "#         plt.figure(2*pidx + 2, figsize=(fig_x, fig_y))\n",
    "#         plt.plot(np.arange(NUM_TRIALS-20-1, NUM_TRIALS-1, 1), re_startT[NUM_TRIALS-1-20:NUM_TRIALS-1, iS])\n",
    "#         plt.xlabel('Trials' )#, color='white')\n",
    "#         plt.ylabel('Reach Error at Last 20 Trials')#, color='white')\n",
    "#         plt.title('Ending RE across trials | learn rate = ' + str(lambda_rate) + '| Decoder Adapt = ' + str(ADAPT_DEC)) #, color = 'white')\n",
    "#         #     plt.show()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = 0\n",
    "y = 1\n",
    "\n",
    "plt.figure(figsize = (12, 8))\n",
    "start_x_mean = np.mean(cursor_start, axis=3)[x, 0, 0:NUM_TRIALS-1]\n",
    "end_x_mean = np.mean(cursor_end, axis=3)[x, 0, 0:NUM_TRIALS-1]\n",
    "start_y_mean = np.mean(cursor_start, axis=3)[y, 0, 0:NUM_TRIALS-1]\n",
    "end_y_mean = np.mean(cursor_end, axis=3)[y, 0, 0:NUM_TRIALS-1]\n",
    "targ_x_mean = np.mean(target_trial, axis=3)[x, 0, 0:NUM_TRIALS-1]\n",
    "targ_y_mean = np.mean(target_trial, axis=3)[y, 0, 0:NUM_TRIALS-1]\n",
    "\n",
    "plt.plot(start_x_mean, linestyle = '-', marker = '.', label = 'cursor (start of trial)')\n",
    "plt.plot(targ_x_mean, linestyle = '-', marker = '.', label = 'target' )\n",
    "plt.legend()\n",
    "plt.xlabel('Trials')\n",
    "plt.ylabel('Starting Cursor and Target Position (X)')\n",
    "plt.title('Cursor Position Across Trials')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# plt.figure(figsize = (12, 8))\n",
    "# plt.plot(np.arange(0, NUM_TRIALS, 1), end_x_mean, linestyle = '-', marker = '.', label = 'cursor (end of trial)')\n",
    "# plt.plot(np.arange(0, NUM_TRIALS, 1), targ_x_mean, linestyle = '-', marker = '.', label = 'target' )\n",
    "# plt.legend()\n",
    "# plt.xlabel('Trials')\n",
    "# plt.ylabel('Ending Cursor and Target Position (X)')\n",
    "# plt.title('Cursor Position Across Trials')\n",
    "# plt.show()\n",
    "\n",
    "plt.figure(figsize = (12, 8))\n",
    "plt.plot(start_y_mean, linestyle = '-', marker = '.', label = 'cursor (start of trial)')\n",
    "plt.plot(targ_y_mean, linestyle = '-', marker = '.', label = 'target' )\n",
    "plt.legend()\n",
    "plt.xlabel('Trials')\n",
    "plt.ylabel('Starting Cursor and Target Position (Y)')\n",
    "plt.title('Cursor Position Across Trials')\n",
    "plt.show()\n",
    "\n",
    "# plt.figure(figsize = (12, 8))\n",
    "# plt.plot(np.arange(0, NUM_TRIALS, 1), end_y_mean, linestyle = '-', marker = '.', label = 'cursor (end of trial)')\n",
    "# plt.plot(np.arange(0, NUM_TRIALS, 1), targ_y_mean, linestyle = '-', marker = '.', label = 'target' )\n",
    "# plt.legend()\n",
    "# plt.xlabel('Trials')\n",
    "# plt.ylabel('Ending Cursor and Target Position (Y)')\n",
    "# plt.title('Cursor Position Across Trials')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (12, 8))\n",
    "plt.plot(start_x_mean - targ_x_mean, linestyle = '-', marker = '.', label = 'X error')\n",
    "plt.plot(start_y_mean - targ_y_mean, linestyle = '-', marker = '.', label = 'Y error' )\n",
    "plt.legend()\n",
    "plt.xlabel('Trials')\n",
    "plt.ylabel('Difference in Starting Cursor and Target Position')\n",
    "plt.title('Cursor Error Across Trials')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Mean KW Matrix (1,1)')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# print(np.shape(lambda_trial))\n",
    "# print(np.shape(k_trial))\n",
    "# print(np.shape((k_trial[:, :,1])))\n",
    "# print(np.shape((lambda_trial[:, 1:3, 1])))\n",
    "\n",
    "lk_mtx = np.zeros((NUM_DIM, NUM_DIM, NUM_TRIALS))\n",
    "lk_mtx_temp = np.zeros((NUM_DIM, NUM_DIM, NUM_TRIALS, NUM_SESSIONS))\n",
    "# print(np.shape((k_trial[:,:, :, 1])))\n",
    "# print((lambda_trial[:, 1:3, 1, 1]))\n",
    "for iT in range(NUM_TRIALS):\n",
    "    for iS in range(NUM_SESSIONS):\n",
    "        lk_mtx_temp[:,:, iT, iS] = np.matmul(k_trial[:,:, iT, iS], lambda_trial[:, 1:3, iT, iS])\n",
    "    lk_mtx = np.mean(lk_mtx_temp[:,:, :, :], axis=3)\n",
    "\n",
    " \n",
    "plt.figure(figsize = (12, 8))\n",
    "plt.subplot(221)\n",
    "plt.plot(lk_mtx[0, 0, :])\n",
    "plt.title(\"Mean KW Matrix (0,0)\")\n",
    "\n",
    "plt.subplot(222)\n",
    "plt.plot(lk_mtx[0, 1, :])\n",
    "plt.title(\"Mean KW Matrix (0,1)\")\n",
    "\n",
    "plt.subplot(223)\n",
    "plt.plot(lk_mtx[1, 0, :])\n",
    "plt.title(\"Mean KW Matrix (1,0)\")\n",
    "\n",
    "plt.subplot(224)\n",
    "plt.plot(lk_mtx[1, 1, :])\n",
    "plt.title(\"Mean KW Matrix (1,1)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Mean KW Matrix (1,1) | Last 100 Trials ')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.figure(figsize = (12, 8))\n",
    "plt.subplot(221)\n",
    "plt.plot(lk_mtx[0, 0, NUM_TRIALS-1-100:NUM_TRIALS-1])\n",
    "plt.title(\"Mean KW Matrix (0,0) | Last 100 Trials \")\n",
    "\n",
    "plt.subplot(222)\n",
    "plt.plot(lk_mtx[0, 1,  NUM_TRIALS-1-100:NUM_TRIALS-1])\n",
    "plt.title(\"Mean KW Matrix (0,1) | Last 100 Trials \")\n",
    "\n",
    "plt.subplot(223)\n",
    "plt.plot(lk_mtx[1, 0,  NUM_TRIALS-1-100:NUM_TRIALS-1])\n",
    "plt.title(\"Mean KW Matrix (1,0) | Last 100 Trials \")\n",
    "\n",
    "plt.subplot(224)\n",
    "plt.plot(lk_mtx[1, 1,  NUM_TRIALS-1-100:NUM_TRIALS-1])\n",
    "plt.title(\"Mean KW Matrix (1,1) | Last 100 Trials \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Reach Error Per Session:\n",
      "Session # 0| RE = 83.97750996494906\n",
      "Session # 1| RE = 3516.92053023774\n",
      "Session # 2| RE = 27.64125266050095\n",
      "Session # 3| RE = 2856.306449635987\n",
      "Session # 4| RE = 1511672.0383731013\n"
     ]
    }
   ],
   "source": [
    "print(\"Average Reach Error Per Session:\")\n",
    "\n",
    "for iS in range(NUM_SESSIONS):\n",
    "    print(\"Session # \" + str(iS) + \"| RE = \" + str(np.mean(re_startT[:, iS])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
